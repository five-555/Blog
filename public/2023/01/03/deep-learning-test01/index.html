<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深度学习实践实验-线性回归 | Zdon</title><meta name="author" content="Zdon"><meta name="copyright" content="Zdon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="实验一、线性回归 已知模型y &#x3D; a*x + b 生成带噪声的数据拟合线性函数 绘制图像拟合效果  12345# 导入相关包import torchimport numpy as np%matplotlib inlinefrom matplotlib import pyplot as plt 1234567# 生成y &#x3D; a*x + b的噪声数据200个# 定义a &#x3D; 3， b &#x3D; 2a, b &#x3D;">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习实践实验-线性回归">
<meta property="og:url" content="http://zdon.fun/2023/01/03/deep-learning-test01/">
<meta property="og:site_name" content="Zdon">
<meta property="og:description" content="实验一、线性回归 已知模型y &#x3D; a*x + b 生成带噪声的数据拟合线性函数 绘制图像拟合效果  12345# 导入相关包import torchimport numpy as np%matplotlib inlinefrom matplotlib import pyplot as plt 1234567# 生成y &#x3D; a*x + b的噪声数据200个# 定义a &#x3D; 3， b &#x3D; 2a, b &#x3D;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://zdon.fun/img/default_cover03.jpg">
<meta property="article:published_time" content="2023-01-03T09:19:30.000Z">
<meta property="article:modified_time" content="2024-03-02T12:10:42.603Z">
<meta property="article:author" content="Zdon">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://zdon.fun/img/default_cover03.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://zdon.fun/2023/01/03/deep-learning-test01/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习实践实验-线性回归',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-02 20:10:42'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/default_cover03.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Zdon"><span class="site-name">Zdon</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习实践实验-线性回归</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-01-03T09:19:30.000Z" title="发表于 2023-01-03 17:19:30">2023-01-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/">算法实践</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习实践实验-线性回归"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="实验一、线性回归"><a href="#实验一、线性回归" class="headerlink" title="实验一、线性回归"></a>实验一、线性回归</h1><ul>
<li>已知模型y = a*x + b</li>
<li>生成带噪声的数据拟合线性函数</li>
<li>绘制图像拟合效果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入相关包</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>%matplotlib inline<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 生成y = a*x + b的噪声数据200个</span><br><span class="hljs-comment"># 定义a = 3， b = 2</span><br>a, b = <span class="hljs-number">3</span>, <span class="hljs-number">2</span><br><br>x_datas = torch.linspace(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">200</span>)<br>rand_noise = torch.randn(<span class="hljs-number">200</span>)*<span class="hljs-number">3</span><br>y_lables = a*x_datas + b + rand_noise<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 绘制散点图</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.scatter(x_datas, y_lables)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p>​<br><img src="/2023/01/03/deep-learning-test01/output_3_0.png" class="" title="png"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将数据划分为训练集和测试集，按照180，20进行划分</span><br><span class="hljs-comment"># 每十个数据中，分层抽取出一个数据作为测试集</span><br><br>test_index = [<span class="hljs-number">10</span>*i + np.random.randint(<span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>)]<br>train_index = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>) <span class="hljs-keyword">if</span> i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> test_index]<br><br>X_train1, X_test1, y_train1, y_test1 = x_datas[train_index], x_datas[test_index], y_lables[train_index], y_lables[test_index]<br>y_train1<br></code></pre></td></tr></table></figure>
<pre><code>tensor([ 3.6945,  4.7438,  7.9504,  5.5705,  5.6000,  9.5666,  8.5461,  4.9789,
         0.6976,  5.6866,  4.2295, 10.9321, 11.2976,  7.9842, 12.1275,  8.0943,
        10.5445, 13.4849, 18.5069, 11.6880, 16.8814, 12.7575, 10.7111, 12.1603,
        14.7055, 14.3254, 11.4367, 17.6528, 18.5793, 17.8409, 13.8733, 16.6622,
        18.6143, 14.5482, 16.6509, 17.4552, 20.0250, 20.3924, 20.6348, 18.2929,
        16.6831, 20.4449, 17.3773, 18.3895, 18.2360, 24.1661, 18.2511, 16.6143,
        20.3642, 16.5544, 19.0061, 25.6141, 20.1254, 21.4796, 23.3279, 20.1736,
        25.3058, 26.7936, 24.8702, 23.0888, 24.2360, 26.3334, 26.8100, 22.9726,
        25.0721, 28.1969, 27.3128, 28.3941, 27.2811, 25.5293, 29.3596, 30.8378,
        29.3787, 30.2246, 28.6970, 19.3994, 31.6431, 35.1937, 26.6844, 31.5928,
        32.8604, 31.2751, 26.1607, 26.1867, 27.4753, 28.5589, 32.5150, 35.3546,
        29.3716, 30.2867, 34.1565, 36.8429, 32.5876, 41.2268, 32.7979, 35.0479,
        38.0979, 34.0405, 35.0074, 40.8656, 39.9885, 37.4418, 37.3445, 33.4271,
        40.4349, 41.4754, 36.4292, 41.2385, 41.1300, 39.4304, 39.1217, 40.2641,
        41.4882, 36.4677, 45.3880, 41.7064, 46.0084, 42.7886, 48.2276, 48.9552,
        45.7761, 46.6802, 49.1144, 47.0020, 41.9040, 47.4266, 48.3905, 51.4273,
        46.7154, 49.9467, 45.0021, 50.9472, 55.9469, 49.3655, 44.3413, 47.9426,
        45.9358, 54.3920, 49.9636, 53.2459, 50.3228, 46.5756, 50.2442, 54.3946,
        50.2086, 49.6290, 50.5312, 54.7947, 47.7757, 50.7428, 52.6791, 55.2901,
        55.9978, 57.0760, 50.6741, 53.8824, 58.6424, 53.3195, 57.1432, 54.2989,
        49.9915, 55.4631, 56.1260, 55.4143, 54.0111, 56.7517, 59.6828, 57.2633,
        56.1236, 63.1750, 59.2744, 54.7133, 54.5091, 57.9472, 64.0721, 63.9801,
        61.2980, 61.6411, 62.6100, 59.2035])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将训练集转化为张量，使用梯度下降法进行训练</span><br><span class="hljs-comment"># 迭代次数 10000，学习率：0.001</span><br><br>a = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>loss = []<br>theta = <span class="hljs-number">0.00001</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>+<span class="hljs-number">1</span>):<br>    y_p = a.expand_as(X_train1)*X_train1 + b.expand_as(X_train1)<br>    loss_tmp = torch.mean((y_p - y_train1)**<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">if</span> i%<span class="hljs-number">500</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;迭代&quot;</span> , i , <span class="hljs-string">&quot;次，损失值为：&quot;</span>,loss_tmp.data.numpy())<br>    <br>    loss.append(loss_tmp.data.numpy())<br>    loss_tmp.backward()<br>    a.data = a.data - theta*a.grad.data<br>    b.data = b.data - theta*b.grad.data<br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    <br><span class="hljs-built_in">print</span>(a, b)<br></code></pre></td></tr></table></figure>
<pre><code>迭代 0 次，损失值为： 1019.3526
迭代 500 次，损失值为： 68.77335
迭代 1000 次，损失值为： 12.962891
迭代 1500 次，损失值为： 9.682995
迭代 2000 次，损失值为： 9.4870615
迭代 2500 次，损失值为： 9.47218
迭代 3000 次，损失值为： 9.467946
迭代 3500 次，损失值为： 9.46435
迭代 4000 次，损失值为： 9.460806
迭代 4500 次，损失值为： 9.457279
迭代 5000 次，损失值为： 9.453774
迭代 5500 次，损失值为： 9.450276
迭代 6000 次，损失值为： 9.446788
迭代 6500 次，损失值为： 9.44333
迭代 7000 次，损失值为： 9.439879
迭代 7500 次，损失值为： 9.436436
迭代 8000 次，损失值为： 9.433018
迭代 8500 次，损失值为： 9.429613
迭代 9000 次，损失值为： 9.426218
迭代 9500 次，损失值为： 9.422838
迭代 10000 次，损失值为： 9.419481
tensor([3.1121], requires_grad=True) tensor([0.9682], requires_grad=True)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.scatter(X_test1, y_test1)<br><br>plt.plot(X_test1.data.numpy(), a.data.numpy()*X_test1.data.numpy() + b.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<img src="/2023/01/03/deep-learning-test01/output_6_0.png" class="" title="png">
<ul>
<li>已知模型y = a<em>x^3 + b</em>x^2 + c*x + d</li>
<li>生成带噪声的数据拟合三次函数</li>
<li>绘制图像拟合效果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 生成200个噪声数据</span><br><span class="hljs-comment"># 参数设置，a=0.005, b=0.01, c=0.1, d=1</span><br><br>a, b, c, d = <span class="hljs-number">0.005</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span><br><br>rand = torch.randn(<span class="hljs-number">200</span>)*<span class="hljs-number">1.5</span><br>X_trains = torch.linspace(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, <span class="hljs-number">200</span>)<br>Y_labels = a*(X_trains**<span class="hljs-number">3</span>) + b*(X_trains**<span class="hljs-number">2</span>) + c*X_trains + d + rand<br><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.scatter(X_trains, Y_labels)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p>​<br><img src="/2023/01/03/deep-learning-test01/output_8_0.png" class="" title="png"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 构造数据集和训练集标签</span><br><br>test_index = [<span class="hljs-number">10</span>*i + np.random.randint(<span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>)]<br>train_index = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>) <span class="hljs-keyword">if</span> i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> test_index]<br><br>X_train2, X_test2, y_train2, y_test2 = X_trains[train_index], X_trains[test_index], Y_labels[train_index], Y_labels[test_index]<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 开始训练</span><br>a = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>c = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>d = torch.rand(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>theta = <span class="hljs-number">0.0000001</span><br>times = <span class="hljs-number">50000</span><br>loss = []<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(times+<span class="hljs-number">1</span>):<br>    loss_tmp = torch.mean(((a.expand_as(X_train2) * (X_train2**<span class="hljs-number">3</span>) + <br>                           b.expand_as(X_train2) * (X_train2**<span class="hljs-number">2</span>) + c.expand_as(X_train2) * X_train2 + <br>                           d.expand_as(X_train2) - y_train2))**<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">if</span> i%<span class="hljs-number">2500</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;迭代&quot;</span>, i,<span class="hljs-string">&quot;次，损失值为：&quot;</span>, loss_tmp.data.numpy())<br>    <br>    loss_tmp.backward()<br>    a.data = a.data - a.grad.data * theta<br>    b.data = b.data - b.grad.data * theta<br>    c.data = c.data - c.grad.data * theta<br>    d.data = d.data - d.grad.data * theta<br>    <br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    c.grad.data.zero_()<br>    d.grad.data.zero_()<br>    <br></code></pre></td></tr></table></figure>
<pre><code>迭代 0 次，损失值为： 3153.991
迭代 2500 次，损失值为： 11.566195
迭代 5000 次，损失值为： 5.8502893
迭代 7500 次，损失值为： 3.6634474
迭代 10000 次，损失值为： 2.8267233
迭代 12500 次，损失值为： 2.506517
迭代 15000 次，损失值为： 2.3839154
迭代 17500 次，损失值为： 2.3369095
迭代 20000 次，损失值为： 2.318825
迭代 22500 次，损失值为： 2.3118067
迭代 25000 次，损失值为： 2.3090246
迭代 27500 次，损失值为： 2.307857
迭代 30000 次，损失值为： 2.307303
迭代 32500 次，损失值为： 2.3069975
迭代 35000 次，损失值为： 2.3067696
迭代 37500 次，损失值为： 2.306577
迭代 40000 次，损失值为： 2.3063998
迭代 42500 次，损失值为： 2.3062305
迭代 45000 次，损失值为： 2.3060641
迭代 47500 次，损失值为： 2.3058996
迭代 50000 次，损失值为： 2.3057368
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对测试集进行预测拟合</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.scatter(X_test2, y_test2)<br><br>plt.plot(X_test2.data.numpy(), a.data.numpy()*(X_test2.data.numpy()**<span class="hljs-number">3</span>) + b.data.numpy()*(X_test2.data.numpy()**<span class="hljs-number">2</span>) + c.data.numpy()*X_test2.data.numpy() + d.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p>​<br><img src="/2023/01/03/deep-learning-test01/output_11_0.png" class="" title="png"><br>​    </p>
<h2 id="设计神经网络对前面的数据进行拟合"><a href="#设计神经网络对前面的数据进行拟合" class="headerlink" title="设计神经网络对前面的数据进行拟合"></a>设计神经网络对前面的数据进行拟合</h2><ul>
<li>记录误差，绘制拟合效果</li>
<li>直线拟合数据为：X_train1, y_train1, X_test1, y_test1</li>
<li>曲线拟合数据为：X_train2, y_train2, X_test2, y_test2</li>
</ul>
<h3 id="一、拟合直线"><a href="#一、拟合直线" class="headerlink" title="一、拟合直线"></a>一、拟合直线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用网络拟合直线</span><br><span class="hljs-comment"># 直线拟合只需要一个神经元就能完成拟合</span><br><br><span class="hljs-comment"># 定义网络</span><br>net = torch.nn.Sequential(<br>    torch.nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),<br>)<br><span class="hljs-comment"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br><span class="hljs-comment"># 梯度下降方法，随机梯度下降</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.0001</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练数据</span><br>losses = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    pred = net(X_train1.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>    loss = loss_fn(pred, y_train1.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">if</span> i%<span class="hljs-number">200</span>==<span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;loss:&#x27;</span>, loss.data)<br>        losses.append(loss.data)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br>    <br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.plot(X_train1.data.numpy(), y_train1.data.numpy(), <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(X_train1.data.numpy(), net(X_train1.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>
<pre><code>loss: tensor(999.4984)
loss: tensor(10.4790)
loss: tensor(10.4377)
loss: tensor(10.4070)
loss: tensor(10.3768)
</code></pre><img src="/2023/01/03/deep-learning-test01/output_15_1.png" class="" title="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对测试集进行预测验证</span><br>pred = net(X_test1.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.plot(X_test1.data.numpy(), y_test1.data.numpy(), <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(X_test1.data.numpy(), pred.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>
<p>​<br><img src="/2023/01/03/deep-learning-test01/output_16_0.png" class="" title="png"><br>​    </p>
<h3 id="二、拟合多项式函数"><a href="#二、拟合多项式函数" class="headerlink" title="二、拟合多项式函数"></a>二、拟合多项式函数</h3><ul>
<li>单层神经网络只能够拟合直线</li>
<li>对多项式函数的拟合需要多层神经网络，且需要激活函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义model类</span><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-comment"># 继承nn.Module</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 第一个隐藏层</span><br>        self.hidden1=nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)<br>        <span class="hljs-comment"># 第二个隐藏层</span><br>        self.hidden2=nn.Linear(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>)<br>        <span class="hljs-comment"># 第三个隐藏层</span><br>        self.hidden3=nn.Linear(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>)<br>        <span class="hljs-comment"># 输出层</span><br>        self.out=nn.Linear(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 定义网络前向运算</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden2(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden3(x)<br>        x = F.sigmoid(x)<br>        x = self.out(x)<br>        <span class="hljs-keyword">return</span> x<br>    <br>net = model()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure>
<pre><code>model(
  (hidden1): Linear(in_features=1, out_features=4, bias=True)
  (hidden2): Linear(in_features=4, out_features=4, bias=True)
  (hidden3): Linear(in_features=4, out_features=4, bias=True)
  (out): Linear(in_features=4, out_features=1, bias=True)
)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练数据</span><br>losses2 = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">50000</span>):<br>    pred = net(X_train2.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>    loss = loss_fn(pred, y_train2.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">if</span> i%<span class="hljs-number">2500</span>==<span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;loss:&#x27;</span>, loss.data)<br>        losses2.append(loss)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br><br><span class="hljs-comment"># 绘制图像</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.plot(X_train2.data.numpy(), y_train2.data.numpy(), <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(X_train2.data.numpy(), net(X_train2.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>
<pre><code>loss: tensor(357.9143)


D:\02_soft\anaconda3\envs\pytorch\lib\site-packages\torch\nn\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)


loss: tensor(146.0952)
loss: tensor(23.4380)
loss: tensor(16.6693)
loss: tensor(12.3312)
loss: tensor(10.4051)
loss: tensor(8.9617)
loss: tensor(7.7465)
loss: tensor(6.7640)
loss: tensor(5.9918)
loss: tensor(5.4033)
loss: tensor(4.9512)
loss: tensor(4.5902)
loss: tensor(4.2906)
loss: tensor(4.0353)
loss: tensor(3.8134)
loss: tensor(3.6182)
loss: tensor(3.4456)
loss: tensor(3.2944)
loss: tensor(3.1646)
</code></pre><img src="/2023/01/03/deep-learning-test01/output_20_3.png" class="" title="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用训练的模型对测试集进行预测</span><br>pred2 = net(X_test2.view(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br>plt.plot(X_test2.data.numpy(), y_test2.data.numpy(), <span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot(X_test2.data.numpy(), pred2.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>
<img src="/2023/01/03/deep-learning-test01/output_21_0.png" class="" title="png">
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://zdon.fun">Zdon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://zdon.fun/2023/01/03/deep-learning-test01/">http://zdon.fun/2023/01/03/deep-learning-test01/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://zdon.fun" target="_blank">Zdon</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="/img/default_cover03.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/04/deep-learning-test02/" title="深度学习实践实验-共享单车预测"><img class="cover" src="/img/default_cover04.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习实践实验-共享单车预测</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/19/digital-image-test04/" title="数字图像处理实验-图像去噪"><img class="cover" src="/img/default_cover05.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">数字图像处理实验-图像去噪</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/18/AI-lab03/" title="人工智能实验-基于LSTM+CTC的验证码"><img class="cover" src="/img/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-18</div><div class="title">人工智能实验-基于LSTM+CTC的验证码</div></div></a></div><div><a href="/2023/02/12/AI-lab02/" title="人工智能实验-花卉图像分类实验"><img class="cover" src="/img/default_cover09.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-12</div><div class="title">人工智能实验-花卉图像分类实验</div></div></a></div><div><a href="/2023/02/02/AI-lab01/" title="人工智能实验-基于tensorflow的猫狗分类"><img class="cover" src="/img/default_cover01.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-02</div><div class="title">人工智能实验-基于tensorflow的猫狗分类</div></div></a></div><div><a href="/2023/01/21/deep-learning-test05/" title="深度学习实践实验-LSTM与迁移学习"><img class="cover" src="/img/default_cover01.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-21</div><div class="title">深度学习实践实验-LSTM与迁移学习</div></div></a></div><div><a href="/2023/01/15/deep-learning-test04/" title="深度学习实践实验-卷积神经网络"><img class="cover" src="/img/default_cover03.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-15</div><div class="title">深度学习实践实验-卷积神经网络</div></div></a></div><div><a href="/2023/01/08/deep-learning-test03/" title="深度学习实践实验-SoftMax回归"><img class="cover" src="/img/default_cover05.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-08</div><div class="title">深度学习实践实验-SoftMax回归</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Zdon</div><div class="author-info__description">我来自偶然，像一颗尘土。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://gitee.com/wzd520"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://gitee.com/wzd520" target="_blank" title="Gitee"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:wuzdon@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%80%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.</span> <span class="toc-text">实验一、线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E5%89%8D%E9%9D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%8B%9F%E5%90%88"><span class="toc-number">1.1.</span> <span class="toc-text">设计神经网络对前面的数据进行拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%8B%9F%E5%90%88%E7%9B%B4%E7%BA%BF"><span class="toc-number">1.1.1.</span> <span class="toc-text">一、拟合直线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%8B%9F%E5%90%88%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.2.</span> <span class="toc-text">二、拟合多项式函数</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/12/c-stl-use/" title="C++中常见容器的使用方法"><img src="/img/default_cover09.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++中常见容器的使用方法"/></a><div class="content"><a class="title" href="/2024/07/12/c-stl-use/" title="C++中常见容器的使用方法">C++中常见容器的使用方法</a><time datetime="2024-07-12T01:52:08.000Z" title="发表于 2024-07-12 09:52:08">2024-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/11/gdb-debug/" title="如何使用GDB进行调试"><img src="/img/default_cover07.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何使用GDB进行调试"/></a><div class="content"><a class="title" href="/2024/07/11/gdb-debug/" title="如何使用GDB进行调试">如何使用GDB进行调试</a><time datetime="2024-07-11T07:12:23.000Z" title="发表于 2024-07-11 15:12:23">2024-07-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/10/go-mutil-routine/" title="Go语言学习-协程、管道、并发"><img src="/img/default_cover02.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go语言学习-协程、管道、并发"/></a><div class="content"><a class="title" href="/2024/07/10/go-mutil-routine/" title="Go语言学习-协程、管道、并发">Go语言学习-协程、管道、并发</a><time datetime="2024-07-10T14:10:44.000Z" title="发表于 2024-07-10 22:10:44">2024-07-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/10/go-base/" title="Go语言学习-基本语法"><img src="/img/default_cover05.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go语言学习-基本语法"/></a><div class="content"><a class="title" href="/2024/07/10/go-base/" title="Go语言学习-基本语法">Go语言学习-基本语法</a><time datetime="2024-07-10T09:16:50.000Z" title="发表于 2024-07-10 17:16:50">2024-07-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/09/go-function/" title="Go语言学习-函数、方法、接口"><img src="/img/default_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go语言学习-函数、方法、接口"/></a><div class="content"><a class="title" href="/2024/07/09/go-function/" title="Go语言学习-函数、方法、接口">Go语言学习-函数、方法、接口</a><time datetime="2024-07-09T08:41:53.000Z" title="发表于 2024-07-09 16:41:53">2024-07-09</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/default_cover03.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Zdon</div><div class="footer_custom_text">没有人是一座孤岛</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'QABC9cDUiFvfbJkVsG3I0mp1-gzGzoHsz',
      appKey: '7s6lJmCCK7Bczu8Z93wTmEWb',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !true) {
    if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="false"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div></body></html>