{"meta":{"version":1,"warehouse":"5.0.0"},"models":{"Asset":[{"_id":"themes/butterfly/source/css/index.styl","path":"css/index.styl","modified":0,"renderable":1},{"_id":"themes/butterfly/source/css/var.styl","path":"css/var.styl","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/404.jpg","path":"img/404.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover.jpg","path":"img/default_cover.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover01.jpg","path":"img/default_cover01.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover02.jpg","path":"img/default_cover02.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover03.jpg","path":"img/default_cover03.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover04.jpg","path":"img/default_cover04.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover05.jpg","path":"img/default_cover05.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover06.jpg","path":"img/default_cover06.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover07.jpg","path":"img/default_cover07.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover08.jpg","path":"img/default_cover08.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover09.jpg","path":"img/default_cover09.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover10.jpg","path":"img/default_cover10.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/default_cover11.jpg","path":"img/default_cover11.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/favicon1.png","path":"img/favicon1.png","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/top.jpg","path":"img/top.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/top1.jpg","path":"img/top1.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/_drafts/the-go-programming-language.md","hash":"8f2004b50c85098ea8f34b983afb10182a15ede1","modified":1717578183317},{"_id":"source/_drafts/design-mode-principle.md","hash":"4d64b3a964430f0cc8c30bd49b962ed4321ae43d","modified":1717578183315},{"_id":"source/_drafts/大话设计模式.md","hash":"d7aaf9d351b707cd38c3198eb216a17ff32efd9e","modified":1717578183319},{"_id":"source/_drafts/Go语言学习笔记.md","hash":"c3b5d5ea4957dda1210ce82e0bee1e7a3b5c68cb","modified":1717578183314},{"_id":"source/tags/index.md","hash":"cfd3eddf84f4f3878ac150aaef576ccbcbfbb421","modified":1717578183829},{"_id":"source/_drafts/leetcode-0209.md","hash":"b6f9c3e844acdfa2293497d8350d59d42a1879f9","modified":1717578183316},{"_id":"source/_posts/AI-lab01.md","hash":"f3547592c5cdcc23fad5d6666f326b53555c8a12","modified":1717578183478},{"_id":"source/_posts/AI-lab03.md","hash":"d83e762b4e65d1649e14285742343fcab2b43342","modified":1717578183511},{"_id":"source/_posts/AI-lab02.md","hash":"bd348d3f72d705ca22e5a82f64b91ac0149e3ee3","modified":1717578183500},{"_id":"source/_posts/15445-study-notes-01-04.md","hash":"bacaa1e2b164b42b6d3df40a83791690d34fd5ec","modified":1717578183465},{"_id":"source/_posts/C-使用zlib库来压缩文件.md","hash":"7c8f80d753e141e778d0c0873b9480dbe2207c91","modified":1717578183518},{"_id":"source/_posts/Effective-Modern-C-notes.md","hash":"f85ca80381c8140f5220eb5c15430e47ec1de96f","modified":1717578183518},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01.md","hash":"195622068d256a9edba8c881f5f825670932a7b6","modified":1717578183520},{"_id":"source/_posts/Physical-design.md","hash":"6b6e70aa03195229dc70548ebdfe0e5947bac350","modified":1717578183582},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02.md","hash":"d8361df5acfeb0cc09a94a590c131c738a747429","modified":1717578183548},{"_id":"source/_posts/a-star-assignment.md","hash":"69a2113cae9157b4d15b9bbabdbd553ac95dce89","modified":1717578183627},{"_id":"source/_posts/VLSI-Physical-Design.md","hash":"607421ba4e2d0b0533a1ad8cb96e449bb698e234","modified":1717578183624},{"_id":"source/_posts/c-primer-plus.md","hash":"c93aa660f9cc928cae54921d0e0153f8a3c54531","modified":1717578183633},{"_id":"source/_posts/build-sample-redis.md","hash":"e8a3fe6759604f679a47ea4ad06303a78cd7b930","modified":1719308744904},{"_id":"source/_posts/c-priority-queue.md","hash":"5198a97a25b90c7fa1da7e360f25552ba02ca75d","modified":1717578183633},{"_id":"source/_posts/cmake-study.md","hash":"326b22c293930da2e7c23e77237b31834fc11345","modified":1717578183633},{"_id":"source/_posts/deep-learning-test01.md","hash":"6cfaee14506cf76c1a9cbf6c64ace6fd3a3f28a9","modified":1717578183689},{"_id":"source/_posts/database-mysql.md","hash":"29cd466cf4d260e7b5cfee43a50c0f65aa3d15fc","modified":1717578183634},{"_id":"source/_posts/deep-learning-test03.md","hash":"545deb6063939ccb1262c1d403b8c827319e365a","modified":1717578183695},{"_id":"source/_posts/deep-learning-test02.md","hash":"73251f14006fb38e80dad86f69e9fb70b28293ad","modified":1717578183693},{"_id":"source/_posts/deep-learning-test04.md","hash":"018822fd1056b03b11c591b458e05baf9ab4f04c","modified":1717578183697},{"_id":"source/_posts/digital-image-test02.md","hash":"c9890a3fc863da8a8b8b15dea910c37f832c23ba","modified":1717578183705},{"_id":"source/_posts/deep-learning-test05.md","hash":"04818a10d718664ff2e9e172910713999ea9fcf4","modified":1717578183697},{"_id":"source/_posts/design-model.md","hash":"d674b112141d3cbfa9bc839ad3cfa55a66a7b7ce","modified":1720000953800},{"_id":"source/_posts/digital-image-test03.md","hash":"69dbec752936c9689ed31696f9fc8018ad144481","modified":1717578183713},{"_id":"source/_posts/digital-image-test01.md","hash":"6377ad1bb69a30bc814712ee109d4cb1ee9347c9","modified":1717578183699},{"_id":"source/_posts/distributed-system.md","hash":"1be889605e40478a9f07dccb4449c536f5f185ee","modified":1717578183748},{"_id":"source/_posts/digital-image-test04.md","hash":"120c0bc8fe23c6e59ea35e1e4bc390031af1cd4a","modified":1717578183731},{"_id":"source/_posts/go-function.md","hash":"5c1ea619b5857a2cb7935dbf73af06656e3aa7c3","modified":1720596295828},{"_id":"source/_posts/eda-summary.md","hash":"846c47ae36d78761e87fe3e8fb6877007183bdda","modified":1717578183775},{"_id":"source/_posts/gcc-parameters.md","hash":"48a928d63811b1a96cdb650eae2dbe1da836e2e8","modified":1717578183788},{"_id":"source/_posts/iEDA-test.md","hash":"7b230283875dade16f359815bb9466d05da66f48","modified":1717578183793},{"_id":"source/_posts/pytorch-install.md","hash":"920e1932d56036fae1e63701799c4fdea32e2f5e","modified":1717578183804},{"_id":"source/_posts/git.md","hash":"b071f49c28d68ca691cc318ac3a8bed30a4218d3","modified":1717578183788},{"_id":"source/_posts/pytorch-use.md","hash":"f9ff3fc9abfc694a3b9af937dcae7e412c0781e5","modified":1717578183809},{"_id":"source/_posts/sort-algrithon.md","hash":"bbd6503081a40111e681b8ce2e7a9db98fff276d","modified":1717578183809},{"_id":"source/_posts/平方根倒数算法.md","hash":"a9720f0c55868fe068f91797560ef145c80ec09b","modified":1717578183816},{"_id":"source/_posts/static-timing-analysis.md","hash":"370507ebdc2dabb8fae06bdf6954d880d9b208f1","modified":1717578183809},{"_id":"source/_posts/thread-pool.md","hash":"45469cdfa96b9fede9dbf37ac9b3570d03cbadb0","modified":1717578183813},{"_id":"source/categories/index.md","hash":"ec5aeaff4eefefc9ade6b411ecb33bedb0c65a2d","modified":1717578183828},{"_id":"source/_posts/进程间的通信方式.md","hash":"3c59a2c6a80f4df0e758963a950eaacdfab77a8b","modified":1717578183818},{"_id":"source/_posts/15445-study-notes-01-04/image-20240110074224104.png","hash":"ff87dfb43af777dc2dffe53f12d614189c0012ec","modified":1717578183474},{"_id":"source/_posts/AI-lab01/image-20230109194724331.png","hash":"de08743103c9cec6a2365f52c4fd5c622a186218","modified":1717578183480},{"_id":"source/_posts/AI-lab01/image-20230109205407961.png","hash":"05c92b8d240dd575bf4c2170efc7ca63e33fb852","modified":1717578183489},{"_id":"source/_posts/AI-lab01/image-20230109222224342.png","hash":"ee876ce2faae0d4c39aba3d724dfd41ec12a86b4","modified":1717578183500},{"_id":"source/_posts/AI-lab02/image-20230108230000075.png","hash":"db6e0d5250387cb053b814d857a90b5ad06bccc5","modified":1717578183506},{"_id":"source/_posts/AI-lab02/image-20230108232154796.png","hash":"fa0721b26fefc9055699a9a240c7d167fc07966a","modified":1717578183511},{"_id":"source/_posts/AI-lab03/image-20230111212922711.png","hash":"6758bfe386595a662ad738d94bba95a87f07dacb","modified":1717578183511},{"_id":"source/_posts/AI-lab03/image-20230111213029737.png","hash":"57a25a65b36662d680e0bcac13a5ff69141e8904","modified":1717578183511},{"_id":"source/_posts/AI-lab03/image-20230111221801614.png","hash":"8b25554cc48d203f1ab131b513a3f70e53bea245","modified":1717578183516},{"_id":"source/_posts/AI-lab03/image-20230111221612234.png","hash":"132fdfe29312f1b3306ab9a39fd3567306914cad","modified":1717578183516},{"_id":"source/_posts/AI-lab03/image-20230111221947792.png","hash":"d88631f8d8f83be69257bf1f9be4b360ae9840bd","modified":1717578183517},{"_id":"source/_posts/AI-lab03/image-20230111221914620.png","hash":"9f611e12340ed140b7218ec376c9b69f124ebbce","modified":1717578183517},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104165645532-17084112899535.png","hash":"713d7afbd431798d5715bec456b9f2de1b61bf93","modified":1717578183545},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116154858801-17084112899536.png","hash":"beccf9c890c54d964fb72d81cab34ea965672e03","modified":1717578183547},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104165645532.png","hash":"713d7afbd431798d5715bec456b9f2de1b61bf93","modified":1717578183546},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116154858801.png","hash":"beccf9c890c54d964fb72d81cab34ea965672e03","modified":1717578183547},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116155210293.png","hash":"68a2653c7b86805026326fd91fd2987475c74ea3","modified":1717578183548},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116155210293-17084112899537.png","hash":"68a2653c7b86805026326fd91fd2987475c74ea3","modified":1717578183547},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116165833300-17084118809565.png","hash":"1df24f5f6956685a0e7de541460502be6186593a","modified":1717578183568},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116165833300.png","hash":"1df24f5f6956685a0e7de541460502be6186593a","modified":1717578183568},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171040632.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1717578183571},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171041924-17084118809567.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1717578183571},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171041924.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1717578183573},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142833380-170841188095612.png","hash":"d43526ac594854d0fec88480beddf17b456bac52","modified":1717578183581},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142833380.png","hash":"d43526ac594854d0fec88480beddf17b456bac52","modified":1717578183581},{"_id":"source/_posts/a-star-assignment/1.jpg","hash":"e5a312ef814273e207c2ad1fa64eb28fee4db905","modified":1717578183627},{"_id":"source/_posts/a-star-assignment/image-20230803171605818.png","hash":"9c7f08e1cb2f20a60e8e1f984d63c7278d261f2e","modified":1717578183629},{"_id":"source/_posts/a-star-assignment/image-20230803172210807.png","hash":"90cb9863c4fb5d4b396cf3650a8f82a29f0bf9c6","modified":1717578183629},{"_id":"source/_posts/a-star-assignment/image-20230803171645811.png","hash":"71a6e8198ff01241f81e886811355e51e92bd412","modified":1717578183629},{"_id":"source/_posts/a-star-assignment/image-20230803173244879.png","hash":"82084ca1b9e5146c8325fdc596d9e24d1f09d708","modified":1717578183630},{"_id":"source/_posts/a-star-assignment/image-20230803173141837.png","hash":"3dd68c5fff946186a679d5cdc88157743adb724c","modified":1717578183630},{"_id":"source/_posts/a-star-assignment/image-20230803173053255.png","hash":"f706f73cb488dacdbc7d6fb8e679da6ec7c987b3","modified":1717578183629},{"_id":"source/_posts/a-star-assignment/image-20230803173329009.png","hash":"d6cb3a8c2c4c7d18bb9053377199c187b73d8c19","modified":1717578183631},{"_id":"source/_posts/a-star-assignment/image-20230803173212434.png","hash":"7502e50c7f04f80f23ed44383a35744e104c8242","modified":1717578183630},{"_id":"source/_posts/a-star-assignment/image-20230803173808529.png","hash":"98a11b085814996f5289a833456875edd25f6bbd","modified":1717578183631},{"_id":"source/_posts/a-star-assignment/image-20230803173754572.png","hash":"120e2d3db10bf256e965d41194e32cf01f96d759","modified":1717578183631},{"_id":"source/_posts/a-star-assignment/image-20230803183939400.png","hash":"b5eb9982fe89c5dfb232b31a23ba31aeafd023d7","modified":1717578183632},{"_id":"source/_posts/a-star-assignment/image-20230803183655944.png","hash":"4695c1253ee703d882d422531bc08789ae08eb8a","modified":1717578183631},{"_id":"source/_posts/a-star-assignment/问题：插入优先队列以后没有更新f值.png","hash":"88c67cc5972ca585cd17d75589281cffd81b9b63","modified":1717578183632},{"_id":"source/_posts/database-mysql/image-20240218204502697.png","hash":"16d59bdcc21b422a885e7da177c5458e43b38f16","modified":1717578183651},{"_id":"source/_posts/database-mysql/image-20240218211138993.png","hash":"a7bf2310f5850960d3a45b2f4479af922ef0f18d","modified":1717578183652},{"_id":"source/_posts/database-mysql/image-20240222075706155.png","hash":"b8ef4f1a6aa4db264aaa2a640f65bb6354fe0f15","modified":1717578183679},{"_id":"source/_posts/deep-learning-test01/output_11_0.png","hash":"005a447a4d83c2cf4fb66a9841c49d25314c380c","modified":1717578183689},{"_id":"source/_posts/database-mysql/innodb-architecture-8-0.png","hash":"994699ac624cd3cf72cff8d7330953c27af67bc1","modified":1717578183689},{"_id":"source/_posts/deep-learning-test01/output_15_1.png","hash":"0fa1d12e8c9332228c13b5d0d04c574c74f992e5","modified":1717578183691},{"_id":"source/_posts/deep-learning-test01/output_16_0.png","hash":"db30f56c26578f3b6cc68b82c7daf2f6acae7859","modified":1717578183691},{"_id":"source/_posts/deep-learning-test01/output_20_3.png","hash":"f22af73919d8a54df32e95d63cd710ba9f945c63","modified":1717578183691},{"_id":"source/_posts/deep-learning-test01/output_21_0.png","hash":"2f748b1d2882a25546794868a450532a5e09f7be","modified":1717578183691},{"_id":"source/_posts/deep-learning-test01/output_3_0.png","hash":"fe2d4182f533e158c4eb9aafad60712a5fce509a","modified":1717578183692},{"_id":"source/_posts/deep-learning-test01/output_6_0.png","hash":"b54b94fac0446dc20a309ef559a1a98204c1fb7c","modified":1717578183692},{"_id":"source/_posts/deep-learning-test01/output_8_0.png","hash":"de244bd271c5de5f1ad83132eae74d397de98733","modified":1717578183693},{"_id":"source/_posts/deep-learning-test02/output_7_1.png","hash":"c0459b50d809a7be2f9bfb62d476e96c527c0fec","modified":1717578183694},{"_id":"source/_posts/deep-learning-test03/output_9_1.png","hash":"9f49c03f3e12d5640bb68156cbf498088a5d522c","modified":1717578183696},{"_id":"source/_posts/deep-learning-test04/output_5_1.png","hash":"e833f87fcbfb72c08ec23225353abf943f23d28b","modified":1717578183697},{"_id":"source/_posts/deep-learning-test04/output_4_3.png","hash":"ea660388e6b31a820d3b1249a52f627538d1aee9","modified":1717578183697},{"_id":"source/_posts/deep-learning-test05/output_5_1.png","hash":"7e1c3674d08ec1d7e1a6599148fa737b70a6279b","modified":1717578183699},{"_id":"source/_posts/design-model/享元模式_01.png","hash":"51fdf3d666d8ee67aa17b8fcb0ab7727727361a6","modified":1719903178027},{"_id":"source/_posts/design-model/单例模式_01.png","hash":"0d1fd59cae8648fb7fc0426f227ee1ba79e2cda0","modified":1719901131292},{"_id":"source/_posts/design-model/装饰器模式_01.png","hash":"6ad8d211df694d765048bbd99216584a94003134","modified":1719901285453},{"_id":"source/_posts/digital-image-test01/image-20240302183514481.png","hash":"ed67b77864295c9228c3e4aec87afc4a5ba26933","modified":1717578183702},{"_id":"source/_posts/digital-image-test02/clip_image002.jpg","hash":"4d2b642a3936f19f390dc75fa7db783f87f81ba5","modified":1717578183705},{"_id":"source/_posts/digital-image-test02/clip_image004.jpg","hash":"4f2dd7ec35b589d894f2c520597bf5e9ef536fa9","modified":1717578183707},{"_id":"source/_posts/digital-image-test02/clip_image006.jpg","hash":"e09a8a5c1b2d326160ffd8fa9f60d018bad23d9a","modified":1717578183708},{"_id":"source/_posts/digital-image-test02/clip_image008.jpg","hash":"16d789a1c5c452a0b6ca951f46fd604ea4606c5e","modified":1717578183708},{"_id":"source/_posts/digital-image-test04/clip_image002.jpg","hash":"ce0b1361e63f247e3a3d85c0035fcc47146c5037","modified":1717578183732},{"_id":"source/_posts/digital-image-test04/clip_image004.jpg","hash":"c7141a99d0271d358bb75fbb8741af9035884269","modified":1717578183735},{"_id":"source/_posts/distributed-system/image-20221130092344725.png","hash":"36eb80cb202a3a754ef4612e2158ab5d7d546f5d","modified":1717578183752},{"_id":"source/_posts/distributed-system/image-20221201100317779.png","hash":"907fc393e7b3ab9117adbaaa5ade3921899b0914","modified":1717578183759},{"_id":"source/_posts/distributed-system/image-20221201101403269.png","hash":"5b3affe183507f68a7a2c2569953e3971e65f9b0","modified":1717578183759},{"_id":"source/_posts/distributed-system/image-20221201152139305.png","hash":"7ab682cf8830c07f54a74874e252640b4afc7e18","modified":1717578183764},{"_id":"source/_posts/eda-summary/image-20230818160028154.png","hash":"17d0ca9f8f8b1df113d03f0a62b73d7739354bff","modified":1717578183782},{"_id":"source/_posts/eda-summary/image-20230828141138808.png","hash":"67b75defcfb622cbf689297fb0a5358d5280e667","modified":1717578183786},{"_id":"source/_posts/git/image-20231204112945547.png","hash":"eff5ebfc4a4c5539cfd8dfd9c4b5dfed83f0fe11","modified":1717578183792},{"_id":"source/_posts/git/image-20231204113304822.png","hash":"8c059b88dc8eac379a01ff2b842f59bc9c7dfcc7","modified":1717578183793},{"_id":"source/_posts/git/image-20231204113208566.png","hash":"be5c376a4091dc37070325f85951ccb5cd214e74","modified":1717578183792},{"_id":"source/_posts/iEDA-test/image-20230823094215828.png","hash":"bc275d04d9d87c210227f5c85bd1c62b4199c2ad","modified":1717578183793},{"_id":"source/_posts/iEDA-test/image-20230830164051317.png","hash":"f742d4d59f322dc38e0ef2037a099a90583af9a1","modified":1717578183804},{"_id":"source/_posts/pytorch-install/image-20221022163847897.png","hash":"cb93468290fe61cadf8f42a4073093719b8cce4a","modified":1717578183805},{"_id":"source/_posts/pytorch-install/image-20221022164808915.png","hash":"bcbdd8f68e81b289cefc616d1ffdd12541daf94f","modified":1717578183806},{"_id":"source/_posts/pytorch-install/image-20221022165103111.png","hash":"d50f9960ad59e993547e4b4ba01fa5ff7dd3a476","modified":1717578183807},{"_id":"source/_posts/static-timing-analysis/image-20230811144505780.png","hash":"2776435c62fa5ab2fe49673976ac93568435ef93","modified":1717578183810},{"_id":"source/_posts/thread-pool/image-20240303211229196.png","hash":"b9873430670ca696c34479e70c246159f14737ee","modified":1717578183814},{"_id":"source/_posts/thread-pool/image-20240303195554869.png","hash":"0d482d1d7d7a945503be97e4db85ea48da11d336","modified":1717578183813},{"_id":"source/_posts/thread-pool/image-20240303200213188.png","hash":"871b2c542bcdc97e75ad9a07f3292cc3a9f64871","modified":1717578183814},{"_id":"source/_posts/thread-pool/image-20240303224717307.png","hash":"e53ec25c7b4d7667a587f22a7921a3cfa3e1a9f5","modified":1717578183816},{"_id":"source/_posts/thread-pool/image-20240303224732958.png","hash":"1f3d5b2670846843298a7955e599ad16ff70c95e","modified":1717578183816},{"_id":"source/_posts/平方根倒数算法/运算过程.png","hash":"452225103f084e7ffb3be1aa9d5609cc1e505016","modified":1717578183817},{"_id":"source/_posts/15445-study-notes-01-04/image-20240110074349028.png","hash":"750177e6ff0eaeedb2eee94ef776719946db6675","modified":1717578183475},{"_id":"source/_posts/AI-lab01/image-20230109195428838.png","hash":"56c9ed863359439eaec39b12422bdf3af8abaf3c","modified":1717578183486},{"_id":"source/_posts/AI-lab01/image-20230109195525256.png","hash":"ae8fb8d6bea32dca2b1110e6f4220ceb9be7b4f3","modified":1717578183487},{"_id":"source/_posts/AI-lab01/image-20230109205151944.png","hash":"e74cd3670406715575f05596d36be5da665e688d","modified":1717578183489},{"_id":"source/_posts/AI-lab01/image-20230109214257445.png","hash":"cf1d5cf393bd050b32841213dff96872d7c89376","modified":1717578183499},{"_id":"source/_posts/AI-lab02/image-20230108232106204.png","hash":"91dfef5746aafbd3422b483d998a0d3aee839bfd","modified":1717578183510},{"_id":"source/_posts/AI-lab03/image-20230111213218547.png","hash":"4a85d2793b3aca9cd27ebbb9436bbb705d3c0b5f","modified":1717578183512},{"_id":"source/_posts/AI-lab03/image-20230111215240888.png","hash":"bc5329ac982db92a7050b850013fc68543c6309f","modified":1717578183514},{"_id":"source/_posts/AI-lab03/image-20230111213428993.png","hash":"d651403b46774fb0aaa19016b491840c34f1cb5c","modified":1717578183513},{"_id":"source/_posts/AI-lab03/image-20230111221331595.png","hash":"b2eb279a3987817b3ba614c854351c501043a7eb","modified":1717578183515},{"_id":"source/_posts/AI-lab02/image-20230108225724739.png","hash":"947058b7de0bb007e1cd18a5f00d795cdb1b30ce","modified":1717578183504},{"_id":"source/_posts/AI-lab03/image-20230111213530417.png","hash":"1ff3a24456b2e36456203cf125dd76818f0bbbf5","modified":1717578183514},{"_id":"source/_posts/AI-lab03/image-20230111221851068.png","hash":"9fd9b060323fb2f715a3fad6ad2da0dce03285be","modified":1717578183517},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164540980.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1717578183537},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164542395.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1717578183538},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164606082.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1717578183540},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164849274.png","hash":"c74c7c09c3192ca3b60bbe42fcd0964a57326f6a","modified":1717578183545},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164849274-17084112899534.png","hash":"c74c7c09c3192ca3b60bbe42fcd0964a57326f6a","modified":1717578183545},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161524873-17084118809551.png","hash":"9876f75069bbf3c2b82109404ef8039fe9d3cdc0","modified":1717578183559},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161727694.png","hash":"2b54f27a1f295261f97ed01b913f5807155ca5df","modified":1717578183562},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161524873.png","hash":"9876f75069bbf3c2b82109404ef8039fe9d3cdc0","modified":1717578183560},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161727694-17084118809562.png","hash":"2b54f27a1f295261f97ed01b913f5807155ca5df","modified":1717578183562},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170520355-17084118809566.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1717578183569},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170520355.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1717578183571},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170519094.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1717578183569},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201110927.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1717578183576},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201112834-17084118809569.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1717578183576},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201139440-170841188095610.png","hash":"f10b268c53316cdc2f77b6168d2d5803ac1416fd","modified":1717578183577},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201112834.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1717578183577},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201139440.png","hash":"f10b268c53316cdc2f77b6168d2d5803ac1416fd","modified":1717578183578},{"_id":"source/_posts/a-star-assignment/image-20230803165730214.png","hash":"5cebe4d13a1306f6e7e3e29e7832b18d5f98684c","modified":1717578183628},{"_id":"source/_posts/database-mysql/image-20240224162152111.png","hash":"e9757e26efec7b79170625394e4c31c35dec09bb","modified":1717578183687},{"_id":"source/_posts/deep-learning-test03/output_1_0.png","hash":"c0b6814794f3bdfd29ae9ffce768032db0c7640b","modified":1717578183696},{"_id":"source/_posts/deep-learning-test05/output_3_1.png","hash":"925e17b936dc91fa3e275f7becf3dd61098d0add","modified":1717578183698},{"_id":"source/_posts/deep-learning-test05/output_4_1.png","hash":"e167d4b910938fd8e62e0e1c40cfdcd124a8cfa1","modified":1717578183698},{"_id":"source/_posts/design-model/工厂模式_01.png","hash":"8617574fbf418804bb4aee58abeb43190fa5f3e6","modified":1719900879664},{"_id":"source/_posts/design-model/策略模式_01.png","hash":"3d0eef75b783abc24edda15c47be9d3f1453f512","modified":1720000268185},{"_id":"source/_posts/design-model/适配器模式_01.png","hash":"a479e248c898c9ced1457aa8ad1b61770f7a36d8","modified":1719901206645},{"_id":"source/_posts/digital-image-test01/image-20240302183456769.png","hash":"f19b8dc52627b273302c6e8e784cc636c9c65bb4","modified":1717578183700},{"_id":"source/_posts/digital-image-test01/image-20240302183504049.png","hash":"9eaec3478a6158bb510e0fd0078c1871657fd852","modified":1717578183701},{"_id":"source/_posts/digital-image-test01/image-20240302183527447.png","hash":"1eb035325a31521e4b46c4863b9e6acf1a470b96","modified":1717578183702},{"_id":"source/_posts/digital-image-test01/image-20240302183532846.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1717578183703},{"_id":"source/_posts/digital-image-test01/image-20240302183534696.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1717578183703},{"_id":"source/_posts/digital-image-test01/image-20240302183542527.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1717578183704},{"_id":"source/_posts/digital-image-test02/image-20240302184201998.png","hash":"116ee52638a1fe8a5b14bab8e96eed1b7a7d949c","modified":1717578183709},{"_id":"source/_posts/digital-image-test02/image-20240302184304968.png","hash":"0880ccf1b96833dff27f2d5d2c16c6e410d4115e","modified":1717578183709},{"_id":"source/_posts/digital-image-test02/image-20240302184311057.png","hash":"5fe1362196610b88b62f880ff5b5bde8563c32e2","modified":1717578183710},{"_id":"source/_posts/digital-image-test02/image-20240302184323543.png","hash":"8e3df318d5913ccb606dfb31f86c82e8bfdb38fc","modified":1717578183711},{"_id":"source/_posts/digital-image-test02/image-20240302184327658.png","hash":"fd4d65ada72a3370930e7b115df48fc154e1c2a6","modified":1717578183712},{"_id":"source/_posts/digital-image-test03/image-20240302184935209.png","hash":"30b56fd672041792c01d8051c7c80d55adfbed8f","modified":1717578183715},{"_id":"source/_posts/digital-image-test03/image-20240302184920811.png","hash":"68e67eb5fa6be752ced2a0b78d427d9e35f6d96e","modified":1717578183714},{"_id":"source/_posts/digital-image-test03/image-20240302184959151.png","hash":"aee0cd427420de8d15003e1d2435de3ed14b8720","modified":1717578183718},{"_id":"source/_posts/digital-image-test03/image-20240302184940449.png","hash":"e5f333c1c3dd3a5ad45b8fc9060ee9be8d2a930d","modified":1717578183717},{"_id":"source/_posts/digital-image-test04/image-20240302185608155.png","hash":"1785fd7cb2602a5b57d96da41aed305e90a7188b","modified":1717578183739},{"_id":"source/_posts/digital-image-test04/image-20240302185739084.png","hash":"6c663b9ac00259bfafd0c42612e00dd2837d035a","modified":1717578183741},{"_id":"source/_posts/digital-image-test04/image-20240302185735104.png","hash":"9019c41b6177657c28f7b940bfe05d15970a964d","modified":1717578183740},{"_id":"source/_posts/digital-image-test04/image-20240302185751435.png","hash":"550dc1109ae1fbd554541dd5fbfcbc053288eaa1","modified":1717578183743},{"_id":"source/_posts/digital-image-test04/image-20240302185800747.png","hash":"9fe19b1c3019710648f2e907d52490261825e8dd","modified":1717578183744},{"_id":"source/_posts/digital-image-test04/image-20240302185829105.png","hash":"51fbeb4a630ac6499cca2d56c7395a2e2599504b","modified":1717578183746},{"_id":"source/_posts/distributed-system/image-20221126155754925.png","hash":"4a37affbab2b1fe64687dae0de2783eed009a2c6","modified":1717578183750},{"_id":"source/_posts/distributed-system/image-20221130091729650.png","hash":"312965394dfce6471c4850d1abb42e9464f24947","modified":1717578183752},{"_id":"source/_posts/distributed-system/image-20221130094553260.png","hash":"568d9c6520c41c288f11efb324930bf79d7b1842","modified":1717578183753},{"_id":"source/_posts/distributed-system/image-20221130102217372.png","hash":"17f927304c1564c7ba8c1ee0b8aee8e5452d5584","modified":1717578183756},{"_id":"source/_posts/distributed-system/image-20221130101949954.png","hash":"99fdd6a6cb70e09938f2e9c4875b71040cfd2e29","modified":1717578183755},{"_id":"source/_posts/distributed-system/image-20221130101048848.png","hash":"5fdd4316cca7d714106ddf55231eb81505fbb4ed","modified":1717578183754},{"_id":"source/_posts/distributed-system/image-20221130143607842.png","hash":"9e317509c1e92c8e09cdce0392fe620c0956927c","modified":1717578183758},{"_id":"source/_posts/distributed-system/image-20221201111903470.png","hash":"5dc9ceedd1ec606b9c3b18b2a44e640fa6a35b0e","modified":1717578183762},{"_id":"source/_posts/distributed-system/image-20221130151005907.png","hash":"d997ca239954fa5012c4da72f7d465ad132628ee","modified":1717578183758},{"_id":"source/_posts/distributed-system/image-20221201151303341.png","hash":"187b0a34e086caa4bb298ac620e3c9c3c57f680c","modified":1717578183763},{"_id":"source/_posts/distributed-system/image-20221201160233164.png","hash":"eb2b547c2f2ead7bd3f09d6d71aba6569153889a","modified":1717578183764},{"_id":"source/_posts/distributed-system/image-20221201110722218.png","hash":"2407b86f90b047e2736a5e0e5578c473460b49a6","modified":1717578183761},{"_id":"source/_posts/git/image-20231204110955462.png","hash":"a0eb304ceda27842d706b29f5dd93e231ce5b5cb","modified":1717578183788},{"_id":"source/_posts/git/image-20231204111125551.png","hash":"225fa0eec9bca8d94a18d88c25a06a7a80c95de9","modified":1717578183789},{"_id":"source/_posts/git/image-20231204111350240.png","hash":"b10c40f287f5e8933502801fe32cb3562b3f5236","modified":1717578183791},{"_id":"source/_posts/git/image-20231204113100512.png","hash":"dea8dd3f1ac6c962555a2122bedaed5565c2f11b","modified":1717578183792},{"_id":"source/_posts/static-timing-analysis/image-20230810165634110.png","hash":"2fd44bcb4a89e9c304263e68f765a303fe8959ef","modified":1717578183810},{"_id":"source/_posts/static-timing-analysis/image-20230817160942849.png","hash":"5a486b9adb7f4ff40a02b60e4ef4c98f5165ac13","modified":1717578183812},{"_id":"source/_posts/static-timing-analysis/image-20230817160931612.png","hash":"71d115d34de1efcc6987686ed1ca11a50e0055e2","modified":1717578183811},{"_id":"source/_posts/thread-pool/image-20240303214601818.png","hash":"733412290daa5076a9e22dec9c83f0bba4340ea9","modified":1717578183815},{"_id":"source/_posts/平方根倒数算法/WTF.png","hash":"58a5cfc1e84918f49258973ec18f362bee15a510","modified":1717578183817},{"_id":"source/_posts/进程间的通信方式/image-20240130223824673.png","hash":"936c1b00abc4de2fb48bb478b04683e98d9f2fd3","modified":1717578183819},{"_id":"source/_posts/进程间的通信方式/image-20240130223920751.png","hash":"936c1b00abc4de2fb48bb478b04683e98d9f2fd3","modified":1717578183820},{"_id":"source/_posts/15445-study-notes-01-04/image-20240104193223551.png","hash":"02de891a2a2b95714763852bc4c97b8d12742c04","modified":1717578183472},{"_id":"source/_posts/15445-study-notes-01-04/image-20240102201317281.png","hash":"ae0106e357ed06333658ee7bdef6e14a6d94eeee","modified":1717578183467},{"_id":"source/_posts/AI-lab01/image-20230109204708818.png","hash":"69f49c2e2c78078b2ceb541f12c957e7141acaa2","modified":1717578183488},{"_id":"source/_posts/AI-lab02/image-20230108225530690.png","hash":"16633adf480e18afad9edfb9706cd24b1e0678ab","modified":1717578183502},{"_id":"source/_posts/AI-lab02/image-20230108230820413.png","hash":"ba6b52c8ad007be7e0fa26632bbb366ed21bcbcf","modified":1717578183508},{"_id":"source/_posts/AI-lab02/image-20230108225829669.png","hash":"c0ca95caa0c7727a6e0e075182eda7549d6ee3e0","modified":1717578183505},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113151777.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1717578183531},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113151777-17084112899531.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1717578183529},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113201064.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1717578183532},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161842894-17084118809563.png","hash":"8baa04211e4bf3b301d6a804e2d00f80c9c58479","modified":1717578183563},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116164956551-17084118809564.png","hash":"3fa6c847173dd62697db1c1ada123010901501b4","modified":1717578183566},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161842894.png","hash":"8baa04211e4bf3b301d6a804e2d00f80c9c58479","modified":1717578183564},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116164956551.png","hash":"3fa6c847173dd62697db1c1ada123010901501b4","modified":1717578183567},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116200444279-17084118809568.png","hash":"0e3d6cc22828451b4bda030dfc545529f8728afb","modified":1717578183574},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116200444279.png","hash":"0e3d6cc22828451b4bda030dfc545529f8728afb","modified":1717578183575},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142130480-170841188095611.png","hash":"4f03cb3c8844b6927cc1877cdf73b1a9b230f649","modified":1717578183579},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142130480.png","hash":"4f03cb3c8844b6927cc1877cdf73b1a9b230f649","modified":1717578183580},{"_id":"source/_posts/VLSI-Physical-Design/image-20230817170808037.png","hash":"04e7f1818a6281b74aa2dee03409e18471cc4fc7","modified":1717578183627},{"_id":"source/_posts/database-mysql/Mysql.png","hash":"a88e0da8c928deb7a463092864da4ca1457807b9","modified":1717578183636},{"_id":"source/_posts/database-mysql/image-20240210160421874.png","hash":"8f012f4795a0b4b44d76204a6dbd9e7f569c8f14","modified":1717578183639},{"_id":"source/_posts/database-mysql/image-20240218221919863.png","hash":"6b143cda1f4a832532a3b02eaf4f17f822419218","modified":1717578183667},{"_id":"source/_posts/database-mysql/image-20240224161313751.png","hash":"c22629a9ef8578a6b472f3bfd6c9c86f244a12b1","modified":1717578183686},{"_id":"source/_posts/database-mysql/image-20240224162359110.png","hash":"d9826c326353f5172f46e1c020e7df3625cf0304","modified":1717578183688},{"_id":"source/_posts/database-mysql/image-20240224162626695.png","hash":"c5a7671a2abd79128c7a4255e69cb6181ddcc483","modified":1717578183688},{"_id":"source/_posts/design-model/工厂模式_02.png","hash":"12b28b1b9ee39f2084782a5cd37b049d4ec38848","modified":1719901040495},{"_id":"source/_posts/digital-image-test02/image-20240302184347311.png","hash":"6385a53a8f2661faaa5062e65369370d75b792d1","modified":1717578183712},{"_id":"source/_posts/digital-image-test03/image-20240302185003442.png","hash":"366b01d6f4d5c858e65f08e0f75b032b3d899f58","modified":1717578183720},{"_id":"source/_posts/digital-image-test03/image-20240302185107213.png","hash":"efbac1d1bcbc29a4816c0e740b8c6ae5004820c8","modified":1717578183721},{"_id":"source/_posts/digital-image-test03/image-20240302184950081.png","hash":"e3b8144f6e8ffd3170ad9d7a961ccf94655379c1","modified":1717578183717},{"_id":"source/_posts/digital-image-test03/image-20240302185116864.png","hash":"1dd79621438c7aa54217c3169f6b928e4c36907d","modified":1717578183722},{"_id":"source/_posts/digital-image-test04/image-20240302185557410.png","hash":"dec299ecf1e17fa9fb56c5ba45a039346478fb62","modified":1717578183736},{"_id":"source/_posts/digital-image-test04/image-20240302185602980.png","hash":"351b2bcbdffaaaefd115e26523100389c7597f7c","modified":1717578183737},{"_id":"source/_posts/digital-image-test04/image-20240302185819182.png","hash":"6c47c050490bb1ee356305db1e8486acd712e3e4","modified":1717578183744},{"_id":"source/_posts/distributed-system/image-20221126155708747.png","hash":"2cca3a046e1c6ae144e77252997c48d1bbf5a78a","modified":1717578183749},{"_id":"source/_posts/distributed-system/image-20221130140722941.png","hash":"4edff4d31fb00553540fd3892c043eb27ac44cd7","modified":1717578183757},{"_id":"source/_posts/distributed-system/image-20221201101451311.png","hash":"bad34f96ded3a9edf19a070ec2fb24b01d5821dd","modified":1717578183760},{"_id":"source/_posts/iEDA-test/image-20230825151306959.png","hash":"0df18ea78a4f268e388c1b10442de81c71ddcca7","modified":1717578183795},{"_id":"source/_posts/iEDA-test/image-20230825163454933.png","hash":"69cc59dce88945050bd47531a2af7df73f5bf5d6","modified":1717578183798},{"_id":"source/_posts/pytorch-install/image-20221022174307472.png","hash":"620299e154d25aa984858b6c0de4463d0ae04451","modified":1717578183808},{"_id":"source/_posts/进程间的通信方式/image-20240130224638178.png","hash":"3fc74a884e2c346ccf3ff5bdfb1c8d0923d91404","modified":1717578183822},{"_id":"source/_posts/进程间的通信方式/image-20240130232827259.png","hash":"fbf784ce1ad312d9fd7a41e90b73d800ae2e0fba","modified":1717578183823},{"_id":"source/_posts/15445-study-notes-01-04/image-20240102163927925.png","hash":"835c1bc441be67e2da17b4b550b474c785343a28","modified":1717578183466},{"_id":"source/_posts/15445-study-notes-01-04/image-20240103093506806.png","hash":"8d00b741b53e6b1b23bcfabbb60331de2b19b6d8","modified":1717578183469},{"_id":"source/_posts/15445-study-notes-01-04/image-20240105160547664.png","hash":"695d1971c93fc9ceaf23c7a18403a8723116a2f6","modified":1717578183474},{"_id":"source/_posts/15445-study-notes-01-04/image-20240112101151040.png","hash":"1da823c64043e26203c966c27e1c3821972ee29f","modified":1717578183477},{"_id":"source/_posts/AI-lab02/image-20230108232000280.png","hash":"ca753ebf56536e860051ba576b2170e15a85071e","modified":1717578183509},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164704660-17084112899533.png","hash":"cfeacbbd7028c9598c655135169d4cc611841ee4","modified":1717578183542},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164704660.png","hash":"cfeacbbd7028c9598c655135169d4cc611841ee4","modified":1717578183544},{"_id":"source/_posts/Physical-design/04.png","hash":"60627afbe440f95a1180b3c2cfe3e21cd170ec7c","modified":1717578183595},{"_id":"source/_posts/Physical-design/10.png","hash":"8a6e2cab074a24548e9072a45291d086fe85bdbe","modified":1717578183608},{"_id":"source/_posts/database-mysql/image-20240218212115878.png","hash":"86bcc05425e727adec4a58fb0d8d8374c43d6ac8","modified":1717578183653},{"_id":"source/_posts/database-mysql/image-20240218212814126.png","hash":"55a69f62cda07a32605ef6c451eea99ff5772d1b","modified":1717578183659},{"_id":"source/_posts/database-mysql/image-20240224160500080.png","hash":"ab1e8d4f492b59b2049221c023ea2dac807c8f9b","modified":1717578183685},{"_id":"source/_posts/deep-learning-test02/output_8_0.png","hash":"8285366797bbd72661390991cd0e0d999970ca0b","modified":1717578183695},{"_id":"source/_posts/digital-image-test01/image-20240302183548286.png","hash":"90b569a59fa4e779b8c4565635df2b99db96fc2e","modified":1717578183705},{"_id":"source/_posts/进程间的通信方式/image-20240130234754230.png","hash":"fd658ca22bb8d21052c0f10e8225855134402c10","modified":1717578183828},{"_id":"source/_posts/digital-image-test02/image-20240302184359230.png","hash":"c7063a871d07faafe5ddec46c1eca9fafb1a52bb","modified":1717578183713},{"_id":"source/_posts/digital-image-test03/image-20240302185113358.png","hash":"e82688778c37c6cad03ee7fbdc7ef928f3753728","modified":1717578183721},{"_id":"source/_posts/digital-image-test03/image-20240302185124222.png","hash":"4dc84e6280aed0d365d93ea1ed03b3a059e47d38","modified":1717578183724},{"_id":"source/_posts/digital-image-test03/image-20240302185142206.png","hash":"08a44975c9da8f96c580be8dc62f23226e99e8b7","modified":1717578183727},{"_id":"source/_posts/digital-image-test03/image-20240302185128004.png","hash":"335b2aafe3f4821d5bcc65b836390a7e7fc0c88d","modified":1717578183726},{"_id":"source/_posts/digital-image-test03/image-20240302185150777.png","hash":"eed151640e2fce651a386269e4d2e3aaa9450b55","modified":1717578183728},{"_id":"source/_posts/digital-image-test04/image-20240302185837682.png","hash":"901eb2404f60f2120d55dc83e73ed1aaa44e6729","modified":1717578183747},{"_id":"source/_posts/digital-image-test04/image-20240302185841933.png","hash":"2f1c8e67c6531051ff75110648fd02a5dd5ac694","modified":1717578183748},{"_id":"source/_posts/distributed-system/image-20240302165702511.png","hash":"9cc11dc79058db54a75cb2d7b167fe4de0e572e7","modified":1717578183772},{"_id":"source/_posts/distributed-system/image-20240302165713656.png","hash":"e755af0748d67a4de1370c9a2920fceb1a16e913","modified":1717578183774},{"_id":"source/_posts/distributed-system/image-20240302165721466.png","hash":"59284da26e73ad92d5200f2f12ffeca45a74b4f9","modified":1717578183775},{"_id":"source/_posts/eda-summary/image-20230828144127572.png","hash":"7730241829f60a3bcb280ab502120bf743da1ecb","modified":1717578183787},{"_id":"source/_posts/iEDA-test/image-20230825164152609.png","hash":"921020aab17eee59e62aeca3c62a5bb562ce6712","modified":1717578183801},{"_id":"source/_posts/iEDA-test/image-20230825163939716.png","hash":"6544a9c9eddc58256e34bfe6dfcf0d910447a409","modified":1717578183800},{"_id":"source/_posts/iEDA-test/image-20230825164459060.png","hash":"6714a3049410eda061550d135f76892e864614eb","modified":1717578183802},{"_id":"source/_posts/iEDA-test/image-20230830164032304.png","hash":"dffccf2ddd62ef2de9ccb4022fed8908783f0586","modified":1717578183804},{"_id":"source/_posts/15445-study-notes-01-04/image-20240104092359606.png","hash":"0f8926021c96616358c973b3f4991f6e63bb4276","modified":1717578183471},{"_id":"source/_posts/15445-study-notes-01-04/image-20240112102928169.png","hash":"a8f53689a4e42bb8e6823138a7eacc9967016310","modified":1717578183478},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104150955701-17084112899532.png","hash":"d1faec91913f175c08eea064a74a7ac6c5be6003","modified":1717578183534},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104150955701.png","hash":"d1faec91913f175c08eea064a74a7ac6c5be6003","modified":1717578183536},{"_id":"source/_posts/Physical-design/02.png","hash":"abcdbc15dc9043f37449c8f9a02b11da173085f6","modified":1717578183589},{"_id":"source/_posts/Physical-design/08.png","hash":"c44f7bc0629b47dd2d2f3c4f3af61eb295d30c93","modified":1717578183603},{"_id":"source/_posts/database-mysql/image-20240216163439353.png","hash":"839776a0910307166c289c050a25f340654055af","modified":1717578183648},{"_id":"source/_posts/database-mysql/image-20240218212542921.png","hash":"0c5e855a8d2f1c2b6b256a96be4e664183c26035","modified":1717578183655},{"_id":"source/_posts/digital-image-test03/image-20240302185159151.png","hash":"5a657950d87c7c53ddf068f1c2ed127f42c1bdf8","modified":1717578183730},{"_id":"themes/butterfly/_config.yml","hash":"61bf43c17e74c7baa8b9c026bd018413d6b68c70","modified":1717578183830},{"_id":"themes/butterfly/package.json","hash":"58300c8f776c115ac8e069a39e9460faafc60122","modified":1717578183859},{"_id":"themes/butterfly/LICENSE","hash":"c8bc7df08db9dd3b39c2c2259a163a36cf2f6808","modified":1717578183829},{"_id":"themes/butterfly/README.md","hash":"20a91bea7f7ada8b8195d2abff106a7ce21bba20","modified":1717578183829},{"_id":"themes/butterfly/README_CN.md","hash":"9d729ee2ffc5e5f703ccfbfbbb7b286d59071125","modified":1717578183830},{"_id":"themes/butterfly/plugins.yml","hash":"5dea6a045a9b33b35809c7f180f256431a6fba09","modified":1717578183859},{"_id":"themes/butterfly/languages/en.yml","hash":"68127be0e6b44cfc5f31353d8b275c02939b3ff9","modified":1717578183830},{"_id":"themes/butterfly/languages/default.yml","hash":"90e9e2f36dc51aa77eb7804ae048b4876035b12d","modified":1717578183830},{"_id":"themes/butterfly/languages/zh-CN.yml","hash":"2dcc70a011b37890215ae0fd6d8f8c78aa8af6b0","modified":1717578183831},{"_id":"themes/butterfly/languages/zh-TW.yml","hash":"1392e7b8c678cdfb54f55523693e66abc7d80538","modified":1717578183831},{"_id":"themes/butterfly/layout/archive.pug","hash":"bc77220dfc269b8faad0930e1a4142ebf68165e5","modified":1717578183832},{"_id":"themes/butterfly/layout/category.pug","hash":"bf979aec88d78b644fc5d31518f8679ad7625792","modified":1717578183832},{"_id":"themes/butterfly/layout/index.pug","hash":"648dcbdb3d145a710de81c909e000e8664d2ac9c","modified":1717578183857},{"_id":"themes/butterfly/layout/page.pug","hash":"bf2d6c6d2d156777b55292e51be02b0b3acf0af8","modified":1717578183858},{"_id":"themes/butterfly/layout/post.pug","hash":"fdbb508b5e6dec30fb8753c5a7fdd494410c4fc0","modified":1717578183858},{"_id":"themes/butterfly/layout/tag.pug","hash":"4bb5efc6dabdf1626685bf6771aaa1467155ae86","modified":1717578183858},{"_id":"themes/butterfly/layout/includes/404.pug","hash":"aace9ddff469de4226e47a52ede1c81e66d66d5c","modified":1717578183832},{"_id":"themes/butterfly/layout/includes/footer.pug","hash":"8715948b93e7508b84d913be1969b28c6b067b9b","modified":1717578183833},{"_id":"themes/butterfly/layout/includes/additional-js.pug","hash":"50eea5aa78cdeb6c72dd22f0aeabc407cc0f712e","modified":1717578183832},{"_id":"themes/butterfly/layout/includes/head.pug","hash":"ea8d4e8ac6af93cd268ba8f6ffcb80417bc2501e","modified":1717578183833},{"_id":"themes/butterfly/layout/includes/layout.pug","hash":"96df62e34661d8ca4a45267286127479e5178a79","modified":1717578183838},{"_id":"themes/butterfly/layout/includes/pagination.pug","hash":"c5c58714fb3cb839653e5c32e6094784c8662935","modified":1717578183841},{"_id":"themes/butterfly/layout/includes/rightside.pug","hash":"f448bf73103b88de4443e52d600e871cf3de3e32","modified":1717578183841},{"_id":"themes/butterfly/layout/includes/sidebar.pug","hash":"9277fead4c29dbe93976f078adaa26e8f9253da3","modified":1717578183843},{"_id":"themes/butterfly/scripts/events/404.js","hash":"f1d1c378356b776e9b2a8411e6dca88dc8c3245c","modified":1717578183859},{"_id":"themes/butterfly/scripts/events/cdn.js","hash":"7864ba45716c51aef8d8b04fd4bc212e0008ce3b","modified":1717578183859},{"_id":"themes/butterfly/scripts/events/comment.js","hash":"95479790234c291b064d031577d71214cdd1d820","modified":1717578183859},{"_id":"themes/butterfly/scripts/events/init.js","hash":"ce68e84a9ccfcf91100befbaa9afc392a0cd93bb","modified":1717578183859},{"_id":"themes/butterfly/scripts/events/merge_config.js","hash":"b1dfc3c898b886eab1241b068fc27d7a26a3b7d2","modified":1717578183860},{"_id":"themes/butterfly/scripts/events/stylus.js","hash":"0a336dfe5ed08952fa0df1532421df38a74a20d6","modified":1717578183861},{"_id":"themes/butterfly/scripts/events/welcome.js","hash":"f59e10305fef59ea3e62a7395106c0927582879d","modified":1717578183861},{"_id":"themes/butterfly/scripts/filters/post_lazyload.js","hash":"5ed2d7ef240c927fe1b7a7fb5bf9e55e2bfd55a5","modified":1717578183861},{"_id":"themes/butterfly/scripts/filters/random_cover.js","hash":"0df22d7dbfa766a65cb6032a1f003348f4307cfe","modified":1717578183861},{"_id":"themes/butterfly/scripts/helpers/aside_archives.js","hash":"4f712b4ea383b59a3122683db1d54c04a79ccc5d","modified":1717578183862},{"_id":"themes/butterfly/scripts/helpers/findArchiveLength.js","hash":"b12895e0765d596494e5526d121de0dd5a7c23d3","modified":1717578183862},{"_id":"themes/butterfly/scripts/helpers/aside_categories.js","hash":"cdd992c8577d583c237b6aac9f5077d8200879b2","modified":1717578183862},{"_id":"themes/butterfly/scripts/helpers/inject_head_js.js","hash":"b55f71347d2ead097c7f98c0ec792b091433345c","modified":1717578183862},{"_id":"themes/butterfly/scripts/helpers/page.js","hash":"c74d6a9b8f71e69447f7847a5f5e81555d68b140","modified":1717578183863},{"_id":"themes/butterfly/scripts/helpers/related_post.js","hash":"76343ac8422c9c8539082e77eda6ffee4b877eb2","modified":1717578183863},{"_id":"themes/butterfly/scripts/helpers/series.js","hash":"17c0095bc8d612a268cdcab000b1742dc4c6f811","modified":1717578183863},{"_id":"themes/butterfly/scripts/tag/button.js","hash":"164d5f1c2d1b4cb5a813a6fc574016743a53c019","modified":1717578183863},{"_id":"themes/butterfly/scripts/tag/flink.js","hash":"3ba7677969ff01fab06fc6713455ddc6861f0024","modified":1717578183863},{"_id":"themes/butterfly/scripts/tag/gallery.js","hash":"7ec77b3093f5de67e7032f40a5b12f1389f6f6ff","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/hide.js","hash":"5d08c3552f7d3c80a724ca628bff66321abe2e5a","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/inlineImg.js","hash":"c863d2732ce4bdc084f2d0db92f50f80328c1007","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/label.js","hash":"b013dc0a3d57d2caa18b89263f23871da9ec456d","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/mermaid.js","hash":"289f85847c58f0b2b7d98a68e370a2896edb8949","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/note.js","hash":"e68d8d21f3a86e3646907a3685550ee20e8d4a9f","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/score.js","hash":"35d54adc92e717cc32e13515122b025fd1a98ea2","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/series.js","hash":"dc56e5182dd3813dc977c9bf8556dcc7615e467b","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/tabs.js","hash":"7c448886f230adb4f4a0208c88fff809abcb5637","modified":1717578183864},{"_id":"themes/butterfly/scripts/tag/timeline.js","hash":"e611074a5a7f489a8b04afac0a3f7f882ce26532","modified":1717578183865},{"_id":"themes/butterfly/source/css/index.styl","hash":"b13d96924a5534bff91d75566b196ac87b4fac22","modified":1717578183878},{"_id":"themes/butterfly/source/css/var.styl","hash":"950250f66faeb611a67540e0fa6cedbcf5a7a321","modified":1717578183878},{"_id":"themes/butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1717578183879},{"_id":"themes/butterfly/source/img/default_cover04.jpg","hash":"9870826d979b563c27cb3c15b3603fd867119a9d","modified":1717578183884},{"_id":"themes/butterfly/source/img/favicon1.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1717578183897},{"_id":"themes/butterfly/source/js/main.js","hash":"59cd756a94ecdf3ec7b18f50691a8a6305f7a65a","modified":1717578183900},{"_id":"themes/butterfly/source/js/utils.js","hash":"7b871fe0c4456660cff4c7b9cc4ed089adac2caf","modified":1717578183901},{"_id":"themes/butterfly/layout/includes/head/Open_Graph.pug","hash":"c8dbdfe6145a0bc6f7691c9551be8169a2698f0a","modified":1717578183834},{"_id":"themes/butterfly/layout/includes/head/analytics.pug","hash":"c7666a10448edd93f5ace37296051b7670495f1b","modified":1717578183834},{"_id":"themes/butterfly/layout/includes/head/google_adsense.pug","hash":"f29123e603cbbcc6ce277d4e8f600ba67498077c","modified":1717578183836},{"_id":"themes/butterfly/layout/includes/head/config_site.pug","hash":"bd5dd5452e28a4fe94c3241a758ec6f4fdb7a149","modified":1717578183835},{"_id":"themes/butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1717578183898},{"_id":"themes/butterfly/layout/includes/head/config.pug","hash":"39e1ca0a54eb5fd3688a78737417a1aaa50914c9","modified":1717578183835},{"_id":"themes/butterfly/layout/includes/head/preconnect.pug","hash":"a7c929b90ae52b78b39b1728e3ab0e3db1cb7b9a","modified":1717578183836},{"_id":"themes/butterfly/layout/includes/head/pwa.pug","hash":"6dc2c9b85df9ab4f5b554305339fd80a90a6cf43","modified":1717578183836},{"_id":"themes/butterfly/layout/includes/head/site_verification.pug","hash":"5168caadc4cf541f5d6676a9c5e8ae47a948f9ad","modified":1717578183836},{"_id":"themes/butterfly/layout/includes/header/index.pug","hash":"1bef867c799ba158c5417272fb137539951aa120","modified":1717578183837},{"_id":"themes/butterfly/layout/includes/header/menu_item.pug","hash":"ca8bcd90ad9467819330bfe7c02b76322754bccf","modified":1717578183837},{"_id":"themes/butterfly/layout/includes/header/nav.pug","hash":"962ee70a35e60a13c31eea47d16b9f98069fe417","modified":1717578183837},{"_id":"themes/butterfly/source/js/tw_cn.js","hash":"d776c670e4076ad6049dbb64cdee7a734b51d37f","modified":1717578183901},{"_id":"themes/butterfly/layout/includes/header/post-info.pug","hash":"e7b25a322ae861dca06d458d3f914220e92758cf","modified":1717578183837},{"_id":"themes/butterfly/layout/includes/header/social.pug","hash":"7a641b5dd45b970e1dafd1433eb32ea149e55cf2","modified":1717578183838},{"_id":"themes/butterfly/layout/includes/loading/fullpage-loading.pug","hash":"766baca6ddce49d1724a02312387b292ff2d0bdc","modified":1717578183838},{"_id":"themes/butterfly/layout/includes/loading/index.pug","hash":"00ae419f527d8225a2dc03d4f977cec737248423","modified":1717578183838},{"_id":"themes/butterfly/layout/includes/loading/pace.pug","hash":"a6fde4835d6460ce7baf792fd5e1977fad73db25","modified":1717578183838},{"_id":"themes/butterfly/layout/includes/mixins/post-ui.pug","hash":"194a5f310dccecee3ae0b648e4e5318f6fbbddcd","modified":1717578183839},{"_id":"themes/butterfly/layout/includes/mixins/article-sort.pug","hash":"9155f01d4c644a2e19b2b13b2d3c6d5e34dd0abf","modified":1717578183839},{"_id":"themes/butterfly/layout/includes/page/default-page.pug","hash":"e9459f122af7b733398578f9f0f8ab3c5e12a217","modified":1717578183839},{"_id":"themes/butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1717578183839},{"_id":"themes/butterfly/layout/includes/page/flink.pug","hash":"e37681bc9c169d4220f26ecda2b3d5c02b6b9a0f","modified":1717578183840},{"_id":"themes/butterfly/layout/includes/page/tags.pug","hash":"12be059c536490af216a397e8f2a7abbf6d4610e","modified":1717578183841},{"_id":"themes/butterfly/layout/includes/post/post-copyright.pug","hash":"0abad416b1974a17e5be7817931d5fe799180170","modified":1717578183841},{"_id":"themes/butterfly/layout/includes/post/reward.pug","hash":"912df10a053db3135968e92b6fd1a707ee94c968","modified":1717578183841},{"_id":"themes/butterfly/layout/includes/third-party/aplayer.pug","hash":"e939344fd389aeb11864ee697d5fd9b036d8325f","modified":1717578183843},{"_id":"themes/butterfly/layout/includes/third-party/effect.pug","hash":"43014bfc63583d3ee8808d526dd165848c0ed52f","modified":1717578183849},{"_id":"themes/butterfly/layout/includes/third-party/prismjs.pug","hash":"08979afbfecb4476a5ae8e360947b92624d285b8","modified":1717578183852},{"_id":"themes/butterfly/layout/includes/third-party/pjax.pug","hash":"9b734d99963f3e7f562597dcf60485ccbf6e961c","modified":1717578183852},{"_id":"themes/butterfly/layout/includes/third-party/pangu.pug","hash":"f0898509da70388b5c532f19e762756d74080200","modified":1717578183852},{"_id":"themes/butterfly/layout/includes/third-party/subtitle.pug","hash":"dfb5e16a7e7106bb20b2ac2d0df1251d0fc79609","modified":1717578183854},{"_id":"themes/butterfly/layout/includes/widget/card_ad.pug","hash":"a8312b527493dabbadbb1280760168d3bc909a3b","modified":1717578183854},{"_id":"themes/butterfly/layout/includes/widget/card_announcement.pug","hash":"21e019bdc3b1e796bb00976bb29af2d51f873624","modified":1717578183854},{"_id":"themes/butterfly/layout/includes/widget/card_author.pug","hash":"ab037bf5794638bd30da4cf7cf106e5d03b5f696","modified":1717578183855},{"_id":"themes/butterfly/layout/includes/widget/card_archives.pug","hash":"73d33b6930e7944187a4b3403daf25d27077a2dd","modified":1717578183854},{"_id":"themes/butterfly/layout/includes/widget/card_bottom_self.pug","hash":"1dba77d250eeebfb6e293d504352c7e9ea31980b","modified":1717578183855},{"_id":"themes/butterfly/layout/includes/widget/card_categories.pug","hash":"66e383b4ef374951eb87dd1bf4cdb7a667193fb5","modified":1717578183855},{"_id":"themes/butterfly/layout/includes/widget/card_newest_comment.pug","hash":"8e22f53886a57a68286970d8af8b4c950fd4a1d7","modified":1717578183855},{"_id":"themes/butterfly/layout/includes/widget/card_post_toc.pug","hash":"d48d77af1670bd568d784794408bf524a448bfcc","modified":1717578183856},{"_id":"themes/butterfly/layout/includes/widget/card_post_series.pug","hash":"e0bb72fa0ce15964b11b8fe421cae3432394e35f","modified":1717578183856},{"_id":"themes/butterfly/layout/includes/widget/card_recent_post.pug","hash":"bb842d2aa6469d65bf06af1372f0a19a9e4ef44c","modified":1717578183856},{"_id":"themes/butterfly/layout/includes/widget/card_tags.pug","hash":"842b772a387b576550fa127030e1c2e9bf65716d","modified":1717578183857},{"_id":"themes/butterfly/layout/includes/widget/card_top_self.pug","hash":"7b5ae404a1205546b7de4be42291315cf918f2b3","modified":1717578183857},{"_id":"themes/butterfly/layout/includes/widget/card_webinfo.pug","hash":"12185713f9ca08984fc74e3b69d8cd6828d23da8","modified":1717578183857},{"_id":"themes/butterfly/layout/includes/widget/index.pug","hash":"8df529f71e25f1c0a00e533de7944ed3d1ba7bd8","modified":1717578183857},{"_id":"themes/butterfly/source/css/_global/function.styl","hash":"e920dae9ce00177922468db49240f5aca0af4f64","modified":1717578183866},{"_id":"themes/butterfly/source/css/_global/index.styl","hash":"0421da07907b3d98df64239e073b23fbb3f04149","modified":1717578183866},{"_id":"themes/butterfly/source/css/_highlight/highlight.styl","hash":"41054740cfbd1357138785464f6859681ca58493","modified":1717578183866},{"_id":"themes/butterfly/source/css/_highlight/theme.styl","hash":"3c178608406c31d768af355ef1d7326da37cc75f","modified":1717578183868},{"_id":"themes/butterfly/source/css/_mode/darkmode.styl","hash":"dbc855795a881f8c805bf5c9c5c4d5d542a648ec","modified":1717578183872},{"_id":"themes/butterfly/source/css/_mode/readmode.styl","hash":"a22fd15048d21452f0015d0765d295d730203308","modified":1717578183872},{"_id":"themes/butterfly/source/css/_layout/aside.styl","hash":"aae70ddd126b2e40158e45036abecbfa33cbfbba","modified":1717578183868},{"_id":"themes/butterfly/source/css/_layout/chat.styl","hash":"792a04d36de32f230ca3256ad87a90fe8392f333","modified":1717578183868},{"_id":"themes/butterfly/source/css/_layout/comments.styl","hash":"fbfce4d67cacd1df22fb73d89d008693f59d9d91","modified":1717578183868},{"_id":"themes/butterfly/source/css/_layout/pagination.styl","hash":"bd099f7d3adef4b7edd24c0a25a07415b156e587","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/footer.styl","hash":"5e27f7842af82ff7498d4b59787ce9ca90fa9e6f","modified":1717578183869},{"_id":"themes/butterfly/source/css/_layout/loading.styl","hash":"f0b01bbf321c2c24fdccaee367dd9fd448031a72","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/head.styl","hash":"66a7a0e3c58ac23c81afe9fe18834b9db9c42698","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/post.styl","hash":"7ae27854a737a02eca89b0b92db94cb298fef59e","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/relatedposts.styl","hash":"6dcf19c0933c8828a439f801b0f4b256447dec07","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/rightside.styl","hash":"0322237e762db401d7b4aa33168d0b9334a9ec26","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/reward.styl","hash":"c0b11a1a5f52e3a6af4e312a8134c93eda18a7dd","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/sidebar.styl","hash":"80ee9d0bfe5d38aac1f0cdcea5fc88b71d310041","modified":1717578183870},{"_id":"themes/butterfly/source/css/_layout/third-party.styl","hash":"15ea7564b2e3bf46bc91fb6e49c94d057b37caaf","modified":1717578183870},{"_id":"themes/butterfly/source/css/_page/archives.styl","hash":"5dd1ba997741d02894ff846eda939ad8051c0bb2","modified":1717578183872},{"_id":"themes/butterfly/source/css/_page/categories.styl","hash":"68bc8cbea25dbb3cdc170f09f9b43ce130547717","modified":1717578183872},{"_id":"themes/butterfly/source/css/_page/404.styl","hash":"a7223a8fcc4fa7b81e552c9a2554be7df9de312e","modified":1717578183872},{"_id":"themes/butterfly/source/css/_page/common.styl","hash":"df7a51fcabbadab5aa31770e3202a47c9599bbb7","modified":1717578183872},{"_id":"themes/butterfly/source/css/_page/flink.styl","hash":"ecc2b2e28c179eb9406fc2c6f00e141078249cdd","modified":1717578183873},{"_id":"themes/butterfly/source/css/_page/tags.styl","hash":"9e35f91847773b915c74a78b8aa66c7bdb950ad0","modified":1717578183873},{"_id":"themes/butterfly/source/css/_page/homepage.styl","hash":"a977cd8161ef4d6ddd5293e81403519076657430","modified":1717578183873},{"_id":"themes/butterfly/source/css/_search/index.styl","hash":"0b23010154e19f37f0c4af0110f9f834d6d41a13","modified":1717578183873},{"_id":"themes/butterfly/source/css/_search/local-search.styl","hash":"8a53d7ba5ca2f5eb4124b684e7845b648583f658","modified":1717578183875},{"_id":"themes/butterfly/source/css/_tags/gallery.styl","hash":"3e9355b76f87e2ee90f652855282b37ab5ae0b3e","modified":1717578183876},{"_id":"themes/butterfly/source/css/_tags/hexo.styl","hash":"985b183db7b7bfd8f9bdb60494549fb7f850348b","modified":1717578183876},{"_id":"themes/butterfly/source/css/_tags/button.styl","hash":"62da1de0d5b8453fcecbfacddb16985265638ba5","modified":1717578183875},{"_id":"themes/butterfly/source/css/_tags/hide.styl","hash":"b7cf7753479fcf2fe07287ffdb0e568adbba4c18","modified":1717578183877},{"_id":"themes/butterfly/source/css/_tags/label.styl","hash":"2f83bd145b870d80d4b18b0ac603235229a5694e","modified":1717578183877},{"_id":"themes/butterfly/source/css/_tags/inlineImg.styl","hash":"5a873d01fabebcf7ddf7a6b1c2e2e5e2714097f4","modified":1717578183877},{"_id":"themes/butterfly/source/css/_search/algolia.styl","hash":"37db99299af380e9111dce2a78a5049b301b13e0","modified":1717578183873},{"_id":"themes/butterfly/source/css/_tags/note.styl","hash":"4929382bd60788d34752a66e2fe764ef797a72a0","modified":1717578183877},{"_id":"themes/butterfly/source/css/_tags/timeline.styl","hash":"07ea7134db7a66c87658116f089fb1a2a6906563","modified":1717578183878},{"_id":"themes/butterfly/source/css/_third-party/normalize.min.css","hash":"8549829fb7d3c21cd9e119884962e8c463a4a267","modified":1717578183878},{"_id":"themes/butterfly/source/css/_tags/tabs.styl","hash":"353b95f9a6c2c1e777d978118cb61f909ccbf89c","modified":1717578183877},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/index.pug","hash":"58f37823f6cd9a194fb50f7ca7c2233e49939034","modified":1717578183843},{"_id":"themes/butterfly/source/js/search/local-search.js","hash":"ab3904451ae1d78903424b8b2ef815c8571e1749","modified":1717578183901},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/abcjs.pug","hash":"8f95aca305b56ccd7c8c7367b03d26db816ebd5f","modified":1717578183843},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/artalk.pug","hash":"19b5cfa1f77781246e02967cefe149f19170e45f","modified":1717578183843},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"d6fff5a7f84c8b09f282f9ddc0020a68a8aac9ea","modified":1717578183844},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"846cabae287ae31b3bbfac3da022475713dd5ecc","modified":1717578183844},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"4b98145d6584d586cabf033493282afc72ae816a","modified":1717578183844},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"cd4fc9c5a61608a5dedf645c1295430a1623040f","modified":1717578183845},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"716dc463fe4ef5112e7018ed60804125fdfa5cad","modified":1717578183844},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"7e233f872aea6fd6beccdc9efd86b1bf9ec9f12d","modified":1717578183844},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"fd2320ee25507bb8ef49f932c2d170586b44ea4d","modified":1717578183845},{"_id":"themes/butterfly/layout/includes/third-party/chat/chatra.pug","hash":"08a85e52fc800d3562df869e5e2613313e76fce6","modified":1717578183845},{"_id":"themes/butterfly/layout/includes/third-party/chat/crisp.pug","hash":"09d2ab2570b67e6f09244a898ccab5567cb82ace","modified":1717578183846},{"_id":"themes/butterfly/layout/includes/third-party/chat/daovoice.pug","hash":"0d960849d5b05d27ec87627b983ca35f2411b9e8","modified":1717578183846},{"_id":"themes/butterfly/layout/includes/third-party/chat/index.pug","hash":"1157118db9f5d7c0c5a0fc7c346f6e934ca00d52","modified":1717578183846},{"_id":"themes/butterfly/layout/includes/third-party/chat/messenger.pug","hash":"799da8f3015e6fe440681b21644bcb3810a5518c","modified":1717578183846},{"_id":"themes/butterfly/layout/includes/third-party/chat/tidio.pug","hash":"6d40b521eec4136f6742c548a4445ed593470b1b","modified":1717578183846},{"_id":"themes/butterfly/layout/includes/third-party/comments/artalk.pug","hash":"2dc9f36085ed33d040549fa3954e8fdecf1e5c6d","modified":1717578183847},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqus.pug","hash":"364d1fd655baca9132038ef1e312abde2c0bc7de","modified":1717578183847},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"f78c9c20c86d58c7cf099f6f8d6097103d7d43e5","modified":1717578183847},{"_id":"themes/butterfly/source/js/search/algolia.js","hash":"a7c2fe73cc05ad3525909b86ad0ede1a9f2d3b48","modified":1717578183901},{"_id":"themes/butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"11f5dca1432e59f22955aaf4ac3e9de6b286d887","modified":1717578183847},{"_id":"themes/butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"1c86c8fc1a28514a02a1f6a25ca9ec05eb3955b7","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/giscus.pug","hash":"1eab7ca1cb16c6786f9c3ca0efef8cc15e444ab4","modified":1717578183847},{"_id":"themes/butterfly/layout/includes/third-party/comments/js.pug","hash":"3abbaaa4ea575c45b3cebffd40bad1acc6ffce84","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/index.pug","hash":"db6713d2b90eb8183f86ac92c26761a8501c0ddb","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/livere.pug","hash":"09c2ef4bc6d005f96dfa48b1d9af1ec095c5266d","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/remark42.pug","hash":"7f450664e6323a076ae59c393b0f22167cfa82e5","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"0b44f6de0f5632b55298d506833f45dae46a6346","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/comments/utterances.pug","hash":"b65a42167df5fb07e2a63f312a58c321d3112a90","modified":1717578183848},{"_id":"themes/butterfly/layout/includes/third-party/math/index.pug","hash":"2afa4c21dd19890f47fb568cfb0d90efb676a253","modified":1717578183849},{"_id":"themes/butterfly/layout/includes/third-party/comments/valine.pug","hash":"4ed7c74087e81c6fcaf4fca7dced58b4e19f4cb1","modified":1717578183849},{"_id":"themes/butterfly/layout/includes/third-party/comments/waline.pug","hash":"a7d794987bde815607206254df6549a5a53e2cb0","modified":1717578183849},{"_id":"themes/butterfly/layout/includes/third-party/math/mathjax.pug","hash":"bb944185f4bb9f9a9b9d70ee215f66ccd6d4c6cf","modified":1717578183850},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/artalk.pug","hash":"6de0c412a4d9b65c576ec79e1949925823c90fa6","modified":1717578183850},{"_id":"themes/butterfly/layout/includes/third-party/math/katex.pug","hash":"f0d3eddd2bed68e5517274b3530bfe0fa5057d8e","modified":1717578183849},{"_id":"themes/butterfly/layout/includes/third-party/math/mermaid.pug","hash":"c682e4d61017fb0dd2e837bfcc242371f1a13364","modified":1717578183850},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"d8898e427acd91ceb97d6a7ee3acb011ca86b9fc","modified":1717578183850},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"f8b65460c399973090c1fb7ab81e3708c252e7cc","modified":1717578183851},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"fc8814bd016d039874ec2fc24dcb78587892e2a6","modified":1717578183851},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"0544d91c0bc9e26e0fe1b5ff490f4a8540ed1ee1","modified":1717578183852},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"17520a86de12ae585289463c066d3ac91b78a2ff","modified":1717578183851},{"_id":"themes/butterfly/layout/includes/third-party/search/algolia.pug","hash":"90338ac4cd114d324fe1caaaeea8be9ca05d6a46","modified":1717578183852},{"_id":"themes/butterfly/layout/includes/third-party/search/docsearch.pug","hash":"52a06a2e039f44383085333cac69f3f4e7d0ad3a","modified":1717578183853},{"_id":"themes/butterfly/layout/includes/third-party/search/index.pug","hash":"3adcf28a8d205ea3ee19828eda0e668702fac07a","modified":1717578183853},{"_id":"themes/butterfly/layout/includes/third-party/search/local-search.pug","hash":"420a86e73d0d748ac234fd00d06d9e433ca5e3f2","modified":1717578183853},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"ecfff55b2c7f6d87ce4d5028fdf9f8c0bf155c73","modified":1717578183851},{"_id":"themes/butterfly/layout/includes/third-party/share/addtoany.pug","hash":"1f02a26730e5f36cc2dfec7ff4d5c93a099ed5ba","modified":1717578183853},{"_id":"themes/butterfly/layout/includes/third-party/share/index.pug","hash":"c16ee69b5ca8db016db0508d014ae0867c4ce929","modified":1717578183853},{"_id":"themes/butterfly/layout/includes/third-party/share/share-js.pug","hash":"8106bd031586f075a994956ee4438eb13be25d7b","modified":1717578183854},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"a4e52188b6effeee1df2a01dcbf4105de76a61a8","modified":1717578183851},{"_id":"themes/butterfly/source/css/_highlight/highlight/index.styl","hash":"fc702a4614d0562a381907b083f71ba63d301d86","modified":1717578183866},{"_id":"themes/butterfly/source/css/_highlight/highlight/diff.styl","hash":"6e77f1ca0cfb0db6b028f5c0238780e66d344f3d","modified":1717578183866},{"_id":"themes/butterfly/source/css/_highlight/prismjs/diff.styl","hash":"1309292f1c8c53d96cd7333507b106bcc24ca8fc","modified":1717578183866},{"_id":"themes/butterfly/source/css/_highlight/prismjs/index.styl","hash":"01ff9e77eb1bd454bec65a6ff5972c8e219bc708","modified":1717578183868},{"_id":"source/_posts/iEDA-test/image-20230825154317023.png","hash":"7a1975b8bd90a1d2f21a1d2a3935d3484409e062","modified":1717578183797},{"_id":"themes/butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"7c9cc43e1d2577f7151039d58e603c30860fd281","modified":1717578183868},{"_id":"source/_posts/进程间的通信方式/image-20240130234556499.png","hash":"20d40b4a577854ace6eb9c63582074db879a5238","modified":1717578183825},{"_id":"source/_drafts/大话设计模式/image-20231008153018253.png","hash":"50691e5e0809c8e9fffe3965645d4101301b58b2","modified":1717578183324},{"_id":"source/_drafts/the-go-programming-language/top_img.png","hash":"7c8dfda83b70c5fffb637da49d3f165b52f61334","modified":1717578183319},{"_id":"source/_posts/AI-lab01/image-20230109194800246.png","hash":"a810c6a377c9e27832b4504ffa4ac3c654d854ff","modified":1717578183481},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104112951691.png","hash":"0972bd7591904fe1733153f47e7e74284fdc8707","modified":1717578183526},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG","hash":"09a82fb967e2f791df4bcc6f3c85ee4cc8148de2","modified":1717578183550},{"_id":"source/_posts/Physical-design/05.png","hash":"b714600899232e7fd337a5ea4e9c1d3624bfcbf1","modified":1717578183597},{"_id":"source/_posts/Physical-design/07.png","hash":"5b18271a81bc189831a4b41594298bc7dc034d2a","modified":1717578183601},{"_id":"source/_posts/database-mysql/image-20240223204149464.png","hash":"78214c52de1344e3cc86e96be117c2f47db2ea89","modified":1717578183683},{"_id":"source/_posts/进程间的通信方式/image-20240130234627976.png","hash":"aa7514d29a51d8d39068e1f27127c68c88501b9b","modified":1717578183827},{"_id":"themes/butterfly/source/img/default_cover02.jpg","hash":"871ca59ac35d61d63cdbc971d1238e74c59cc87e","modified":1717578183883},{"_id":"themes/butterfly/source/img/default_cover07.jpg","hash":"d4c52a125644bb0ab6ae9fb969aab95709bc0b0d","modified":1717578183887},{"_id":"themes/butterfly/source/img/default_cover01.jpg","hash":"1519bfd0b6c04b57aefa0bf72ca893b8e8747923","modified":1717578183882},{"_id":"themes/butterfly/source/img/default_cover03.jpg","hash":"d9e5a8a0908a7d64f04feb4ccff0de4023072889","modified":1717578183884},{"_id":"themes/butterfly/source/img/default_cover09.jpg","hash":"2d0404a37e5c23a63b0c8fcfd53e701f400bd680","modified":1717578183888},{"_id":"themes/butterfly/source/img/top1.jpg","hash":"a06a4f6d30842aa85a075c668cca0c1db6e37aaa","modified":1717578183900},{"_id":"themes/butterfly/source/img/default_cover08.jpg","hash":"2f7b5746a97539b5b47dddb47a571d3e5127b326","modified":1717578183888},{"_id":"source/_posts/AI-lab02/image-20230108225641834.png","hash":"cdb746614140d61fb22590564ee23344ef6ce8a2","modified":1717578183503},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/games101.png","hash":"1a98c119c680bafa350624b8da492f2c4fb24283","modified":1717578183523},{"_id":"source/_posts/Physical-design/06.png","hash":"7eee19a7c4a42c543be115a66062b5ce1fc495b2","modified":1717578183600},{"_id":"source/_posts/Physical-design/09.png","hash":"afb2f8b57d80ee3af77d52f0b31f6ec398c1f00d","modified":1717578183606},{"_id":"source/_posts/database-mysql/image-20240216162803064.png","hash":"d80d6df3550320d2e6b1dc5499772fb4f9297e85","modified":1717578183642},{"_id":"source/_posts/database-mysql/image-20240216162915509.png","hash":"a71b628d4448bb69cc84eaf2ff3310619701b361","modified":1717578183646},{"_id":"source/_posts/database-mysql/image-20240216162850762.png","hash":"a71b628d4448bb69cc84eaf2ff3310619701b361","modified":1717578183644},{"_id":"source/_posts/database-mysql/image-20240218221642388.png","hash":"71d50c0b9c73756391dbeed74775fd4db4393103","modified":1717578183666},{"_id":"source/_posts/database-mysql/image-20240218221539849.png","hash":"5066c5f9fef1b8e7e218baa3bb3fc172fc506c6a","modified":1717578183664},{"_id":"source/_posts/database-mysql/image-20240218221534161.png","hash":"5066c5f9fef1b8e7e218baa3bb3fc172fc506c6a","modified":1717578183661},{"_id":"source/_posts/database-mysql/image-20240218223950361.png","hash":"8f8cbaef5982874765d1c1a22ea909e01074e425","modified":1717578183671},{"_id":"source/_posts/database-mysql/image-20240218224016746.png","hash":"1e5fc6e8f4b410247d56509afce5304ff85c5a9f","modified":1717578183674},{"_id":"themes/butterfly/source/img/default_cover10.jpg","hash":"0d77d31bd95ea98a514df868a70fe615b335c92a","modified":1717578183891},{"_id":"themes/butterfly/source/img/default_cover06.jpg","hash":"c04e2d5366cd81379330aa4e077c8c41aeeae179","modified":1717578183886},{"_id":"themes/butterfly/source/img/top.jpg","hash":"85c08d94ad786052c9c34bb7555c9e43a4fb8972","modified":1717578183899},{"_id":"source/_posts/database-mysql/image-20240223203653517.png","hash":"d084d3eb93a438626579e5f1dbfa53a32e51991c","modified":1717578183681},{"_id":"source/_posts/eda-summary/image-20230818170602715.png","hash":"61b8f53ce68ef2354ca8b65aeaf108573241d090","modified":1717578183785},{"_id":"themes/butterfly/source/img/default_cover05.jpg","hash":"876dd4bf5f89d917cefa6b3db4eaeca142326718","modified":1717578183885},{"_id":"themes/butterfly/source/img/favicon.png","hash":"ec2d958aec90f0f78f63204dc666249245d82874","modified":1717578183897},{"_id":"source/_posts/Physical-design/03.png","hash":"bcac5d18221bbdc21f03cf7d0e6ae1ca377b6e83","modified":1717578183593},{"_id":"source/_posts/Physical-design/image-20230809095839094.png","hash":"3d6e10bcb14b102665d34a45a349aad85d51bb36","modified":1717578183615},{"_id":"source/_posts/database-mysql/image-20240218203730285.png","hash":"58aa795f7dd5051c2210c20e36c50eb6848a4894","modified":1717578183651},{"_id":"source/_posts/database-mysql/image-20240222075448991.png","hash":"9b23bcd5e8f05a32c19909eaf03ee069e62355cd","modified":1717578183678},{"_id":"source/_posts/Physical-design/image-20230809102800761.png","hash":"43051a95956721b471e180446e07068dcd25ccee","modified":1717578183620},{"_id":"source/_posts/Physical-design/image-20230809105341276.png","hash":"0a8b85f20725b8ce5d440f7ab674ed0c07f4b71c","modified":1717578183624},{"_id":"source/_posts/AI-lab01/image-20230109195226820.png","hash":"8dd27f9995d30fbdf90a2f81603f55892c6b0f1b","modified":1717578183485},{"_id":"source/_posts/Physical-design/11.png","hash":"d097de12fa663485e8dec52e0b65a527a36a3bf7","modified":1717578183612},{"_id":"source/_posts/distributed-system/image-20240302163915592.png","hash":"ec2dab00d76158052d326c1e82f94b0478fdbeeb","modified":1717578183770},{"_id":"themes/butterfly/source/img/default_cover.jpg","hash":"4f8150c0a22f0aa00b15350496ce262899a742ae","modified":1717578183881},{"_id":"source/_posts/AI-lab01/image-20230109205453040.png","hash":"af44d05d3c380b738a93d1073d0824f0d2687fb2","modified":1717578183498},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/games101.png","hash":"a2e563a31f101e2738c018c49d06a7852f6991a2","modified":1717578183553},{"_id":"source/_posts/Physical-design/01.png","hash":"5fc8fb1222d1a877c2cabcd4dc89f1735223a1a4","modified":1717578183587},{"_id":"themes/butterfly/source/img/default_cover11.jpg","hash":"5427333b6b3d3c2863912cfbe55808e912ea788e","modified":1717578183895},{"_id":"source/_posts/AI-lab01/image-20230109205438300.png","hash":"4aebdff7807f33b32b93bf3b1af5fbc763016f93","modified":1717578183494},{"_id":"source/_posts/eda-summary/EDA流程.jpg","hash":"05e7cde88fb8b372c27ee9a72bf6c40d1b589174","modified":1717578183782},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/games101_top.png","hash":"4aa5011abc438708eedf39a4d8dc56f84e4c9cf9","modified":1717578183558},{"_id":"source/_drafts/大话设计模式/设计模式 可复用面向对象软件的基础 ( etc.) (Z-Library).pdf","hash":"5395f2f469434d4a13000ccd3220517e25b367af","modified":1717578183463},{"_id":"public/search.xml","hash":"48423dc41b7c27aff4b402ed824e69fe2b26b6ee","modified":1720596380183},{"_id":"public/tags/index.html","hash":"dcae8cf0efa512e688d1cce7aed8461e9f5161af","modified":1720596380183},{"_id":"public/categories/index.html","hash":"49b6b5eaeb5baba3057013f892a5023b3ad48eb4","modified":1720596380183},{"_id":"public/2024/07/09/go-function/index.html","hash":"9bf3407eb0d3383432acbdb51c38202ec164a14e","modified":1720596380183},{"_id":"public/2024/06/26/design-model/index.html","hash":"d77e0a622fc5d5570ac51a1e7487961e5d341c83","modified":1720596380183},{"_id":"public/2024/03/06/c-priority-queue/index.html","hash":"f3cf5a208704462aec436e39e3a00e70253663d9","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/index.html","hash":"0c4885ef8a6dccd6a900f4ca931c25044d911c32","modified":1720596380183},{"_id":"public/2024/03/02/gcc-parameters/index.html","hash":"6803771c43b119eeed806ff1702c9753d9499278","modified":1720596380183},{"_id":"public/2024/02/27/build-sample-redis/index.html","hash":"2f769d7943699ea11c431976b4fee758d25381d4","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/index.html","hash":"585fb1270bbd7740480d875e75580b8eb37524cf","modified":1720596380183},{"_id":"public/2024/02/21/sort-algrithon/index.html","hash":"87f6445f93528fe05eca4a132d4c62fb87917636","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/index.html","hash":"2ba969d06b1178fedf7d43696248590582654179","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/index.html","hash":"5601519e3dbe69a25c40d5bdbc9746d18e673adb","modified":1720596380183},{"_id":"public/2024/01/26/C-使用zlib库来压缩文件/index.html","hash":"147a718bebd1a8e0725ff50ce584a5575507fa05","modified":1720596380183},{"_id":"public/2024/01/24/平方根倒数算法/index.html","hash":"fa99215f269d3012c74317d681ae4777149f4f9d","modified":1720596380183},{"_id":"public/2024/01/04/git/index.html","hash":"d72ed2cb936fec416f6fc1caa6a29b4c392106e3","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/index.html","hash":"dcfc9d69edeb551cf70015a14c2f07489bdcd894","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/index.html","hash":"6374803835b863e6c9a0263a8d17785981a3c387","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/index.html","hash":"a9cf69b7b2e038bdd794abc65d508e8a711e06c8","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/index.html","hash":"1102cdf8358385246e5d768eb051fc75df02452d","modified":1720596380183},{"_id":"public/2023/08/28/VLSI-Physical-Design/index.html","hash":"b3d3b040dd2329e290ebe541ad7c6a1183eb30f2","modified":1720596380183},{"_id":"public/2023/08/26/static-timing-analysis/index.html","hash":"9958afb27f9bffe83079dd5231daf6c4f1171a59","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/index.html","hash":"e57ce897310a893d48bf875f456829e9e4674afe","modified":1720596380183},{"_id":"public/2023/08/15/Effective-Modern-C-notes/index.html","hash":"a3991e1254e25409865d55b73b9ef4ffe89da684","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/index.html","hash":"4917ebb8c966ecf9b364d5780e3f481a2cfe51cc","modified":1720596380183},{"_id":"public/2023/07/26/cmake-study/index.html","hash":"c7cb25cd536cae539f07ce0d1e7b696d96fb02ca","modified":1720596380183},{"_id":"public/2023/07/21/c-primer-plus/index.html","hash":"c55281b2314738df38f50f3d93df15a4231b4f6f","modified":1720596380183},{"_id":"public/2023/03/02/pytorch-use/index.html","hash":"b27c67750181eeb366db31386d9771f81bc40cca","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/index.html","hash":"82a381fafdd82a228c69a68298663812b672f869","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/index.html","hash":"674bbceeaefa3cfc66e38804109cbed472eeb7e4","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/index.html","hash":"dc29d854f5cefe4f15f2b4439f1059f417dda50f","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/index.html","hash":"edcad30a67d754c8446c5275f517a5bcdbe5d466","modified":1720596380183},{"_id":"public/2023/02/02/pytorch-install/index.html","hash":"d55c0fd0f1c41c333a00d80a8674bfb6d7361a3c","modified":1720596380183},{"_id":"public/2023/01/21/deep-learning-test05/index.html","hash":"5c4b8ff34e784c288ba69781f2f73ad9c28e5535","modified":1720596380183},{"_id":"public/2023/01/15/deep-learning-test04/index.html","hash":"ce4cb87c1e6e471a1fe52ee8b66abd6e2b5a0dc4","modified":1720596380183},{"_id":"public/2023/01/08/deep-learning-test03/index.html","hash":"02e4a730f8e61b4261c6f9ab7802d78a787537ae","modified":1720596380183},{"_id":"public/2023/01/04/deep-learning-test02/index.html","hash":"76b1bf7cb42d36e2a104d41e209d2cf44f34bae3","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/index.html","hash":"c0cd8a5f2ca2c84b04bd190f6342781e81d09959","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/index.html","hash":"644c2b1992c5f9824bf1f3c84a9769c98b3ed275","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/index.html","hash":"fd6fd7771ff20f9a7f04634a1e54f86ef6a9a7c6","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/index.html","hash":"effe2ad75549a642b8c954d6ed6345d07d4cd70b","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/index.html","hash":"cf1f65a8e0d9ffb27ecabf5a4b476da059e8c66a","modified":1720596380183},{"_id":"public/archives/index.html","hash":"3c5bb46285226e31dce2f586c1f0a132c40e4e01","modified":1720596380183},{"_id":"public/archives/page/2/index.html","hash":"33fbf301d8b80bb95595d7f5f5911d6470d8a2b7","modified":1720596380183},{"_id":"public/archives/page/4/index.html","hash":"0cc617a3ce5b5b213e152193fbe47ba6d063afa1","modified":1720596380183},{"_id":"public/archives/page/3/index.html","hash":"b24cab44c048bd580e2fcbdd5a588c848d6370ae","modified":1720596380183},{"_id":"public/archives/2022/index.html","hash":"c964938a51728717e5218341e81d2c6d7e0d6b84","modified":1720596380183},{"_id":"public/archives/2022/10/index.html","hash":"a2e39b7c636ca628878fdfa2141faf96bd8d67bc","modified":1720596380183},{"_id":"public/archives/2022/09/index.html","hash":"ad2c671332508a2f3b629d0c1e633f9b508b15f0","modified":1720596380183},{"_id":"public/archives/2023/index.html","hash":"f6d416e35d963defd84564bebd0a0762a71ba038","modified":1720596380183},{"_id":"public/archives/2023/page/2/index.html","hash":"e4e102978dee7a4414353e3fb785617122cbc960","modified":1720596380183},{"_id":"public/archives/2023/page/3/index.html","hash":"037e68d45c23cc52028f2f6de4ff5654c921c2b8","modified":1720596380183},{"_id":"public/archives/2023/01/index.html","hash":"f5d81933928085b80e4e90be6d2d0a0caf34620b","modified":1720596380183},{"_id":"public/archives/2023/03/index.html","hash":"ca3fa94f7d4259aabc3cb0782df142bd4558773d","modified":1720596380183},{"_id":"public/archives/2023/02/index.html","hash":"91cde69afaef95a0cbb0a2cce4c171ab681dafd7","modified":1720596380183},{"_id":"public/archives/2023/08/index.html","hash":"d973d7cedb3c8411eee99108b59db973b4d5bbcf","modified":1720596380183},{"_id":"public/archives/2023/07/index.html","hash":"54e1b4c747b8bd1c4598e3ee2f00e08ebfe7e87f","modified":1720596380183},{"_id":"public/archives/2023/09/index.html","hash":"49303a6d4af94b2868c14be6b27a0017eb2e1571","modified":1720596380183},{"_id":"public/archives/2023/12/index.html","hash":"d5b49d24a6f2ea3c813af4d4a8b8dac2386146e4","modified":1720596380183},{"_id":"public/archives/2024/index.html","hash":"13c6cf5405f5b9d3902eca47476a5c408b80e89b","modified":1720596380183},{"_id":"public/archives/2024/page/2/index.html","hash":"b681b2a34fcca9de27a2ddc0757de57314e1abbe","modified":1720596380183},{"_id":"public/archives/2024/01/index.html","hash":"55bff2b6121dc23d85365cf70fb9921dc46321f5","modified":1720596380183},{"_id":"public/archives/2024/02/index.html","hash":"14df654b898291cf2ec78bb43f4c9cbea9a713ea","modified":1720596380183},{"_id":"public/archives/2024/03/index.html","hash":"a64073d3f73c3385e4babd90a49fcaba2c87cd14","modified":1720596380183},{"_id":"public/archives/2024/06/index.html","hash":"c45bd86b8e3c2fc3082f0aeebac3046634b3a6b1","modified":1720596380183},{"_id":"public/archives/2024/07/index.html","hash":"89595fa9524d55bd68c19e37927b1d5b7dd79a0e","modified":1720596380183},{"_id":"public/categories/学习笔记/index.html","hash":"62982a64234d6405a0efe5ca32b6559ee96ed82d","modified":1720596380183},{"_id":"public/categories/学习笔记/page/2/index.html","hash":"40ef4164daa446425e6d02e5773730f732dbcd38","modified":1720596380183},{"_id":"public/categories/算法实践/index.html","hash":"3195aae28c12724f30e6e5c74be3efe9e712374a","modified":1720596380183},{"_id":"public/categories/算法实践/page/2/index.html","hash":"ef71ee3378abce2c139f8cfcd9c4a6221c24be09","modified":1720596380183},{"_id":"public/categories/技术研究/index.html","hash":"d41c6cb7e6bc38a910837344a9662a0b0765416a","modified":1720596380183},{"_id":"public/index.html","hash":"134a22867aaf85765ec1c0212587eb3010eb4d64","modified":1720596380183},{"_id":"public/categories/技术研究/page/2/index.html","hash":"a90046185d20b3e0dc633f705b3ec259e6ef319c","modified":1720596380183},{"_id":"public/page/2/index.html","hash":"586824aa9f012bd4abcf6610b098f9072a5ea257","modified":1720596380183},{"_id":"public/page/4/index.html","hash":"310d8fb414677cb1e611ba24d2fd3a7aa40fe641","modified":1720596380183},{"_id":"public/page/3/index.html","hash":"9c4fe27eea464e5e7ac73203b423af602f24a3e7","modified":1720596380183},{"_id":"public/page/5/index.html","hash":"b41ed62103f5932d6d657bfc58c5d793046da067","modified":1720596380183},{"_id":"public/tags/CMU15445/index.html","hash":"5f5bb9dc08775b5ac5ed35c86b4235559aa82ca2","modified":1720596380183},{"_id":"public/tags/数据库/index.html","hash":"cf7b850988ddf98133b2a5d10e7f30cc69e2be89","modified":1720596380183},{"_id":"public/tags/人工智能/index.html","hash":"3aa5c0c78d9f138bd96bc6fbf41e8c329cc25b93","modified":1720596380183},{"_id":"public/tags/深度学习/index.html","hash":"87c16bc21d6a379d3a030488813ec2d86b7bd425","modified":1720596380183},{"_id":"public/tags/C/index.html","hash":"91a08f6eda0e6e0ff5034a258afbd8839a5531ab","modified":1720596380183},{"_id":"public/tags/zlib/index.html","hash":"258dc3acf81c407326b6b99a642779b4c402bde1","modified":1720596380183},{"_id":"public/tags/C-新特性/index.html","hash":"4535a981d5c64f296e55dec4d216a52e67e35ff0","modified":1720596380183},{"_id":"public/tags/计算机图形学/index.html","hash":"6a15e587737a7ccdb9eeb21570753e97f8a46fad","modified":1720596380183},{"_id":"public/tags/GAMES101/index.html","hash":"979698fb0e4eb656749e1663f20a8008e9b2e416","modified":1720596380183},{"_id":"public/tags/物理设计/index.html","hash":"a8ad3583d524dfc6f0790901c5d0ff9e275565cb","modified":1720596380183},{"_id":"public/tags/集成电路/index.html","hash":"ff4d77414385ae1409f7a78cd55d3215004f9e30","modified":1720596380183},{"_id":"public/tags/EDA/index.html","hash":"b9673ebfd3f2dfbcf38e8c7a28ec66bece73ec42","modified":1720596380183},{"_id":"public/tags/Pyhsical-Design/index.html","hash":"7e4f00cfc92c357d359cdf5d7f4fd5de98b68c42","modified":1720596380183},{"_id":"public/tags/电子设计自动化/index.html","hash":"83de8b62dcf16afb517bce4161e5be8089d42473","modified":1720596380183},{"_id":"public/tags/VLSI/index.html","hash":"4eb0e6dc40883d34952c6edddcbc8cd30d486eaf","modified":1720596380183},{"_id":"public/tags/Redis/index.html","hash":"dc74b3df21a3cb6e987fa75287732ea13fed9782","modified":1720596380183},{"_id":"public/tags/A-算法/index.html","hash":"fff553b28cb09ff1aeda241eb54599ab2580c700","modified":1720596380183},{"_id":"public/tags/数据库缓存/index.html","hash":"45be1f378a3d95792186542eeba7c87eea6530ee","modified":1720596380183},{"_id":"public/tags/C-进阶/index.html","hash":"ae3feefb2fb8135b224e1506c5ce6c80475567e9","modified":1720596380183},{"_id":"public/tags/优先队列/index.html","hash":"4f503736b0cbf700fdfe866d0bb3f4649ada5095","modified":1720596380183},{"_id":"public/tags/Cmake/index.html","hash":"be6ce880a90ea5cbef4155593e08b53493d757af","modified":1720596380183},{"_id":"public/tags/编译/index.html","hash":"e6fa24f9b42c40f610e888b5e84c3f9ae20d8297","modified":1720596380183},{"_id":"public/tags/Mysql/index.html","hash":"e241b93722a7947cfab13d0af6cfa8b04af9db30","modified":1720596380183},{"_id":"public/tags/Database/index.html","hash":"caf65061e0d2e0891a5c7dc17683879fa05b0972","modified":1720596380183},{"_id":"public/tags/SQL/index.html","hash":"4ef136cabe83bbe547f8c0868db88f315c9e14eb","modified":1720596380183},{"_id":"public/tags/神经网络/index.html","hash":"d88f12072e4d4fff2e6391bddd79a6084f8e22f1","modified":1720596380183},{"_id":"public/tags/数字图像/index.html","hash":"d066bc43ad66c31c1d6f6547c8a04affd4220d5d","modified":1720596380183},{"_id":"public/tags/OpenCV/index.html","hash":"5584c3bd9efd91c0a94ff5770a6d5d1f057ea716","modified":1720596380183},{"_id":"public/tags/设计模式/index.html","hash":"809691eca15d3c9c8f212f9c77a678946dc1048b","modified":1720596380183},{"_id":"public/tags/UML/index.html","hash":"034e8119e16ca4b77352334697605a018ed7109f","modified":1720596380183},{"_id":"public/tags/软件工程/index.html","hash":"fc82673ec4e583889cbadaec735b725705674a7e","modified":1720596380183},{"_id":"public/tags/分布式系统/index.html","hash":"fe71a6baa5143de126663d247b80250a94d7a073","modified":1720596380183},{"_id":"public/tags/布局/index.html","hash":"8a2cc0a861470fa9c294cb13744fe58dbbebd50e","modified":1720596380183},{"_id":"public/tags/GCC/index.html","hash":"4d1eef05328014ec7c75ce4c04d9050f2879f1c8","modified":1720596380183},{"_id":"public/tags/布线/index.html","hash":"b0d6a38727998de4cd7a3ce6f2075efd9bf3faa9","modified":1720596380183},{"_id":"public/tags/G/index.html","hash":"364f9eac0a2655c26cd84ff7d8263d3627e9788c","modified":1720596380183},{"_id":"public/tags/Golang/index.html","hash":"2b5d1f51960020366827c7718d1e84f98328a31b","modified":1720596380183},{"_id":"public/tags/git/index.html","hash":"eb3bf160fb27c79b3c09b54d3df39696709c9867","modified":1720596380183},{"_id":"public/tags/开源项目/index.html","hash":"c98e4a9187620f5593a29022bcad52ad3907f4b3","modified":1720596380183},{"_id":"public/tags/iEDA/index.html","hash":"43c40834ea8f931811e7a9eea91279c35e3e7792","modified":1720596380183},{"_id":"public/tags/AI/index.html","hash":"5d9086cc8ae8ce4268af6893ffd1367d8040f206","modified":1720596380183},{"_id":"public/tags/PyTorch/index.html","hash":"34b8b0db3cb313ae299bb90f100b6489ba8c97de","modified":1720596380183},{"_id":"public/tags/DeepLearning/index.html","hash":"b1de8a317efb4f43cbb4ec34828ae14f47664978","modified":1720596380183},{"_id":"public/tags/算法/index.html","hash":"3d116dc5885400a700fa73eaead70b008df78650","modified":1720596380183},{"_id":"public/tags/排序/index.html","hash":"c2385e85e8b46459d2217fa33aaaa214cbb0ed52","modified":1720596380183},{"_id":"public/tags/冒泡排序/index.html","hash":"95c8e3fccb9d569471ed5d679c1dd4897213f545","modified":1720596380183},{"_id":"public/tags/选择排序/index.html","hash":"7fa81e3c748fa6c463d548a4a9ec2ae482b763ec","modified":1720596380183},{"_id":"public/tags/插入排序/index.html","hash":"ce805dc547e626a5671c0ec750e36fd7073a2a2c","modified":1720596380183},{"_id":"public/tags/快速排序/index.html","hash":"9722421f81d2dd0c2026845755bd2b6d093e88eb","modified":1720596380183},{"_id":"public/tags/归并排序/index.html","hash":"548282877fad006b362daa0ed5b0999cc5552219","modified":1720596380183},{"_id":"public/tags/计数排序/index.html","hash":"2c8997067862ad67e273d2d501ab3d1c651d2270","modified":1720596380183},{"_id":"public/tags/堆排序/index.html","hash":"23111005e524b934b952f2bd2eb8fcd4aac266c1","modified":1720596380183},{"_id":"public/tags/静态时序分析/index.html","hash":"35fbeedeaff323ad12e3836736b46db66920ded0","modified":1720596380183},{"_id":"public/tags/并行/index.html","hash":"25d1800b3c10b36b2ba77be5d01a98d68c8487b1","modified":1720596380183},{"_id":"public/tags/多线程/index.html","hash":"6e751202bf5b58b23a08bceb85d7e89b7eba5bb6","modified":1720596380183},{"_id":"public/tags/数学/index.html","hash":"a989a36ccaac7dbf7c00fae60e51e8f1cf757492","modified":1720596380183},{"_id":"public/tags/Thread/index.html","hash":"ac4825a97b9040937e39c584bcf8084b64a4f91b","modified":1720596380183},{"_id":"public/tags/操作系统/index.html","hash":"424083066a8989ae17ddba03d492eb1c15020898","modified":1720596380183},{"_id":"public/tags/进程通信/index.html","hash":"da184a5fa174de95ac84a87ffa25141c7e48bda6","modified":1720596380183},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1720596380183},{"_id":"public/img/default_cover04.jpg","hash":"9870826d979b563c27cb3c15b3603fd867119a9d","modified":1720596380183},{"_id":"public/img/favicon1.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1720596380183},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109194724331.png","hash":"de08743103c9cec6a2365f52c4fd5c622a186218","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109205407961.png","hash":"05c92b8d240dd575bf4c2170efc7ca63e33fb852","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109222224342.png","hash":"ee876ce2faae0d4c39aba3d724dfd41ec12a86b4","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240110074224104.png","hash":"ff87dfb43af777dc2dffe53f12d614189c0012ec","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108230000075.png","hash":"db6e0d5250387cb053b814d857a90b5ad06bccc5","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108232154796.png","hash":"fa0721b26fefc9055699a9a240c7d167fc07966a","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111212922711.png","hash":"6758bfe386595a662ad738d94bba95a87f07dacb","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111213029737.png","hash":"57a25a65b36662d680e0bcac13a5ff69141e8904","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221612234.png","hash":"132fdfe29312f1b3306ab9a39fd3567306914cad","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221801614.png","hash":"8b25554cc48d203f1ab131b513a3f70e53bea245","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221914620.png","hash":"9f611e12340ed140b7218ec376c9b69f124ebbce","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221947792.png","hash":"d88631f8d8f83be69257bf1f9be4b360ae9840bd","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104165645532-17084112899535.png","hash":"713d7afbd431798d5715bec456b9f2de1b61bf93","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231116154858801-17084112899536.png","hash":"beccf9c890c54d964fb72d81cab34ea965672e03","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104165645532.png","hash":"713d7afbd431798d5715bec456b9f2de1b61bf93","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231116154858801.png","hash":"beccf9c890c54d964fb72d81cab34ea965672e03","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231116155210293-17084112899537.png","hash":"68a2653c7b86805026326fd91fd2987475c74ea3","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231116155210293.png","hash":"68a2653c7b86805026326fd91fd2987475c74ea3","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/1.jpg","hash":"e5a312ef814273e207c2ad1fa64eb28fee4db905","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803171605818.png","hash":"9c7f08e1cb2f20a60e8e1f984d63c7278d261f2e","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803171645811.png","hash":"71a6e8198ff01241f81e886811355e51e92bd412","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173053255.png","hash":"f706f73cb488dacdbc7d6fb8e679da6ec7c987b3","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803172210807.png","hash":"90cb9863c4fb5d4b396cf3650a8f82a29f0bf9c6","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173212434.png","hash":"7502e50c7f04f80f23ed44383a35744e104c8242","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173141837.png","hash":"3dd68c5fff946186a679d5cdc88157743adb724c","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173244879.png","hash":"82084ca1b9e5146c8325fdc596d9e24d1f09d708","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173754572.png","hash":"120e2d3db10bf256e965d41194e32cf01f96d759","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173808529.png","hash":"98a11b085814996f5289a833456875edd25f6bbd","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803183655944.png","hash":"4695c1253ee703d882d422531bc08789ae08eb8a","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803173329009.png","hash":"d6cb3a8c2c4c7d18bb9053377199c187b73d8c19","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803183939400.png","hash":"b5eb9982fe89c5dfb232b31a23ba31aeafd023d7","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/问题：插入优先队列以后没有更新f值.png","hash":"88c67cc5972ca585cd17d75589281cffd81b9b63","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116165833300.png","hash":"1df24f5f6956685a0e7de541460502be6186593a","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116165833300-17084118809565.png","hash":"1df24f5f6956685a0e7de541460502be6186593a","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116171041924-17084118809567.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116171040632.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116171041924.png","hash":"ca9ef6cf8fd95302600171e190ea1a3d230fb79c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231118142833380-170841188095612.png","hash":"d43526ac594854d0fec88480beddf17b456bac52","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231118142833380.png","hash":"d43526ac594854d0fec88480beddf17b456bac52","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218204502697.png","hash":"16d59bdcc21b422a885e7da177c5458e43b38f16","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218211138993.png","hash":"a7bf2310f5850960d3a45b2f4479af922ef0f18d","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240222075706155.png","hash":"b8ef4f1a6aa4db264aaa2a640f65bb6354fe0f15","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/innodb-architecture-8-0.png","hash":"994699ac624cd3cf72cff8d7330953c27af67bc1","modified":1720596380183},{"_id":"public/2023/01/08/deep-learning-test03/output_9_1.png","hash":"9f49c03f3e12d5640bb68156cbf498088a5d522c","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_15_1.png","hash":"0fa1d12e8c9332228c13b5d0d04c574c74f992e5","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_11_0.png","hash":"005a447a4d83c2cf4fb66a9841c49d25314c380c","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_16_0.png","hash":"db30f56c26578f3b6cc68b82c7daf2f6acae7859","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_20_3.png","hash":"f22af73919d8a54df32e95d63cd710ba9f945c63","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_21_0.png","hash":"2f748b1d2882a25546794868a450532a5e09f7be","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_3_0.png","hash":"fe2d4182f533e158c4eb9aafad60712a5fce509a","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_6_0.png","hash":"b54b94fac0446dc20a309ef559a1a98204c1fb7c","modified":1720596380183},{"_id":"public/2023/01/03/deep-learning-test01/output_8_0.png","hash":"de244bd271c5de5f1ad83132eae74d397de98733","modified":1720596380183},{"_id":"public/2023/01/04/deep-learning-test02/output_7_1.png","hash":"c0459b50d809a7be2f9bfb62d476e96c527c0fec","modified":1720596380183},{"_id":"public/2023/01/15/deep-learning-test04/output_5_1.png","hash":"e833f87fcbfb72c08ec23225353abf943f23d28b","modified":1720596380183},{"_id":"public/2023/01/15/deep-learning-test04/output_4_3.png","hash":"ea660388e6b31a820d3b1249a52f627538d1aee9","modified":1720596380183},{"_id":"public/2023/01/21/deep-learning-test05/output_5_1.png","hash":"7e1c3674d08ec1d7e1a6599148fa737b70a6279b","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183514481.png","hash":"ed67b77864295c9228c3e4aec87afc4a5ba26933","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/clip_image002.jpg","hash":"4d2b642a3936f19f390dc75fa7db783f87f81ba5","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/clip_image006.jpg","hash":"e09a8a5c1b2d326160ffd8fa9f60d018bad23d9a","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/clip_image004.jpg","hash":"4f2dd7ec35b589d894f2c520597bf5e9ef536fa9","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/clip_image008.jpg","hash":"16d789a1c5c452a0b6ca951f46fd604ea4606c5e","modified":1720596380183},{"_id":"public/2024/06/26/design-model/享元模式_01.png","hash":"51fdf3d666d8ee67aa17b8fcb0ab7727727361a6","modified":1720596380183},{"_id":"public/2024/06/26/design-model/单例模式_01.png","hash":"0d1fd59cae8648fb7fc0426f227ee1ba79e2cda0","modified":1720596380183},{"_id":"public/2024/06/26/design-model/装饰器模式_01.png","hash":"6ad8d211df694d765048bbd99216584a94003134","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/clip_image004.jpg","hash":"c7141a99d0271d358bb75fbb8741af9035884269","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/clip_image002.jpg","hash":"ce0b1361e63f247e3a3d85c0035fcc47146c5037","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130092344725.png","hash":"36eb80cb202a3a754ef4612e2158ab5d7d546f5d","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201101403269.png","hash":"5b3affe183507f68a7a2c2569953e3971e65f9b0","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201100317779.png","hash":"907fc393e7b3ab9117adbaaa5ade3921899b0914","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201152139305.png","hash":"7ab682cf8830c07f54a74874e252640b4afc7e18","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/image-20230818160028154.png","hash":"17d0ca9f8f8b1df113d03f0a62b73d7739354bff","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/image-20230828141138808.png","hash":"67b75defcfb622cbf689297fb0a5358d5280e667","modified":1720596380183},{"_id":"public/2023/02/02/pytorch-install/image-20221022164808915.png","hash":"bcbdd8f68e81b289cefc616d1ffdd12541daf94f","modified":1720596380183},{"_id":"public/2023/02/02/pytorch-install/image-20221022163847897.png","hash":"cb93468290fe61cadf8f42a4073093719b8cce4a","modified":1720596380183},{"_id":"public/2023/02/02/pytorch-install/image-20221022165103111.png","hash":"d50f9960ad59e993547e4b4ba01fa5ff7dd3a476","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230823094215828.png","hash":"bc275d04d9d87c210227f5c85bd1c62b4199c2ad","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230830164051317.png","hash":"f742d4d59f322dc38e0ef2037a099a90583af9a1","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204112945547.png","hash":"eff5ebfc4a4c5539cfd8dfd9c4b5dfed83f0fe11","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204113208566.png","hash":"be5c376a4091dc37070325f85951ccb5cd214e74","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204113304822.png","hash":"8c059b88dc8eac379a01ff2b842f59bc9c7dfcc7","modified":1720596380183},{"_id":"public/2023/08/26/static-timing-analysis/image-20230811144505780.png","hash":"2776435c62fa5ab2fe49673976ac93568435ef93","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303195554869.png","hash":"0d482d1d7d7a945503be97e4db85ea48da11d336","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303200213188.png","hash":"871b2c542bcdc97e75ad9a07f3292cc3a9f64871","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303211229196.png","hash":"b9873430670ca696c34479e70c246159f14737ee","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303224717307.png","hash":"e53ec25c7b4d7667a587f22a7921a3cfa3e1a9f5","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303224732958.png","hash":"1f3d5b2670846843298a7955e599ad16ff70c95e","modified":1720596380183},{"_id":"public/2024/01/24/平方根倒数算法/运算过程.png","hash":"452225103f084e7ffb3be1aa9d5609cc1e505016","modified":1720596380183},{"_id":"public/img/default_cover02.jpg","hash":"871ca59ac35d61d63cdbc971d1238e74c59cc87e","modified":1720596380183},{"_id":"public/img/default_cover01.jpg","hash":"1519bfd0b6c04b57aefa0bf72ca893b8e8747923","modified":1720596380183},{"_id":"public/img/default_cover07.jpg","hash":"d4c52a125644bb0ab6ae9fb969aab95709bc0b0d","modified":1720596380183},{"_id":"public/img/default_cover03.jpg","hash":"d9e5a8a0908a7d64f04feb4ccff0de4023072889","modified":1720596380183},{"_id":"public/img/default_cover08.jpg","hash":"2f7b5746a97539b5b47dddb47a571d3e5127b326","modified":1720596380183},{"_id":"public/img/default_cover09.jpg","hash":"2d0404a37e5c23a63b0c8fcfd53e701f400bd680","modified":1720596380183},{"_id":"public/img/top1.jpg","hash":"a06a4f6d30842aa85a075c668cca0c1db6e37aaa","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109195428838.png","hash":"56c9ed863359439eaec39b12422bdf3af8abaf3c","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109195525256.png","hash":"ae8fb8d6bea32dca2b1110e6f4220ceb9be7b4f3","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109205151944.png","hash":"e74cd3670406715575f05596d36be5da665e688d","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109214257445.png","hash":"cf1d5cf393bd050b32841213dff96872d7c89376","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240110074349028.png","hash":"750177e6ff0eaeedb2eee94ef776719946db6675","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108225724739.png","hash":"947058b7de0bb007e1cd18a5f00d795cdb1b30ce","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108232106204.png","hash":"91dfef5746aafbd3422b483d998a0d3aee839bfd","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111213218547.png","hash":"4a85d2793b3aca9cd27ebbb9436bbb705d3c0b5f","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111213428993.png","hash":"d651403b46774fb0aaa19016b491840c34f1cb5c","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111215240888.png","hash":"bc5329ac982db92a7050b850013fc68543c6309f","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111213530417.png","hash":"1ff3a24456b2e36456203cf125dd76818f0bbbf5","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221331595.png","hash":"b2eb279a3987817b3ba614c854351c501043a7eb","modified":1720596380183},{"_id":"public/2023/02/18/AI-lab03/image-20230111221851068.png","hash":"9fd9b060323fb2f715a3fad6ad2da0dce03285be","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164540980.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164606082.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164542395.png","hash":"9aa07539cca172c5f9acefa3543c964048bc6de6","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164849274.png","hash":"c74c7c09c3192ca3b60bbe42fcd0964a57326f6a","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164849274-17084112899534.png","hash":"c74c7c09c3192ca3b60bbe42fcd0964a57326f6a","modified":1720596380183},{"_id":"public/2023/07/28/a-star-assignment/image-20230803165730214.png","hash":"5cebe4d13a1306f6e7e3e29e7832b18d5f98684c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161524873-17084118809551.png","hash":"9876f75069bbf3c2b82109404ef8039fe9d3cdc0","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161524873.png","hash":"9876f75069bbf3c2b82109404ef8039fe9d3cdc0","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161727694.png","hash":"2b54f27a1f295261f97ed01b913f5807155ca5df","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161727694-17084118809562.png","hash":"2b54f27a1f295261f97ed01b913f5807155ca5df","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116170519094.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116170520355-17084118809566.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116170520355.png","hash":"e7f0c7e589386f9da1127b7ec7e3da50aa8de0d3","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116201110927.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116201112834.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116201112834-17084118809569.png","hash":"356119b35abde3da95cbc63e7f3194b8ab55e77c","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116201139440-170841188095610.png","hash":"f10b268c53316cdc2f77b6168d2d5803ac1416fd","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116201139440.png","hash":"f10b268c53316cdc2f77b6168d2d5803ac1416fd","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240224162152111.png","hash":"e9757e26efec7b79170625394e4c31c35dec09bb","modified":1720596380183},{"_id":"public/2023/01/08/deep-learning-test03/output_1_0.png","hash":"c0b6814794f3bdfd29ae9ffce768032db0c7640b","modified":1720596380183},{"_id":"public/2023/01/21/deep-learning-test05/output_4_1.png","hash":"e167d4b910938fd8e62e0e1c40cfdcd124a8cfa1","modified":1720596380183},{"_id":"public/2023/01/21/deep-learning-test05/output_3_1.png","hash":"925e17b936dc91fa3e275f7becf3dd61098d0add","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183504049.png","hash":"9eaec3478a6158bb510e0fd0078c1871657fd852","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183527447.png","hash":"1eb035325a31521e4b46c4863b9e6acf1a470b96","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183532846.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183534696.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183456769.png","hash":"f19b8dc52627b273302c6e8e784cc636c9c65bb4","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183542527.png","hash":"2bc0d96822c9874d6e8093666c0a9aa81d54b19b","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184201998.png","hash":"116ee52638a1fe8a5b14bab8e96eed1b7a7d949c","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184304968.png","hash":"0880ccf1b96833dff27f2d5d2c16c6e410d4115e","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184311057.png","hash":"5fe1362196610b88b62f880ff5b5bde8563c32e2","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184323543.png","hash":"8e3df318d5913ccb606dfb31f86c82e8bfdb38fc","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184327658.png","hash":"fd4d65ada72a3370930e7b115df48fc154e1c2a6","modified":1720596380183},{"_id":"public/2024/06/26/design-model/工厂模式_01.png","hash":"8617574fbf418804bb4aee58abeb43190fa5f3e6","modified":1720596380183},{"_id":"public/2024/06/26/design-model/策略模式_01.png","hash":"3d0eef75b783abc24edda15c47be9d3f1453f512","modified":1720596380183},{"_id":"public/2024/06/26/design-model/适配器模式_01.png","hash":"a479e248c898c9ced1457aa8ad1b61770f7a36d8","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302184920811.png","hash":"68e67eb5fa6be752ced2a0b78d427d9e35f6d96e","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302184935209.png","hash":"30b56fd672041792c01d8051c7c80d55adfbed8f","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302184940449.png","hash":"e5f333c1c3dd3a5ad45b8fc9060ee9be8d2a930d","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302184959151.png","hash":"aee0cd427420de8d15003e1d2435de3ed14b8720","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185608155.png","hash":"1785fd7cb2602a5b57d96da41aed305e90a7188b","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185735104.png","hash":"9019c41b6177657c28f7b940bfe05d15970a964d","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185739084.png","hash":"6c663b9ac00259bfafd0c42612e00dd2837d035a","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185751435.png","hash":"550dc1109ae1fbd554541dd5fbfcbc053288eaa1","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185800747.png","hash":"9fe19b1c3019710648f2e907d52490261825e8dd","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185829105.png","hash":"51fbeb4a630ac6499cca2d56c7395a2e2599504b","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221126155754925.png","hash":"4a37affbab2b1fe64687dae0de2783eed009a2c6","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130091729650.png","hash":"312965394dfce6471c4850d1abb42e9464f24947","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130094553260.png","hash":"568d9c6520c41c288f11efb324930bf79d7b1842","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130101048848.png","hash":"5fdd4316cca7d714106ddf55231eb81505fbb4ed","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130101949954.png","hash":"99fdd6a6cb70e09938f2e9c4875b71040cfd2e29","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130102217372.png","hash":"17f927304c1564c7ba8c1ee0b8aee8e5452d5584","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130143607842.png","hash":"9e317509c1e92c8e09cdce0392fe620c0956927c","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130151005907.png","hash":"d997ca239954fa5012c4da72f7d465ad132628ee","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201110722218.png","hash":"2407b86f90b047e2736a5e0e5578c473460b49a6","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201111903470.png","hash":"5dc9ceedd1ec606b9c3b18b2a44e640fa6a35b0e","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201151303341.png","hash":"187b0a34e086caa4bb298ac620e3c9c3c57f680c","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201160233164.png","hash":"eb2b547c2f2ead7bd3f09d6d71aba6569153889a","modified":1720596380183},{"_id":"public/assets/algolia/algoliasearchLite.min.js","hash":"982e19bbba01db904832ad94ecffb5c75036181a","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204110955462.png","hash":"a0eb304ceda27842d706b29f5dd93e231ce5b5cb","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204111125551.png","hash":"225fa0eec9bca8d94a18d88c25a06a7a80c95de9","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204111350240.png","hash":"b10c40f287f5e8933502801fe32cb3562b3f5236","modified":1720596380183},{"_id":"public/2024/01/04/git/image-20231204113100512.png","hash":"dea8dd3f1ac6c962555a2122bedaed5565c2f11b","modified":1720596380183},{"_id":"public/2023/08/26/static-timing-analysis/image-20230810165634110.png","hash":"2fd44bcb4a89e9c304263e68f765a303fe8959ef","modified":1720596380183},{"_id":"public/2023/08/26/static-timing-analysis/image-20230817160931612.png","hash":"71d115d34de1efcc6987686ed1ca11a50e0055e2","modified":1720596380183},{"_id":"public/2023/08/26/static-timing-analysis/image-20230817160942849.png","hash":"5a486b9adb7f4ff40a02b60e4ef4c98f5165ac13","modified":1720596380183},{"_id":"public/2024/03/03/thread-pool/image-20240303214601818.png","hash":"733412290daa5076a9e22dec9c83f0bba4340ea9","modified":1720596380183},{"_id":"public/2024/01/24/平方根倒数算法/WTF.png","hash":"58a5cfc1e84918f49258973ec18f362bee15a510","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130223824673.png","hash":"936c1b00abc4de2fb48bb478b04683e98d9f2fd3","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130223920751.png","hash":"936c1b00abc4de2fb48bb478b04683e98d9f2fd3","modified":1720596380183},{"_id":"public/assets/algolia/algoliasearchLite.js","hash":"0cc2b1c6000e9941268768ad3aff2ed9d6f1856f","modified":1720596380183},{"_id":"public/assets/algolia/algoliasearch.min.js","hash":"43d4529ba2f1204484109138f2bd7ff25afa24ff","modified":1720596380183},{"_id":"public/css/index.css","hash":"57ca0dc0906ca46518668e83b0f0473a2fff7ff0","modified":1720596380183},{"_id":"public/js/tw_cn.js","hash":"f8d2e3f31468991a7f5171cbfdb157dfb86d3372","modified":1720596380183},{"_id":"public/js/main.js","hash":"0dac585446445e0c419b86eec5580bc9b0657dc6","modified":1720596380183},{"_id":"public/js/search/local-search.js","hash":"e1f60ebac53a3f596fd0a4769b4f9275c48c6542","modified":1720596380183},{"_id":"public/js/utils.js","hash":"8e6b48d294e7aeaba8ff6348c43b2271cf865547","modified":1720596380183},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1720596380183},{"_id":"public/js/search/algolia.js","hash":"108988d046da9a4716148df43b3975217c8ceaae","modified":1720596380183},{"_id":"public/img/default_cover06.jpg","hash":"c04e2d5366cd81379330aa4e077c8c41aeeae179","modified":1720596380183},{"_id":"public/img/default_cover10.jpg","hash":"0d77d31bd95ea98a514df868a70fe615b335c92a","modified":1720596380183},{"_id":"public/img/top.jpg","hash":"85c08d94ad786052c9c34bb7555c9e43a4fb8972","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109204708818.png","hash":"69f49c2e2c78078b2ceb541f12c957e7141acaa2","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240102201317281.png","hash":"ae0106e357ed06333658ee7bdef6e14a6d94eeee","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240104193223551.png","hash":"02de891a2a2b95714763852bc4c97b8d12742c04","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108225530690.png","hash":"16633adf480e18afad9edfb9706cd24b1e0678ab","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108225829669.png","hash":"c0ca95caa0c7727a6e0e075182eda7549d6ee3e0","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108230820413.png","hash":"ba6b52c8ad007be7e0fa26632bbb366ed21bcbcf","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104113201064.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104113151777-17084112899531.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104113151777.png","hash":"371116c9fa15e1f073c48e143e356dcf0ec6eda6","modified":1720596380183},{"_id":"public/2023/08/28/VLSI-Physical-Design/image-20230817170808037.png","hash":"04e7f1818a6281b74aa2dee03409e18471cc4fc7","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161842894-17084118809563.png","hash":"8baa04211e4bf3b301d6a804e2d00f80c9c58479","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116161842894.png","hash":"8baa04211e4bf3b301d6a804e2d00f80c9c58479","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116164956551-17084118809564.png","hash":"3fa6c847173dd62697db1c1ada123010901501b4","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116164956551.png","hash":"3fa6c847173dd62697db1c1ada123010901501b4","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116200444279-17084118809568.png","hash":"0e3d6cc22828451b4bda030dfc545529f8728afb","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231116200444279.png","hash":"0e3d6cc22828451b4bda030dfc545529f8728afb","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231118142130480.png","hash":"4f03cb3c8844b6927cc1877cdf73b1a9b230f649","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/image-20231118142130480-170841188095611.png","hash":"4f03cb3c8844b6927cc1877cdf73b1a9b230f649","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240210160421874.png","hash":"8f012f4795a0b4b44d76204a6dbd9e7f569c8f14","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218221919863.png","hash":"6b143cda1f4a832532a3b02eaf4f17f822419218","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240224161313751.png","hash":"c22629a9ef8578a6b472f3bfd6c9c86f244a12b1","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240224162626695.png","hash":"c5a7671a2abd79128c7a4255e69cb6181ddcc483","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240224162359110.png","hash":"d9826c326353f5172f46e1c020e7df3625cf0304","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/Mysql.png","hash":"a88e0da8c928deb7a463092864da4ca1457807b9","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184347311.png","hash":"6385a53a8f2661faaa5062e65369370d75b792d1","modified":1720596380183},{"_id":"public/2024/06/26/design-model/工厂模式_02.png","hash":"12b28b1b9ee39f2084782a5cd37b049d4ec38848","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302184950081.png","hash":"e3b8144f6e8ffd3170ad9d7a961ccf94655379c1","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185003442.png","hash":"366b01d6f4d5c858e65f08e0f75b032b3d899f58","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185107213.png","hash":"efbac1d1bcbc29a4816c0e740b8c6ae5004820c8","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185116864.png","hash":"1dd79621438c7aa54217c3169f6b928e4c36907d","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185557410.png","hash":"dec299ecf1e17fa9fb56c5ba45a039346478fb62","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185602980.png","hash":"351b2bcbdffaaaefd115e26523100389c7597f7c","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185819182.png","hash":"6c47c050490bb1ee356305db1e8486acd712e3e4","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221126155708747.png","hash":"2cca3a046e1c6ae144e77252997c48d1bbf5a78a","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221130140722941.png","hash":"4edff4d31fb00553540fd3892c043eb27ac44cd7","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20221201101451311.png","hash":"bad34f96ded3a9edf19a070ec2fb24b01d5821dd","modified":1720596380183},{"_id":"public/2023/02/02/pytorch-install/image-20221022174307472.png","hash":"620299e154d25aa984858b6c0de4463d0ae04451","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825151306959.png","hash":"0df18ea78a4f268e388c1b10442de81c71ddcca7","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825163454933.png","hash":"69cc59dce88945050bd47531a2af7df73f5bf5d6","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130232827259.png","hash":"fbf784ce1ad312d9fd7a41e90b73d800ae2e0fba","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130224638178.png","hash":"3fc74a884e2c346ccf3ff5bdfb1c8d0923d91404","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130234754230.png","hash":"fd658ca22bb8d21052c0f10e8225855134402c10","modified":1720596380183},{"_id":"public/img/default_cover05.jpg","hash":"876dd4bf5f89d917cefa6b3db4eaeca142326718","modified":1720596380183},{"_id":"public/img/favicon.png","hash":"ec2d958aec90f0f78f63204dc666249245d82874","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240102163927925.png","hash":"835c1bc441be67e2da17b4b550b474c785343a28","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240103093506806.png","hash":"8d00b741b53e6b1b23bcfabbb60331de2b19b6d8","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240105160547664.png","hash":"695d1971c93fc9ceaf23c7a18403a8723116a2f6","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240112101151040.png","hash":"1da823c64043e26203c966c27e1c3821972ee29f","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108232000280.png","hash":"ca753ebf56536e860051ba576b2170e15a85071e","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164704660-17084112899533.png","hash":"cfeacbbd7028c9598c655135169d4cc611841ee4","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104164704660.png","hash":"cfeacbbd7028c9598c655135169d4cc611841ee4","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/04.png","hash":"60627afbe440f95a1180b3c2cfe3e21cd170ec7c","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/10.png","hash":"8a6e2cab074a24548e9072a45291d086fe85bdbe","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218212115878.png","hash":"86bcc05425e727adec4a58fb0d8d8374c43d6ac8","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218212814126.png","hash":"55a69f62cda07a32605ef6c451eea99ff5772d1b","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240224160500080.png","hash":"ab1e8d4f492b59b2049221c023ea2dac807c8f9b","modified":1720596380183},{"_id":"public/2023/01/04/deep-learning-test02/output_8_0.png","hash":"8285366797bbd72661390991cd0e0d999970ca0b","modified":1720596380183},{"_id":"public/2022/09/20/digital-image-test01/image-20240302183548286.png","hash":"90b569a59fa4e779b8c4565635df2b99db96fc2e","modified":1720596380183},{"_id":"public/2022/09/23/digital-image-test02/image-20240302184359230.png","hash":"c7063a871d07faafe5ddec46c1eca9fafb1a52bb","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185124222.png","hash":"4dc84e6280aed0d365d93ea1ed03b3a059e47d38","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185113358.png","hash":"e82688778c37c6cad03ee7fbdc7ef928f3753728","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185128004.png","hash":"335b2aafe3f4821d5bcc65b836390a7e7fc0c88d","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185142206.png","hash":"08a44975c9da8f96c580be8dc62f23226e99e8b7","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185150777.png","hash":"eed151640e2fce651a386269e4d2e3aaa9450b55","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185837682.png","hash":"901eb2404f60f2120d55dc83e73ed1aaa44e6729","modified":1720596380183},{"_id":"public/2022/10/19/digital-image-test04/image-20240302185841933.png","hash":"2f1c8e67c6531051ff75110648fd02a5dd5ac694","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20240302165702511.png","hash":"9cc11dc79058db54a75cb2d7b167fe4de0e572e7","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20240302165713656.png","hash":"e755af0748d67a4de1370c9a2920fceb1a16e913","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20240302165721466.png","hash":"59284da26e73ad92d5200f2f12ffeca45a74b4f9","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/image-20230828144127572.png","hash":"7730241829f60a3bcb280ab502120bf743da1ecb","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825164152609.png","hash":"921020aab17eee59e62aeca3c62a5bb562ce6712","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825163939716.png","hash":"6544a9c9eddc58256e34bfe6dfcf0d910447a409","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825164459060.png","hash":"6714a3049410eda061550d135f76892e864614eb","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230830164032304.png","hash":"dffccf2ddd62ef2de9ccb4022fed8908783f0586","modified":1720596380183},{"_id":"public/assets/algolia/algoliasearch.js","hash":"5ac1ea04228fc1fe7ba0e8d5d7e92422a6898352","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240104092359606.png","hash":"0f8926021c96616358c973b3f4991f6e63bb4276","modified":1720596380183},{"_id":"public/2024/02/10/15445-study-notes-01-04/image-20240112102928169.png","hash":"a8f53689a4e42bb8e6823138a7eacc9967016310","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104150955701-17084112899532.png","hash":"d1faec91913f175c08eea064a74a7ac6c5be6003","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104150955701.png","hash":"d1faec91913f175c08eea064a74a7ac6c5be6003","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/02.png","hash":"abcdbc15dc9043f37449c8f9a02b11da173085f6","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/08.png","hash":"c44f7bc0629b47dd2d2f3c4f3af61eb295d30c93","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240216163439353.png","hash":"839776a0910307166c289c050a25f340654055af","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218212542921.png","hash":"0c5e855a8d2f1c2b6b256a96be4e664183c26035","modified":1720596380183},{"_id":"public/2022/10/02/digital-image-test03/image-20240302185159151.png","hash":"5a657950d87c7c53ddf068f1c2ed127f42c1bdf8","modified":1720596380183},{"_id":"public/2023/09/10/iEDA-test/image-20230825154317023.png","hash":"7a1975b8bd90a1d2f21a1d2a3935d3484409e062","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130234556499.png","hash":"20d40b4a577854ace6eb9c63582074db879a5238","modified":1720596380183},{"_id":"public/2024/01/30/进程间的通信方式/image-20240130234627976.png","hash":"aa7514d29a51d8d39068e1f27127c68c88501b9b","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109194800246.png","hash":"a810c6a377c9e27832b4504ffa4ac3c654d854ff","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/image-20231104112951691.png","hash":"0972bd7591904fe1733153f47e7e74284fdc8707","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/07.png","hash":"5b18271a81bc189831a4b41594298bc7dc034d2a","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/05.png","hash":"b714600899232e7fd337a5ea4e9c1d3624bfcbf1","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG","hash":"09a82fb967e2f791df4bcc6f3c85ee4cc8148de2","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240223204149464.png","hash":"78214c52de1344e3cc86e96be117c2f47db2ea89","modified":1720596380183},{"_id":"public/2023/02/12/AI-lab02/image-20230108225641834.png","hash":"cdb746614140d61fb22590564ee23344ef6ce8a2","modified":1720596380183},{"_id":"public/2023/12/15/GAMES101现代计算机图形学入门-01/games101.png","hash":"1a98c119c680bafa350624b8da492f2c4fb24283","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/09.png","hash":"afb2f8b57d80ee3af77d52f0b31f6ec398c1f00d","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/06.png","hash":"7eee19a7c4a42c543be115a66062b5ce1fc495b2","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240216162803064.png","hash":"d80d6df3550320d2e6b1dc5499772fb4f9297e85","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240216162850762.png","hash":"a71b628d4448bb69cc84eaf2ff3310619701b361","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240216162915509.png","hash":"a71b628d4448bb69cc84eaf2ff3310619701b361","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218221539849.png","hash":"5066c5f9fef1b8e7e218baa3bb3fc172fc506c6a","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218221642388.png","hash":"71d50c0b9c73756391dbeed74775fd4db4393103","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218221534161.png","hash":"5066c5f9fef1b8e7e218baa3bb3fc172fc506c6a","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218223950361.png","hash":"8f8cbaef5982874765d1c1a22ea909e01074e425","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218224016746.png","hash":"1e5fc6e8f4b410247d56509afce5304ff85c5a9f","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240223203653517.png","hash":"d084d3eb93a438626579e5f1dbfa53a32e51991c","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/image-20230818170602715.png","hash":"61b8f53ce68ef2354ca8b65aeaf108573241d090","modified":1720596380183},{"_id":"public/img/default_cover.jpg","hash":"4f8150c0a22f0aa00b15350496ce262899a742ae","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/03.png","hash":"bcac5d18221bbdc21f03cf7d0e6ae1ca377b6e83","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/image-20230809095839094.png","hash":"3d6e10bcb14b102665d34a45a349aad85d51bb36","modified":1720596380183},{"_id":"public/img/default_cover11.jpg","hash":"5427333b6b3d3c2863912cfbe55808e912ea788e","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240218203730285.png","hash":"58aa795f7dd5051c2210c20e36c50eb6848a4894","modified":1720596380183},{"_id":"public/2024/02/10/database-mysql/image-20240222075448991.png","hash":"9b23bcd5e8f05a32c19909eaf03ee069e62355cd","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/image-20230809105341276.png","hash":"0a8b85f20725b8ce5d440f7ab674ed0c07f4b71c","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/image-20230809102800761.png","hash":"43051a95956721b471e180446e07068dcd25ccee","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109195226820.png","hash":"8dd27f9995d30fbdf90a2f81603f55892c6b0f1b","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/11.png","hash":"d097de12fa663485e8dec52e0b65a527a36a3bf7","modified":1720596380183},{"_id":"public/2023/03/02/distributed-system/image-20240302163915592.png","hash":"ec2dab00d76158052d326c1e82f94b0478fdbeeb","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109205453040.png","hash":"af44d05d3c380b738a93d1073d0824f0d2687fb2","modified":1720596380183},{"_id":"public/2023/08/09/Physical-design/01.png","hash":"5fc8fb1222d1a877c2cabcd4dc89f1735223a1a4","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/games101.png","hash":"a2e563a31f101e2738c018c49d06a7852f6991a2","modified":1720596380183},{"_id":"public/2023/02/02/AI-lab01/image-20230109205438300.png","hash":"4aebdff7807f33b32b93bf3b1af5fbc763016f93","modified":1720596380183},{"_id":"public/2023/09/04/eda-summary/EDA流程.jpg","hash":"05e7cde88fb8b372c27ee9a72bf6c40d1b589174","modified":1720596380183},{"_id":"public/2023/12/16/GAMES101现代计算机图形学入门-02/games101_top.png","hash":"4aa5011abc438708eedf39a4d8dc56f84e4c9cf9","modified":1720596380183}],"Category":[{"name":"学习笔记","_id":"clyfintte000908jv0ltv0uyy"},{"name":"算法实践","_id":"clyfintth000e08jv8c5eaakv"},{"name":"技术研究","_id":"clyfinttn000w08jv6x5og5vf"}],"Data":[],"Page":[{"title":"标签","date":"2024-01-26T15:53:19.000Z","type":"tags","orderby":"random","order":1,"_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2024-01-26 23:53:19\ntype: \"tags\"\norderby: random\norder: 1\n---\n","updated":"2024-06-05T09:03:03.829Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clyfintt5000008jv068e7p7z","content":"","cover":"/img/default_cover01.jpg","cover_type":"img","excerpt":"","more":""},{"title":"分类","date":"2024-01-26T15:56:15.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2024-01-26 23:56:15\ntype: \"categories\"\n---\n","updated":"2024-06-05T09:03:03.828Z","path":"categories/index.html","comments":1,"layout":"page","_id":"clyfintta000208jva12wbtsb","content":"","cover":"/img/default_cover07.jpg","cover_type":"img","excerpt":"","more":""}],"Post":[{"title":"设计模式","date":"2024-02-22T03:34:52.000Z","cover":"/img/default_cover03.jpg","top_img":null,"_content":"## 设计模式原则\n\n设计模式原则通常指的是设计模式中所遵循的一些基本原则或准则，这些原则有助于指导软件设计的过程，并确保设计出高质量、可维护、可扩展的软件系统。以下是常见的几种设计模式原则：\n\n1. **单一职责原则（Single Responsibility Principle，SRP）**：一个类应该只有一个引起变化的原因。换句话说，一个类应该只负责一种类型的任务或功能。\n\n   一个类不应该承担太多的职责，不同职责中可能会存在互相牵连，这样的类耦合性会很高，不利于类的复用。\n\n   **优点**：类和方法的职责划分清晰，能够提高代码可读性，同时降低程序出错的风险，降低维护成本。\n\n2. **开放-封闭原则（Open-Closed Principle，OCP）**：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。意思是在不修改原有代码的情况下，通过扩展来添加新的功能或行为。\n\n   抽象化是开闭原则的关键，抽象层应当是稳定的，类似于在C++中的底层类会提供接口，抽象类，虚函数等机制作为抽象层的拓展应用，通过具体类的实现来完成拓展。如果需要修改系统的行为，正确的方式应当是增加新的具体类来实现新的业务。\n\n   **优点**：增加程序的可拓展性，降低程序维护成本，因为对底层的变动影响是很大的，越是抽象和底层的东西，上层的依赖就会越高。\n\n3. **里氏替换原则（Liskov Substitution Principle，LSP）**：子类必须能够替换其父类并出现在父类能够出现的任何地方，而不改变程序的正确性。\n\n   如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类。但是我喜欢狗，不能据此断定我喜欢动物。\n\n   面向对象的多态就是遵循的里氏替换原则，基类指针可以指向不同的子类对象。子类对象中会继承基类对象的属性和方法，并根据不同的子类对象应用场景进行重写。\n\n   **优点**：可以检验继承使用的正确性，约束继承在使用上的泛滥\n\n4. **依赖倒置原则（Dependency Inversion Principle，DIP）**：高层模块不应该依赖于低层模块，两者都应该依赖于抽象。换句话说，不应该直接依赖具体的实现细节，而是应该依赖于抽象接口或类。\n\n   应当针对接口编程，而不是针对实现编程。\n\n5. **接口隔离原则（Interface Segregation Principle，ISP）**：不应该强迫客户端依赖于它们不需要的接口。应该将大的接口分割成更小、更具体的接口，以便客户端只需知道与其相关的方法。\n\n6. **合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）**：优先使用对象组合（合成）或聚合，而不是继承来达到代码复用的目的。\n\n开闭原则（Open-Closed Principle，OCP）\n\n里氏替换原则（Liskov Substitution Principle，LSP）\n\n依赖倒置原则（Dependency Inversion Principle，DIP）\n\n单一职责原则（Single Responsibility Principle，SRP）\n\n迪米特法则\n\n接口分离原则（Interface Segregation Principle，ISP）\n\n合成复用原则（Composite/Aggregate Reuse Principle，CARP）\n\n\n\n// TODO\n\n常见的设计模式\n\n工厂模式\n\n单例模式\n\n适配器模式\n\n外观模式\n\n代理模式\n\n包装模式（装饰器模式）\n\n桥接模式\n\n模板方法模式\n\n策略模式\n\n观察者模式\n\n职责链模式\n","source":"_drafts/design-mode-principle.md","raw":"---\ntitle: 设计模式\ndate: 2024-02-22 11:34:52\ntags: [设计模式, 软件工程]\ncategories: 技术研究\ncover:\ntop_img:\n---\n## 设计模式原则\n\n设计模式原则通常指的是设计模式中所遵循的一些基本原则或准则，这些原则有助于指导软件设计的过程，并确保设计出高质量、可维护、可扩展的软件系统。以下是常见的几种设计模式原则：\n\n1. **单一职责原则（Single Responsibility Principle，SRP）**：一个类应该只有一个引起变化的原因。换句话说，一个类应该只负责一种类型的任务或功能。\n\n   一个类不应该承担太多的职责，不同职责中可能会存在互相牵连，这样的类耦合性会很高，不利于类的复用。\n\n   **优点**：类和方法的职责划分清晰，能够提高代码可读性，同时降低程序出错的风险，降低维护成本。\n\n2. **开放-封闭原则（Open-Closed Principle，OCP）**：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。意思是在不修改原有代码的情况下，通过扩展来添加新的功能或行为。\n\n   抽象化是开闭原则的关键，抽象层应当是稳定的，类似于在C++中的底层类会提供接口，抽象类，虚函数等机制作为抽象层的拓展应用，通过具体类的实现来完成拓展。如果需要修改系统的行为，正确的方式应当是增加新的具体类来实现新的业务。\n\n   **优点**：增加程序的可拓展性，降低程序维护成本，因为对底层的变动影响是很大的，越是抽象和底层的东西，上层的依赖就会越高。\n\n3. **里氏替换原则（Liskov Substitution Principle，LSP）**：子类必须能够替换其父类并出现在父类能够出现的任何地方，而不改变程序的正确性。\n\n   如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类。但是我喜欢狗，不能据此断定我喜欢动物。\n\n   面向对象的多态就是遵循的里氏替换原则，基类指针可以指向不同的子类对象。子类对象中会继承基类对象的属性和方法，并根据不同的子类对象应用场景进行重写。\n\n   **优点**：可以检验继承使用的正确性，约束继承在使用上的泛滥\n\n4. **依赖倒置原则（Dependency Inversion Principle，DIP）**：高层模块不应该依赖于低层模块，两者都应该依赖于抽象。换句话说，不应该直接依赖具体的实现细节，而是应该依赖于抽象接口或类。\n\n   应当针对接口编程，而不是针对实现编程。\n\n5. **接口隔离原则（Interface Segregation Principle，ISP）**：不应该强迫客户端依赖于它们不需要的接口。应该将大的接口分割成更小、更具体的接口，以便客户端只需知道与其相关的方法。\n\n6. **合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）**：优先使用对象组合（合成）或聚合，而不是继承来达到代码复用的目的。\n\n开闭原则（Open-Closed Principle，OCP）\n\n里氏替换原则（Liskov Substitution Principle，LSP）\n\n依赖倒置原则（Dependency Inversion Principle，DIP）\n\n单一职责原则（Single Responsibility Principle，SRP）\n\n迪米特法则\n\n接口分离原则（Interface Segregation Principle，ISP）\n\n合成复用原则（Composite/Aggregate Reuse Principle，CARP）\n\n\n\n// TODO\n\n常见的设计模式\n\n工厂模式\n\n单例模式\n\n适配器模式\n\n外观模式\n\n代理模式\n\n包装模式（装饰器模式）\n\n桥接模式\n\n模板方法模式\n\n策略模式\n\n观察者模式\n\n职责链模式\n","slug":"design-mode-principle","published":0,"updated":"2024-06-05T09:03:03.315Z","comments":1,"layout":"post","photos":[],"_id":"clyfintt8000108jvbrja2tgy","content":"<h2 id=\"设计模式原则\"><a href=\"#设计模式原则\" class=\"headerlink\" title=\"设计模式原则\"></a>设计模式原则</h2><p>设计模式原则通常指的是设计模式中所遵循的一些基本原则或准则，这些原则有助于指导软件设计的过程，并确保设计出高质量、可维护、可扩展的软件系统。以下是常见的几种设计模式原则：</p>\n<ol>\n<li><p><strong>单一职责原则（Single Responsibility Principle，SRP）</strong>：一个类应该只有一个引起变化的原因。换句话说，一个类应该只负责一种类型的任务或功能。</p>\n<p>一个类不应该承担太多的职责，不同职责中可能会存在互相牵连，这样的类耦合性会很高，不利于类的复用。</p>\n<p><strong>优点</strong>：类和方法的职责划分清晰，能够提高代码可读性，同时降低程序出错的风险，降低维护成本。</p>\n</li>\n<li><p><strong>开放-封闭原则（Open-Closed Principle，OCP）</strong>：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。意思是在不修改原有代码的情况下，通过扩展来添加新的功能或行为。</p>\n<p>抽象化是开闭原则的关键，抽象层应当是稳定的，类似于在C++中的底层类会提供接口，抽象类，虚函数等机制作为抽象层的拓展应用，通过具体类的实现来完成拓展。如果需要修改系统的行为，正确的方式应当是增加新的具体类来实现新的业务。</p>\n<p><strong>优点</strong>：增加程序的可拓展性，降低程序维护成本，因为对底层的变动影响是很大的，越是抽象和底层的东西，上层的依赖就会越高。</p>\n</li>\n<li><p><strong>里氏替换原则（Liskov Substitution Principle，LSP）</strong>：子类必须能够替换其父类并出现在父类能够出现的任何地方，而不改变程序的正确性。</p>\n<p>如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类。但是我喜欢狗，不能据此断定我喜欢动物。</p>\n<p>面向对象的多态就是遵循的里氏替换原则，基类指针可以指向不同的子类对象。子类对象中会继承基类对象的属性和方法，并根据不同的子类对象应用场景进行重写。</p>\n<p><strong>优点</strong>：可以检验继承使用的正确性，约束继承在使用上的泛滥</p>\n</li>\n<li><p><strong>依赖倒置原则（Dependency Inversion Principle，DIP）</strong>：高层模块不应该依赖于低层模块，两者都应该依赖于抽象。换句话说，不应该直接依赖具体的实现细节，而是应该依赖于抽象接口或类。</p>\n<p>应当针对接口编程，而不是针对实现编程。</p>\n</li>\n<li><p><strong>接口隔离原则（Interface Segregation Principle，ISP）</strong>：不应该强迫客户端依赖于它们不需要的接口。应该将大的接口分割成更小、更具体的接口，以便客户端只需知道与其相关的方法。</p>\n</li>\n<li><p><strong>合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）</strong>：优先使用对象组合（合成）或聚合，而不是继承来达到代码复用的目的。</p>\n</li>\n</ol>\n<p>开闭原则（Open-Closed Principle，OCP）</p>\n<p>里氏替换原则（Liskov Substitution Principle，LSP）</p>\n<p>依赖倒置原则（Dependency Inversion Principle，DIP）</p>\n<p>单一职责原则（Single Responsibility Principle，SRP）</p>\n<p>迪米特法则</p>\n<p>接口分离原则（Interface Segregation Principle，ISP）</p>\n<p>合成复用原则（Composite/Aggregate Reuse Principle，CARP）</p>\n<p>// TODO</p>\n<p>常见的设计模式</p>\n<p>工厂模式</p>\n<p>单例模式</p>\n<p>适配器模式</p>\n<p>外观模式</p>\n<p>代理模式</p>\n<p>包装模式（装饰器模式）</p>\n<p>桥接模式</p>\n<p>模板方法模式</p>\n<p>策略模式</p>\n<p>观察者模式</p>\n<p>职责链模式</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"设计模式原则\"><a href=\"#设计模式原则\" class=\"headerlink\" title=\"设计模式原则\"></a>设计模式原则</h2><p>设计模式原则通常指的是设计模式中所遵循的一些基本原则或准则，这些原则有助于指导软件设计的过程，并确保设计出高质量、可维护、可扩展的软件系统。以下是常见的几种设计模式原则：</p>\n<ol>\n<li><p><strong>单一职责原则（Single Responsibility Principle，SRP）</strong>：一个类应该只有一个引起变化的原因。换句话说，一个类应该只负责一种类型的任务或功能。</p>\n<p>一个类不应该承担太多的职责，不同职责中可能会存在互相牵连，这样的类耦合性会很高，不利于类的复用。</p>\n<p><strong>优点</strong>：类和方法的职责划分清晰，能够提高代码可读性，同时降低程序出错的风险，降低维护成本。</p>\n</li>\n<li><p><strong>开放-封闭原则（Open-Closed Principle，OCP）</strong>：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。意思是在不修改原有代码的情况下，通过扩展来添加新的功能或行为。</p>\n<p>抽象化是开闭原则的关键，抽象层应当是稳定的，类似于在C++中的底层类会提供接口，抽象类，虚函数等机制作为抽象层的拓展应用，通过具体类的实现来完成拓展。如果需要修改系统的行为，正确的方式应当是增加新的具体类来实现新的业务。</p>\n<p><strong>优点</strong>：增加程序的可拓展性，降低程序维护成本，因为对底层的变动影响是很大的，越是抽象和底层的东西，上层的依赖就会越高。</p>\n</li>\n<li><p><strong>里氏替换原则（Liskov Substitution Principle，LSP）</strong>：子类必须能够替换其父类并出现在父类能够出现的任何地方，而不改变程序的正确性。</p>\n<p>如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类。但是我喜欢狗，不能据此断定我喜欢动物。</p>\n<p>面向对象的多态就是遵循的里氏替换原则，基类指针可以指向不同的子类对象。子类对象中会继承基类对象的属性和方法，并根据不同的子类对象应用场景进行重写。</p>\n<p><strong>优点</strong>：可以检验继承使用的正确性，约束继承在使用上的泛滥</p>\n</li>\n<li><p><strong>依赖倒置原则（Dependency Inversion Principle，DIP）</strong>：高层模块不应该依赖于低层模块，两者都应该依赖于抽象。换句话说，不应该直接依赖具体的实现细节，而是应该依赖于抽象接口或类。</p>\n<p>应当针对接口编程，而不是针对实现编程。</p>\n</li>\n<li><p><strong>接口隔离原则（Interface Segregation Principle，ISP）</strong>：不应该强迫客户端依赖于它们不需要的接口。应该将大的接口分割成更小、更具体的接口，以便客户端只需知道与其相关的方法。</p>\n</li>\n<li><p><strong>合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）</strong>：优先使用对象组合（合成）或聚合，而不是继承来达到代码复用的目的。</p>\n</li>\n</ol>\n<p>开闭原则（Open-Closed Principle，OCP）</p>\n<p>里氏替换原则（Liskov Substitution Principle，LSP）</p>\n<p>依赖倒置原则（Dependency Inversion Principle，DIP）</p>\n<p>单一职责原则（Single Responsibility Principle，SRP）</p>\n<p>迪米特法则</p>\n<p>接口分离原则（Interface Segregation Principle，ISP）</p>\n<p>合成复用原则（Composite/Aggregate Reuse Principle，CARP）</p>\n<p>// TODO</p>\n<p>常见的设计模式</p>\n<p>工厂模式</p>\n<p>单例模式</p>\n<p>适配器模式</p>\n<p>外观模式</p>\n<p>代理模式</p>\n<p>包装模式（装饰器模式）</p>\n<p>桥接模式</p>\n<p>模板方法模式</p>\n<p>策略模式</p>\n<p>观察者模式</p>\n<p>职责链模式</p>\n"},{"title":"Go语言基本语法","date":"2023-12-14T09:16:50.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"\n## 基本语法\n\n### GO语言特性\n\n* 并发编程\n\n  Go语言中引入了`goroutine`，通过调用`go`关键字，可以让函数以goroutine的方式进行运行，以协程为单位进行运行。\n\n  协程相比线程更加轻量级，也更节省系统资源。\n\n  goroutine内部采用管道`channel`进行消息传递，从而实现共享内存。\n\n* 错误处理\n\n  函数通过返回错误类型`error`或者`bool`类型表明函数执行结果，通过判断返回值是否为`nil`。\n\n  引入了defer关键字用于标准的错误处理流程，提供内置函数`panic`，`recover`完成异常抛出和捕捉\n\n* 垃圾回收\n\n  自带自动回收功能，不需要`delete`和`free`来释放内存\n\n* 多返回值\n\n  支持多返回值，可以用下划线作为占用符丢掉不要的返回值\n\n* 匿名函数\n\n  支持常规的匿名函数和闭包\n\n```go\n// hello.go\n\npackage main\n\nimport (\n    \"fmt\" //导入fmt包，调用其中的Println()函数\n)\n\nfunc main() {\n    fmt.Println(\"Hello，world！\")\n}\n```\n\n### 数据类型\n\n* 常量\n\n  使用`const`声明，可以限定常量类型，也可以不指定类型（称为字面常量）\n\n```\nconst limit = 512\nconst top uint16 = 1421\nconst Pi float64 = 3.1415926\n// 多重赋值\nconst x,y int = 1,2\n\n// 多个常量赋值\nconst (\n\tone = 1\n\ttwo = 2\n)\n```\n\n* iota\n\n  `iota`是一个可以被编译器修改的常量，在`const`关键字出现时被重置为`0`，在下一个`const`出现之前，每出现一次`iota`，所代表的数字自动加1\n\n```\nconst (\n    a = iota  //a == 0\n    b = iota  //b ==1\n    c = iota  //c == 2\n)\n\nconst d = iota //d==0,因为const的出现，iota被重置为0\n```\n\n* 变量\n\n  变量使用`var`进行声明，可以使用`:=`对变量之间进行初始化，Go编译器会自动推导出该变量的类型\n\n* 整型\n\n  可以通过`unsafe.Sizeof`函数来查看字节长度\n\n| 类型      | 说明                                                         |\n| :-------- | :----------------------------------------------------------- |\n| `byte`    | 等同于 uint8，uint8的别名                                    |\n| `int`     | 依赖于不同平台下的实现，可以是 int32 或者 int64              |\n| `int8`    | [-128, 127]                                                  |\n| `int16`   | [-32768, 32767]                                              |\n| `int32`   | [-2147483648, 2147483647]                                    |\n| `int64`   | [-9223372036854775808, 9223372036854775807]                  |\n| `rune`    | 等同于 int32，代表Unicode字符类型                            |\n| `uint`    | 依赖于不同平台下的实现，可以是 uint32 或者 uint64            |\n| `uint8`   | [0, 255]                                                     |\n| `uint16`  | [0, 65535]                                                   |\n| `uint32`  | [0, 4294967295]                                              |\n| `uint64`  | [0, 18446744073709551615]                                    |\n| `uintptr` | 一个可以恰好容纳指针值的无符号整型（对 32 位平台是 uint32, 对 64 位平台是 uint64） |\n\n* 浮点类型\n\n| 类型      | 说明                                                         |\n| --------- | ------------------------------------------------------------ |\n| float32   | ±3.402 823 466 385 288 598 117 041 834 845 169 254 40x1038 计算精度大概是小数点后 7 个十进制数 |\n| float64   | ±1.797 693 134 862 315 708 145 274 237 317 043 567 981x1038 计算精度大概是小数点后 15 个十进制数 |\n| complex32 | 复数，实部和虚部都是 float32                                 |\n| complex64 | 复数，实部和虚部都是 float64                                 |\n\n* 布尔类型\n\n  `true`和`false`：布尔类型不能接受其他类型的赋值，不支持自动或强制的类型转换。\n\n* 字符串\n\n  * 字符串可以使用双引号`(\"\")`或者反引号来创建。双引号用来创建可解析的字符串字面量，可解析的是指字符串中的一些符号可以被格式化为其他内容，如 `\\n` 在在输出时候会被格式化成换行符，如果需要按照原始字符输出必须进行转义。而反引号创建的字符串原始是什么样，那输出还是什么，不需要进行任何转义。\n\n  * 支持切片操作：对字符串中字符依次访问，可以使用 `range` 操作符。获取字符串的长度可能有两种含义，一种是指获取字符串的字节长度，一种是指获取字符串的字符数量。\n\n  支持的操作\n\n| 语法             | 描述                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| `s += t`         | 将字符串 t 追加到 s 末尾                                     |\n| `s + t`          | 将字符串 s 和 t 级联                                         |\n| `s[n]`           | 从字符串 s 中索引位置为 n 处的原始字节                       |\n| `s[n:m]`         | 从位置 n 到位置 `m-1` 处取得的字符（字节）串                 |\n| `s[n:]`          | 从位置 n 到位置 `len(s)-1` 处取得的字符（字节）串            |\n| `s[:m]`          | 从位置 0 到位置 `m-1` 处取得的字符（字节）串                 |\n| `len(s)`         | 字符串 s 中的字节数                                          |\n| `len([]rune(s))` | 字符串 s 中字符的个数，可以使用更快的方法 `utf8.RuneCountInString()` |\n| `[]rune(s)`      | 将字符串 s 转换为一个 unicode 值组成的串                     |\n| `string(chars)`  | chars 类型是 `[]rune` 或者 `[]int32`, 将之转换为字符串       |\n| `[]byte(s)`      | 无副本的将字符串 s 转换为一个原始的字节的切片数组，不保证转换的字节是合法的 UTF-8 编码字节 |\n\n### 顺序编程\n\n* if\n\n  `if`后面可以紧接一个表达式`optionalStatement1`，表达式会在进入`block`前执行，决定进入`block`分支的是布尔表达式`booleanExpression1`\n\n```go\nif optionalStatement1; booleanExpression1 {\n    block1\n} else if optionalStatement2; booleanExpression2 {\n    block2\n} else {\n    block3\n}\n```\n\n* for\n\n  `for`循环可以遍历数组，切片，映射等类型，也可以用于无限循环\n\n```go\nfor { // 无限循环\n    block\n}\n\nfor booleanExpression { // while循环，在Go语言中没有while关键字\n\n}\n\nfor index, char := range aString { // 迭代字符串\n\n}\n\nfor item := range aChannel { // 迭代通道\n\n}\n```\n\n* goto\n\n  `goto`可以实现跳转，在程序代码前定义一个标签以后可以使用goto跳转到标签\n\n* switch\n\n**类型处理**\n\n* 类型转换\n\n* 类型断言\n\n  将空接口类型转化为我们所需要的类型，这个操作称为类型断言。（有点难懂）\n\n**defer**\n\n* 当函数执行到最后时，`defer`语句会按照逆序执行，最后该函数返回，`defer`会在`return`之后执行。\n\n### 面向对象编程\n\n* 自定义类型及结构体\n\n  Go的代码是以包结构来组织的，如果标识符（变量名，函数名，自定义类型），以大写字母开头的标识符是可以导出的，可以在任何导入了定义该标识符的包中使用，Go语言不支持继承，只支持组合。\n\n  * \n\n* 方法\n\n* 组合\n\n* 接口\n\n  > 接口是一组方法签名。当一个类型为接口中的所有方法提供定义时，它被称为实现该接口。接口指定类型应具有的方法，类型决定如何实现这些方法。\n\n  接口定义了一组方法的集合，任何类型只要实现了接口中定义的所有方法，就被认为实现了该接口。\n\n  接口在Go中的实现方式是隐式的，无需显性地声明，这种设计允许对象在不同的上下文中被看作是不同的类型，从而实现了多态性。\n\n```go\npackage main\n\nimport \"fmt\"\n\n// Animal 接口定义了 Speak 方法\ntype Animal interface {\n    Speak() string\n}\n\n// Dog 类型实现了 Animal 接口\ntype Dog struct{}\n\nfunc (d Dog) Speak() string {\n    return \"Woof!\"\n}\n\n// Cat 类型实现了 Animal 接口\ntype Cat struct{}\n\nfunc (c Cat) Speak() string {\n    return \"Meow!\"\n}\n\nfunc main() {\n    // 定义一个接口类型的变量\n    var animal Animal\n\n    // 可以将不同类型的对象赋值给接口变量\n    animal = Dog{}\n    fmt.Println(animal.Speak()) // 输出: Woof!\n\n    animal = Cat{}\n    fmt.Println(animal.Speak()) // 输出: Meow!\n}\n```\n\n","source":"_drafts/Go语言学习笔记.md","raw":"---\ntitle: Go语言基本语法\ndate: 2023-12-14 17:16:50\ntags: [go语言 并发]\ncategories: 学习笔记\ncover: /img/default_cover05.jpg\ntop_img:\n---\n\n## 基本语法\n\n### GO语言特性\n\n* 并发编程\n\n  Go语言中引入了`goroutine`，通过调用`go`关键字，可以让函数以goroutine的方式进行运行，以协程为单位进行运行。\n\n  协程相比线程更加轻量级，也更节省系统资源。\n\n  goroutine内部采用管道`channel`进行消息传递，从而实现共享内存。\n\n* 错误处理\n\n  函数通过返回错误类型`error`或者`bool`类型表明函数执行结果，通过判断返回值是否为`nil`。\n\n  引入了defer关键字用于标准的错误处理流程，提供内置函数`panic`，`recover`完成异常抛出和捕捉\n\n* 垃圾回收\n\n  自带自动回收功能，不需要`delete`和`free`来释放内存\n\n* 多返回值\n\n  支持多返回值，可以用下划线作为占用符丢掉不要的返回值\n\n* 匿名函数\n\n  支持常规的匿名函数和闭包\n\n```go\n// hello.go\n\npackage main\n\nimport (\n    \"fmt\" //导入fmt包，调用其中的Println()函数\n)\n\nfunc main() {\n    fmt.Println(\"Hello，world！\")\n}\n```\n\n### 数据类型\n\n* 常量\n\n  使用`const`声明，可以限定常量类型，也可以不指定类型（称为字面常量）\n\n```\nconst limit = 512\nconst top uint16 = 1421\nconst Pi float64 = 3.1415926\n// 多重赋值\nconst x,y int = 1,2\n\n// 多个常量赋值\nconst (\n\tone = 1\n\ttwo = 2\n)\n```\n\n* iota\n\n  `iota`是一个可以被编译器修改的常量，在`const`关键字出现时被重置为`0`，在下一个`const`出现之前，每出现一次`iota`，所代表的数字自动加1\n\n```\nconst (\n    a = iota  //a == 0\n    b = iota  //b ==1\n    c = iota  //c == 2\n)\n\nconst d = iota //d==0,因为const的出现，iota被重置为0\n```\n\n* 变量\n\n  变量使用`var`进行声明，可以使用`:=`对变量之间进行初始化，Go编译器会自动推导出该变量的类型\n\n* 整型\n\n  可以通过`unsafe.Sizeof`函数来查看字节长度\n\n| 类型      | 说明                                                         |\n| :-------- | :----------------------------------------------------------- |\n| `byte`    | 等同于 uint8，uint8的别名                                    |\n| `int`     | 依赖于不同平台下的实现，可以是 int32 或者 int64              |\n| `int8`    | [-128, 127]                                                  |\n| `int16`   | [-32768, 32767]                                              |\n| `int32`   | [-2147483648, 2147483647]                                    |\n| `int64`   | [-9223372036854775808, 9223372036854775807]                  |\n| `rune`    | 等同于 int32，代表Unicode字符类型                            |\n| `uint`    | 依赖于不同平台下的实现，可以是 uint32 或者 uint64            |\n| `uint8`   | [0, 255]                                                     |\n| `uint16`  | [0, 65535]                                                   |\n| `uint32`  | [0, 4294967295]                                              |\n| `uint64`  | [0, 18446744073709551615]                                    |\n| `uintptr` | 一个可以恰好容纳指针值的无符号整型（对 32 位平台是 uint32, 对 64 位平台是 uint64） |\n\n* 浮点类型\n\n| 类型      | 说明                                                         |\n| --------- | ------------------------------------------------------------ |\n| float32   | ±3.402 823 466 385 288 598 117 041 834 845 169 254 40x1038 计算精度大概是小数点后 7 个十进制数 |\n| float64   | ±1.797 693 134 862 315 708 145 274 237 317 043 567 981x1038 计算精度大概是小数点后 15 个十进制数 |\n| complex32 | 复数，实部和虚部都是 float32                                 |\n| complex64 | 复数，实部和虚部都是 float64                                 |\n\n* 布尔类型\n\n  `true`和`false`：布尔类型不能接受其他类型的赋值，不支持自动或强制的类型转换。\n\n* 字符串\n\n  * 字符串可以使用双引号`(\"\")`或者反引号来创建。双引号用来创建可解析的字符串字面量，可解析的是指字符串中的一些符号可以被格式化为其他内容，如 `\\n` 在在输出时候会被格式化成换行符，如果需要按照原始字符输出必须进行转义。而反引号创建的字符串原始是什么样，那输出还是什么，不需要进行任何转义。\n\n  * 支持切片操作：对字符串中字符依次访问，可以使用 `range` 操作符。获取字符串的长度可能有两种含义，一种是指获取字符串的字节长度，一种是指获取字符串的字符数量。\n\n  支持的操作\n\n| 语法             | 描述                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| `s += t`         | 将字符串 t 追加到 s 末尾                                     |\n| `s + t`          | 将字符串 s 和 t 级联                                         |\n| `s[n]`           | 从字符串 s 中索引位置为 n 处的原始字节                       |\n| `s[n:m]`         | 从位置 n 到位置 `m-1` 处取得的字符（字节）串                 |\n| `s[n:]`          | 从位置 n 到位置 `len(s)-1` 处取得的字符（字节）串            |\n| `s[:m]`          | 从位置 0 到位置 `m-1` 处取得的字符（字节）串                 |\n| `len(s)`         | 字符串 s 中的字节数                                          |\n| `len([]rune(s))` | 字符串 s 中字符的个数，可以使用更快的方法 `utf8.RuneCountInString()` |\n| `[]rune(s)`      | 将字符串 s 转换为一个 unicode 值组成的串                     |\n| `string(chars)`  | chars 类型是 `[]rune` 或者 `[]int32`, 将之转换为字符串       |\n| `[]byte(s)`      | 无副本的将字符串 s 转换为一个原始的字节的切片数组，不保证转换的字节是合法的 UTF-8 编码字节 |\n\n### 顺序编程\n\n* if\n\n  `if`后面可以紧接一个表达式`optionalStatement1`，表达式会在进入`block`前执行，决定进入`block`分支的是布尔表达式`booleanExpression1`\n\n```go\nif optionalStatement1; booleanExpression1 {\n    block1\n} else if optionalStatement2; booleanExpression2 {\n    block2\n} else {\n    block3\n}\n```\n\n* for\n\n  `for`循环可以遍历数组，切片，映射等类型，也可以用于无限循环\n\n```go\nfor { // 无限循环\n    block\n}\n\nfor booleanExpression { // while循环，在Go语言中没有while关键字\n\n}\n\nfor index, char := range aString { // 迭代字符串\n\n}\n\nfor item := range aChannel { // 迭代通道\n\n}\n```\n\n* goto\n\n  `goto`可以实现跳转，在程序代码前定义一个标签以后可以使用goto跳转到标签\n\n* switch\n\n**类型处理**\n\n* 类型转换\n\n* 类型断言\n\n  将空接口类型转化为我们所需要的类型，这个操作称为类型断言。（有点难懂）\n\n**defer**\n\n* 当函数执行到最后时，`defer`语句会按照逆序执行，最后该函数返回，`defer`会在`return`之后执行。\n\n### 面向对象编程\n\n* 自定义类型及结构体\n\n  Go的代码是以包结构来组织的，如果标识符（变量名，函数名，自定义类型），以大写字母开头的标识符是可以导出的，可以在任何导入了定义该标识符的包中使用，Go语言不支持继承，只支持组合。\n\n  * \n\n* 方法\n\n* 组合\n\n* 接口\n\n  > 接口是一组方法签名。当一个类型为接口中的所有方法提供定义时，它被称为实现该接口。接口指定类型应具有的方法，类型决定如何实现这些方法。\n\n  接口定义了一组方法的集合，任何类型只要实现了接口中定义的所有方法，就被认为实现了该接口。\n\n  接口在Go中的实现方式是隐式的，无需显性地声明，这种设计允许对象在不同的上下文中被看作是不同的类型，从而实现了多态性。\n\n```go\npackage main\n\nimport \"fmt\"\n\n// Animal 接口定义了 Speak 方法\ntype Animal interface {\n    Speak() string\n}\n\n// Dog 类型实现了 Animal 接口\ntype Dog struct{}\n\nfunc (d Dog) Speak() string {\n    return \"Woof!\"\n}\n\n// Cat 类型实现了 Animal 接口\ntype Cat struct{}\n\nfunc (c Cat) Speak() string {\n    return \"Meow!\"\n}\n\nfunc main() {\n    // 定义一个接口类型的变量\n    var animal Animal\n\n    // 可以将不同类型的对象赋值给接口变量\n    animal = Dog{}\n    fmt.Println(animal.Speak()) // 输出: Woof!\n\n    animal = Cat{}\n    fmt.Println(animal.Speak()) // 输出: Meow!\n}\n```\n\n","slug":"Go语言学习笔记","published":0,"updated":"2024-06-05T09:03:03.314Z","comments":1,"layout":"post","photos":[],"_id":"clyfintta000308jvgul5gdtq","content":"<h2 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h2><h3 id=\"GO语言特性\"><a href=\"#GO语言特性\" class=\"headerlink\" title=\"GO语言特性\"></a>GO语言特性</h3><ul>\n<li><p>并发编程</p>\n<p>Go语言中引入了<code>goroutine</code>，通过调用<code>go</code>关键字，可以让函数以goroutine的方式进行运行，以协程为单位进行运行。</p>\n<p>协程相比线程更加轻量级，也更节省系统资源。</p>\n<p>goroutine内部采用管道<code>channel</code>进行消息传递，从而实现共享内存。</p>\n</li>\n<li><p>错误处理</p>\n<p>函数通过返回错误类型<code>error</code>或者<code>bool</code>类型表明函数执行结果，通过判断返回值是否为<code>nil</code>。</p>\n<p>引入了defer关键字用于标准的错误处理流程，提供内置函数<code>panic</code>，<code>recover</code>完成异常抛出和捕捉</p>\n</li>\n<li><p>垃圾回收</p>\n<p>自带自动回收功能，不需要<code>delete</code>和<code>free</code>来释放内存</p>\n</li>\n<li><p>多返回值</p>\n<p>支持多返回值，可以用下划线作为占用符丢掉不要的返回值</p>\n</li>\n<li><p>匿名函数</p>\n<p>支持常规的匿名函数和闭包</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-comment\">// hello.go</span><br><br><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> (<br>    <span class=\"hljs-string\">&quot;fmt&quot;</span> <span class=\"hljs-comment\">//导入fmt包，调用其中的Println()函数</span><br>)<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    fmt.Println(<span class=\"hljs-string\">&quot;Hello，world！&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h3><ul>\n<li><p>常量</p>\n<p>使用<code>const</code>声明，可以限定常量类型，也可以不指定类型（称为字面常量）</p>\n</li>\n</ul>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">const</span> limit = <span class=\"hljs-number\">512</span><br><span class=\"hljs-keyword\">const</span> top <span class=\"hljs-built_in\">uint16</span> = <span class=\"hljs-number\">1421</span><br><span class=\"hljs-keyword\">const</span> Pi <span class=\"hljs-built_in\">float</span>64 = <span class=\"hljs-number\">3.1415926</span><br><span class=\"hljs-comment\">// 多重赋值</span><br><span class=\"hljs-keyword\">const</span> x,y <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span><br><br><span class=\"hljs-comment\">// 多个常量赋值</span><br><span class=\"hljs-keyword\">const</span> (<br>\tone = <span class=\"hljs-number\">1</span><br>\ttwo = <span class=\"hljs-number\">2</span><br>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>iota</p>\n<p><code>iota</code>是一个可以被编译器修改的常量，在<code>const</code>关键字出现时被重置为<code>0</code>，在下一个<code>const</code>出现之前，每出现一次<code>iota</code>，所代表的数字自动加1</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">const</span> (<br>    a = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//a == 0</span><br>    b = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//b ==1</span><br>    c = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//c == 2</span><br>)<br><br><span class=\"hljs-keyword\">const</span> d = <span class=\"hljs-literal\">iota</span> <span class=\"hljs-comment\">//d==0,因为const的出现，iota被重置为0</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>变量</p>\n<p>变量使用<code>var</code>进行声明，可以使用<code>:=</code>对变量之间进行初始化，Go编译器会自动推导出该变量的类型</p>\n</li>\n<li><p>整型</p>\n<p>可以通过<code>unsafe.Sizeof</code>函数来查看字节长度</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">类型</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>byte</code></td>\n<td style=\"text-align:left\">等同于 uint8，uint8的别名</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int</code></td>\n<td style=\"text-align:left\">依赖于不同平台下的实现，可以是 int32 或者 int64</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int8</code></td>\n<td style=\"text-align:left\">[-128, 127]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int16</code></td>\n<td style=\"text-align:left\">[-32768, 32767]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int32</code></td>\n<td style=\"text-align:left\">[-2147483648, 2147483647]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int64</code></td>\n<td style=\"text-align:left\">[-9223372036854775808, 9223372036854775807]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>rune</code></td>\n<td style=\"text-align:left\">等同于 int32，代表Unicode字符类型</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint</code></td>\n<td style=\"text-align:left\">依赖于不同平台下的实现，可以是 uint32 或者 uint64</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint8</code></td>\n<td style=\"text-align:left\">[0, 255]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint16</code></td>\n<td style=\"text-align:left\">[0, 65535]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint32</code></td>\n<td style=\"text-align:left\">[0, 4294967295]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint64</code></td>\n<td style=\"text-align:left\">[0, 18446744073709551615]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uintptr</code></td>\n<td style=\"text-align:left\">一个可以恰好容纳指针值的无符号整型（对 32 位平台是 uint32, 对 64 位平台是 uint64）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>浮点类型</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>float32</td>\n<td>±3.402 823 466 385 288 598 117 041 834 845 169 254 40x1038 计算精度大概是小数点后 7 个十进制数</td>\n</tr>\n<tr>\n<td>float64</td>\n<td>±1.797 693 134 862 315 708 145 274 237 317 043 567 981x1038 计算精度大概是小数点后 15 个十进制数</td>\n</tr>\n<tr>\n<td>complex32</td>\n<td>复数，实部和虚部都是 float32</td>\n</tr>\n<tr>\n<td>complex64</td>\n<td>复数，实部和虚部都是 float64</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>布尔类型</p>\n<p><code>true</code>和<code>false</code>：布尔类型不能接受其他类型的赋值，不支持自动或强制的类型转换。</p>\n</li>\n<li><p>字符串</p>\n<ul>\n<li><p>字符串可以使用双引号<code>(&quot;&quot;)</code>或者反引号来创建。双引号用来创建可解析的字符串字面量，可解析的是指字符串中的一些符号可以被格式化为其他内容，如 <code>\\n</code> 在在输出时候会被格式化成换行符，如果需要按照原始字符输出必须进行转义。而反引号创建的字符串原始是什么样，那输出还是什么，不需要进行任何转义。</p>\n</li>\n<li><p>支持切片操作：对字符串中字符依次访问，可以使用 <code>range</code> 操作符。获取字符串的长度可能有两种含义，一种是指获取字符串的字节长度，一种是指获取字符串的字符数量。</p>\n</li>\n</ul>\n<p>支持的操作</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>语法</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>s += t</code></td>\n<td>将字符串 t 追加到 s 末尾</td>\n</tr>\n<tr>\n<td><code>s + t</code></td>\n<td>将字符串 s 和 t 级联</td>\n</tr>\n<tr>\n<td><code>s[n]</code></td>\n<td>从字符串 s 中索引位置为 n 处的原始字节</td>\n</tr>\n<tr>\n<td><code>s[n:m]</code></td>\n<td>从位置 n 到位置 <code>m-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>s[n:]</code></td>\n<td>从位置 n 到位置 <code>len(s)-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>s[:m]</code></td>\n<td>从位置 0 到位置 <code>m-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>len(s)</code></td>\n<td>字符串 s 中的字节数</td>\n</tr>\n<tr>\n<td><code>len([]rune(s))</code></td>\n<td>字符串 s 中字符的个数，可以使用更快的方法 <code>utf8.RuneCountInString()</code></td>\n</tr>\n<tr>\n<td><code>[]rune(s)</code></td>\n<td>将字符串 s 转换为一个 unicode 值组成的串</td>\n</tr>\n<tr>\n<td><code>string(chars)</code></td>\n<td>chars 类型是 <code>[]rune</code> 或者 <code>[]int32</code>, 将之转换为字符串</td>\n</tr>\n<tr>\n<td><code>[]byte(s)</code></td>\n<td>无副本的将字符串 s 转换为一个原始的字节的切片数组，不保证转换的字节是合法的 UTF-8 编码字节</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"顺序编程\"><a href=\"#顺序编程\" class=\"headerlink\" title=\"顺序编程\"></a>顺序编程</h3><ul>\n<li><p>if</p>\n<p><code>if</code>后面可以紧接一个表达式<code>optionalStatement1</code>，表达式会在进入<code>block</code>前执行，决定进入<code>block</code>分支的是布尔表达式<code>booleanExpression1</code></p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">if</span> optionalStatement1; booleanExpression1 &#123;<br>    block1<br>&#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> optionalStatement2; booleanExpression2 &#123;<br>    block2<br>&#125; <span class=\"hljs-keyword\">else</span> &#123;<br>    block3<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>for</p>\n<p><code>for</code>循环可以遍历数组，切片，映射等类型，也可以用于无限循环</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">for</span> &#123; <span class=\"hljs-comment\">// 无限循环</span><br>    block<br>&#125;<br><br><span class=\"hljs-keyword\">for</span> booleanExpression &#123; <span class=\"hljs-comment\">// while循环，在Go语言中没有while关键字</span><br><br>&#125;<br><br><span class=\"hljs-keyword\">for</span> index, char := <span class=\"hljs-keyword\">range</span> aString &#123; <span class=\"hljs-comment\">// 迭代字符串</span><br><br>&#125;<br><br><span class=\"hljs-keyword\">for</span> item := <span class=\"hljs-keyword\">range</span> aChannel &#123; <span class=\"hljs-comment\">// 迭代通道</span><br><br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>goto</p>\n<p><code>goto</code>可以实现跳转，在程序代码前定义一个标签以后可以使用goto跳转到标签</p>\n</li>\n<li><p>switch</p>\n</li>\n</ul>\n<p><strong>类型处理</strong></p>\n<ul>\n<li><p>类型转换</p>\n</li>\n<li><p>类型断言</p>\n<p>将空接口类型转化为我们所需要的类型，这个操作称为类型断言。（有点难懂）</p>\n</li>\n</ul>\n<p><strong>defer</strong></p>\n<ul>\n<li>当函数执行到最后时，<code>defer</code>语句会按照逆序执行，最后该函数返回，<code>defer</code>会在<code>return</code>之后执行。</li>\n</ul>\n<h3 id=\"面向对象编程\"><a href=\"#面向对象编程\" class=\"headerlink\" title=\"面向对象编程\"></a>面向对象编程</h3><ul>\n<li><p>自定义类型及结构体</p>\n<p>Go的代码是以包结构来组织的，如果标识符（变量名，函数名，自定义类型），以大写字母开头的标识符是可以导出的，可以在任何导入了定义该标识符的包中使用，Go语言不支持继承，只支持组合。</p>\n<ul>\n<li></li>\n</ul>\n</li>\n<li><p>方法</p>\n</li>\n<li><p>组合</p>\n</li>\n<li><p>接口</p>\n<blockquote>\n<p>接口是一组方法签名。当一个类型为接口中的所有方法提供定义时，它被称为实现该接口。接口指定类型应具有的方法，类型决定如何实现这些方法。</p>\n</blockquote>\n<p>接口定义了一组方法的集合，任何类型只要实现了接口中定义的所有方法，就被认为实现了该接口。</p>\n<p>接口在Go中的实现方式是隐式的，无需显性地声明，这种设计允许对象在不同的上下文中被看作是不同的类型，从而实现了多态性。</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">&quot;fmt&quot;</span><br><br><span class=\"hljs-comment\">// Animal 接口定义了 Speak 方法</span><br><span class=\"hljs-keyword\">type</span> Animal <span class=\"hljs-keyword\">interface</span> &#123;<br>    Speak() <span class=\"hljs-type\">string</span><br>&#125;<br><br><span class=\"hljs-comment\">// Dog 类型实现了 Animal 接口</span><br><span class=\"hljs-keyword\">type</span> Dog <span class=\"hljs-keyword\">struct</span>&#123;&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(d Dog)</span></span> Speak() <span class=\"hljs-type\">string</span> &#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Woof!&quot;</span><br>&#125;<br><br><span class=\"hljs-comment\">// Cat 类型实现了 Animal 接口</span><br><span class=\"hljs-keyword\">type</span> Cat <span class=\"hljs-keyword\">struct</span>&#123;&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(c Cat)</span></span> Speak() <span class=\"hljs-type\">string</span> &#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Meow!&quot;</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-comment\">// 定义一个接口类型的变量</span><br>    <span class=\"hljs-keyword\">var</span> animal Animal<br><br>    <span class=\"hljs-comment\">// 可以将不同类型的对象赋值给接口变量</span><br>    animal = Dog&#123;&#125;<br>    fmt.Println(animal.Speak()) <span class=\"hljs-comment\">// 输出: Woof!</span><br><br>    animal = Cat&#123;&#125;<br>    fmt.Println(animal.Speak()) <span class=\"hljs-comment\">// 输出: Meow!</span><br>&#125;<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h2><h3 id=\"GO语言特性\"><a href=\"#GO语言特性\" class=\"headerlink\" title=\"GO语言特性\"></a>GO语言特性</h3><ul>\n<li><p>并发编程</p>\n<p>Go语言中引入了<code>goroutine</code>，通过调用<code>go</code>关键字，可以让函数以goroutine的方式进行运行，以协程为单位进行运行。</p>\n<p>协程相比线程更加轻量级，也更节省系统资源。</p>\n<p>goroutine内部采用管道<code>channel</code>进行消息传递，从而实现共享内存。</p>\n</li>\n<li><p>错误处理</p>\n<p>函数通过返回错误类型<code>error</code>或者<code>bool</code>类型表明函数执行结果，通过判断返回值是否为<code>nil</code>。</p>\n<p>引入了defer关键字用于标准的错误处理流程，提供内置函数<code>panic</code>，<code>recover</code>完成异常抛出和捕捉</p>\n</li>\n<li><p>垃圾回收</p>\n<p>自带自动回收功能，不需要<code>delete</code>和<code>free</code>来释放内存</p>\n</li>\n<li><p>多返回值</p>\n<p>支持多返回值，可以用下划线作为占用符丢掉不要的返回值</p>\n</li>\n<li><p>匿名函数</p>\n<p>支持常规的匿名函数和闭包</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-comment\">// hello.go</span><br><br><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> (<br>    <span class=\"hljs-string\">&quot;fmt&quot;</span> <span class=\"hljs-comment\">//导入fmt包，调用其中的Println()函数</span><br>)<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    fmt.Println(<span class=\"hljs-string\">&quot;Hello，world！&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h3><ul>\n<li><p>常量</p>\n<p>使用<code>const</code>声明，可以限定常量类型，也可以不指定类型（称为字面常量）</p>\n</li>\n</ul>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">const</span> limit = <span class=\"hljs-number\">512</span><br><span class=\"hljs-keyword\">const</span> top <span class=\"hljs-built_in\">uint16</span> = <span class=\"hljs-number\">1421</span><br><span class=\"hljs-keyword\">const</span> Pi <span class=\"hljs-built_in\">float</span>64 = <span class=\"hljs-number\">3.1415926</span><br><span class=\"hljs-comment\">// 多重赋值</span><br><span class=\"hljs-keyword\">const</span> x,y <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span><br><br><span class=\"hljs-comment\">// 多个常量赋值</span><br><span class=\"hljs-keyword\">const</span> (<br>\tone = <span class=\"hljs-number\">1</span><br>\ttwo = <span class=\"hljs-number\">2</span><br>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>iota</p>\n<p><code>iota</code>是一个可以被编译器修改的常量，在<code>const</code>关键字出现时被重置为<code>0</code>，在下一个<code>const</code>出现之前，每出现一次<code>iota</code>，所代表的数字自动加1</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">const</span> (<br>    a = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//a == 0</span><br>    b = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//b ==1</span><br>    c = <span class=\"hljs-literal\">iota</span>  <span class=\"hljs-comment\">//c == 2</span><br>)<br><br><span class=\"hljs-keyword\">const</span> d = <span class=\"hljs-literal\">iota</span> <span class=\"hljs-comment\">//d==0,因为const的出现，iota被重置为0</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>变量</p>\n<p>变量使用<code>var</code>进行声明，可以使用<code>:=</code>对变量之间进行初始化，Go编译器会自动推导出该变量的类型</p>\n</li>\n<li><p>整型</p>\n<p>可以通过<code>unsafe.Sizeof</code>函数来查看字节长度</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">类型</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>byte</code></td>\n<td style=\"text-align:left\">等同于 uint8，uint8的别名</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int</code></td>\n<td style=\"text-align:left\">依赖于不同平台下的实现，可以是 int32 或者 int64</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int8</code></td>\n<td style=\"text-align:left\">[-128, 127]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int16</code></td>\n<td style=\"text-align:left\">[-32768, 32767]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int32</code></td>\n<td style=\"text-align:left\">[-2147483648, 2147483647]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>int64</code></td>\n<td style=\"text-align:left\">[-9223372036854775808, 9223372036854775807]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>rune</code></td>\n<td style=\"text-align:left\">等同于 int32，代表Unicode字符类型</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint</code></td>\n<td style=\"text-align:left\">依赖于不同平台下的实现，可以是 uint32 或者 uint64</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint8</code></td>\n<td style=\"text-align:left\">[0, 255]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint16</code></td>\n<td style=\"text-align:left\">[0, 65535]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint32</code></td>\n<td style=\"text-align:left\">[0, 4294967295]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uint64</code></td>\n<td style=\"text-align:left\">[0, 18446744073709551615]</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>uintptr</code></td>\n<td style=\"text-align:left\">一个可以恰好容纳指针值的无符号整型（对 32 位平台是 uint32, 对 64 位平台是 uint64）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>浮点类型</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>float32</td>\n<td>±3.402 823 466 385 288 598 117 041 834 845 169 254 40x1038 计算精度大概是小数点后 7 个十进制数</td>\n</tr>\n<tr>\n<td>float64</td>\n<td>±1.797 693 134 862 315 708 145 274 237 317 043 567 981x1038 计算精度大概是小数点后 15 个十进制数</td>\n</tr>\n<tr>\n<td>complex32</td>\n<td>复数，实部和虚部都是 float32</td>\n</tr>\n<tr>\n<td>complex64</td>\n<td>复数，实部和虚部都是 float64</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>布尔类型</p>\n<p><code>true</code>和<code>false</code>：布尔类型不能接受其他类型的赋值，不支持自动或强制的类型转换。</p>\n</li>\n<li><p>字符串</p>\n<ul>\n<li><p>字符串可以使用双引号<code>(&quot;&quot;)</code>或者反引号来创建。双引号用来创建可解析的字符串字面量，可解析的是指字符串中的一些符号可以被格式化为其他内容，如 <code>\\n</code> 在在输出时候会被格式化成换行符，如果需要按照原始字符输出必须进行转义。而反引号创建的字符串原始是什么样，那输出还是什么，不需要进行任何转义。</p>\n</li>\n<li><p>支持切片操作：对字符串中字符依次访问，可以使用 <code>range</code> 操作符。获取字符串的长度可能有两种含义，一种是指获取字符串的字节长度，一种是指获取字符串的字符数量。</p>\n</li>\n</ul>\n<p>支持的操作</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>语法</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>s += t</code></td>\n<td>将字符串 t 追加到 s 末尾</td>\n</tr>\n<tr>\n<td><code>s + t</code></td>\n<td>将字符串 s 和 t 级联</td>\n</tr>\n<tr>\n<td><code>s[n]</code></td>\n<td>从字符串 s 中索引位置为 n 处的原始字节</td>\n</tr>\n<tr>\n<td><code>s[n:m]</code></td>\n<td>从位置 n 到位置 <code>m-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>s[n:]</code></td>\n<td>从位置 n 到位置 <code>len(s)-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>s[:m]</code></td>\n<td>从位置 0 到位置 <code>m-1</code> 处取得的字符（字节）串</td>\n</tr>\n<tr>\n<td><code>len(s)</code></td>\n<td>字符串 s 中的字节数</td>\n</tr>\n<tr>\n<td><code>len([]rune(s))</code></td>\n<td>字符串 s 中字符的个数，可以使用更快的方法 <code>utf8.RuneCountInString()</code></td>\n</tr>\n<tr>\n<td><code>[]rune(s)</code></td>\n<td>将字符串 s 转换为一个 unicode 值组成的串</td>\n</tr>\n<tr>\n<td><code>string(chars)</code></td>\n<td>chars 类型是 <code>[]rune</code> 或者 <code>[]int32</code>, 将之转换为字符串</td>\n</tr>\n<tr>\n<td><code>[]byte(s)</code></td>\n<td>无副本的将字符串 s 转换为一个原始的字节的切片数组，不保证转换的字节是合法的 UTF-8 编码字节</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"顺序编程\"><a href=\"#顺序编程\" class=\"headerlink\" title=\"顺序编程\"></a>顺序编程</h3><ul>\n<li><p>if</p>\n<p><code>if</code>后面可以紧接一个表达式<code>optionalStatement1</code>，表达式会在进入<code>block</code>前执行，决定进入<code>block</code>分支的是布尔表达式<code>booleanExpression1</code></p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">if</span> optionalStatement1; booleanExpression1 &#123;<br>    block1<br>&#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> optionalStatement2; booleanExpression2 &#123;<br>    block2<br>&#125; <span class=\"hljs-keyword\">else</span> &#123;<br>    block3<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>for</p>\n<p><code>for</code>循环可以遍历数组，切片，映射等类型，也可以用于无限循环</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">for</span> &#123; <span class=\"hljs-comment\">// 无限循环</span><br>    block<br>&#125;<br><br><span class=\"hljs-keyword\">for</span> booleanExpression &#123; <span class=\"hljs-comment\">// while循环，在Go语言中没有while关键字</span><br><br>&#125;<br><br><span class=\"hljs-keyword\">for</span> index, char := <span class=\"hljs-keyword\">range</span> aString &#123; <span class=\"hljs-comment\">// 迭代字符串</span><br><br>&#125;<br><br><span class=\"hljs-keyword\">for</span> item := <span class=\"hljs-keyword\">range</span> aChannel &#123; <span class=\"hljs-comment\">// 迭代通道</span><br><br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>goto</p>\n<p><code>goto</code>可以实现跳转，在程序代码前定义一个标签以后可以使用goto跳转到标签</p>\n</li>\n<li><p>switch</p>\n</li>\n</ul>\n<p><strong>类型处理</strong></p>\n<ul>\n<li><p>类型转换</p>\n</li>\n<li><p>类型断言</p>\n<p>将空接口类型转化为我们所需要的类型，这个操作称为类型断言。（有点难懂）</p>\n</li>\n</ul>\n<p><strong>defer</strong></p>\n<ul>\n<li>当函数执行到最后时，<code>defer</code>语句会按照逆序执行，最后该函数返回，<code>defer</code>会在<code>return</code>之后执行。</li>\n</ul>\n<h3 id=\"面向对象编程\"><a href=\"#面向对象编程\" class=\"headerlink\" title=\"面向对象编程\"></a>面向对象编程</h3><ul>\n<li><p>自定义类型及结构体</p>\n<p>Go的代码是以包结构来组织的，如果标识符（变量名，函数名，自定义类型），以大写字母开头的标识符是可以导出的，可以在任何导入了定义该标识符的包中使用，Go语言不支持继承，只支持组合。</p>\n<ul>\n<li></li>\n</ul>\n</li>\n<li><p>方法</p>\n</li>\n<li><p>组合</p>\n</li>\n<li><p>接口</p>\n<blockquote>\n<p>接口是一组方法签名。当一个类型为接口中的所有方法提供定义时，它被称为实现该接口。接口指定类型应具有的方法，类型决定如何实现这些方法。</p>\n</blockquote>\n<p>接口定义了一组方法的集合，任何类型只要实现了接口中定义的所有方法，就被认为实现了该接口。</p>\n<p>接口在Go中的实现方式是隐式的，无需显性地声明，这种设计允许对象在不同的上下文中被看作是不同的类型，从而实现了多态性。</p>\n</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">&quot;fmt&quot;</span><br><br><span class=\"hljs-comment\">// Animal 接口定义了 Speak 方法</span><br><span class=\"hljs-keyword\">type</span> Animal <span class=\"hljs-keyword\">interface</span> &#123;<br>    Speak() <span class=\"hljs-type\">string</span><br>&#125;<br><br><span class=\"hljs-comment\">// Dog 类型实现了 Animal 接口</span><br><span class=\"hljs-keyword\">type</span> Dog <span class=\"hljs-keyword\">struct</span>&#123;&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(d Dog)</span></span> Speak() <span class=\"hljs-type\">string</span> &#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Woof!&quot;</span><br>&#125;<br><br><span class=\"hljs-comment\">// Cat 类型实现了 Animal 接口</span><br><span class=\"hljs-keyword\">type</span> Cat <span class=\"hljs-keyword\">struct</span>&#123;&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(c Cat)</span></span> Speak() <span class=\"hljs-type\">string</span> &#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Meow!&quot;</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-comment\">// 定义一个接口类型的变量</span><br>    <span class=\"hljs-keyword\">var</span> animal Animal<br><br>    <span class=\"hljs-comment\">// 可以将不同类型的对象赋值给接口变量</span><br>    animal = Dog&#123;&#125;<br>    fmt.Println(animal.Speak()) <span class=\"hljs-comment\">// 输出: Woof!</span><br><br>    animal = Cat&#123;&#125;<br>    fmt.Println(animal.Speak()) <span class=\"hljs-comment\">// 输出: Meow!</span><br>&#125;<br></code></pre></td></tr></table></figure>\n"},{"title":"算法题-数组和字符串","date":"2024-02-09T10:07:22.000Z","cover":"/img/top.jpg","top_img":null,"_content":"### [80.删除有序数组中的重复项 Ⅱ](https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/?envType=study-plan-v2&envId=top-interview-150)\n\n给你一个有序数组 `nums` ，请你**原地**删除重复出现的元素，使得出现次数超过两次的元素**只出现两次** ，返回删除后数组的新长度。\n\n不要使用额外的数组空间，你必须在 **原地修改输入数组** 并在使用 O(1) 额外空间的条件下完成。\n\n**示例 1：**\n\n```\n输入：nums = [1,1,1,2,2,3]\n输出：5, nums = [1,1,2,2,3]\n解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3。 不需要考虑数组中超出新长度后面的元素。\n```\n\n**示例 2：**\n\n```\n输入：nums = [0,0,1,1,1,1,2,3,3]\n输出：7, nums = [0,0,1,1,2,3,3]\n解释：函数应返回新长度 length = 7, 并且原数组的前七个元素被修改为 0, 0, 1, 1, 2, 3, 3。不需要考虑数组中超出新长度后面的元素。\n```\n\n\n\n**解析**\n\n使用快fast慢slow指针来遍历数组，慢指针记录数组的长度，快指针记录当前所在的元素是是否需要保留，如果需要保留则将当前位置nums[slow]存放快指针所在的元素，如果不需要保留则需要将fast++\n\n```C++\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n\n        int n = nums.size();\n        if(n <= 2){\n            return n;\n        }\n        \n        // 因为前两个元素都是必然回保留的，所以slow和fast都从2开始\n        int slow = 2;\n        int fast = 2;\n        // 使用fast来遍历\n        while(fast < n){\n            // 如果快指针所在的元素不等于当前位置-2所在的元素\n            // 说明，快指针所在的位置的元素的前面至多只有slow - 1位置的元素和其相等，即至多只有一个，所以当前fast所在的位置的元素是需要保留的\n            // 如果相等的话，说明slow-1和slow-2和fast都相等，所以fast是不需要保留的，fast++\n            if(nums[slow - 2] != nums[fast]){\n                nums[slow] = nums[fast];\n                // 更新slow位置\n                ++slow;\n            }\n            ++fast;\n        }\n        return slow;\n    }\n};\n```\n\n\n\n### [122.买股票的最佳时机 Ⅱ](https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/description/?envType=study-plan-v2&envId=top-interview-150)\n\n给你一个整数数组 `prices` ，其中 `prices[i]` 表示某支股票第 `i` 天的价格。\n\n在每一天，你可以决定是否购买和/或出售股票。你在任何时候 **最多** 只能持有 **一股** 股票。你也可以先购买，然后在 **同一天** 出售。\n\n返回 *你能获得的 **最大** 利润* 。\n\n**示例 1：**\n\n```\n输入：prices = [7,1,5,3,6,4]\n输出：7\n解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\n     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。\n     总利润为 4 + 3 = 7 。\n```\n\n**示例 2：**\n\n```\n输入：prices = [1,2,3,4,5]\n输出：4\n解释：在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\n     总利润为 4 。\n```\n\n**示例 3：**\n\n```\n输入：prices = [7,6,4,3,1]\n输出：0\n解释：在这种情况下, 交易无法获得正利润，所以不参与交易可以获得最大利润，最大利润为 0 。\n```\n\n \n\n**提示：**\n\n- `1 <= prices.length <= 3 * 104`\n- `0 <= prices[i] <= 104`","source":"_drafts/leetcode-0209.md","raw":"---\ntitle: 算法题-数组和字符串\ndate: 2024-02-09 18:07:22\ntags: [leetcode, 算法, 数组, 字符串]\ncategories: 算法实践\ncover: /img/top.jpg\ntop_img:\n---\n### [80.删除有序数组中的重复项 Ⅱ](https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/?envType=study-plan-v2&envId=top-interview-150)\n\n给你一个有序数组 `nums` ，请你**原地**删除重复出现的元素，使得出现次数超过两次的元素**只出现两次** ，返回删除后数组的新长度。\n\n不要使用额外的数组空间，你必须在 **原地修改输入数组** 并在使用 O(1) 额外空间的条件下完成。\n\n**示例 1：**\n\n```\n输入：nums = [1,1,1,2,2,3]\n输出：5, nums = [1,1,2,2,3]\n解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3。 不需要考虑数组中超出新长度后面的元素。\n```\n\n**示例 2：**\n\n```\n输入：nums = [0,0,1,1,1,1,2,3,3]\n输出：7, nums = [0,0,1,1,2,3,3]\n解释：函数应返回新长度 length = 7, 并且原数组的前七个元素被修改为 0, 0, 1, 1, 2, 3, 3。不需要考虑数组中超出新长度后面的元素。\n```\n\n\n\n**解析**\n\n使用快fast慢slow指针来遍历数组，慢指针记录数组的长度，快指针记录当前所在的元素是是否需要保留，如果需要保留则将当前位置nums[slow]存放快指针所在的元素，如果不需要保留则需要将fast++\n\n```C++\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n\n        int n = nums.size();\n        if(n <= 2){\n            return n;\n        }\n        \n        // 因为前两个元素都是必然回保留的，所以slow和fast都从2开始\n        int slow = 2;\n        int fast = 2;\n        // 使用fast来遍历\n        while(fast < n){\n            // 如果快指针所在的元素不等于当前位置-2所在的元素\n            // 说明，快指针所在的位置的元素的前面至多只有slow - 1位置的元素和其相等，即至多只有一个，所以当前fast所在的位置的元素是需要保留的\n            // 如果相等的话，说明slow-1和slow-2和fast都相等，所以fast是不需要保留的，fast++\n            if(nums[slow - 2] != nums[fast]){\n                nums[slow] = nums[fast];\n                // 更新slow位置\n                ++slow;\n            }\n            ++fast;\n        }\n        return slow;\n    }\n};\n```\n\n\n\n### [122.买股票的最佳时机 Ⅱ](https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/description/?envType=study-plan-v2&envId=top-interview-150)\n\n给你一个整数数组 `prices` ，其中 `prices[i]` 表示某支股票第 `i` 天的价格。\n\n在每一天，你可以决定是否购买和/或出售股票。你在任何时候 **最多** 只能持有 **一股** 股票。你也可以先购买，然后在 **同一天** 出售。\n\n返回 *你能获得的 **最大** 利润* 。\n\n**示例 1：**\n\n```\n输入：prices = [7,1,5,3,6,4]\n输出：7\n解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\n     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。\n     总利润为 4 + 3 = 7 。\n```\n\n**示例 2：**\n\n```\n输入：prices = [1,2,3,4,5]\n输出：4\n解释：在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\n     总利润为 4 。\n```\n\n**示例 3：**\n\n```\n输入：prices = [7,6,4,3,1]\n输出：0\n解释：在这种情况下, 交易无法获得正利润，所以不参与交易可以获得最大利润，最大利润为 0 。\n```\n\n \n\n**提示：**\n\n- `1 <= prices.length <= 3 * 104`\n- `0 <= prices[i] <= 104`","slug":"leetcode-0209","published":0,"updated":"2024-06-05T09:03:03.316Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttc000408jv4zn7hbj8","content":"<h3 id=\"80-删除有序数组中的重复项-Ⅱ\"><a href=\"#80-删除有序数组中的重复项-Ⅱ\" class=\"headerlink\" title=\"80.删除有序数组中的重复项 Ⅱ\"></a><a href=\"https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/?envType=study-plan-v2&amp;envId=top-interview-150\">80.删除有序数组中的重复项 Ⅱ</a></h3><p>给你一个有序数组 <code>nums</code> ，请你<strong>原地</strong>删除重复出现的元素，使得出现次数超过两次的元素<strong>只出现两次</strong> ，返回删除后数组的新长度。</p>\n<p>不要使用额外的数组空间，你必须在 <strong>原地修改输入数组</strong> 并在使用 O(1) 额外空间的条件下完成。</p>\n<p><strong>示例 1：</strong></p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：nums = <span class=\"hljs-string\">[1,1,1,2,2,3]</span><br>输出：<span class=\"hljs-number\">5</span>, nums = <span class=\"hljs-string\">[1,1,2,2,3]</span><br>解释：函数应返回新长度 length = <span class=\"hljs-number\">5</span>, 并且原数组的前五个元素被修改为 <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>。 不需要考虑数组中超出新长度后面的元素。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 2：</strong></p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">输入：nums = [<span class=\"hljs-number\">0,0,1,1</span>,<span class=\"hljs-number\">1,1,2,3</span>,<span class=\"hljs-number\">3</span>]<br>输出：<span class=\"hljs-number\">7</span>, nums = [<span class=\"hljs-number\">0,0,1,1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">3</span>]<br>解释：函数应返回新长度 length = <span class=\"hljs-number\">7</span>, 并且原数组的前七个元素被修改为 <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>。不需要考虑数组中超出新长度后面的元素。<br></code></pre></td></tr></table></figure>\n<p><strong>解析</strong></p>\n<p>使用快fast慢slow指针来遍历数组，慢指针记录数组的长度，快指针记录当前所在的元素是是否需要保留，如果需要保留则将当前位置nums[slow]存放快指针所在的元素，如果不需要保留则需要将fast++</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Solution</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">removeDuplicates</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br><br>        <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>        <span class=\"hljs-keyword\">if</span>(n &lt;= <span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">return</span> n;<br>        &#125;<br>        <br>        <span class=\"hljs-comment\">// 因为前两个元素都是必然回保留的，所以slow和fast都从2开始</span><br>        <span class=\"hljs-type\">int</span> slow = <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-type\">int</span> fast = <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-comment\">// 使用fast来遍历</span><br>        <span class=\"hljs-keyword\">while</span>(fast &lt; n)&#123;<br>            <span class=\"hljs-comment\">// 如果快指针所在的元素不等于当前位置-2所在的元素</span><br>            <span class=\"hljs-comment\">// 说明，快指针所在的位置的元素的前面至多只有slow - 1位置的元素和其相等，即至多只有一个，所以当前fast所在的位置的元素是需要保留的</span><br>            <span class=\"hljs-comment\">// 如果相等的话，说明slow-1和slow-2和fast都相等，所以fast是不需要保留的，fast++</span><br>            <span class=\"hljs-keyword\">if</span>(nums[slow - <span class=\"hljs-number\">2</span>] != nums[fast])&#123;<br>                nums[slow] = nums[fast];<br>                <span class=\"hljs-comment\">// 更新slow位置</span><br>                ++slow;<br>            &#125;<br>            ++fast;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> slow;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"122-买股票的最佳时机-Ⅱ\"><a href=\"#122-买股票的最佳时机-Ⅱ\" class=\"headerlink\" title=\"122.买股票的最佳时机 Ⅱ\"></a><a href=\"https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/description/?envType=study-plan-v2&amp;envId=top-interview-150\">122.买股票的最佳时机 Ⅱ</a></h3><p>给你一个整数数组 <code>prices</code> ，其中 <code>prices[i]</code> 表示某支股票第 <code>i</code> 天的价格。</p>\n<p>在每一天，你可以决定是否购买和/或出售股票。你在任何时候 <strong>最多</strong> 只能持有 <strong>一股</strong> 股票。你也可以先购买，然后在 <strong>同一天</strong> 出售。</p>\n<p>返回 <em>你能获得的 <strong>最大</strong> 利润</em> 。</p>\n<p><strong>示例 1：</strong></p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">输入：prices = [7,1,5,3,6,4]<br>输出：7<br>解释：在第<span class=\"hljs-number\"> 2 </span>天（股票价格 = 1）的时候买入，在第<span class=\"hljs-number\"> 3 </span>天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 5 </span>-<span class=\"hljs-number\"> 1 </span>=<span class=\"hljs-number\"> 4 </span>。<br>     随后，在第<span class=\"hljs-number\"> 4 </span>天（股票价格 = 3）的时候买入，在第<span class=\"hljs-number\"> 5 </span>天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 6 </span>-<span class=\"hljs-number\"> 3 </span>=<span class=\"hljs-number\"> 3 </span>。<br>     总利润为<span class=\"hljs-number\"> 4 </span>+<span class=\"hljs-number\"> 3 </span>=<span class=\"hljs-number\"> 7 </span>。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 2：</strong></p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">输入：prices = [1,2,3,4,5]<br>输出：4<br>解释：在第<span class=\"hljs-number\"> 1 </span>天（股票价格 = 1）的时候买入，在第<span class=\"hljs-number\"> 5 </span>天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 5 </span>-<span class=\"hljs-number\"> 1 </span>=<span class=\"hljs-number\"> 4 </span>。<br>     总利润为<span class=\"hljs-number\"> 4 </span>。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 3：</strong></p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：prices = <span class=\"hljs-string\">[7,6,4,3,1]</span><br>输出：<span class=\"hljs-number\">0</span><br>解释：在这种情况下, 交易无法获得正利润，所以不参与交易可以获得最大利润，最大利润为 <span class=\"hljs-number\">0</span> 。<br></code></pre></td></tr></table></figure>\n<p><strong>提示：</strong></p>\n<ul>\n<li><code>1 &lt;= prices.length &lt;= 3 * 104</code></li>\n<li><code>0 &lt;= prices[i] &lt;= 104</code></li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"80-删除有序数组中的重复项-Ⅱ\"><a href=\"#80-删除有序数组中的重复项-Ⅱ\" class=\"headerlink\" title=\"80.删除有序数组中的重复项 Ⅱ\"></a><a href=\"https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/?envType=study-plan-v2&amp;envId=top-interview-150\">80.删除有序数组中的重复项 Ⅱ</a></h3><p>给你一个有序数组 <code>nums</code> ，请你<strong>原地</strong>删除重复出现的元素，使得出现次数超过两次的元素<strong>只出现两次</strong> ，返回删除后数组的新长度。</p>\n<p>不要使用额外的数组空间，你必须在 <strong>原地修改输入数组</strong> 并在使用 O(1) 额外空间的条件下完成。</p>\n<p><strong>示例 1：</strong></p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：nums = <span class=\"hljs-string\">[1,1,1,2,2,3]</span><br>输出：<span class=\"hljs-number\">5</span>, nums = <span class=\"hljs-string\">[1,1,2,2,3]</span><br>解释：函数应返回新长度 length = <span class=\"hljs-number\">5</span>, 并且原数组的前五个元素被修改为 <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>。 不需要考虑数组中超出新长度后面的元素。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 2：</strong></p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">输入：nums = [<span class=\"hljs-number\">0,0,1,1</span>,<span class=\"hljs-number\">1,1,2,3</span>,<span class=\"hljs-number\">3</span>]<br>输出：<span class=\"hljs-number\">7</span>, nums = [<span class=\"hljs-number\">0,0,1,1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">3</span>]<br>解释：函数应返回新长度 length = <span class=\"hljs-number\">7</span>, 并且原数组的前七个元素被修改为 <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>。不需要考虑数组中超出新长度后面的元素。<br></code></pre></td></tr></table></figure>\n<p><strong>解析</strong></p>\n<p>使用快fast慢slow指针来遍历数组，慢指针记录数组的长度，快指针记录当前所在的元素是是否需要保留，如果需要保留则将当前位置nums[slow]存放快指针所在的元素，如果不需要保留则需要将fast++</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Solution</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">removeDuplicates</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br><br>        <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>        <span class=\"hljs-keyword\">if</span>(n &lt;= <span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">return</span> n;<br>        &#125;<br>        <br>        <span class=\"hljs-comment\">// 因为前两个元素都是必然回保留的，所以slow和fast都从2开始</span><br>        <span class=\"hljs-type\">int</span> slow = <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-type\">int</span> fast = <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-comment\">// 使用fast来遍历</span><br>        <span class=\"hljs-keyword\">while</span>(fast &lt; n)&#123;<br>            <span class=\"hljs-comment\">// 如果快指针所在的元素不等于当前位置-2所在的元素</span><br>            <span class=\"hljs-comment\">// 说明，快指针所在的位置的元素的前面至多只有slow - 1位置的元素和其相等，即至多只有一个，所以当前fast所在的位置的元素是需要保留的</span><br>            <span class=\"hljs-comment\">// 如果相等的话，说明slow-1和slow-2和fast都相等，所以fast是不需要保留的，fast++</span><br>            <span class=\"hljs-keyword\">if</span>(nums[slow - <span class=\"hljs-number\">2</span>] != nums[fast])&#123;<br>                nums[slow] = nums[fast];<br>                <span class=\"hljs-comment\">// 更新slow位置</span><br>                ++slow;<br>            &#125;<br>            ++fast;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> slow;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"122-买股票的最佳时机-Ⅱ\"><a href=\"#122-买股票的最佳时机-Ⅱ\" class=\"headerlink\" title=\"122.买股票的最佳时机 Ⅱ\"></a><a href=\"https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/description/?envType=study-plan-v2&amp;envId=top-interview-150\">122.买股票的最佳时机 Ⅱ</a></h3><p>给你一个整数数组 <code>prices</code> ，其中 <code>prices[i]</code> 表示某支股票第 <code>i</code> 天的价格。</p>\n<p>在每一天，你可以决定是否购买和/或出售股票。你在任何时候 <strong>最多</strong> 只能持有 <strong>一股</strong> 股票。你也可以先购买，然后在 <strong>同一天</strong> 出售。</p>\n<p>返回 <em>你能获得的 <strong>最大</strong> 利润</em> 。</p>\n<p><strong>示例 1：</strong></p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">输入：prices = [7,1,5,3,6,4]<br>输出：7<br>解释：在第<span class=\"hljs-number\"> 2 </span>天（股票价格 = 1）的时候买入，在第<span class=\"hljs-number\"> 3 </span>天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 5 </span>-<span class=\"hljs-number\"> 1 </span>=<span class=\"hljs-number\"> 4 </span>。<br>     随后，在第<span class=\"hljs-number\"> 4 </span>天（股票价格 = 3）的时候买入，在第<span class=\"hljs-number\"> 5 </span>天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 6 </span>-<span class=\"hljs-number\"> 3 </span>=<span class=\"hljs-number\"> 3 </span>。<br>     总利润为<span class=\"hljs-number\"> 4 </span>+<span class=\"hljs-number\"> 3 </span>=<span class=\"hljs-number\"> 7 </span>。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 2：</strong></p>\n<figure class=\"highlight tap\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tap\">输入：prices = [1,2,3,4,5]<br>输出：4<br>解释：在第<span class=\"hljs-number\"> 1 </span>天（股票价格 = 1）的时候买入，在第<span class=\"hljs-number\"> 5 </span>天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 =<span class=\"hljs-number\"> 5 </span>-<span class=\"hljs-number\"> 1 </span>=<span class=\"hljs-number\"> 4 </span>。<br>     总利润为<span class=\"hljs-number\"> 4 </span>。<br></code></pre></td></tr></table></figure>\n<p><strong>示例 3：</strong></p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：prices = <span class=\"hljs-string\">[7,6,4,3,1]</span><br>输出：<span class=\"hljs-number\">0</span><br>解释：在这种情况下, 交易无法获得正利润，所以不参与交易可以获得最大利润，最大利润为 <span class=\"hljs-number\">0</span> 。<br></code></pre></td></tr></table></figure>\n<p><strong>提示：</strong></p>\n<ul>\n<li><code>1 &lt;= prices.length &lt;= 3 * 104</code></li>\n<li><code>0 &lt;= prices[i] &lt;= 104</code></li>\n</ul>\n"},{"title":"the_go_programming_language","date":"2024-02-12T05:29:11.000Z","cover":"2024/02/12/the-go-programming-language/top_img.png","top_img":"2024/02/12/the-go-programming-language/top_img.png","_content":"\n### GO语言基础要点\n\n四种变量声明方式\n\n* 第一种是短变量声明，只能在函数内部使用，不能用于包变量\n* 第二种依赖于字符串的默认初始化零值机制\n* 第三种用得较少，除非用于声明多个变量\n* 第四种当变量类型与初值类型相同时，类型冗余，但是类型不同时，变量类型就必须了\n\n```go\ns := \"\"\nvar s string\nvar s = \"\"\nvar s string = \"\"\n```\n\n","source":"_drafts/the-go-programming-language.md","raw":"---\ntitle: the_go_programming_language\ndate: 2024-02-12 13:29:11\ntags: [golang Go语言圣经]\ncategories: 学习笔记\ncover: top_img.png\ntop_img: top_img.png\n---\n\n### GO语言基础要点\n\n四种变量声明方式\n\n* 第一种是短变量声明，只能在函数内部使用，不能用于包变量\n* 第二种依赖于字符串的默认初始化零值机制\n* 第三种用得较少，除非用于声明多个变量\n* 第四种当变量类型与初值类型相同时，类型冗余，但是类型不同时，变量类型就必须了\n\n```go\ns := \"\"\nvar s string\nvar s = \"\"\nvar s string = \"\"\n```\n\n","slug":"the-go-programming-language","published":0,"updated":"2024-06-05T09:03:03.317Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttc000508jvhcox6yqn","content":"<h3 id=\"GO语言基础要点\"><a href=\"#GO语言基础要点\" class=\"headerlink\" title=\"GO语言基础要点\"></a>GO语言基础要点</h3><p>四种变量声明方式</p>\n<ul>\n<li>第一种是短变量声明，只能在函数内部使用，不能用于包变量</li>\n<li>第二种依赖于字符串的默认初始化零值机制</li>\n<li>第三种用得较少，除非用于声明多个变量</li>\n<li>第四种当变量类型与初值类型相同时，类型冗余，但是类型不同时，变量类型就必须了</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\">s := <span class=\"hljs-string\">&quot;&quot;</span><br><span class=\"hljs-keyword\">var</span> s <span class=\"hljs-type\">string</span><br><span class=\"hljs-keyword\">var</span> s = <span class=\"hljs-string\">&quot;&quot;</span><br><span class=\"hljs-keyword\">var</span> s <span class=\"hljs-type\">string</span> = <span class=\"hljs-string\">&quot;&quot;</span><br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"GO语言基础要点\"><a href=\"#GO语言基础要点\" class=\"headerlink\" title=\"GO语言基础要点\"></a>GO语言基础要点</h3><p>四种变量声明方式</p>\n<ul>\n<li>第一种是短变量声明，只能在函数内部使用，不能用于包变量</li>\n<li>第二种依赖于字符串的默认初始化零值机制</li>\n<li>第三种用得较少，除非用于声明多个变量</li>\n<li>第四种当变量类型与初值类型相同时，类型冗余，但是类型不同时，变量类型就必须了</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\">s := <span class=\"hljs-string\">&quot;&quot;</span><br><span class=\"hljs-keyword\">var</span> s <span class=\"hljs-type\">string</span><br><span class=\"hljs-keyword\">var</span> s = <span class=\"hljs-string\">&quot;&quot;</span><br><span class=\"hljs-keyword\">var</span> s <span class=\"hljs-type\">string</span> = <span class=\"hljs-string\">&quot;&quot;</span><br></code></pre></td></tr></table></figure>\n"},{"title":"大话设计模式","date":"2024-02-20T07:09:00.000Z","cover":"/img/default_cover03.jpg","top_img":null,"_content":"## 一、简单工厂模式\n\n> 注意：命名规范、多个分支使用switch、考虑异常情况\n\n面向对象的编程，对代码做到：可维护、可复用、灵活性好\n\n* 业务的封装\n\n  前后端分离，将业务逻辑和界面逻辑分开，让他们之间的耦合度下降，可以依赖面向对象的三大特性来实现\n\n* 工厂模式\n\n  通过工厂类，传入不同的字符串来返回不同继承类的构造函数，需要实例哪一个子类，可以通过传入参数来进行选择\n\n  可以使用switch，或者使用map映射等方式\n\n* UML类图\n\n  * 依赖关系\n  * 聚合关系\n  * 合成关系\n  * 继承关系\n  * 关联关系\n  * 接口关系\n  * 泛化关系\n\n![image-20231008153018253](大话设计模式/image-20231008153018253.png)\n\n## 二、策略模式\n\n> 策略模式定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的用户。\n\n只有算法需要替换，而其它不需要替换\n\n使用策略类，定义所有支持算法的公共接口\n\n* 策略模式是一种定义一系列算法的方法，所有这些算法完成的是相同的工作，但是实现不同，可以以相同的方式调用所有的方法，减少了各种算法类与使用算法类之间的耦合\n* 策略模式的优点可以简化单元测试，因为每个算法都有自己的类，可以通过自己的接口单独测试\n\n```\n策略模式的三个要点\n1、基类，策略接口，用于子类继承该基类，并重写基类中的策略方法\n2、具体的策略类，不同的策略类使用不同的方法来实现基类的虚方法\n3、上下文，context，在上下文中，通过一个公共的方法，来调用不同子类实现的虚方法（使用传入不同子类对象来实现）\n\n用户只需要使用context来使用不同对象传入即可以完成不同的策略选择\n```\n\n## 三、单一职责原则\n\n> 对于一个类而言，应该仅有一个引起它变化的原因。\n>\n> 如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者这个类完成其它职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭到意想不到的破坏。\n\n## 四、开放-封闭原则\n\n**软件实体（类、模块、函数等）应该可以扩展但不可修改，即对拓展开放，对修改封闭**\n\n##  五、依赖倒置原则\n\n1、高层模块不应该依赖底层模块，两个都应该依赖抽象\n\n2、抽象不应该依赖细节，细节应该依赖抽象\n\n* 里氏代换原则\n\n  一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类对象和子类对象的区别。\n\n  即：子类型必须能够替换掉它们的父类型\n\n```\n和策略模式有一定的相似之处，例子\n\nDevice类\nclass Device:\n    def turn_on(self):\n        pass\n\n    def turn_off(self):\n        pass\n\n子类\nclass Light(Device):\n    def turn_on(self):\n        print(\"Light is turned on\")\n\n    def turn_off(self):\n        print(\"Light is turned off\")\n\nclass Fan(Device):\n    def turn_on(self):\n        print(\"Fan is turned on\")\n\n    def turn_off(self):\n        print(\"Fan is turned off\")\n\nclass Speaker(Device):\n    def turn_on(self):\n        print(\"Speaker is turned on\")\n\n    def turn_off(self):\n        print(\"Speaker is turned off\")\n\n高层模块\nclass DeviceController:\n    def __init__(self, device):\n        self.device = device\n\n    def operate(self):\n        self.device.turn_on()\n\n    def stop(self):\n        self.device.turn_off()\n\nmain\nif __name__ == \"__main__\":\n    light = Light()\n    fan = Fan()\n    speaker = Speaker()\n\n    controller1 = DeviceController(light)\n    controller2 = DeviceController(fan)\n    controller3 = DeviceController(speaker)\n\n    controller1.operate()\n    controller2.operate()\n    controller3.operate()\n\n    controller1.stop()\n    controller2.stop()\n    controller3.stop()\n高层模块 DeviceController 不直接依赖于具体的设备类（如 Light、Fan 和 Speaker），而是依赖于抽象的 Device 接口。这就是依赖倒置原则的应用，它使得高层模块更加灵活，可以轻松地切换和扩展不同类型的设备，而不需要修改高层模块的代码。这有助于创建松耦合的、易于维护和扩展的代码\n```\n\n\n\n## 六、装饰模式\n\n**动态地给一个对象添加一些额外的职责**，就增加功能来说，装饰模式比生成子类更为灵活\n\n在子类中定义一个父类对象，该对象使用需要装饰的对象作为初始化，并在子类中对该对象进行操作，即可达到，对对象的额外装饰结果，但是这一个对象和之前的对象不一定是同一个对象。\n\n* 基本结构\n\n```\n1、父类：父类定义一个抽象的方法\n2、子类：子类继承父类抽象方法并添加一些最基本的属性\n3、装饰器类：装饰器类继承父类，并定义一个父类的保护类型数据\n4、不同的装饰器类：不同的装饰器类继承于装饰器类，重写各自装饰器需要添加的职责\n\n通常第“2”步中定义基本属性的子类，会作为第一层装饰包装子类，后续会作为参数传入到装饰器类中\n```\n\n装饰模式可以把类中的装饰功能从类中搬移去除，这样就可以简化原有的类。同事有效地把类的核心职责和装饰功能区分开，去除相关类中的重复的装饰逻辑，重复的装饰逻辑可以使用一个子类作为最基类型。\n\n```\nexp：\n游戏中，不同人物角色使用不同技能进行装饰。最开始都是有一个人物的基类（低级的时候）。公共技能可以作为重复逻辑继承在一个类中，使用装饰模式，可以学习一些不同的技能。\n```\n\n## 七、代理模式\n\n代理模式，为其它对象提供一种代理以控制对这个对象的访问\n\n在客户与另一客户交互的过程中，中间会有一层代理，代理可以拥有两个客户的接口，作为中间实体来进行来促使两客户进行交互，在代理中如果需要交互，则需要定义一个客户的类，来调用该客户的方法。\n\n* 代理模式应用场景\n\n  远程代理：为一个对象在不同的地址空间提供局部代表，这样可以隐藏一个对象存在于不同地址空间的事实\n\n  虚拟代理：根据需要创建开销很大的对象，通过它来存放实例化需要很长时间的真实对象，浏览器中加载图片就是使用虚拟代理\n\n  安全代理：用来控制真实对象访问时的权限\n\n  智能指引：当掉哟个真实对象时，代理处理另外一些事\n\n## 八、工厂方法模式\n\n封装实例来创建过程，可以让创建实例的过程封装到工厂类中，避免耦合\n\n\n\n\n## 九、原型模式\n\n用原型（Prototype）实例指定创建对象的种类，并且通过复制这些原型创建新的对象\n\n* 用法\n\n  在类里面定义一个函数，函数可以返回一个原型对象\n\n* 在类中定义修改原型中属性的set方法\n\n* 在使用的过程中，只需要调用set方法修改不同的地方\n\n深拷贝与浅拷贝，若在原型类中使用对象引用，在修改的时候记得使用深拷贝\n\n\n\n## 十、模板方法模式\n\n定义一个操作中的算法的骨架，将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤\n\n\n\n## 十一、迪米特法则\n\n> 最小知识原则\n\n如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。","source":"_drafts/大话设计模式.md","raw":"---\ntitle: 大话设计模式\ndate: 2024-02-20 15:09:00\ntags: [设计模式, UML]\ncategories: 学习笔记\ncover:\ntop_img:\n---\n## 一、简单工厂模式\n\n> 注意：命名规范、多个分支使用switch、考虑异常情况\n\n面向对象的编程，对代码做到：可维护、可复用、灵活性好\n\n* 业务的封装\n\n  前后端分离，将业务逻辑和界面逻辑分开，让他们之间的耦合度下降，可以依赖面向对象的三大特性来实现\n\n* 工厂模式\n\n  通过工厂类，传入不同的字符串来返回不同继承类的构造函数，需要实例哪一个子类，可以通过传入参数来进行选择\n\n  可以使用switch，或者使用map映射等方式\n\n* UML类图\n\n  * 依赖关系\n  * 聚合关系\n  * 合成关系\n  * 继承关系\n  * 关联关系\n  * 接口关系\n  * 泛化关系\n\n![image-20231008153018253](大话设计模式/image-20231008153018253.png)\n\n## 二、策略模式\n\n> 策略模式定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的用户。\n\n只有算法需要替换，而其它不需要替换\n\n使用策略类，定义所有支持算法的公共接口\n\n* 策略模式是一种定义一系列算法的方法，所有这些算法完成的是相同的工作，但是实现不同，可以以相同的方式调用所有的方法，减少了各种算法类与使用算法类之间的耦合\n* 策略模式的优点可以简化单元测试，因为每个算法都有自己的类，可以通过自己的接口单独测试\n\n```\n策略模式的三个要点\n1、基类，策略接口，用于子类继承该基类，并重写基类中的策略方法\n2、具体的策略类，不同的策略类使用不同的方法来实现基类的虚方法\n3、上下文，context，在上下文中，通过一个公共的方法，来调用不同子类实现的虚方法（使用传入不同子类对象来实现）\n\n用户只需要使用context来使用不同对象传入即可以完成不同的策略选择\n```\n\n## 三、单一职责原则\n\n> 对于一个类而言，应该仅有一个引起它变化的原因。\n>\n> 如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者这个类完成其它职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭到意想不到的破坏。\n\n## 四、开放-封闭原则\n\n**软件实体（类、模块、函数等）应该可以扩展但不可修改，即对拓展开放，对修改封闭**\n\n##  五、依赖倒置原则\n\n1、高层模块不应该依赖底层模块，两个都应该依赖抽象\n\n2、抽象不应该依赖细节，细节应该依赖抽象\n\n* 里氏代换原则\n\n  一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类对象和子类对象的区别。\n\n  即：子类型必须能够替换掉它们的父类型\n\n```\n和策略模式有一定的相似之处，例子\n\nDevice类\nclass Device:\n    def turn_on(self):\n        pass\n\n    def turn_off(self):\n        pass\n\n子类\nclass Light(Device):\n    def turn_on(self):\n        print(\"Light is turned on\")\n\n    def turn_off(self):\n        print(\"Light is turned off\")\n\nclass Fan(Device):\n    def turn_on(self):\n        print(\"Fan is turned on\")\n\n    def turn_off(self):\n        print(\"Fan is turned off\")\n\nclass Speaker(Device):\n    def turn_on(self):\n        print(\"Speaker is turned on\")\n\n    def turn_off(self):\n        print(\"Speaker is turned off\")\n\n高层模块\nclass DeviceController:\n    def __init__(self, device):\n        self.device = device\n\n    def operate(self):\n        self.device.turn_on()\n\n    def stop(self):\n        self.device.turn_off()\n\nmain\nif __name__ == \"__main__\":\n    light = Light()\n    fan = Fan()\n    speaker = Speaker()\n\n    controller1 = DeviceController(light)\n    controller2 = DeviceController(fan)\n    controller3 = DeviceController(speaker)\n\n    controller1.operate()\n    controller2.operate()\n    controller3.operate()\n\n    controller1.stop()\n    controller2.stop()\n    controller3.stop()\n高层模块 DeviceController 不直接依赖于具体的设备类（如 Light、Fan 和 Speaker），而是依赖于抽象的 Device 接口。这就是依赖倒置原则的应用，它使得高层模块更加灵活，可以轻松地切换和扩展不同类型的设备，而不需要修改高层模块的代码。这有助于创建松耦合的、易于维护和扩展的代码\n```\n\n\n\n## 六、装饰模式\n\n**动态地给一个对象添加一些额外的职责**，就增加功能来说，装饰模式比生成子类更为灵活\n\n在子类中定义一个父类对象，该对象使用需要装饰的对象作为初始化，并在子类中对该对象进行操作，即可达到，对对象的额外装饰结果，但是这一个对象和之前的对象不一定是同一个对象。\n\n* 基本结构\n\n```\n1、父类：父类定义一个抽象的方法\n2、子类：子类继承父类抽象方法并添加一些最基本的属性\n3、装饰器类：装饰器类继承父类，并定义一个父类的保护类型数据\n4、不同的装饰器类：不同的装饰器类继承于装饰器类，重写各自装饰器需要添加的职责\n\n通常第“2”步中定义基本属性的子类，会作为第一层装饰包装子类，后续会作为参数传入到装饰器类中\n```\n\n装饰模式可以把类中的装饰功能从类中搬移去除，这样就可以简化原有的类。同事有效地把类的核心职责和装饰功能区分开，去除相关类中的重复的装饰逻辑，重复的装饰逻辑可以使用一个子类作为最基类型。\n\n```\nexp：\n游戏中，不同人物角色使用不同技能进行装饰。最开始都是有一个人物的基类（低级的时候）。公共技能可以作为重复逻辑继承在一个类中，使用装饰模式，可以学习一些不同的技能。\n```\n\n## 七、代理模式\n\n代理模式，为其它对象提供一种代理以控制对这个对象的访问\n\n在客户与另一客户交互的过程中，中间会有一层代理，代理可以拥有两个客户的接口，作为中间实体来进行来促使两客户进行交互，在代理中如果需要交互，则需要定义一个客户的类，来调用该客户的方法。\n\n* 代理模式应用场景\n\n  远程代理：为一个对象在不同的地址空间提供局部代表，这样可以隐藏一个对象存在于不同地址空间的事实\n\n  虚拟代理：根据需要创建开销很大的对象，通过它来存放实例化需要很长时间的真实对象，浏览器中加载图片就是使用虚拟代理\n\n  安全代理：用来控制真实对象访问时的权限\n\n  智能指引：当掉哟个真实对象时，代理处理另外一些事\n\n## 八、工厂方法模式\n\n封装实例来创建过程，可以让创建实例的过程封装到工厂类中，避免耦合\n\n\n\n\n## 九、原型模式\n\n用原型（Prototype）实例指定创建对象的种类，并且通过复制这些原型创建新的对象\n\n* 用法\n\n  在类里面定义一个函数，函数可以返回一个原型对象\n\n* 在类中定义修改原型中属性的set方法\n\n* 在使用的过程中，只需要调用set方法修改不同的地方\n\n深拷贝与浅拷贝，若在原型类中使用对象引用，在修改的时候记得使用深拷贝\n\n\n\n## 十、模板方法模式\n\n定义一个操作中的算法的骨架，将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤\n\n\n\n## 十一、迪米特法则\n\n> 最小知识原则\n\n如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。","slug":"大话设计模式","published":0,"updated":"2024-06-05T09:03:03.319Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttd000608jv8t6x659m","content":"<h2 id=\"一、简单工厂模式\"><a href=\"#一、简单工厂模式\" class=\"headerlink\" title=\"一、简单工厂模式\"></a>一、简单工厂模式</h2><blockquote>\n<p>注意：命名规范、多个分支使用switch、考虑异常情况</p>\n</blockquote>\n<p>面向对象的编程，对代码做到：可维护、可复用、灵活性好</p>\n<ul>\n<li><p>业务的封装</p>\n<p>前后端分离，将业务逻辑和界面逻辑分开，让他们之间的耦合度下降，可以依赖面向对象的三大特性来实现</p>\n</li>\n<li><p>工厂模式</p>\n<p>通过工厂类，传入不同的字符串来返回不同继承类的构造函数，需要实例哪一个子类，可以通过传入参数来进行选择</p>\n<p>可以使用switch，或者使用map映射等方式</p>\n</li>\n<li><p>UML类图</p>\n<ul>\n<li>依赖关系</li>\n<li>聚合关系</li>\n<li>合成关系</li>\n<li>继承关系</li>\n<li>关联关系</li>\n<li>接口关系</li>\n<li>泛化关系</li>\n</ul>\n</li>\n</ul>\n\n<h2 id=\"二、策略模式\"><a href=\"#二、策略模式\" class=\"headerlink\" title=\"二、策略模式\"></a>二、策略模式</h2><blockquote>\n<p>策略模式定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的用户。</p>\n</blockquote>\n<p>只有算法需要替换，而其它不需要替换</p>\n<p>使用策略类，定义所有支持算法的公共接口</p>\n<ul>\n<li>策略模式是一种定义一系列算法的方法，所有这些算法完成的是相同的工作，但是实现不同，可以以相同的方式调用所有的方法，减少了各种算法类与使用算法类之间的耦合</li>\n<li>策略模式的优点可以简化单元测试，因为每个算法都有自己的类，可以通过自己的接口单独测试</li>\n</ul>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">策略模式的三个要点<br><span class=\"hljs-number\">1</span>、基类，策略接口，用于子类继承该基类，并重写基类中的策略方法<br><span class=\"hljs-number\">2</span>、具体的策略类，不同的策略类使用不同的方法来实现基类的虚方法<br><span class=\"hljs-number\">3</span>、上下文，<span class=\"hljs-built_in\">context</span>，在上下文中，通过一个公共的方法，来调用不同子类实现的虚方法（使用传入不同子类对象来实现）<br><br>用户只需要使用<span class=\"hljs-built_in\">context</span>来使用不同对象传入即可以完成不同的策略选择<br></code></pre></td></tr></table></figure>\n<h2 id=\"三、单一职责原则\"><a href=\"#三、单一职责原则\" class=\"headerlink\" title=\"三、单一职责原则\"></a>三、单一职责原则</h2><blockquote>\n<p>对于一个类而言，应该仅有一个引起它变化的原因。</p>\n<p>如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者这个类完成其它职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭到意想不到的破坏。</p>\n</blockquote>\n<h2 id=\"四、开放-封闭原则\"><a href=\"#四、开放-封闭原则\" class=\"headerlink\" title=\"四、开放-封闭原则\"></a>四、开放-封闭原则</h2><p><strong>软件实体（类、模块、函数等）应该可以扩展但不可修改，即对拓展开放，对修改封闭</strong></p>\n<h2 id=\"五、依赖倒置原则\"><a href=\"#五、依赖倒置原则\" class=\"headerlink\" title=\"五、依赖倒置原则\"></a>五、依赖倒置原则</h2><p>1、高层模块不应该依赖底层模块，两个都应该依赖抽象</p>\n<p>2、抽象不应该依赖细节，细节应该依赖抽象</p>\n<ul>\n<li><p>里氏代换原则</p>\n<p>一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类对象和子类对象的区别。</p>\n<p>即：子类型必须能够替换掉它们的父类型</p>\n</li>\n</ul>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\">和策略模式有一定的相似之处，例子<br><br><span class=\"hljs-title class_\">Device</span>类<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Device</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        pass<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        pass<br><br>子类<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Light</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Light is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Light is turned off&quot;</span>)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Fan</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Fan is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Fan is turned off&quot;</span>)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Speaker</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Speaker is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Speaker is turned off&quot;</span>)<br><br>高层模块<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DeviceController</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, device</span>):<br>        <span class=\"hljs-variable language_\">self</span>.device = device<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">operate</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        <span class=\"hljs-variable language_\">self</span>.device.turn_on()<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">stop</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        <span class=\"hljs-variable language_\">self</span>.device.turn_off()<br><br>main<br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    light = <span class=\"hljs-title class_\">Light</span>()<br>    fan = <span class=\"hljs-title class_\">Fan</span>()<br>    speaker = <span class=\"hljs-title class_\">Speaker</span>()<br><br>    controller1 = <span class=\"hljs-title class_\">DeviceController</span>(light)<br>    controller2 = <span class=\"hljs-title class_\">DeviceController</span>(fan)<br>    controller3 = <span class=\"hljs-title class_\">DeviceController</span>(speaker)<br><br>    controller1.operate()<br>    controller2.operate()<br>    controller3.operate()<br><br>    controller1.stop()<br>    controller2.stop()<br>    controller3.stop()<br>高层模块 <span class=\"hljs-title class_\">DeviceController</span> 不直接依赖于具体的设备类（如 <span class=\"hljs-title class_\">Light</span>、<span class=\"hljs-title class_\">Fan</span> 和 <span class=\"hljs-title class_\">Speaker</span>），而是依赖于抽象的 <span class=\"hljs-title class_\">Device</span> 接口。这就是依赖倒置原则的应用，它使得高层模块更加灵活，可以轻松地切换和扩展不同类型的设备，而不需要修改高层模块的代码。这有助于创建松耦合的、易于维护和扩展的代码<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、装饰模式\"><a href=\"#六、装饰模式\" class=\"headerlink\" title=\"六、装饰模式\"></a>六、装饰模式</h2><p><strong>动态地给一个对象添加一些额外的职责</strong>，就增加功能来说，装饰模式比生成子类更为灵活</p>\n<p>在子类中定义一个父类对象，该对象使用需要装饰的对象作为初始化，并在子类中对该对象进行操作，即可达到，对对象的额外装饰结果，但是这一个对象和之前的对象不一定是同一个对象。</p>\n<ul>\n<li>基本结构</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">1、父类：父类定义一个抽象的方法<br>2、子类：子类继承父类抽象方法并添加一些最基本的属性<br>3、装饰器类：装饰器类继承父类，并定义一个父类的保护类型数据<br>4、不同的装饰器类：不同的装饰器类继承于装饰器类，重写各自装饰器需要添加的职责<br><br>通常第“2”步中定义基本属性的子类，会作为第一层装饰包装子类，后续会作为参数传入到装饰器类中<br></code></pre></td></tr></table></figure>\n<p>装饰模式可以把类中的装饰功能从类中搬移去除，这样就可以简化原有的类。同事有效地把类的核心职责和装饰功能区分开，去除相关类中的重复的装饰逻辑，重复的装饰逻辑可以使用一个子类作为最基类型。</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs 1c\"><span class=\"hljs-built_in\">exp</span>：<br>游戏中，不同人物角色使用不同技能进行装饰。最开始都是有一个人物的基类（低级的时候）。公共技能可以作为重复逻辑继承在一个类中，使用装饰模式，可以学习一些不同的技能。<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、代理模式\"><a href=\"#七、代理模式\" class=\"headerlink\" title=\"七、代理模式\"></a>七、代理模式</h2><p>代理模式，为其它对象提供一种代理以控制对这个对象的访问</p>\n<p>在客户与另一客户交互的过程中，中间会有一层代理，代理可以拥有两个客户的接口，作为中间实体来进行来促使两客户进行交互，在代理中如果需要交互，则需要定义一个客户的类，来调用该客户的方法。</p>\n<ul>\n<li><p>代理模式应用场景</p>\n<p>远程代理：为一个对象在不同的地址空间提供局部代表，这样可以隐藏一个对象存在于不同地址空间的事实</p>\n<p>虚拟代理：根据需要创建开销很大的对象，通过它来存放实例化需要很长时间的真实对象，浏览器中加载图片就是使用虚拟代理</p>\n<p>安全代理：用来控制真实对象访问时的权限</p>\n<p>智能指引：当掉哟个真实对象时，代理处理另外一些事</p>\n</li>\n</ul>\n<h2 id=\"八、工厂方法模式\"><a href=\"#八、工厂方法模式\" class=\"headerlink\" title=\"八、工厂方法模式\"></a>八、工厂方法模式</h2><p>封装实例来创建过程，可以让创建实例的过程封装到工厂类中，避免耦合</p>\n<h2 id=\"九、原型模式\"><a href=\"#九、原型模式\" class=\"headerlink\" title=\"九、原型模式\"></a>九、原型模式</h2><p>用原型（Prototype）实例指定创建对象的种类，并且通过复制这些原型创建新的对象</p>\n<ul>\n<li><p>用法</p>\n<p>在类里面定义一个函数，函数可以返回一个原型对象</p>\n</li>\n<li><p>在类中定义修改原型中属性的set方法</p>\n</li>\n<li><p>在使用的过程中，只需要调用set方法修改不同的地方</p>\n</li>\n</ul>\n<p>深拷贝与浅拷贝，若在原型类中使用对象引用，在修改的时候记得使用深拷贝</p>\n<h2 id=\"十、模板方法模式\"><a href=\"#十、模板方法模式\" class=\"headerlink\" title=\"十、模板方法模式\"></a>十、模板方法模式</h2><p>定义一个操作中的算法的骨架，将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤</p>\n<h2 id=\"十一、迪米特法则\"><a href=\"#十一、迪米特法则\" class=\"headerlink\" title=\"十一、迪米特法则\"></a>十一、迪米特法则</h2><blockquote>\n<p>最小知识原则</p>\n</blockquote>\n<p>如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"一、简单工厂模式\"><a href=\"#一、简单工厂模式\" class=\"headerlink\" title=\"一、简单工厂模式\"></a>一、简单工厂模式</h2><blockquote>\n<p>注意：命名规范、多个分支使用switch、考虑异常情况</p>\n</blockquote>\n<p>面向对象的编程，对代码做到：可维护、可复用、灵活性好</p>\n<ul>\n<li><p>业务的封装</p>\n<p>前后端分离，将业务逻辑和界面逻辑分开，让他们之间的耦合度下降，可以依赖面向对象的三大特性来实现</p>\n</li>\n<li><p>工厂模式</p>\n<p>通过工厂类，传入不同的字符串来返回不同继承类的构造函数，需要实例哪一个子类，可以通过传入参数来进行选择</p>\n<p>可以使用switch，或者使用map映射等方式</p>\n</li>\n<li><p>UML类图</p>\n<ul>\n<li>依赖关系</li>\n<li>聚合关系</li>\n<li>合成关系</li>\n<li>继承关系</li>\n<li>关联关系</li>\n<li>接口关系</li>\n<li>泛化关系</li>\n</ul>\n</li>\n</ul>\n\n<h2 id=\"二、策略模式\"><a href=\"#二、策略模式\" class=\"headerlink\" title=\"二、策略模式\"></a>二、策略模式</h2><blockquote>\n<p>策略模式定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的用户。</p>\n</blockquote>\n<p>只有算法需要替换，而其它不需要替换</p>\n<p>使用策略类，定义所有支持算法的公共接口</p>\n<ul>\n<li>策略模式是一种定义一系列算法的方法，所有这些算法完成的是相同的工作，但是实现不同，可以以相同的方式调用所有的方法，减少了各种算法类与使用算法类之间的耦合</li>\n<li>策略模式的优点可以简化单元测试，因为每个算法都有自己的类，可以通过自己的接口单独测试</li>\n</ul>\n<figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">策略模式的三个要点<br><span class=\"hljs-number\">1</span>、基类，策略接口，用于子类继承该基类，并重写基类中的策略方法<br><span class=\"hljs-number\">2</span>、具体的策略类，不同的策略类使用不同的方法来实现基类的虚方法<br><span class=\"hljs-number\">3</span>、上下文，<span class=\"hljs-built_in\">context</span>，在上下文中，通过一个公共的方法，来调用不同子类实现的虚方法（使用传入不同子类对象来实现）<br><br>用户只需要使用<span class=\"hljs-built_in\">context</span>来使用不同对象传入即可以完成不同的策略选择<br></code></pre></td></tr></table></figure>\n<h2 id=\"三、单一职责原则\"><a href=\"#三、单一职责原则\" class=\"headerlink\" title=\"三、单一职责原则\"></a>三、单一职责原则</h2><blockquote>\n<p>对于一个类而言，应该仅有一个引起它变化的原因。</p>\n<p>如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者这个类完成其它职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭到意想不到的破坏。</p>\n</blockquote>\n<h2 id=\"四、开放-封闭原则\"><a href=\"#四、开放-封闭原则\" class=\"headerlink\" title=\"四、开放-封闭原则\"></a>四、开放-封闭原则</h2><p><strong>软件实体（类、模块、函数等）应该可以扩展但不可修改，即对拓展开放，对修改封闭</strong></p>\n<h2 id=\"五、依赖倒置原则\"><a href=\"#五、依赖倒置原则\" class=\"headerlink\" title=\"五、依赖倒置原则\"></a>五、依赖倒置原则</h2><p>1、高层模块不应该依赖底层模块，两个都应该依赖抽象</p>\n<p>2、抽象不应该依赖细节，细节应该依赖抽象</p>\n<ul>\n<li><p>里氏代换原则</p>\n<p>一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类对象和子类对象的区别。</p>\n<p>即：子类型必须能够替换掉它们的父类型</p>\n</li>\n</ul>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\">和策略模式有一定的相似之处，例子<br><br><span class=\"hljs-title class_\">Device</span>类<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Device</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        pass<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        pass<br><br>子类<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Light</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Light is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Light is turned off&quot;</span>)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Fan</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Fan is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Fan is turned off&quot;</span>)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Speaker</span>(<span class=\"hljs-title class_\">Device</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_on</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Speaker is turned on&quot;</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">turn_off</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        print(<span class=\"hljs-string\">&quot;Speaker is turned off&quot;</span>)<br><br>高层模块<br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DeviceController</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, device</span>):<br>        <span class=\"hljs-variable language_\">self</span>.device = device<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">operate</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        <span class=\"hljs-variable language_\">self</span>.device.turn_on()<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">stop</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span></span>):<br>        <span class=\"hljs-variable language_\">self</span>.device.turn_off()<br><br>main<br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    light = <span class=\"hljs-title class_\">Light</span>()<br>    fan = <span class=\"hljs-title class_\">Fan</span>()<br>    speaker = <span class=\"hljs-title class_\">Speaker</span>()<br><br>    controller1 = <span class=\"hljs-title class_\">DeviceController</span>(light)<br>    controller2 = <span class=\"hljs-title class_\">DeviceController</span>(fan)<br>    controller3 = <span class=\"hljs-title class_\">DeviceController</span>(speaker)<br><br>    controller1.operate()<br>    controller2.operate()<br>    controller3.operate()<br><br>    controller1.stop()<br>    controller2.stop()<br>    controller3.stop()<br>高层模块 <span class=\"hljs-title class_\">DeviceController</span> 不直接依赖于具体的设备类（如 <span class=\"hljs-title class_\">Light</span>、<span class=\"hljs-title class_\">Fan</span> 和 <span class=\"hljs-title class_\">Speaker</span>），而是依赖于抽象的 <span class=\"hljs-title class_\">Device</span> 接口。这就是依赖倒置原则的应用，它使得高层模块更加灵活，可以轻松地切换和扩展不同类型的设备，而不需要修改高层模块的代码。这有助于创建松耦合的、易于维护和扩展的代码<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、装饰模式\"><a href=\"#六、装饰模式\" class=\"headerlink\" title=\"六、装饰模式\"></a>六、装饰模式</h2><p><strong>动态地给一个对象添加一些额外的职责</strong>，就增加功能来说，装饰模式比生成子类更为灵活</p>\n<p>在子类中定义一个父类对象，该对象使用需要装饰的对象作为初始化，并在子类中对该对象进行操作，即可达到，对对象的额外装饰结果，但是这一个对象和之前的对象不一定是同一个对象。</p>\n<ul>\n<li>基本结构</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">1、父类：父类定义一个抽象的方法<br>2、子类：子类继承父类抽象方法并添加一些最基本的属性<br>3、装饰器类：装饰器类继承父类，并定义一个父类的保护类型数据<br>4、不同的装饰器类：不同的装饰器类继承于装饰器类，重写各自装饰器需要添加的职责<br><br>通常第“2”步中定义基本属性的子类，会作为第一层装饰包装子类，后续会作为参数传入到装饰器类中<br></code></pre></td></tr></table></figure>\n<p>装饰模式可以把类中的装饰功能从类中搬移去除，这样就可以简化原有的类。同事有效地把类的核心职责和装饰功能区分开，去除相关类中的重复的装饰逻辑，重复的装饰逻辑可以使用一个子类作为最基类型。</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs 1c\"><span class=\"hljs-built_in\">exp</span>：<br>游戏中，不同人物角色使用不同技能进行装饰。最开始都是有一个人物的基类（低级的时候）。公共技能可以作为重复逻辑继承在一个类中，使用装饰模式，可以学习一些不同的技能。<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、代理模式\"><a href=\"#七、代理模式\" class=\"headerlink\" title=\"七、代理模式\"></a>七、代理模式</h2><p>代理模式，为其它对象提供一种代理以控制对这个对象的访问</p>\n<p>在客户与另一客户交互的过程中，中间会有一层代理，代理可以拥有两个客户的接口，作为中间实体来进行来促使两客户进行交互，在代理中如果需要交互，则需要定义一个客户的类，来调用该客户的方法。</p>\n<ul>\n<li><p>代理模式应用场景</p>\n<p>远程代理：为一个对象在不同的地址空间提供局部代表，这样可以隐藏一个对象存在于不同地址空间的事实</p>\n<p>虚拟代理：根据需要创建开销很大的对象，通过它来存放实例化需要很长时间的真实对象，浏览器中加载图片就是使用虚拟代理</p>\n<p>安全代理：用来控制真实对象访问时的权限</p>\n<p>智能指引：当掉哟个真实对象时，代理处理另外一些事</p>\n</li>\n</ul>\n<h2 id=\"八、工厂方法模式\"><a href=\"#八、工厂方法模式\" class=\"headerlink\" title=\"八、工厂方法模式\"></a>八、工厂方法模式</h2><p>封装实例来创建过程，可以让创建实例的过程封装到工厂类中，避免耦合</p>\n<h2 id=\"九、原型模式\"><a href=\"#九、原型模式\" class=\"headerlink\" title=\"九、原型模式\"></a>九、原型模式</h2><p>用原型（Prototype）实例指定创建对象的种类，并且通过复制这些原型创建新的对象</p>\n<ul>\n<li><p>用法</p>\n<p>在类里面定义一个函数，函数可以返回一个原型对象</p>\n</li>\n<li><p>在类中定义修改原型中属性的set方法</p>\n</li>\n<li><p>在使用的过程中，只需要调用set方法修改不同的地方</p>\n</li>\n</ul>\n<p>深拷贝与浅拷贝，若在原型类中使用对象引用，在修改的时候记得使用深拷贝</p>\n<h2 id=\"十、模板方法模式\"><a href=\"#十、模板方法模式\" class=\"headerlink\" title=\"十、模板方法模式\"></a>十、模板方法模式</h2><p>定义一个操作中的算法的骨架，将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤</p>\n<h2 id=\"十一、迪米特法则\"><a href=\"#十一、迪米特法则\" class=\"headerlink\" title=\"十一、迪米特法则\"></a>十一、迪米特法则</h2><blockquote>\n<p>最小知识原则</p>\n</blockquote>\n<p>如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。</p>\n"},{"title":"CMU15445数据库学习笔记01-04","date":"2024-02-10T08:08:56.000Z","cover":"/img/default_cover01.jpg","top_img":null,"_content":"## 01-Relational Model & Relational Algebra \n\n### 数据库基本概念\n\n数据库管理系统：允许应用在数据库中存储、操作、分析数据信息的一种软件。通常的数据库管理系统（DBMS）支持通过一些数据模型（data model）定义、创建、查询、更新以及数据库的管理工作\n\n数据模型（data model）： 将存储的概念的高级抽象在数据库中，是数据库中描述数据的一种概念集合，能够表明数据的形状、属性等。\n\n* 关系型数据模型：关系型数据库\n* 非关系型模型Nosql：key/value、Graph、Document/Object\n* 矩阵/向量/列表\n* 分层、网络\n\n模式（schema）：是一个逻辑概念，用于组织数据库中的对象。模式中的对象通常包括表、索引、数据类型、序列、视图、存储过程、主键、外键等。\n\n### 关系型模型（Relational Model）\n\n定义了一个数据库抽象层，用于如何替换表示关系以避免数据库维护的开销。\n\n* 三大原则\n  * 存储数据库的简单数据结构\n  * 数据库的存储由数据库管理系统来实现，无需用户定义数据的存储形式，例如tree等\n  * 允许数据使用高级语言，数据库管理系统产生最优的执行策略\n\n关系（table、relation）：包含代表实体属性关系的一种无序集合\n\n元组（tuple）：关系中的属性值表现的集合，值也叫做域（domain）\n\n主键（primary key）：识别唯一元组的方法，是一组关键的属性\n\n外键（foreign key）：允许定义一个关系中的数据如何与另一个关系相关，外键作为一个映射表（交叉引用表）\n\n\n\n### 基本语法\n\n* SELECT\n\n  从一个关系中通过某些过滤信息选择出元组的子集，条件通常写在where 后面\n\n  ![image-20240102163927925](15445-study-notes-01-04/image-20240102163927925.png)\n\n* PROJECTION（投影）\n\n  使用数据库中的元组重新生成一个关系，只包含某一些特殊的属性。\n\n  把原来的表映射成一个新的表\n\n  ![image-20240102201317281](15445-study-notes-01-04/image-20240102201317281.png)\n\n* UNION（联合关系）\n\n  UNION ALL：不去重\n\n  UNION：去重\n\n  联合不同的数据库，但是数据库具有完全相同的属性。\n\n  默认情况下并集允许重复性\n\n* INTERSECT（交集关系）\n\n  两个数据库关系的交集，相同的元组集合\n\n* DIFFERENCE（取补集）\n\n  语法：EXCEPT\n\n* PRODUCT（笛卡尔积）\n\n  语法CROSS JOIN\n\n* JOIN\n\n  ![image-20240103093506806](15445-study-notes-01-04/image-20240103093506806.png)\n\n## 02-Modern SQL\n\n### AGGREGATES\n\n> 聚合（aggregations）：类似一个在查询中获取一组元组的函数\n>\n> AVG、MIN、MAX、SUM、COUNT\n\n![image-20240104092359606](15445-study-notes-01-04/image-20240104092359606.png)\n\n```\nCREATE TABLE student(\n\tsid INT PRIMARY KEY,\n\tname VARCHAR(50) NOT NULL,\n\tlogin VARCHAR(50) NOT NULL,\n\tage INT NOT NULL,\n\tgpa FLOAT DEFAULT 0\n);\n\nINSERT INTO student (sid, name, login, age, gpa) VALUES\n(53666, \"Kanye\", \"kanye@cs\", 44, 4.0),\n(53688, \"Bieber\", \"jbieber@cs\", 27, 3.9),\n(53655, \"Tupac\", \"shakur@cs\", 25, 3.5);\n\nCREATE TABLE enrolled(\n\tsid \n)\n```\n\n\n\n* 获取到student表中的注册统计数\n\n```\nSELECT COUNT(login) AS cnt FROM student WHERE login LIKE '%@cs';\n// 大多数数据库都对count（*）有优化\nSELECT COUNT(*) AS cnt FROM student WHERE login LIKE '%@cs';\nSELECT COUNT(1) AS cnt FROM student WHERE login LIKE '%@cs';\n```\n\n* 多聚合，多个属性的聚合\n\n```\nSELECT AVG(gpa), COUNT(sid) FROM student WHERE login LIKE '%@cs';\n```\n\n* DISTINCT\n\n  COUNT、SUM、AVG支持DISTINCT，表示只会统计不同的元素，去重\n\n```\nSELECT COUNTA(DISTINCT login) FROM student WHERE login LIKE '%@cs';\n```\n\n* GROUP BY\n\n  按照group by后面的元组进行select操作\n\n```\n// 按照cid的分组来计算gpa的平均值，并聚合cid和平均值两列元素\nSELECT AVG(s.gpa), e.cid\nFROM enrolled AS e, student AS s\nWHERE e.sid = s.sid\nGROUP BY e.cid;\n```\n\n* HAVING\n\n  在完成group by以后还需要再进行一些筛选，可以使用having\n\n### STRING OPERATIONS（字符串操作）\n\n* 模糊查询\n\n  > 数据库中没有搜索引擎，少用右模糊查询或者全模糊查询，百分号尽量不放在前面，在索引过程当中遵循最左匹配原则\n\n  %：代表一个或多个字符\n\n  _：代表单个字符\n\n* SUBSTRING\n\n  字符串切片操作\n\n```\n// 对name这一列中的字符串进行切片操作\nSELECT SUBSTRING(name, 1, 5) AS abbrv_name FROM student WHERE sid = 53688;\n```\n\n* UPPER：大写\n\n* LOWER：小写\n\n* CONCAT\n\n  连接操作，将字符串拼接起来\n\n```\nSELECT name FROM student WHERE login = CONCAT(LOWER(name), '@cs');\n```\n\n### OUTPUT REDIRECTION（输出重定向）\n\n将一个查询的结果集建成一个新的表，要求重定向的表是没有被定义的表，同时\n\n* CREATE TABLE\n\n```\n# 使用查询建一张表格\nCREATE TABLE CourseIds(\n\tSELECT DISTINCT cid FROM enrolled\n);\n```\n\n* ORDER BY <cloumn*> [ASC|DESC]\n\n  按照某一列或者多列进行增序或者降序\n\n```\n# ORDER BY 1: 根据第一列进行排序\nSELECT sid, grade FROM enrolled WHERE cid = '15-721' ORDER BY grade\n```\n\n* LIMIT < count > [offset]\n\n  输出count行，从第offset个开始\n\n```\n# 从满足条件的第10个开始查找20个学生\nSELECT sid, name FROM student\nWHERE login LIKE '%@cs'\nLIMIT 20 OFFSET 10;\n```\n\n### NESTED QUERIES（嵌套查询）\n\n将一个查询或多个查询嵌入到另一个查询当中\n\n![image-20240104193223551](15445-study-notes-01-04/image-20240104193223551.png)\n\n对子嵌套的关系进行操作\n\n* ALL：所有的行必须满足子查询中的表达式\n* ANY：至少一行必须在子查询中匹配\n* IN：等价于=ANY\n* EXISTS：只要内部查询产生一个输出记录就返回\n\n```\nSELECT name FROM student\nWHERE sid = ANY(\nSELECT sid FROM enrolled\nWHERE cid = '15-445'\n);\n```\n\n### WINDOW FUNCTIONS（窗口函数）\n\n类似于聚合，但不仅仅是将元组折叠成单个聚合，而是以一种增量的方式计算聚合\n\n* SELECT ... FUNC-NAME(...) OVER(...) FROM table\n\n  使用窗口函数FUNC-NAME，按照OVER的方式对查询的col进行聚合\n\n* 窗口函数种类\n\n  * ROW_NUMBER() ：每一行的行号\n  * RANK() ：位置\n  * 二者的区别在于，rank可以并列，但是row_number是唯一的\n\n* PARTITION BY  cid：按照cid分组，可以写在over中的条件里面\n\n```\n# 先将enrolled表按照cid分组，并按照grade排序\n# 再找出每一门课当中的第二名，ranking中第2高成绩的数据\nSELECT * FROM (\nSELECT *, RANK() OVER (PARTITION BY cid\nORDER BY grade ASC) AS rank\nFROM enrolled) AS ranking\nWHERE ranking.rank = 2\n```\n\n* CTE（COMMON TABLE EXPRESSIONS）\n\n  通用表达式：只在sql语句内部起作用的临时语句\n\n  RECURSIVE：递归调用，不是所有的sql都能够使用递归\n\n```\nWITH cteName (col1, col2) AS (\nSELECT 1, 2\n)\nSELECT col1 + col2 FROM cteName\n\nWITH cteSource (maxId) AS (\nSELECT MAX(sid) FROM enrolled\n)\nSELECT name FROM student, cteSource\nWHERE student.sid = cteSource.maxId\n\n# CTE递归的调用，很少用，可读性差\nWITH RECURSIVE cteSource (counter) AS (\n(SELECT 1)\nUNION ALL\n(SELECT counter + 1 FROM cteSource\nWHERE counter < 10)\n)\nSELECT * FROM cteSource\n```\n\n* CTE可以递归调用自身\n\n  \n\n## 03-Database Storage 1\n\n### 基于磁盘的架构\n\n>  数据库管理系统（DBMS）假设数据库的主要存储位置位于非易失性磁盘上。DBMS 的各个组件负责管理在非易失性存储和易失性存储之间的数据移动。\n\n* 数据库系统的设计目标\n\n  > 数据库系统做的操作有点类似于虚拟内存，如下图\n\n  1、系统可以管理超过内存可使用的总内存的数据\n\n  2、由于读写内存十分昂贵，需要尽可能避免数据大量的读写内存造成的性能损耗\n\n  3、尽可能使用顺序存储的方式提高效率\n\n* 为什么不适用操作系统？操作系统的虚拟内存可以进行相关操作\n\n  > 数据库管理系统使用内存映射存储文件的内容到程序的地址空间\n  >\n  > 操作系统负责文件页面的命中与否，数据库管理系统不需要考虑\n\n  \n\n![image-20240105160547664](15445-study-notes-01-04/image-20240105160547664.png)\n\n* 内存映射会遇到的问题（MEMORY MAPPED I/O PROBLEMS）\n\n  * 事务安全Transaction Safety\n\n  * I/O阻塞\n\n    数据库系统不知道内存中有哪些页面，所以在取数据如果发生错误，操作系统会阻塞线程\n\n  * 错误处理\n\n  * 性能问题\n\n结论：数据库管理系统不使用MMAP内存映射\n\n* 数据库进行管理\n\n  问题1、数据库系统如何表示磁盘上的文件数据\n\n  问题2、如何管理内存以从磁盘中来回移动这些页面的数据，数据的读入与写回\n\n### 文件存储\n\n> 数据库系统会使用数据库独有的文件格式在磁盘上存储一个或者多个文件\n>\n> 操作系统并无法知晓文件的内容\n\n* 存储管理器\n\n  用于维护数据库文件，进行页面调度提升性能，利用局部性原则，组织一系列的页面文件读写\n\n* 数据页面\n\n  > 页面被锁定为固定大小的数据块，可以包含任何内容，不可以包含混合的数据\n\n  硬件页面：存储设备可以保证它原子写出的最小数据或数据块大小，默认大小4KB\n\n  操作系统页面：通常4KB\n\n  数据库页面：512B-16KB\n\n  * 硬件页面是存储设备能够保证正确写入的最大块大小\n  * 使用更大的页面可以减少IO，运用到局部性原理，但是不能够确保更大的页面读写是原子的，需要使用一些操作来确保数据不会丢失\n\n* 堆文件heap file\n\n  按照随机顺序存储的无序页面的集合\n\n  包含有获取、创建、写入、删除页面，以及迭代功能\n\n  数据库管理系统维护一张特殊的表格用于定位数据库文件中的页面，也可以称为目录\n\n\n### 页面Page\n\n* 页面标头\n\n  页面大小\n\n  校验和：检查是否有数据损坏\n\n  数据库管理系统版本：升级系统会更新\n\n  事务可见性：用于进行权限管理\n\n  压缩信息、备份\n\n* 内部组织形式\n\n  * 面向元组tuple的存储方式\n\n    * 方式1\n\n    ![image-20240110074224104](15445-study-notes-01-04/image-20240110074224104.png)\n\n    删除其中一个tuple需要进行线性的移动\n\n    无法对可变长度的属性进行存储\n\n    * 方式二、开槽页面slot\n\n    在页面开头存入槽数组，将元组映射到页面的实际位置\n\n    槽页面是从尾端按照顺序存储\n\n    ![image-20240110074349028](15445-study-notes-01-04/image-20240110074349028.png)\n\n* Record IDS\n\n  > 每一个元组都有一个唯一的记录ID号\n\n  大部分格式为：页面ID+偏移量，可以使用ctid来获取（数据库中不能有列名为ctid的列） \n\n  * 每个元组都有元数据，元组头部：可见性信息（元组是否删除）、使用位图表示元组中的空值\n\n```\n#在数据库中可以对碎片整理，会填补前面因为元组删除而空余的slot\nVACUUM FULL table;\n```\n\n## 04-Database Storage 2\n\n### 基于日志的架构\n\n> 数据库管理系统存包含改变元组的日志记录（PUT、DELETE）\n>\n> 每一条日志记录包含元组独特的ID\n>\n> PUT：包含元组修改后的内容\n>\n> DELETE：将元组标记为删除\n\n数据库管理系统在内存页面中存储对元组操作的一些记录，例如修改某一个元组，删除某一个元组，当页面存满以后，记录会被永久保存，并切换到下一个页面，这样的好处可以磁盘IO更少，便于写入\n\n读入的时候，会需要向前不断追溯到最新的记录，读入很慢，在数据库管理系统中会维护一张index的表，映射到元组id的最新记录\n\n* 日志压缩\n\n  因为日志是随着数据库的操作而进行持续增长的，数据库管理系统会定期的压缩页面以减少空间浪费\n\n  通过将多个页面合并（找到记录的最新版本），移除掉不必要的记录\n\n  * 通用压缩（Universal Compation）\n\n    查看两个连续的排序文件，将其组合在一起，随后删除旧的文件\n\n  * 层级压缩（Level Compation）\n\n    类似于2048，层级较低的过多以后，整合压缩成更大的高层文件\n\n* 基于日志的架构有什么缺点\n\n  * 对写功能的放大\n\n    如果需要更新某一个元组，会在查询的过程中压缩，会和压缩过后的页面一起写回，写就被放大了\n\n  * 压缩代价较大\n\n### 元组的存储\n\n4类基本数据类型：整型，浮点（FLOAT/REAL，NUMERIC/DECIMAL），varchar，time\n\n* 高精度的数据\n  * Postgres，最终结果使用字符串的别名来表示，需要实现不同数据的拼接，很影响性能\n\n![image-20240112101151040](15445-study-notes-01-04/image-20240112101151040.png)\n\n* 大数据：例如大小超过一个页面的数据\n\n  使用其它的页面存储这些更大的页\n\n![image-20240112102928169](15445-study-notes-01-04/image-20240112102928169.png)\n\n* 外部资源数据\n\n  一些数据库系统允许存储外部文件的数据，对于这些外部文件，数据库系统无法做到持续性保护以及业务的保护，无法保证外部文件不被修改\n\n* 系统目录\n\n  数据库系统维护数据库的一些表格\n","source":"_posts/15445-study-notes-01-04.md","raw":"---\ntitle: CMU15445数据库学习笔记01-04\ndate: 2024-02-10 16:08:56\ntags: [数据库, CMU15445]\ncategories: [学习笔记]\ncover:\ntop_img:\n---\n## 01-Relational Model & Relational Algebra \n\n### 数据库基本概念\n\n数据库管理系统：允许应用在数据库中存储、操作、分析数据信息的一种软件。通常的数据库管理系统（DBMS）支持通过一些数据模型（data model）定义、创建、查询、更新以及数据库的管理工作\n\n数据模型（data model）： 将存储的概念的高级抽象在数据库中，是数据库中描述数据的一种概念集合，能够表明数据的形状、属性等。\n\n* 关系型数据模型：关系型数据库\n* 非关系型模型Nosql：key/value、Graph、Document/Object\n* 矩阵/向量/列表\n* 分层、网络\n\n模式（schema）：是一个逻辑概念，用于组织数据库中的对象。模式中的对象通常包括表、索引、数据类型、序列、视图、存储过程、主键、外键等。\n\n### 关系型模型（Relational Model）\n\n定义了一个数据库抽象层，用于如何替换表示关系以避免数据库维护的开销。\n\n* 三大原则\n  * 存储数据库的简单数据结构\n  * 数据库的存储由数据库管理系统来实现，无需用户定义数据的存储形式，例如tree等\n  * 允许数据使用高级语言，数据库管理系统产生最优的执行策略\n\n关系（table、relation）：包含代表实体属性关系的一种无序集合\n\n元组（tuple）：关系中的属性值表现的集合，值也叫做域（domain）\n\n主键（primary key）：识别唯一元组的方法，是一组关键的属性\n\n外键（foreign key）：允许定义一个关系中的数据如何与另一个关系相关，外键作为一个映射表（交叉引用表）\n\n\n\n### 基本语法\n\n* SELECT\n\n  从一个关系中通过某些过滤信息选择出元组的子集，条件通常写在where 后面\n\n  ![image-20240102163927925](15445-study-notes-01-04/image-20240102163927925.png)\n\n* PROJECTION（投影）\n\n  使用数据库中的元组重新生成一个关系，只包含某一些特殊的属性。\n\n  把原来的表映射成一个新的表\n\n  ![image-20240102201317281](15445-study-notes-01-04/image-20240102201317281.png)\n\n* UNION（联合关系）\n\n  UNION ALL：不去重\n\n  UNION：去重\n\n  联合不同的数据库，但是数据库具有完全相同的属性。\n\n  默认情况下并集允许重复性\n\n* INTERSECT（交集关系）\n\n  两个数据库关系的交集，相同的元组集合\n\n* DIFFERENCE（取补集）\n\n  语法：EXCEPT\n\n* PRODUCT（笛卡尔积）\n\n  语法CROSS JOIN\n\n* JOIN\n\n  ![image-20240103093506806](15445-study-notes-01-04/image-20240103093506806.png)\n\n## 02-Modern SQL\n\n### AGGREGATES\n\n> 聚合（aggregations）：类似一个在查询中获取一组元组的函数\n>\n> AVG、MIN、MAX、SUM、COUNT\n\n![image-20240104092359606](15445-study-notes-01-04/image-20240104092359606.png)\n\n```\nCREATE TABLE student(\n\tsid INT PRIMARY KEY,\n\tname VARCHAR(50) NOT NULL,\n\tlogin VARCHAR(50) NOT NULL,\n\tage INT NOT NULL,\n\tgpa FLOAT DEFAULT 0\n);\n\nINSERT INTO student (sid, name, login, age, gpa) VALUES\n(53666, \"Kanye\", \"kanye@cs\", 44, 4.0),\n(53688, \"Bieber\", \"jbieber@cs\", 27, 3.9),\n(53655, \"Tupac\", \"shakur@cs\", 25, 3.5);\n\nCREATE TABLE enrolled(\n\tsid \n)\n```\n\n\n\n* 获取到student表中的注册统计数\n\n```\nSELECT COUNT(login) AS cnt FROM student WHERE login LIKE '%@cs';\n// 大多数数据库都对count（*）有优化\nSELECT COUNT(*) AS cnt FROM student WHERE login LIKE '%@cs';\nSELECT COUNT(1) AS cnt FROM student WHERE login LIKE '%@cs';\n```\n\n* 多聚合，多个属性的聚合\n\n```\nSELECT AVG(gpa), COUNT(sid) FROM student WHERE login LIKE '%@cs';\n```\n\n* DISTINCT\n\n  COUNT、SUM、AVG支持DISTINCT，表示只会统计不同的元素，去重\n\n```\nSELECT COUNTA(DISTINCT login) FROM student WHERE login LIKE '%@cs';\n```\n\n* GROUP BY\n\n  按照group by后面的元组进行select操作\n\n```\n// 按照cid的分组来计算gpa的平均值，并聚合cid和平均值两列元素\nSELECT AVG(s.gpa), e.cid\nFROM enrolled AS e, student AS s\nWHERE e.sid = s.sid\nGROUP BY e.cid;\n```\n\n* HAVING\n\n  在完成group by以后还需要再进行一些筛选，可以使用having\n\n### STRING OPERATIONS（字符串操作）\n\n* 模糊查询\n\n  > 数据库中没有搜索引擎，少用右模糊查询或者全模糊查询，百分号尽量不放在前面，在索引过程当中遵循最左匹配原则\n\n  %：代表一个或多个字符\n\n  _：代表单个字符\n\n* SUBSTRING\n\n  字符串切片操作\n\n```\n// 对name这一列中的字符串进行切片操作\nSELECT SUBSTRING(name, 1, 5) AS abbrv_name FROM student WHERE sid = 53688;\n```\n\n* UPPER：大写\n\n* LOWER：小写\n\n* CONCAT\n\n  连接操作，将字符串拼接起来\n\n```\nSELECT name FROM student WHERE login = CONCAT(LOWER(name), '@cs');\n```\n\n### OUTPUT REDIRECTION（输出重定向）\n\n将一个查询的结果集建成一个新的表，要求重定向的表是没有被定义的表，同时\n\n* CREATE TABLE\n\n```\n# 使用查询建一张表格\nCREATE TABLE CourseIds(\n\tSELECT DISTINCT cid FROM enrolled\n);\n```\n\n* ORDER BY <cloumn*> [ASC|DESC]\n\n  按照某一列或者多列进行增序或者降序\n\n```\n# ORDER BY 1: 根据第一列进行排序\nSELECT sid, grade FROM enrolled WHERE cid = '15-721' ORDER BY grade\n```\n\n* LIMIT < count > [offset]\n\n  输出count行，从第offset个开始\n\n```\n# 从满足条件的第10个开始查找20个学生\nSELECT sid, name FROM student\nWHERE login LIKE '%@cs'\nLIMIT 20 OFFSET 10;\n```\n\n### NESTED QUERIES（嵌套查询）\n\n将一个查询或多个查询嵌入到另一个查询当中\n\n![image-20240104193223551](15445-study-notes-01-04/image-20240104193223551.png)\n\n对子嵌套的关系进行操作\n\n* ALL：所有的行必须满足子查询中的表达式\n* ANY：至少一行必须在子查询中匹配\n* IN：等价于=ANY\n* EXISTS：只要内部查询产生一个输出记录就返回\n\n```\nSELECT name FROM student\nWHERE sid = ANY(\nSELECT sid FROM enrolled\nWHERE cid = '15-445'\n);\n```\n\n### WINDOW FUNCTIONS（窗口函数）\n\n类似于聚合，但不仅仅是将元组折叠成单个聚合，而是以一种增量的方式计算聚合\n\n* SELECT ... FUNC-NAME(...) OVER(...) FROM table\n\n  使用窗口函数FUNC-NAME，按照OVER的方式对查询的col进行聚合\n\n* 窗口函数种类\n\n  * ROW_NUMBER() ：每一行的行号\n  * RANK() ：位置\n  * 二者的区别在于，rank可以并列，但是row_number是唯一的\n\n* PARTITION BY  cid：按照cid分组，可以写在over中的条件里面\n\n```\n# 先将enrolled表按照cid分组，并按照grade排序\n# 再找出每一门课当中的第二名，ranking中第2高成绩的数据\nSELECT * FROM (\nSELECT *, RANK() OVER (PARTITION BY cid\nORDER BY grade ASC) AS rank\nFROM enrolled) AS ranking\nWHERE ranking.rank = 2\n```\n\n* CTE（COMMON TABLE EXPRESSIONS）\n\n  通用表达式：只在sql语句内部起作用的临时语句\n\n  RECURSIVE：递归调用，不是所有的sql都能够使用递归\n\n```\nWITH cteName (col1, col2) AS (\nSELECT 1, 2\n)\nSELECT col1 + col2 FROM cteName\n\nWITH cteSource (maxId) AS (\nSELECT MAX(sid) FROM enrolled\n)\nSELECT name FROM student, cteSource\nWHERE student.sid = cteSource.maxId\n\n# CTE递归的调用，很少用，可读性差\nWITH RECURSIVE cteSource (counter) AS (\n(SELECT 1)\nUNION ALL\n(SELECT counter + 1 FROM cteSource\nWHERE counter < 10)\n)\nSELECT * FROM cteSource\n```\n\n* CTE可以递归调用自身\n\n  \n\n## 03-Database Storage 1\n\n### 基于磁盘的架构\n\n>  数据库管理系统（DBMS）假设数据库的主要存储位置位于非易失性磁盘上。DBMS 的各个组件负责管理在非易失性存储和易失性存储之间的数据移动。\n\n* 数据库系统的设计目标\n\n  > 数据库系统做的操作有点类似于虚拟内存，如下图\n\n  1、系统可以管理超过内存可使用的总内存的数据\n\n  2、由于读写内存十分昂贵，需要尽可能避免数据大量的读写内存造成的性能损耗\n\n  3、尽可能使用顺序存储的方式提高效率\n\n* 为什么不适用操作系统？操作系统的虚拟内存可以进行相关操作\n\n  > 数据库管理系统使用内存映射存储文件的内容到程序的地址空间\n  >\n  > 操作系统负责文件页面的命中与否，数据库管理系统不需要考虑\n\n  \n\n![image-20240105160547664](15445-study-notes-01-04/image-20240105160547664.png)\n\n* 内存映射会遇到的问题（MEMORY MAPPED I/O PROBLEMS）\n\n  * 事务安全Transaction Safety\n\n  * I/O阻塞\n\n    数据库系统不知道内存中有哪些页面，所以在取数据如果发生错误，操作系统会阻塞线程\n\n  * 错误处理\n\n  * 性能问题\n\n结论：数据库管理系统不使用MMAP内存映射\n\n* 数据库进行管理\n\n  问题1、数据库系统如何表示磁盘上的文件数据\n\n  问题2、如何管理内存以从磁盘中来回移动这些页面的数据，数据的读入与写回\n\n### 文件存储\n\n> 数据库系统会使用数据库独有的文件格式在磁盘上存储一个或者多个文件\n>\n> 操作系统并无法知晓文件的内容\n\n* 存储管理器\n\n  用于维护数据库文件，进行页面调度提升性能，利用局部性原则，组织一系列的页面文件读写\n\n* 数据页面\n\n  > 页面被锁定为固定大小的数据块，可以包含任何内容，不可以包含混合的数据\n\n  硬件页面：存储设备可以保证它原子写出的最小数据或数据块大小，默认大小4KB\n\n  操作系统页面：通常4KB\n\n  数据库页面：512B-16KB\n\n  * 硬件页面是存储设备能够保证正确写入的最大块大小\n  * 使用更大的页面可以减少IO，运用到局部性原理，但是不能够确保更大的页面读写是原子的，需要使用一些操作来确保数据不会丢失\n\n* 堆文件heap file\n\n  按照随机顺序存储的无序页面的集合\n\n  包含有获取、创建、写入、删除页面，以及迭代功能\n\n  数据库管理系统维护一张特殊的表格用于定位数据库文件中的页面，也可以称为目录\n\n\n### 页面Page\n\n* 页面标头\n\n  页面大小\n\n  校验和：检查是否有数据损坏\n\n  数据库管理系统版本：升级系统会更新\n\n  事务可见性：用于进行权限管理\n\n  压缩信息、备份\n\n* 内部组织形式\n\n  * 面向元组tuple的存储方式\n\n    * 方式1\n\n    ![image-20240110074224104](15445-study-notes-01-04/image-20240110074224104.png)\n\n    删除其中一个tuple需要进行线性的移动\n\n    无法对可变长度的属性进行存储\n\n    * 方式二、开槽页面slot\n\n    在页面开头存入槽数组，将元组映射到页面的实际位置\n\n    槽页面是从尾端按照顺序存储\n\n    ![image-20240110074349028](15445-study-notes-01-04/image-20240110074349028.png)\n\n* Record IDS\n\n  > 每一个元组都有一个唯一的记录ID号\n\n  大部分格式为：页面ID+偏移量，可以使用ctid来获取（数据库中不能有列名为ctid的列） \n\n  * 每个元组都有元数据，元组头部：可见性信息（元组是否删除）、使用位图表示元组中的空值\n\n```\n#在数据库中可以对碎片整理，会填补前面因为元组删除而空余的slot\nVACUUM FULL table;\n```\n\n## 04-Database Storage 2\n\n### 基于日志的架构\n\n> 数据库管理系统存包含改变元组的日志记录（PUT、DELETE）\n>\n> 每一条日志记录包含元组独特的ID\n>\n> PUT：包含元组修改后的内容\n>\n> DELETE：将元组标记为删除\n\n数据库管理系统在内存页面中存储对元组操作的一些记录，例如修改某一个元组，删除某一个元组，当页面存满以后，记录会被永久保存，并切换到下一个页面，这样的好处可以磁盘IO更少，便于写入\n\n读入的时候，会需要向前不断追溯到最新的记录，读入很慢，在数据库管理系统中会维护一张index的表，映射到元组id的最新记录\n\n* 日志压缩\n\n  因为日志是随着数据库的操作而进行持续增长的，数据库管理系统会定期的压缩页面以减少空间浪费\n\n  通过将多个页面合并（找到记录的最新版本），移除掉不必要的记录\n\n  * 通用压缩（Universal Compation）\n\n    查看两个连续的排序文件，将其组合在一起，随后删除旧的文件\n\n  * 层级压缩（Level Compation）\n\n    类似于2048，层级较低的过多以后，整合压缩成更大的高层文件\n\n* 基于日志的架构有什么缺点\n\n  * 对写功能的放大\n\n    如果需要更新某一个元组，会在查询的过程中压缩，会和压缩过后的页面一起写回，写就被放大了\n\n  * 压缩代价较大\n\n### 元组的存储\n\n4类基本数据类型：整型，浮点（FLOAT/REAL，NUMERIC/DECIMAL），varchar，time\n\n* 高精度的数据\n  * Postgres，最终结果使用字符串的别名来表示，需要实现不同数据的拼接，很影响性能\n\n![image-20240112101151040](15445-study-notes-01-04/image-20240112101151040.png)\n\n* 大数据：例如大小超过一个页面的数据\n\n  使用其它的页面存储这些更大的页\n\n![image-20240112102928169](15445-study-notes-01-04/image-20240112102928169.png)\n\n* 外部资源数据\n\n  一些数据库系统允许存储外部文件的数据，对于这些外部文件，数据库系统无法做到持续性保护以及业务的保护，无法保证外部文件不被修改\n\n* 系统目录\n\n  数据库系统维护数据库的一些表格\n","slug":"15445-study-notes-01-04","published":1,"updated":"2024-06-05T09:03:03.465Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttd000708jvcqa5cy2c","content":"<h2 id=\"01-Relational-Model-amp-Relational-Algebra\"><a href=\"#01-Relational-Model-amp-Relational-Algebra\" class=\"headerlink\" title=\"01-Relational Model &amp; Relational Algebra\"></a>01-Relational Model &amp; Relational Algebra</h2><h3 id=\"数据库基本概念\"><a href=\"#数据库基本概念\" class=\"headerlink\" title=\"数据库基本概念\"></a>数据库基本概念</h3><p>数据库管理系统：允许应用在数据库中存储、操作、分析数据信息的一种软件。通常的数据库管理系统（DBMS）支持通过一些数据模型（data model）定义、创建、查询、更新以及数据库的管理工作</p>\n<p>数据模型（data model）： 将存储的概念的高级抽象在数据库中，是数据库中描述数据的一种概念集合，能够表明数据的形状、属性等。</p>\n<ul>\n<li>关系型数据模型：关系型数据库</li>\n<li>非关系型模型Nosql：key/value、Graph、Document/Object</li>\n<li>矩阵/向量/列表</li>\n<li>分层、网络</li>\n</ul>\n<p>模式（schema）：是一个逻辑概念，用于组织数据库中的对象。模式中的对象通常包括表、索引、数据类型、序列、视图、存储过程、主键、外键等。</p>\n<h3 id=\"关系型模型（Relational-Model）\"><a href=\"#关系型模型（Relational-Model）\" class=\"headerlink\" title=\"关系型模型（Relational Model）\"></a>关系型模型（Relational Model）</h3><p>定义了一个数据库抽象层，用于如何替换表示关系以避免数据库维护的开销。</p>\n<ul>\n<li>三大原则<ul>\n<li>存储数据库的简单数据结构</li>\n<li>数据库的存储由数据库管理系统来实现，无需用户定义数据的存储形式，例如tree等</li>\n<li>允许数据使用高级语言，数据库管理系统产生最优的执行策略</li>\n</ul>\n</li>\n</ul>\n<p>关系（table、relation）：包含代表实体属性关系的一种无序集合</p>\n<p>元组（tuple）：关系中的属性值表现的集合，值也叫做域（domain）</p>\n<p>主键（primary key）：识别唯一元组的方法，是一组关键的属性</p>\n<p>外键（foreign key）：允许定义一个关系中的数据如何与另一个关系相关，外键作为一个映射表（交叉引用表）</p>\n<h3 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h3><ul>\n<li><p>SELECT</p>\n<p>从一个关系中通过某些过滤信息选择出元组的子集，条件通常写在where 后面</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240102163927925.png\" class=\"\" title=\"image-20240102163927925\">\n</li>\n<li><p>PROJECTION（投影）</p>\n<p>使用数据库中的元组重新生成一个关系，只包含某一些特殊的属性。</p>\n<p>把原来的表映射成一个新的表</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240102201317281.png\" class=\"\" title=\"image-20240102201317281\">\n</li>\n<li><p>UNION（联合关系）</p>\n<p>UNION ALL：不去重</p>\n<p>UNION：去重</p>\n<p>联合不同的数据库，但是数据库具有完全相同的属性。</p>\n<p>默认情况下并集允许重复性</p>\n</li>\n<li><p>INTERSECT（交集关系）</p>\n<p>两个数据库关系的交集，相同的元组集合</p>\n</li>\n<li><p>DIFFERENCE（取补集）</p>\n<p>语法：EXCEPT</p>\n</li>\n<li><p>PRODUCT（笛卡尔积）</p>\n<p>语法CROSS JOIN</p>\n</li>\n<li><p>JOIN</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240103093506806.png\" class=\"\" title=\"image-20240103093506806\">\n</li>\n</ul>\n<h2 id=\"02-Modern-SQL\"><a href=\"#02-Modern-SQL\" class=\"headerlink\" title=\"02-Modern SQL\"></a>02-Modern SQL</h2><h3 id=\"AGGREGATES\"><a href=\"#AGGREGATES\" class=\"headerlink\" title=\"AGGREGATES\"></a>AGGREGATES</h3><blockquote>\n<p>聚合（aggregations）：类似一个在查询中获取一组元组的函数</p>\n<p>AVG、MIN、MAX、SUM、COUNT</p>\n</blockquote>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240104092359606.png\" class=\"\" title=\"image-20240104092359606\">\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> student(<br>\tsid <span class=\"hljs-type\">INT</span> <span class=\"hljs-keyword\">PRIMARY KEY</span>,<br>\t<span class=\"hljs-type\">name</span> <span class=\"hljs-type\">VARCHAR</span>(<span class=\"hljs-number\">50</span>) <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\t<span class=\"hljs-keyword\">login</span> <span class=\"hljs-type\">VARCHAR</span>(<span class=\"hljs-number\">50</span>) <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\tage <span class=\"hljs-type\">INT</span> <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\tgpa <span class=\"hljs-type\">FLOAT</span> <span class=\"hljs-keyword\">DEFAULT</span> <span class=\"hljs-number\">0</span><br>);<br><br><span class=\"hljs-keyword\">INSERT</span> <span class=\"hljs-keyword\">INTO</span> student (sid, <span class=\"hljs-type\">name</span>, <span class=\"hljs-keyword\">login</span>, age, gpa) <span class=\"hljs-keyword\">VALUES</span><br>(<span class=\"hljs-number\">53666</span>, &quot;Kanye&quot;, &quot;kanye@cs&quot;, <span class=\"hljs-number\">44</span>, <span class=\"hljs-number\">4.0</span>),<br>(<span class=\"hljs-number\">53688</span>, &quot;Bieber&quot;, &quot;jbieber@cs&quot;, <span class=\"hljs-number\">27</span>, <span class=\"hljs-number\">3.9</span>),<br>(<span class=\"hljs-number\">53655</span>, &quot;Tupac&quot;, &quot;shakur@cs&quot;, <span class=\"hljs-number\">25</span>, <span class=\"hljs-number\">3.5</span>);<br><br><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> enrolled(<br>\tsid <br>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>获取到student表中的注册统计数</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> COUNT(<span class=\"hljs-keyword\">login</span>) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br>// 大多数数据库都对count（*）有优化<br><span class=\"hljs-keyword\">SELECT</span> COUNT(*) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br><span class=\"hljs-keyword\">SELECT</span> COUNT(<span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>多聚合，多个属性的聚合</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> AVG(gpa), COUNT(sid) <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>DISTINCT</p>\n<p>COUNT、SUM、AVG支持DISTINCT，表示只会统计不同的元素，去重</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> COUNTA(<span class=\"hljs-keyword\">DISTINCT</span> <span class=\"hljs-keyword\">login</span>) <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>GROUP BY</p>\n<p>按照group by后面的元组进行select操作</p>\n</li>\n</ul>\n<figure class=\"highlight n1ql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs n1ql\">// 按照cid的分组来计算gpa的平均值，并聚合cid和平均值两列元素<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-built_in\">AVG</span>(s.gpa), <span class=\"hljs-built_in\">e</span>.cid<br><span class=\"hljs-keyword\">FROM</span> enrolled <span class=\"hljs-keyword\">AS</span> <span class=\"hljs-built_in\">e</span>, student <span class=\"hljs-keyword\">AS</span> s<br><span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-built_in\">e</span>.sid = s.sid<br><span class=\"hljs-keyword\">GROUP</span> <span class=\"hljs-keyword\">BY</span> <span class=\"hljs-built_in\">e</span>.cid;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>HAVING</p>\n<p>在完成group by以后还需要再进行一些筛选，可以使用having</p>\n</li>\n</ul>\n<h3 id=\"STRING-OPERATIONS（字符串操作）\"><a href=\"#STRING-OPERATIONS（字符串操作）\" class=\"headerlink\" title=\"STRING OPERATIONS（字符串操作）\"></a>STRING OPERATIONS（字符串操作）</h3><ul>\n<li><p>模糊查询</p>\n<blockquote>\n<p>数据库中没有搜索引擎，少用右模糊查询或者全模糊查询，百分号尽量不放在前面，在索引过程当中遵循最左匹配原则</p>\n</blockquote>\n<p>%：代表一个或多个字符</p>\n<p>_：代表单个字符</p>\n</li>\n<li><p>SUBSTRING</p>\n<p>字符串切片操作</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">// 对<span class=\"hljs-type\">name</span>这一列中的字符串进行切片操作<br><span class=\"hljs-keyword\">SELECT</span> SUBSTRING(<span class=\"hljs-type\">name</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>) <span class=\"hljs-keyword\">AS</span> abbrv_name <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> sid = <span class=\"hljs-number\">53688</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>UPPER：大写</p>\n</li>\n<li><p>LOWER：小写</p>\n</li>\n<li><p>CONCAT</p>\n<p>连接操作，将字符串拼接起来</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> = CONCAT(LOWER(<span class=\"hljs-type\">name</span>), <span class=\"hljs-string\">&#x27;@cs&#x27;</span>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"OUTPUT-REDIRECTION（输出重定向）\"><a href=\"#OUTPUT-REDIRECTION（输出重定向）\" class=\"headerlink\" title=\"OUTPUT REDIRECTION（输出重定向）\"></a>OUTPUT REDIRECTION（输出重定向）</h3><p>将一个查询的结果集建成一个新的表，要求重定向的表是没有被定义的表，同时</p>\n<ul>\n<li>CREATE TABLE</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 使用查询建一张表格<br><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> CourseIds(<br>\t<span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-keyword\">DISTINCT</span> cid <span class=\"hljs-keyword\">FROM</span> enrolled<br>);<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>ORDER BY <cloumn*> [ASC|DESC]</p>\n<p>按照某一列或者多列进行增序或者降序</p>\n</li>\n</ul>\n<figure class=\"highlight oxygene\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs oxygene\"># <span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> <span class=\"hljs-number\">1</span>: 根据第一列进行排序<br><span class=\"hljs-keyword\">SELECT</span> sid, grade <span class=\"hljs-keyword\">FROM</span> enrolled <span class=\"hljs-keyword\">WHERE</span> cid = <span class=\"hljs-string\">&#x27;15-721&#x27;</span> <span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> grade<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>LIMIT &lt; count &gt; [offset]</p>\n<p>输出count行，从第offset个开始</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 从满足条件的第<span class=\"hljs-number\">10</span>个开始查找<span class=\"hljs-number\">20</span>个学生<br><span class=\"hljs-keyword\">SELECT</span> sid, <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student<br><span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span><br><span class=\"hljs-keyword\">LIMIT</span> <span class=\"hljs-number\">20</span> <span class=\"hljs-keyword\">OFFSET</span> <span class=\"hljs-number\">10</span>;<br></code></pre></td></tr></table></figure>\n<h3 id=\"NESTED-QUERIES（嵌套查询）\"><a href=\"#NESTED-QUERIES（嵌套查询）\" class=\"headerlink\" title=\"NESTED QUERIES（嵌套查询）\"></a>NESTED QUERIES（嵌套查询）</h3><p>将一个查询或多个查询嵌入到另一个查询当中</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240104193223551.png\" class=\"\" title=\"image-20240104193223551\">\n<p>对子嵌套的关系进行操作</p>\n<ul>\n<li>ALL：所有的行必须满足子查询中的表达式</li>\n<li>ANY：至少一行必须在子查询中匹配</li>\n<li>IN：等价于=ANY</li>\n<li>EXISTS：只要内部查询产生一个输出记录就返回</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student<br><span class=\"hljs-keyword\">WHERE</span> sid = <span class=\"hljs-keyword\">ANY</span>(<br><span class=\"hljs-keyword\">SELECT</span> sid <span class=\"hljs-keyword\">FROM</span> enrolled<br><span class=\"hljs-keyword\">WHERE</span> cid = <span class=\"hljs-string\">&#x27;15-445&#x27;</span><br>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"WINDOW-FUNCTIONS（窗口函数）\"><a href=\"#WINDOW-FUNCTIONS（窗口函数）\" class=\"headerlink\" title=\"WINDOW FUNCTIONS（窗口函数）\"></a>WINDOW FUNCTIONS（窗口函数）</h3><p>类似于聚合，但不仅仅是将元组折叠成单个聚合，而是以一种增量的方式计算聚合</p>\n<ul>\n<li><p>SELECT … FUNC-NAME(…) OVER(…) FROM table</p>\n<p>使用窗口函数FUNC-NAME，按照OVER的方式对查询的col进行聚合</p>\n</li>\n<li><p>窗口函数种类</p>\n<ul>\n<li>ROW_NUMBER() ：每一行的行号</li>\n<li>RANK() ：位置</li>\n<li>二者的区别在于，rank可以并列，但是row_number是唯一的</li>\n</ul>\n</li>\n<li><p>PARTITION BY  cid：按照cid分组，可以写在over中的条件里面</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 先将enrolled表按照cid分组，并按照grade排序<br># 再找出每一门课当中的第二名，ranking中第<span class=\"hljs-number\">2</span>高成绩的数据<br><span class=\"hljs-keyword\">SELECT</span> * <span class=\"hljs-keyword\">FROM</span> (<br><span class=\"hljs-keyword\">SELECT</span> *, RANK() <span class=\"hljs-keyword\">OVER</span> (<span class=\"hljs-keyword\">PARTITION</span> <span class=\"hljs-keyword\">BY</span> cid<br><span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> grade <span class=\"hljs-keyword\">ASC</span>) <span class=\"hljs-keyword\">AS</span> rank<br><span class=\"hljs-keyword\">FROM</span> enrolled) <span class=\"hljs-keyword\">AS</span> ranking<br><span class=\"hljs-keyword\">WHERE</span> ranking.rank = <span class=\"hljs-number\">2</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>CTE（COMMON TABLE EXPRESSIONS）</p>\n<p>通用表达式：只在sql语句内部起作用的临时语句</p>\n<p>RECURSIVE：递归调用，不是所有的sql都能够使用递归</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">WITH</span> cteName (col1, col2) <span class=\"hljs-keyword\">AS</span> (<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span><br>)<br><span class=\"hljs-keyword\">SELECT</span> col1 + col2 <span class=\"hljs-keyword\">FROM</span> cteName<br><br><span class=\"hljs-keyword\">WITH</span> cteSource (maxId) <span class=\"hljs-keyword\">AS</span> (<br><span class=\"hljs-keyword\">SELECT</span> MAX(sid) <span class=\"hljs-keyword\">FROM</span> enrolled<br>)<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student, cteSource<br><span class=\"hljs-keyword\">WHERE</span> student.sid = cteSource.maxId<br><br># CTE递归的调用，很少用，可读性差<br><span class=\"hljs-keyword\">WITH</span> <span class=\"hljs-keyword\">RECURSIVE</span> cteSource (counter) <span class=\"hljs-keyword\">AS</span> (<br>(<span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-number\">1</span>)<br><span class=\"hljs-keyword\">UNION</span> <span class=\"hljs-keyword\">ALL</span><br>(<span class=\"hljs-keyword\">SELECT</span> counter + <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">FROM</span> cteSource<br><span class=\"hljs-keyword\">WHERE</span> counter &lt; <span class=\"hljs-number\">10</span>)<br>)<br><span class=\"hljs-keyword\">SELECT</span> * <span class=\"hljs-keyword\">FROM</span> cteSource<br></code></pre></td></tr></table></figure>\n<ul>\n<li>CTE可以递归调用自身</li>\n</ul>\n<h2 id=\"03-Database-Storage-1\"><a href=\"#03-Database-Storage-1\" class=\"headerlink\" title=\"03-Database Storage 1\"></a>03-Database Storage 1</h2><h3 id=\"基于磁盘的架构\"><a href=\"#基于磁盘的架构\" class=\"headerlink\" title=\"基于磁盘的架构\"></a>基于磁盘的架构</h3><blockquote>\n<p> 数据库管理系统（DBMS）假设数据库的主要存储位置位于非易失性磁盘上。DBMS 的各个组件负责管理在非易失性存储和易失性存储之间的数据移动。</p>\n</blockquote>\n<ul>\n<li><p>数据库系统的设计目标</p>\n<blockquote>\n<p>数据库系统做的操作有点类似于虚拟内存，如下图</p>\n</blockquote>\n<p>1、系统可以管理超过内存可使用的总内存的数据</p>\n<p>2、由于读写内存十分昂贵，需要尽可能避免数据大量的读写内存造成的性能损耗</p>\n<p>3、尽可能使用顺序存储的方式提高效率</p>\n</li>\n<li><p>为什么不适用操作系统？操作系统的虚拟内存可以进行相关操作</p>\n<blockquote>\n<p>数据库管理系统使用内存映射存储文件的内容到程序的地址空间</p>\n<p>操作系统负责文件页面的命中与否，数据库管理系统不需要考虑</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240105160547664.png\" class=\"\" title=\"image-20240105160547664\">\n<ul>\n<li><p>内存映射会遇到的问题（MEMORY MAPPED I/O PROBLEMS）</p>\n<ul>\n<li><p>事务安全Transaction Safety</p>\n</li>\n<li><p>I/O阻塞</p>\n<p>数据库系统不知道内存中有哪些页面，所以在取数据如果发生错误，操作系统会阻塞线程</p>\n</li>\n<li><p>错误处理</p>\n</li>\n<li><p>性能问题</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>结论：数据库管理系统不使用MMAP内存映射</p>\n<ul>\n<li><p>数据库进行管理</p>\n<p>问题1、数据库系统如何表示磁盘上的文件数据</p>\n<p>问题2、如何管理内存以从磁盘中来回移动这些页面的数据，数据的读入与写回</p>\n</li>\n</ul>\n<h3 id=\"文件存储\"><a href=\"#文件存储\" class=\"headerlink\" title=\"文件存储\"></a>文件存储</h3><blockquote>\n<p>数据库系统会使用数据库独有的文件格式在磁盘上存储一个或者多个文件</p>\n<p>操作系统并无法知晓文件的内容</p>\n</blockquote>\n<ul>\n<li><p>存储管理器</p>\n<p>用于维护数据库文件，进行页面调度提升性能，利用局部性原则，组织一系列的页面文件读写</p>\n</li>\n<li><p>数据页面</p>\n<blockquote>\n<p>页面被锁定为固定大小的数据块，可以包含任何内容，不可以包含混合的数据</p>\n</blockquote>\n<p>硬件页面：存储设备可以保证它原子写出的最小数据或数据块大小，默认大小4KB</p>\n<p>操作系统页面：通常4KB</p>\n<p>数据库页面：512B-16KB</p>\n<ul>\n<li>硬件页面是存储设备能够保证正确写入的最大块大小</li>\n<li>使用更大的页面可以减少IO，运用到局部性原理，但是不能够确保更大的页面读写是原子的，需要使用一些操作来确保数据不会丢失</li>\n</ul>\n</li>\n<li><p>堆文件heap file</p>\n<p>按照随机顺序存储的无序页面的集合</p>\n<p>包含有获取、创建、写入、删除页面，以及迭代功能</p>\n<p>数据库管理系统维护一张特殊的表格用于定位数据库文件中的页面，也可以称为目录</p>\n</li>\n</ul>\n<h3 id=\"页面Page\"><a href=\"#页面Page\" class=\"headerlink\" title=\"页面Page\"></a>页面Page</h3><ul>\n<li><p>页面标头</p>\n<p>页面大小</p>\n<p>校验和：检查是否有数据损坏</p>\n<p>数据库管理系统版本：升级系统会更新</p>\n<p>事务可见性：用于进行权限管理</p>\n<p>压缩信息、备份</p>\n</li>\n<li><p>内部组织形式</p>\n<ul>\n<li><p>面向元组tuple的存储方式</p>\n<ul>\n<li>方式1</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240110074224104.png\" class=\"\" title=\"image-20240110074224104\">\n<p>删除其中一个tuple需要进行线性的移动</p>\n<p>无法对可变长度的属性进行存储</p>\n<ul>\n<li>方式二、开槽页面slot</li>\n</ul>\n<p>在页面开头存入槽数组，将元组映射到页面的实际位置</p>\n<p>槽页面是从尾端按照顺序存储</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240110074349028.png\" class=\"\" title=\"image-20240110074349028\">\n</li>\n</ul>\n</li>\n<li><p>Record IDS</p>\n<blockquote>\n<p>每一个元组都有一个唯一的记录ID号</p>\n</blockquote>\n<p>大部分格式为：页面ID+偏移量，可以使用ctid来获取（数据库中不能有列名为ctid的列） </p>\n<ul>\n<li>每个元组都有元数据，元组头部：可见性信息（元组是否删除）、使用位图表示元组中的空值</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">#在数据库中可以对碎片整理，会填补前面因为元组删除而空余的slot<br><span class=\"hljs-keyword\">VACUUM</span> <span class=\"hljs-keyword\">FULL</span> <span class=\"hljs-keyword\">table</span>;<br></code></pre></td></tr></table></figure>\n<h2 id=\"04-Database-Storage-2\"><a href=\"#04-Database-Storage-2\" class=\"headerlink\" title=\"04-Database Storage 2\"></a>04-Database Storage 2</h2><h3 id=\"基于日志的架构\"><a href=\"#基于日志的架构\" class=\"headerlink\" title=\"基于日志的架构\"></a>基于日志的架构</h3><blockquote>\n<p>数据库管理系统存包含改变元组的日志记录（PUT、DELETE）</p>\n<p>每一条日志记录包含元组独特的ID</p>\n<p>PUT：包含元组修改后的内容</p>\n<p>DELETE：将元组标记为删除</p>\n</blockquote>\n<p>数据库管理系统在内存页面中存储对元组操作的一些记录，例如修改某一个元组，删除某一个元组，当页面存满以后，记录会被永久保存，并切换到下一个页面，这样的好处可以磁盘IO更少，便于写入</p>\n<p>读入的时候，会需要向前不断追溯到最新的记录，读入很慢，在数据库管理系统中会维护一张index的表，映射到元组id的最新记录</p>\n<ul>\n<li><p>日志压缩</p>\n<p>因为日志是随着数据库的操作而进行持续增长的，数据库管理系统会定期的压缩页面以减少空间浪费</p>\n<p>通过将多个页面合并（找到记录的最新版本），移除掉不必要的记录</p>\n<ul>\n<li><p>通用压缩（Universal Compation）</p>\n<p>查看两个连续的排序文件，将其组合在一起，随后删除旧的文件</p>\n</li>\n<li><p>层级压缩（Level Compation）</p>\n<p>类似于2048，层级较低的过多以后，整合压缩成更大的高层文件</p>\n</li>\n</ul>\n</li>\n<li><p>基于日志的架构有什么缺点</p>\n<ul>\n<li><p>对写功能的放大</p>\n<p>如果需要更新某一个元组，会在查询的过程中压缩，会和压缩过后的页面一起写回，写就被放大了</p>\n</li>\n<li><p>压缩代价较大</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"元组的存储\"><a href=\"#元组的存储\" class=\"headerlink\" title=\"元组的存储\"></a>元组的存储</h3><p>4类基本数据类型：整型，浮点（FLOAT/REAL，NUMERIC/DECIMAL），varchar，time</p>\n<ul>\n<li>高精度的数据<ul>\n<li>Postgres，最终结果使用字符串的别名来表示，需要实现不同数据的拼接，很影响性能</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240112101151040.png\" class=\"\" title=\"image-20240112101151040\">\n<ul>\n<li><p>大数据：例如大小超过一个页面的数据</p>\n<p>使用其它的页面存储这些更大的页</p>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240112102928169.png\" class=\"\" title=\"image-20240112102928169\">\n<ul>\n<li><p>外部资源数据</p>\n<p>一些数据库系统允许存储外部文件的数据，对于这些外部文件，数据库系统无法做到持续性保护以及业务的保护，无法保证外部文件不被修改</p>\n</li>\n<li><p>系统目录</p>\n<p>数据库系统维护数据库的一些表格</p>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"01-Relational-Model-amp-Relational-Algebra\"><a href=\"#01-Relational-Model-amp-Relational-Algebra\" class=\"headerlink\" title=\"01-Relational Model &amp; Relational Algebra\"></a>01-Relational Model &amp; Relational Algebra</h2><h3 id=\"数据库基本概念\"><a href=\"#数据库基本概念\" class=\"headerlink\" title=\"数据库基本概念\"></a>数据库基本概念</h3><p>数据库管理系统：允许应用在数据库中存储、操作、分析数据信息的一种软件。通常的数据库管理系统（DBMS）支持通过一些数据模型（data model）定义、创建、查询、更新以及数据库的管理工作</p>\n<p>数据模型（data model）： 将存储的概念的高级抽象在数据库中，是数据库中描述数据的一种概念集合，能够表明数据的形状、属性等。</p>\n<ul>\n<li>关系型数据模型：关系型数据库</li>\n<li>非关系型模型Nosql：key/value、Graph、Document/Object</li>\n<li>矩阵/向量/列表</li>\n<li>分层、网络</li>\n</ul>\n<p>模式（schema）：是一个逻辑概念，用于组织数据库中的对象。模式中的对象通常包括表、索引、数据类型、序列、视图、存储过程、主键、外键等。</p>\n<h3 id=\"关系型模型（Relational-Model）\"><a href=\"#关系型模型（Relational-Model）\" class=\"headerlink\" title=\"关系型模型（Relational Model）\"></a>关系型模型（Relational Model）</h3><p>定义了一个数据库抽象层，用于如何替换表示关系以避免数据库维护的开销。</p>\n<ul>\n<li>三大原则<ul>\n<li>存储数据库的简单数据结构</li>\n<li>数据库的存储由数据库管理系统来实现，无需用户定义数据的存储形式，例如tree等</li>\n<li>允许数据使用高级语言，数据库管理系统产生最优的执行策略</li>\n</ul>\n</li>\n</ul>\n<p>关系（table、relation）：包含代表实体属性关系的一种无序集合</p>\n<p>元组（tuple）：关系中的属性值表现的集合，值也叫做域（domain）</p>\n<p>主键（primary key）：识别唯一元组的方法，是一组关键的属性</p>\n<p>外键（foreign key）：允许定义一个关系中的数据如何与另一个关系相关，外键作为一个映射表（交叉引用表）</p>\n<h3 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h3><ul>\n<li><p>SELECT</p>\n<p>从一个关系中通过某些过滤信息选择出元组的子集，条件通常写在where 后面</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240102163927925.png\" class=\"\" title=\"image-20240102163927925\">\n</li>\n<li><p>PROJECTION（投影）</p>\n<p>使用数据库中的元组重新生成一个关系，只包含某一些特殊的属性。</p>\n<p>把原来的表映射成一个新的表</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240102201317281.png\" class=\"\" title=\"image-20240102201317281\">\n</li>\n<li><p>UNION（联合关系）</p>\n<p>UNION ALL：不去重</p>\n<p>UNION：去重</p>\n<p>联合不同的数据库，但是数据库具有完全相同的属性。</p>\n<p>默认情况下并集允许重复性</p>\n</li>\n<li><p>INTERSECT（交集关系）</p>\n<p>两个数据库关系的交集，相同的元组集合</p>\n</li>\n<li><p>DIFFERENCE（取补集）</p>\n<p>语法：EXCEPT</p>\n</li>\n<li><p>PRODUCT（笛卡尔积）</p>\n<p>语法CROSS JOIN</p>\n</li>\n<li><p>JOIN</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240103093506806.png\" class=\"\" title=\"image-20240103093506806\">\n</li>\n</ul>\n<h2 id=\"02-Modern-SQL\"><a href=\"#02-Modern-SQL\" class=\"headerlink\" title=\"02-Modern SQL\"></a>02-Modern SQL</h2><h3 id=\"AGGREGATES\"><a href=\"#AGGREGATES\" class=\"headerlink\" title=\"AGGREGATES\"></a>AGGREGATES</h3><blockquote>\n<p>聚合（aggregations）：类似一个在查询中获取一组元组的函数</p>\n<p>AVG、MIN、MAX、SUM、COUNT</p>\n</blockquote>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240104092359606.png\" class=\"\" title=\"image-20240104092359606\">\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> student(<br>\tsid <span class=\"hljs-type\">INT</span> <span class=\"hljs-keyword\">PRIMARY KEY</span>,<br>\t<span class=\"hljs-type\">name</span> <span class=\"hljs-type\">VARCHAR</span>(<span class=\"hljs-number\">50</span>) <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\t<span class=\"hljs-keyword\">login</span> <span class=\"hljs-type\">VARCHAR</span>(<span class=\"hljs-number\">50</span>) <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\tage <span class=\"hljs-type\">INT</span> <span class=\"hljs-keyword\">NOT</span> <span class=\"hljs-keyword\">NULL</span>,<br>\tgpa <span class=\"hljs-type\">FLOAT</span> <span class=\"hljs-keyword\">DEFAULT</span> <span class=\"hljs-number\">0</span><br>);<br><br><span class=\"hljs-keyword\">INSERT</span> <span class=\"hljs-keyword\">INTO</span> student (sid, <span class=\"hljs-type\">name</span>, <span class=\"hljs-keyword\">login</span>, age, gpa) <span class=\"hljs-keyword\">VALUES</span><br>(<span class=\"hljs-number\">53666</span>, &quot;Kanye&quot;, &quot;kanye@cs&quot;, <span class=\"hljs-number\">44</span>, <span class=\"hljs-number\">4.0</span>),<br>(<span class=\"hljs-number\">53688</span>, &quot;Bieber&quot;, &quot;jbieber@cs&quot;, <span class=\"hljs-number\">27</span>, <span class=\"hljs-number\">3.9</span>),<br>(<span class=\"hljs-number\">53655</span>, &quot;Tupac&quot;, &quot;shakur@cs&quot;, <span class=\"hljs-number\">25</span>, <span class=\"hljs-number\">3.5</span>);<br><br><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> enrolled(<br>\tsid <br>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>获取到student表中的注册统计数</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> COUNT(<span class=\"hljs-keyword\">login</span>) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br>// 大多数数据库都对count（*）有优化<br><span class=\"hljs-keyword\">SELECT</span> COUNT(*) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br><span class=\"hljs-keyword\">SELECT</span> COUNT(<span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">AS</span> cnt <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>多聚合，多个属性的聚合</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> AVG(gpa), COUNT(sid) <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>DISTINCT</p>\n<p>COUNT、SUM、AVG支持DISTINCT，表示只会统计不同的元素，去重</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> COUNTA(<span class=\"hljs-keyword\">DISTINCT</span> <span class=\"hljs-keyword\">login</span>) <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>GROUP BY</p>\n<p>按照group by后面的元组进行select操作</p>\n</li>\n</ul>\n<figure class=\"highlight n1ql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs n1ql\">// 按照cid的分组来计算gpa的平均值，并聚合cid和平均值两列元素<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-built_in\">AVG</span>(s.gpa), <span class=\"hljs-built_in\">e</span>.cid<br><span class=\"hljs-keyword\">FROM</span> enrolled <span class=\"hljs-keyword\">AS</span> <span class=\"hljs-built_in\">e</span>, student <span class=\"hljs-keyword\">AS</span> s<br><span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-built_in\">e</span>.sid = s.sid<br><span class=\"hljs-keyword\">GROUP</span> <span class=\"hljs-keyword\">BY</span> <span class=\"hljs-built_in\">e</span>.cid;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>HAVING</p>\n<p>在完成group by以后还需要再进行一些筛选，可以使用having</p>\n</li>\n</ul>\n<h3 id=\"STRING-OPERATIONS（字符串操作）\"><a href=\"#STRING-OPERATIONS（字符串操作）\" class=\"headerlink\" title=\"STRING OPERATIONS（字符串操作）\"></a>STRING OPERATIONS（字符串操作）</h3><ul>\n<li><p>模糊查询</p>\n<blockquote>\n<p>数据库中没有搜索引擎，少用右模糊查询或者全模糊查询，百分号尽量不放在前面，在索引过程当中遵循最左匹配原则</p>\n</blockquote>\n<p>%：代表一个或多个字符</p>\n<p>_：代表单个字符</p>\n</li>\n<li><p>SUBSTRING</p>\n<p>字符串切片操作</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">// 对<span class=\"hljs-type\">name</span>这一列中的字符串进行切片操作<br><span class=\"hljs-keyword\">SELECT</span> SUBSTRING(<span class=\"hljs-type\">name</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>) <span class=\"hljs-keyword\">AS</span> abbrv_name <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> sid = <span class=\"hljs-number\">53688</span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>UPPER：大写</p>\n</li>\n<li><p>LOWER：小写</p>\n</li>\n<li><p>CONCAT</p>\n<p>连接操作，将字符串拼接起来</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student <span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> = CONCAT(LOWER(<span class=\"hljs-type\">name</span>), <span class=\"hljs-string\">&#x27;@cs&#x27;</span>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"OUTPUT-REDIRECTION（输出重定向）\"><a href=\"#OUTPUT-REDIRECTION（输出重定向）\" class=\"headerlink\" title=\"OUTPUT REDIRECTION（输出重定向）\"></a>OUTPUT REDIRECTION（输出重定向）</h3><p>将一个查询的结果集建成一个新的表，要求重定向的表是没有被定义的表，同时</p>\n<ul>\n<li>CREATE TABLE</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 使用查询建一张表格<br><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> CourseIds(<br>\t<span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-keyword\">DISTINCT</span> cid <span class=\"hljs-keyword\">FROM</span> enrolled<br>);<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>ORDER BY <cloumn*> [ASC|DESC]</p>\n<p>按照某一列或者多列进行增序或者降序</p>\n</li>\n</ul>\n<figure class=\"highlight oxygene\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs oxygene\"># <span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> <span class=\"hljs-number\">1</span>: 根据第一列进行排序<br><span class=\"hljs-keyword\">SELECT</span> sid, grade <span class=\"hljs-keyword\">FROM</span> enrolled <span class=\"hljs-keyword\">WHERE</span> cid = <span class=\"hljs-string\">&#x27;15-721&#x27;</span> <span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> grade<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>LIMIT &lt; count &gt; [offset]</p>\n<p>输出count行，从第offset个开始</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 从满足条件的第<span class=\"hljs-number\">10</span>个开始查找<span class=\"hljs-number\">20</span>个学生<br><span class=\"hljs-keyword\">SELECT</span> sid, <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student<br><span class=\"hljs-keyword\">WHERE</span> <span class=\"hljs-keyword\">login</span> <span class=\"hljs-keyword\">LIKE</span> <span class=\"hljs-string\">&#x27;%@cs&#x27;</span><br><span class=\"hljs-keyword\">LIMIT</span> <span class=\"hljs-number\">20</span> <span class=\"hljs-keyword\">OFFSET</span> <span class=\"hljs-number\">10</span>;<br></code></pre></td></tr></table></figure>\n<h3 id=\"NESTED-QUERIES（嵌套查询）\"><a href=\"#NESTED-QUERIES（嵌套查询）\" class=\"headerlink\" title=\"NESTED QUERIES（嵌套查询）\"></a>NESTED QUERIES（嵌套查询）</h3><p>将一个查询或多个查询嵌入到另一个查询当中</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240104193223551.png\" class=\"\" title=\"image-20240104193223551\">\n<p>对子嵌套的关系进行操作</p>\n<ul>\n<li>ALL：所有的行必须满足子查询中的表达式</li>\n<li>ANY：至少一行必须在子查询中匹配</li>\n<li>IN：等价于=ANY</li>\n<li>EXISTS：只要内部查询产生一个输出记录就返回</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student<br><span class=\"hljs-keyword\">WHERE</span> sid = <span class=\"hljs-keyword\">ANY</span>(<br><span class=\"hljs-keyword\">SELECT</span> sid <span class=\"hljs-keyword\">FROM</span> enrolled<br><span class=\"hljs-keyword\">WHERE</span> cid = <span class=\"hljs-string\">&#x27;15-445&#x27;</span><br>);<br></code></pre></td></tr></table></figure>\n<h3 id=\"WINDOW-FUNCTIONS（窗口函数）\"><a href=\"#WINDOW-FUNCTIONS（窗口函数）\" class=\"headerlink\" title=\"WINDOW FUNCTIONS（窗口函数）\"></a>WINDOW FUNCTIONS（窗口函数）</h3><p>类似于聚合，但不仅仅是将元组折叠成单个聚合，而是以一种增量的方式计算聚合</p>\n<ul>\n<li><p>SELECT … FUNC-NAME(…) OVER(…) FROM table</p>\n<p>使用窗口函数FUNC-NAME，按照OVER的方式对查询的col进行聚合</p>\n</li>\n<li><p>窗口函数种类</p>\n<ul>\n<li>ROW_NUMBER() ：每一行的行号</li>\n<li>RANK() ：位置</li>\n<li>二者的区别在于，rank可以并列，但是row_number是唯一的</li>\n</ul>\n</li>\n<li><p>PARTITION BY  cid：按照cid分组，可以写在over中的条件里面</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"># 先将enrolled表按照cid分组，并按照grade排序<br># 再找出每一门课当中的第二名，ranking中第<span class=\"hljs-number\">2</span>高成绩的数据<br><span class=\"hljs-keyword\">SELECT</span> * <span class=\"hljs-keyword\">FROM</span> (<br><span class=\"hljs-keyword\">SELECT</span> *, RANK() <span class=\"hljs-keyword\">OVER</span> (<span class=\"hljs-keyword\">PARTITION</span> <span class=\"hljs-keyword\">BY</span> cid<br><span class=\"hljs-keyword\">ORDER</span> <span class=\"hljs-keyword\">BY</span> grade <span class=\"hljs-keyword\">ASC</span>) <span class=\"hljs-keyword\">AS</span> rank<br><span class=\"hljs-keyword\">FROM</span> enrolled) <span class=\"hljs-keyword\">AS</span> ranking<br><span class=\"hljs-keyword\">WHERE</span> ranking.rank = <span class=\"hljs-number\">2</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>CTE（COMMON TABLE EXPRESSIONS）</p>\n<p>通用表达式：只在sql语句内部起作用的临时语句</p>\n<p>RECURSIVE：递归调用，不是所有的sql都能够使用递归</p>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">WITH</span> cteName (col1, col2) <span class=\"hljs-keyword\">AS</span> (<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span><br>)<br><span class=\"hljs-keyword\">SELECT</span> col1 + col2 <span class=\"hljs-keyword\">FROM</span> cteName<br><br><span class=\"hljs-keyword\">WITH</span> cteSource (maxId) <span class=\"hljs-keyword\">AS</span> (<br><span class=\"hljs-keyword\">SELECT</span> MAX(sid) <span class=\"hljs-keyword\">FROM</span> enrolled<br>)<br><span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-type\">name</span> <span class=\"hljs-keyword\">FROM</span> student, cteSource<br><span class=\"hljs-keyword\">WHERE</span> student.sid = cteSource.maxId<br><br># CTE递归的调用，很少用，可读性差<br><span class=\"hljs-keyword\">WITH</span> <span class=\"hljs-keyword\">RECURSIVE</span> cteSource (counter) <span class=\"hljs-keyword\">AS</span> (<br>(<span class=\"hljs-keyword\">SELECT</span> <span class=\"hljs-number\">1</span>)<br><span class=\"hljs-keyword\">UNION</span> <span class=\"hljs-keyword\">ALL</span><br>(<span class=\"hljs-keyword\">SELECT</span> counter + <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">FROM</span> cteSource<br><span class=\"hljs-keyword\">WHERE</span> counter &lt; <span class=\"hljs-number\">10</span>)<br>)<br><span class=\"hljs-keyword\">SELECT</span> * <span class=\"hljs-keyword\">FROM</span> cteSource<br></code></pre></td></tr></table></figure>\n<ul>\n<li>CTE可以递归调用自身</li>\n</ul>\n<h2 id=\"03-Database-Storage-1\"><a href=\"#03-Database-Storage-1\" class=\"headerlink\" title=\"03-Database Storage 1\"></a>03-Database Storage 1</h2><h3 id=\"基于磁盘的架构\"><a href=\"#基于磁盘的架构\" class=\"headerlink\" title=\"基于磁盘的架构\"></a>基于磁盘的架构</h3><blockquote>\n<p> 数据库管理系统（DBMS）假设数据库的主要存储位置位于非易失性磁盘上。DBMS 的各个组件负责管理在非易失性存储和易失性存储之间的数据移动。</p>\n</blockquote>\n<ul>\n<li><p>数据库系统的设计目标</p>\n<blockquote>\n<p>数据库系统做的操作有点类似于虚拟内存，如下图</p>\n</blockquote>\n<p>1、系统可以管理超过内存可使用的总内存的数据</p>\n<p>2、由于读写内存十分昂贵，需要尽可能避免数据大量的读写内存造成的性能损耗</p>\n<p>3、尽可能使用顺序存储的方式提高效率</p>\n</li>\n<li><p>为什么不适用操作系统？操作系统的虚拟内存可以进行相关操作</p>\n<blockquote>\n<p>数据库管理系统使用内存映射存储文件的内容到程序的地址空间</p>\n<p>操作系统负责文件页面的命中与否，数据库管理系统不需要考虑</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240105160547664.png\" class=\"\" title=\"image-20240105160547664\">\n<ul>\n<li><p>内存映射会遇到的问题（MEMORY MAPPED I/O PROBLEMS）</p>\n<ul>\n<li><p>事务安全Transaction Safety</p>\n</li>\n<li><p>I/O阻塞</p>\n<p>数据库系统不知道内存中有哪些页面，所以在取数据如果发生错误，操作系统会阻塞线程</p>\n</li>\n<li><p>错误处理</p>\n</li>\n<li><p>性能问题</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>结论：数据库管理系统不使用MMAP内存映射</p>\n<ul>\n<li><p>数据库进行管理</p>\n<p>问题1、数据库系统如何表示磁盘上的文件数据</p>\n<p>问题2、如何管理内存以从磁盘中来回移动这些页面的数据，数据的读入与写回</p>\n</li>\n</ul>\n<h3 id=\"文件存储\"><a href=\"#文件存储\" class=\"headerlink\" title=\"文件存储\"></a>文件存储</h3><blockquote>\n<p>数据库系统会使用数据库独有的文件格式在磁盘上存储一个或者多个文件</p>\n<p>操作系统并无法知晓文件的内容</p>\n</blockquote>\n<ul>\n<li><p>存储管理器</p>\n<p>用于维护数据库文件，进行页面调度提升性能，利用局部性原则，组织一系列的页面文件读写</p>\n</li>\n<li><p>数据页面</p>\n<blockquote>\n<p>页面被锁定为固定大小的数据块，可以包含任何内容，不可以包含混合的数据</p>\n</blockquote>\n<p>硬件页面：存储设备可以保证它原子写出的最小数据或数据块大小，默认大小4KB</p>\n<p>操作系统页面：通常4KB</p>\n<p>数据库页面：512B-16KB</p>\n<ul>\n<li>硬件页面是存储设备能够保证正确写入的最大块大小</li>\n<li>使用更大的页面可以减少IO，运用到局部性原理，但是不能够确保更大的页面读写是原子的，需要使用一些操作来确保数据不会丢失</li>\n</ul>\n</li>\n<li><p>堆文件heap file</p>\n<p>按照随机顺序存储的无序页面的集合</p>\n<p>包含有获取、创建、写入、删除页面，以及迭代功能</p>\n<p>数据库管理系统维护一张特殊的表格用于定位数据库文件中的页面，也可以称为目录</p>\n</li>\n</ul>\n<h3 id=\"页面Page\"><a href=\"#页面Page\" class=\"headerlink\" title=\"页面Page\"></a>页面Page</h3><ul>\n<li><p>页面标头</p>\n<p>页面大小</p>\n<p>校验和：检查是否有数据损坏</p>\n<p>数据库管理系统版本：升级系统会更新</p>\n<p>事务可见性：用于进行权限管理</p>\n<p>压缩信息、备份</p>\n</li>\n<li><p>内部组织形式</p>\n<ul>\n<li><p>面向元组tuple的存储方式</p>\n<ul>\n<li>方式1</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240110074224104.png\" class=\"\" title=\"image-20240110074224104\">\n<p>删除其中一个tuple需要进行线性的移动</p>\n<p>无法对可变长度的属性进行存储</p>\n<ul>\n<li>方式二、开槽页面slot</li>\n</ul>\n<p>在页面开头存入槽数组，将元组映射到页面的实际位置</p>\n<p>槽页面是从尾端按照顺序存储</p>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240110074349028.png\" class=\"\" title=\"image-20240110074349028\">\n</li>\n</ul>\n</li>\n<li><p>Record IDS</p>\n<blockquote>\n<p>每一个元组都有一个唯一的记录ID号</p>\n</blockquote>\n<p>大部分格式为：页面ID+偏移量，可以使用ctid来获取（数据库中不能有列名为ctid的列） </p>\n<ul>\n<li>每个元组都有元数据，元组头部：可见性信息（元组是否删除）、使用位图表示元组中的空值</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">#在数据库中可以对碎片整理，会填补前面因为元组删除而空余的slot<br><span class=\"hljs-keyword\">VACUUM</span> <span class=\"hljs-keyword\">FULL</span> <span class=\"hljs-keyword\">table</span>;<br></code></pre></td></tr></table></figure>\n<h2 id=\"04-Database-Storage-2\"><a href=\"#04-Database-Storage-2\" class=\"headerlink\" title=\"04-Database Storage 2\"></a>04-Database Storage 2</h2><h3 id=\"基于日志的架构\"><a href=\"#基于日志的架构\" class=\"headerlink\" title=\"基于日志的架构\"></a>基于日志的架构</h3><blockquote>\n<p>数据库管理系统存包含改变元组的日志记录（PUT、DELETE）</p>\n<p>每一条日志记录包含元组独特的ID</p>\n<p>PUT：包含元组修改后的内容</p>\n<p>DELETE：将元组标记为删除</p>\n</blockquote>\n<p>数据库管理系统在内存页面中存储对元组操作的一些记录，例如修改某一个元组，删除某一个元组，当页面存满以后，记录会被永久保存，并切换到下一个页面，这样的好处可以磁盘IO更少，便于写入</p>\n<p>读入的时候，会需要向前不断追溯到最新的记录，读入很慢，在数据库管理系统中会维护一张index的表，映射到元组id的最新记录</p>\n<ul>\n<li><p>日志压缩</p>\n<p>因为日志是随着数据库的操作而进行持续增长的，数据库管理系统会定期的压缩页面以减少空间浪费</p>\n<p>通过将多个页面合并（找到记录的最新版本），移除掉不必要的记录</p>\n<ul>\n<li><p>通用压缩（Universal Compation）</p>\n<p>查看两个连续的排序文件，将其组合在一起，随后删除旧的文件</p>\n</li>\n<li><p>层级压缩（Level Compation）</p>\n<p>类似于2048，层级较低的过多以后，整合压缩成更大的高层文件</p>\n</li>\n</ul>\n</li>\n<li><p>基于日志的架构有什么缺点</p>\n<ul>\n<li><p>对写功能的放大</p>\n<p>如果需要更新某一个元组，会在查询的过程中压缩，会和压缩过后的页面一起写回，写就被放大了</p>\n</li>\n<li><p>压缩代价较大</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"元组的存储\"><a href=\"#元组的存储\" class=\"headerlink\" title=\"元组的存储\"></a>元组的存储</h3><p>4类基本数据类型：整型，浮点（FLOAT/REAL，NUMERIC/DECIMAL），varchar，time</p>\n<ul>\n<li>高精度的数据<ul>\n<li>Postgres，最终结果使用字符串的别名来表示，需要实现不同数据的拼接，很影响性能</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240112101151040.png\" class=\"\" title=\"image-20240112101151040\">\n<ul>\n<li><p>大数据：例如大小超过一个页面的数据</p>\n<p>使用其它的页面存储这些更大的页</p>\n</li>\n</ul>\n<img src=\"/2024/02/10/15445-study-notes-01-04/image-20240112102928169.png\" class=\"\" title=\"image-20240112102928169\">\n<ul>\n<li><p>外部资源数据</p>\n<p>一些数据库系统允许存储外部文件的数据，对于这些外部文件，数据库系统无法做到持续性保护以及业务的保护，无法保证外部文件不被修改</p>\n</li>\n<li><p>系统目录</p>\n<p>数据库系统维护数据库的一些表格</p>\n</li>\n</ul>\n"},{"title":"人工智能实验-基于tensorflow的猫狗分类","date":"2023-02-02T11:02:41.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"## 实验三、基于tensorflow的猫狗分类\n\n### 一、实验目的\n\n* 掌握如何使用tensorflow/pytorch编程实现模型，并会使用JupyterNotebook或Pycharm完成项目\n\n### 二、实验内容\n\n* 完成猫狗分类的模型的编码实现和模型训练\n\n### 三、实验步骤\n\n* 导入需要的函数包\n\n  ```python\n  import numpy as np\n  import pandas as pd\n  \n  from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n  from tensorflow.keras.utils import to_categorical\n  from sklearn.model_selection import train_test_split\n  \n  import matplotlib.pylab as plt\n  import random\n  import os\n  ```\n\n* 定义常量\n\n  ```python\n  FAST_RUN = False\n  IMAGE_WIDTH = 128\n  IMAGE_HEIGHT = 128\n  IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n  IMAGE_CHANNELS = 3\n  ```\n\n* 处理数据集文件夹\n\n  ```python\n  # 处理数据集\n  filenames = os.listdir('train')\n  categories = []\n  for filename in filenames:\n      category = filename.split('.')[0]\n      # 将所有图片按照顺序打上标签，如果是dog标记为1，如果是cat标记为0\n      if category == 'dog':\n          categories.append(1)\n      else:\n          categories.append(0)\n  \n  # 将文件名与标签一一对应\n  df = pd.DataFrame({\n      'filename':filenames,\n      'category':categories\n  })\n  ```\n\n* 查看前十行数据内容\n\n  ```python\n  # 查看前十行内容\n  df.head(10)\n  ```\n\n  ![image-20230109194724331](AI-lab01/image-20230109194724331.png)\n\n* 随机打开一张图片样本\n\n  ```python\n  # 随机打开一张图片样本\n  sample = random.choice(filenames)\n  image = load_img('train/'+sample)\n  plt.imshow(image)\n  ```\n\n  ![image-20230109194800246](AI-lab01/image-20230109194800246.png)\n\n* 处理数据标签\n\n  * 生成训练数据\n  * 划分训练集和验证集\n\n  ```python\n  df['category'] = df['category'].replace({0: 'cat', 1: 'dog'})\n  # 划分训练集和验证集\n  df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42)\n  df_train = df_train.reset_index(drop=True)\n  df_valid = df_valid.reset_index(drop=True)\n  \n  # 设置Batch Size与训练和验证样本数\n  total_train = df_train.shape[0]\n  total_valid = df_valid.shape[0]\n  batch_size = 128\n  ```\n\n* 数据生成器\n\n  ```python\n  # 训练集数据生成\n  train_datagen = ImageDataGenerator(\n      rotation_range=5,\n      rescale=1./255,\n      shear_range=0.1,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      width_shift_range=0.1,\n      height_shift_range=0.1\n  )\n  \n  train_generator = train_datagen.flow_from_dataframe(\n      df_train,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical',\n      batch_size=batch_size\n  )\n  ```\n\n  ```python\n  # 验证机数据生成\n  valid_datagen = ImageDataGenerator(rescale=1./255)\n  valid_generator = valid_datagen.flow_from_dataframe(\n      df_valid,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical',\n      batch_size=batch_size\n  )\n  ```\n\n* 查看数据生成样本\n\n  ```python\n  # 查看数据生成样例\n  df_example = df_train.sample(n=1).reset_index(drop=True)\n  example_generator = train_datagen.flow_from_dataframe(\n      df_example,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical'\n  )\n  \n  plt.figure(figsize=(12,12))\n  for i in range(0, 15):\n      plt.subplot(5, 3, i+1)\n      for X_batch, Y_batch in example_generator:\n          image = X_batch[0]\n          plt.imshow(image)\n          break\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109195226820](AI-lab01/image-20230109195226820.png)\n\n* 建立模型\n\n  ```python\n  from tensorflow.keras.models import Sequential\n  from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n  \n  model = Sequential()\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding='same'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Conv2D(32, (3, 3), activation='relu'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Flatten())\n  model.add(Dense(512, activation='relu'))\n  model.add(Dropout(0.1))\n  model.add(Dense(2, activation='softmax'))\n  ```\n\n* 定义损失函数\n\n  > 使用交叉熵损失函数\n\n  ```python\n  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n  ```\n\n* 查看深度学习网络\n\n  ```python\n  model.summary()\n  ```\n\n  ![image-20230109195428838](AI-lab01/image-20230109195428838.png)\n\n  ```python\n  # 回调：在模型训练期间的某些点调用的实用程序\n  from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n  \n  earlystop = EarlyStopping(patience=10)\n  learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                              patience=5,\n                                              verbose=1,\n                                              factor=0.5,\n                                              min_lr=0.00001)\n  ```\n\n  ```python\n  callbacks = [earlystop, learning_rate_reduction]\n  ```\n\n* 开始训练模型\n\n  > 一共完成50个epoch训练，每个epoch含有156个steps\n\n  ```python\n  # 模型训练\n  FAST_RUN = False\n  epochs = 3 if FAST_RUN else 50\n  \n  history = model.fit(train_generator,\n                     epochs=epochs,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  ```\n\n  ![image-20230109195525256](AI-lab01/image-20230109195525256.png)\n\n* 保存模型\n\n  > 利用model.save_weights与model.load_weights先训练10个epoch，保存模型后，再次加载继续训练20个epoch\n\n  ```python\n  # 训练10个epoch并保存模型\n  FAST_RUN = False\n  epochs = 3 if FAST_RUN else 50\n  \n  history = model.fit(train_generator,\n                     epochs=10,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  \n  model.save_weights('weights.ckpt')\n  ```\n\n  ![image-20230109204708818](AI-lab01/image-20230109204708818.png)\n\n  ```python\n  # 重新加载模型\n  model.load_weights('weights.ckpt')\n  # 继续训练20个epoch\n  history1 = model.fit(train_generator,\n                     epochs=20,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  ```\n\n  ![image-20230109214257445](AI-lab01/image-20230109214257445.png)\n\n* 对训练的结果进行可视化\n\n  > 对存储的损失值和精度值拟合成曲线\n\n  ```python\n  # 可视化训练结果\n  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n  ax1.plot(history.history['loss'], color='b', label='Training loss')\n  ax1.plot(history.history['val_loss'], color='r', label='Validation loss')\n  ax1.set_xticks(np.arange(1, epochs, 1))\n  ax1.set_yticks(np.arange(0, 1, 0.1))\n  ax1.legend(loc='best', shadow=True)\n  \n  ax2.plot(history.history['accuracy'], color='b', label='Training accuracy')\n  ax2.plot(history.history['val_accuracy'], color='r', label='Validation accuracy')\n  ax2.set_xticks(np.arange(1, epochs, 1))\n  \n  legend = plt.legend(loc='best', shadow=True)\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109205151944](AI-lab01/image-20230109205151944.png)\n\n* 准备测试集\n\n  ```python\n  # 准备测试集以及创建测试机\n  test_filenames = os.listdir('test1')\n  df_test = pd.DataFrame({\n      'filename':test_filenames\n  })\n  nb_samples = df_test.shape[0]\n  ```\n\n  ```\n  test_datagen = ImageDataGenerator(rescale=1./255)\n  test_generator = test_datagen.flow_from_dataframe(\n      df_test,\n      'test1/',\n      x_col='filename',\n      y_col=None,\n      class_mode=None,\n      target_size=IMAGE_SIZE,\n      batch_size=batch_size,\n      shuffle=False\n  )\n  ```\n\n* 预测\n\n  > 通过神经网络，对测试集的数据进行预测\n  >\n  > 选择输出概率最高的做为预测结果\n\n  ```python\n  predict = model.predict(test_generator,\n                         steps=np.ceil(nb_samples/batch_size),\n                         workers=12)\n  ```\n\n  ```python\n  df_test['category'] = np.argmax(predict, axis=-1)\n  \n  label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n  df_test['category'] = df_test['category'].replace(label_map)\n  \n  df_test['category'] = df_test['category'].replace({'dog':1, 'cat':0})\n  \n  df_test['category'].value_counts().plot.bar()\n  ```\n\n  ![image-20230109205407961](AI-lab01/image-20230109205407961.png)\n\n* 查看预测结果\n\n  > 可视化了前三十个预测结果，只有1002一张图片预测错误\n\n  ```python\n  sample_test = df_test.head(30)\n  sample_test.head()\n  dict_1 = {1:'dog', 0:'cat'}\n  plt.figure(figsize=(12, 24))\n  for index, row in sample_test.iterrows():\n      filename = row['filename']\n      category = row['category']\n      img = load_img('test1/' + filename, target_size=IMAGE_SIZE)\n      plt.subplot(10, 3, index+1)\n      plt.imshow(img)\n      plt.xlabel(filename + '(' + '{}'.format(category) + ')' + dict_1[category])\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109205438300](AI-lab01/image-20230109205438300.png)\n\n  ![image-20230109205453040](AI-lab01/image-20230109205453040.png)\n\n#### 四、总结\n\n* 叙述从逻辑回归到神经元工作原理\n\n  逻辑回归工作原理：逻辑回归用于二分类问题，将输入的数据进行处理过后得到一个输出数据，再通过sigmoid函数，通过阈值的设置来判断将输出的数据映射为0，或者是1.\n\n  神经元工作原理：神经元的每一个输入都会对应一个相应的权值，通过神经元后，再经过激活函数，产生输出，常见的激活函数有sigmoid函数，relu函数。\n\n* 两种常用的激活函数\n\n  Sigmoid激活函数、Relu激活函数\n\n* 两种池化方式\n\n  最大池化：将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。\n\n  平均池化：将输入的图像划分为若干个矩形区域，对每个子区域输出所有元素的平均值\n\n* 卷积神经网络要素：卷积核、池化、特征图\n\n  卷积核：卷积核，是卷积层中用于与输入的矩阵进行卷积运算的单元，通过与卷积核的卷积运算能够提取出原始图像中的一些特征属性。\n\n  池化：池化的重要的目的在于进一步降低网络的整体计算代价，同时也能够在一定程度上降低网络出现过拟合的风险，能够将原始图像矩阵通过一定的池化方式进行压缩。\n\n  特征图：通过卷积层进行与卷积核运算过后所得到的图就称为提取特征后的特征图。\n\n* 实验用到的模型图示，给出实验中的关键代码并解释\n\n  ![image-20230109222224342](AI-lab01/image-20230109222224342.png)\n\n  ```python\n  model = Sequential()\n  # 卷积层1，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding='same'))\n  \n  # 对数据进行标准化，加快训练速度\n  model.add(BatchNormalization())\n  \n  # 池化层1，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 卷积层2，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n  model.add(BatchNormalization())\n  # 池化层2，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 卷积层3，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu'))\n  model.add(BatchNormalization())\n  # 池化层3，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 扁平层，将多维数据一维化\n  model.add(Flatten())\n  # 全连接层2，将输入的数据转化为512维度\n  model.add(Dense(512, activation='relu'))\n  # 删除10%的神经元，将其置为0，防止过拟合\n  model.add(Dropout(0.1))\n  # 全连接层2，将数据最终转化为2为数据，通过softmax映射成概率值\n  model.add(Dense(2, activation='softmax'))\n  ```\n\n* 问答\n\n  问题：在训练过程中，学习率是怎样进行调整的？\n\n  回答：使用ReduceLROnPlateau和EarlyStopping配合动态调整学习率，ReduceLRonPlateau函数中有一些列参数可以搭配使用来动态调整学习率。\n\n  ```python\n  monitor：监测的值，可以是accuracy，val_loss,val_accuracy\n  factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少\n  patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发\n  mode：‘auto’，‘min’，‘max’之一 默认‘auto’就行\n  epsilon：阈值，用来确定是否进入检测值的“平原区”\n  cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作\n  min_lr：学习率最小值，能缩小到的下限\n  ```\n\n  ","source":"_posts/AI-lab01.md","raw":"---\ntitle: 人工智能实验-基于tensorflow的猫狗分类\ncategories: 算法实践\ndate: 2023-02-02 19:02:41\ntags: [人工智能, 深度学习]\ncover:\ntop_img:\n---\n## 实验三、基于tensorflow的猫狗分类\n\n### 一、实验目的\n\n* 掌握如何使用tensorflow/pytorch编程实现模型，并会使用JupyterNotebook或Pycharm完成项目\n\n### 二、实验内容\n\n* 完成猫狗分类的模型的编码实现和模型训练\n\n### 三、实验步骤\n\n* 导入需要的函数包\n\n  ```python\n  import numpy as np\n  import pandas as pd\n  \n  from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n  from tensorflow.keras.utils import to_categorical\n  from sklearn.model_selection import train_test_split\n  \n  import matplotlib.pylab as plt\n  import random\n  import os\n  ```\n\n* 定义常量\n\n  ```python\n  FAST_RUN = False\n  IMAGE_WIDTH = 128\n  IMAGE_HEIGHT = 128\n  IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n  IMAGE_CHANNELS = 3\n  ```\n\n* 处理数据集文件夹\n\n  ```python\n  # 处理数据集\n  filenames = os.listdir('train')\n  categories = []\n  for filename in filenames:\n      category = filename.split('.')[0]\n      # 将所有图片按照顺序打上标签，如果是dog标记为1，如果是cat标记为0\n      if category == 'dog':\n          categories.append(1)\n      else:\n          categories.append(0)\n  \n  # 将文件名与标签一一对应\n  df = pd.DataFrame({\n      'filename':filenames,\n      'category':categories\n  })\n  ```\n\n* 查看前十行数据内容\n\n  ```python\n  # 查看前十行内容\n  df.head(10)\n  ```\n\n  ![image-20230109194724331](AI-lab01/image-20230109194724331.png)\n\n* 随机打开一张图片样本\n\n  ```python\n  # 随机打开一张图片样本\n  sample = random.choice(filenames)\n  image = load_img('train/'+sample)\n  plt.imshow(image)\n  ```\n\n  ![image-20230109194800246](AI-lab01/image-20230109194800246.png)\n\n* 处理数据标签\n\n  * 生成训练数据\n  * 划分训练集和验证集\n\n  ```python\n  df['category'] = df['category'].replace({0: 'cat', 1: 'dog'})\n  # 划分训练集和验证集\n  df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42)\n  df_train = df_train.reset_index(drop=True)\n  df_valid = df_valid.reset_index(drop=True)\n  \n  # 设置Batch Size与训练和验证样本数\n  total_train = df_train.shape[0]\n  total_valid = df_valid.shape[0]\n  batch_size = 128\n  ```\n\n* 数据生成器\n\n  ```python\n  # 训练集数据生成\n  train_datagen = ImageDataGenerator(\n      rotation_range=5,\n      rescale=1./255,\n      shear_range=0.1,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      width_shift_range=0.1,\n      height_shift_range=0.1\n  )\n  \n  train_generator = train_datagen.flow_from_dataframe(\n      df_train,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical',\n      batch_size=batch_size\n  )\n  ```\n\n  ```python\n  # 验证机数据生成\n  valid_datagen = ImageDataGenerator(rescale=1./255)\n  valid_generator = valid_datagen.flow_from_dataframe(\n      df_valid,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical',\n      batch_size=batch_size\n  )\n  ```\n\n* 查看数据生成样本\n\n  ```python\n  # 查看数据生成样例\n  df_example = df_train.sample(n=1).reset_index(drop=True)\n  example_generator = train_datagen.flow_from_dataframe(\n      df_example,\n      'train/',\n      x_col='filename',\n      y_col='category',\n      target_size=IMAGE_SIZE,\n      class_mode='categorical'\n  )\n  \n  plt.figure(figsize=(12,12))\n  for i in range(0, 15):\n      plt.subplot(5, 3, i+1)\n      for X_batch, Y_batch in example_generator:\n          image = X_batch[0]\n          plt.imshow(image)\n          break\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109195226820](AI-lab01/image-20230109195226820.png)\n\n* 建立模型\n\n  ```python\n  from tensorflow.keras.models import Sequential\n  from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n  \n  model = Sequential()\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding='same'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Conv2D(32, (3, 3), activation='relu'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  model.add(Flatten())\n  model.add(Dense(512, activation='relu'))\n  model.add(Dropout(0.1))\n  model.add(Dense(2, activation='softmax'))\n  ```\n\n* 定义损失函数\n\n  > 使用交叉熵损失函数\n\n  ```python\n  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n  ```\n\n* 查看深度学习网络\n\n  ```python\n  model.summary()\n  ```\n\n  ![image-20230109195428838](AI-lab01/image-20230109195428838.png)\n\n  ```python\n  # 回调：在模型训练期间的某些点调用的实用程序\n  from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n  \n  earlystop = EarlyStopping(patience=10)\n  learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                              patience=5,\n                                              verbose=1,\n                                              factor=0.5,\n                                              min_lr=0.00001)\n  ```\n\n  ```python\n  callbacks = [earlystop, learning_rate_reduction]\n  ```\n\n* 开始训练模型\n\n  > 一共完成50个epoch训练，每个epoch含有156个steps\n\n  ```python\n  # 模型训练\n  FAST_RUN = False\n  epochs = 3 if FAST_RUN else 50\n  \n  history = model.fit(train_generator,\n                     epochs=epochs,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  ```\n\n  ![image-20230109195525256](AI-lab01/image-20230109195525256.png)\n\n* 保存模型\n\n  > 利用model.save_weights与model.load_weights先训练10个epoch，保存模型后，再次加载继续训练20个epoch\n\n  ```python\n  # 训练10个epoch并保存模型\n  FAST_RUN = False\n  epochs = 3 if FAST_RUN else 50\n  \n  history = model.fit(train_generator,\n                     epochs=10,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  \n  model.save_weights('weights.ckpt')\n  ```\n\n  ![image-20230109204708818](AI-lab01/image-20230109204708818.png)\n\n  ```python\n  # 重新加载模型\n  model.load_weights('weights.ckpt')\n  # 继续训练20个epoch\n  history1 = model.fit(train_generator,\n                     epochs=20,\n                     validation_data=valid_generator,\n                     validation_steps=total_valid//batch_size,\n                     steps_per_epoch=total_train//batch_size,\n                     callbacks=callbacks,\n                     workers=12)\n  ```\n\n  ![image-20230109214257445](AI-lab01/image-20230109214257445.png)\n\n* 对训练的结果进行可视化\n\n  > 对存储的损失值和精度值拟合成曲线\n\n  ```python\n  # 可视化训练结果\n  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n  ax1.plot(history.history['loss'], color='b', label='Training loss')\n  ax1.plot(history.history['val_loss'], color='r', label='Validation loss')\n  ax1.set_xticks(np.arange(1, epochs, 1))\n  ax1.set_yticks(np.arange(0, 1, 0.1))\n  ax1.legend(loc='best', shadow=True)\n  \n  ax2.plot(history.history['accuracy'], color='b', label='Training accuracy')\n  ax2.plot(history.history['val_accuracy'], color='r', label='Validation accuracy')\n  ax2.set_xticks(np.arange(1, epochs, 1))\n  \n  legend = plt.legend(loc='best', shadow=True)\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109205151944](AI-lab01/image-20230109205151944.png)\n\n* 准备测试集\n\n  ```python\n  # 准备测试集以及创建测试机\n  test_filenames = os.listdir('test1')\n  df_test = pd.DataFrame({\n      'filename':test_filenames\n  })\n  nb_samples = df_test.shape[0]\n  ```\n\n  ```\n  test_datagen = ImageDataGenerator(rescale=1./255)\n  test_generator = test_datagen.flow_from_dataframe(\n      df_test,\n      'test1/',\n      x_col='filename',\n      y_col=None,\n      class_mode=None,\n      target_size=IMAGE_SIZE,\n      batch_size=batch_size,\n      shuffle=False\n  )\n  ```\n\n* 预测\n\n  > 通过神经网络，对测试集的数据进行预测\n  >\n  > 选择输出概率最高的做为预测结果\n\n  ```python\n  predict = model.predict(test_generator,\n                         steps=np.ceil(nb_samples/batch_size),\n                         workers=12)\n  ```\n\n  ```python\n  df_test['category'] = np.argmax(predict, axis=-1)\n  \n  label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n  df_test['category'] = df_test['category'].replace(label_map)\n  \n  df_test['category'] = df_test['category'].replace({'dog':1, 'cat':0})\n  \n  df_test['category'].value_counts().plot.bar()\n  ```\n\n  ![image-20230109205407961](AI-lab01/image-20230109205407961.png)\n\n* 查看预测结果\n\n  > 可视化了前三十个预测结果，只有1002一张图片预测错误\n\n  ```python\n  sample_test = df_test.head(30)\n  sample_test.head()\n  dict_1 = {1:'dog', 0:'cat'}\n  plt.figure(figsize=(12, 24))\n  for index, row in sample_test.iterrows():\n      filename = row['filename']\n      category = row['category']\n      img = load_img('test1/' + filename, target_size=IMAGE_SIZE)\n      plt.subplot(10, 3, index+1)\n      plt.imshow(img)\n      plt.xlabel(filename + '(' + '{}'.format(category) + ')' + dict_1[category])\n  plt.tight_layout()\n  plt.show()\n  ```\n\n  ![image-20230109205438300](AI-lab01/image-20230109205438300.png)\n\n  ![image-20230109205453040](AI-lab01/image-20230109205453040.png)\n\n#### 四、总结\n\n* 叙述从逻辑回归到神经元工作原理\n\n  逻辑回归工作原理：逻辑回归用于二分类问题，将输入的数据进行处理过后得到一个输出数据，再通过sigmoid函数，通过阈值的设置来判断将输出的数据映射为0，或者是1.\n\n  神经元工作原理：神经元的每一个输入都会对应一个相应的权值，通过神经元后，再经过激活函数，产生输出，常见的激活函数有sigmoid函数，relu函数。\n\n* 两种常用的激活函数\n\n  Sigmoid激活函数、Relu激活函数\n\n* 两种池化方式\n\n  最大池化：将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。\n\n  平均池化：将输入的图像划分为若干个矩形区域，对每个子区域输出所有元素的平均值\n\n* 卷积神经网络要素：卷积核、池化、特征图\n\n  卷积核：卷积核，是卷积层中用于与输入的矩阵进行卷积运算的单元，通过与卷积核的卷积运算能够提取出原始图像中的一些特征属性。\n\n  池化：池化的重要的目的在于进一步降低网络的整体计算代价，同时也能够在一定程度上降低网络出现过拟合的风险，能够将原始图像矩阵通过一定的池化方式进行压缩。\n\n  特征图：通过卷积层进行与卷积核运算过后所得到的图就称为提取特征后的特征图。\n\n* 实验用到的模型图示，给出实验中的关键代码并解释\n\n  ![image-20230109222224342](AI-lab01/image-20230109222224342.png)\n\n  ```python\n  model = Sequential()\n  # 卷积层1，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding='same'))\n  \n  # 对数据进行标准化，加快训练速度\n  model.add(BatchNormalization())\n  \n  # 池化层1，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 卷积层2，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n  model.add(BatchNormalization())\n  # 池化层2，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 卷积层3，卷积核的大小为（3，3），使用relu激活函数\n  model.add(Conv2D(32, (3, 3), activation='relu'))\n  model.add(BatchNormalization())\n  # 池化层3，使用最大池化的方法，池化尺寸为（2，2）\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  \n  # 扁平层，将多维数据一维化\n  model.add(Flatten())\n  # 全连接层2，将输入的数据转化为512维度\n  model.add(Dense(512, activation='relu'))\n  # 删除10%的神经元，将其置为0，防止过拟合\n  model.add(Dropout(0.1))\n  # 全连接层2，将数据最终转化为2为数据，通过softmax映射成概率值\n  model.add(Dense(2, activation='softmax'))\n  ```\n\n* 问答\n\n  问题：在训练过程中，学习率是怎样进行调整的？\n\n  回答：使用ReduceLROnPlateau和EarlyStopping配合动态调整学习率，ReduceLRonPlateau函数中有一些列参数可以搭配使用来动态调整学习率。\n\n  ```python\n  monitor：监测的值，可以是accuracy，val_loss,val_accuracy\n  factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少\n  patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发\n  mode：‘auto’，‘min’，‘max’之一 默认‘auto’就行\n  epsilon：阈值，用来确定是否进入检测值的“平原区”\n  cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作\n  min_lr：学习率最小值，能缩小到的下限\n  ```\n\n  ","slug":"AI-lab01","published":1,"updated":"2024-06-05T09:03:03.478Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttd000808jv7cz4gn9x","content":"<h2 id=\"实验三、基于tensorflow的猫狗分类\"><a href=\"#实验三、基于tensorflow的猫狗分类\" class=\"headerlink\" title=\"实验三、基于tensorflow的猫狗分类\"></a>实验三、基于tensorflow的猫狗分类</h2><h3 id=\"一、实验目的\"><a href=\"#一、实验目的\" class=\"headerlink\" title=\"一、实验目的\"></a>一、实验目的</h3><ul>\n<li>掌握如何使用tensorflow/pytorch编程实现模型，并会使用JupyterNotebook或Pycharm完成项目</li>\n</ul>\n<h3 id=\"二、实验内容\"><a href=\"#二、实验内容\" class=\"headerlink\" title=\"二、实验内容\"></a>二、实验内容</h3><ul>\n<li>完成猫狗分类的模型的编码实现和模型训练</li>\n</ul>\n<h3 id=\"三、实验步骤\"><a href=\"#三、实验步骤\" class=\"headerlink\" title=\"三、实验步骤\"></a>三、实验步骤</h3><ul>\n<li><p>导入需要的函数包</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.preprocessing.image <span class=\"hljs-keyword\">import</span> ImageDataGenerator, load_img<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> to_categorical<br><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split<br><br><span class=\"hljs-keyword\">import</span> matplotlib.pylab <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> os<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义常量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">FAST_RUN = <span class=\"hljs-literal\">False</span><br>IMAGE_WIDTH = <span class=\"hljs-number\">128</span><br>IMAGE_HEIGHT = <span class=\"hljs-number\">128</span><br>IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)<br>IMAGE_CHANNELS = <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>处理数据集文件夹</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 处理数据集</span><br>filenames = os.listdir(<span class=\"hljs-string\">&#x27;train&#x27;</span>)<br>categories = []<br><span class=\"hljs-keyword\">for</span> filename <span class=\"hljs-keyword\">in</span> filenames:<br>    category = filename.split(<span class=\"hljs-string\">&#x27;.&#x27;</span>)[<span class=\"hljs-number\">0</span>]<br>    <span class=\"hljs-comment\"># 将所有图片按照顺序打上标签，如果是dog标记为1，如果是cat标记为0</span><br>    <span class=\"hljs-keyword\">if</span> category == <span class=\"hljs-string\">&#x27;dog&#x27;</span>:<br>        categories.append(<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-keyword\">else</span>:<br>        categories.append(<span class=\"hljs-number\">0</span>)<br><br><span class=\"hljs-comment\"># 将文件名与标签一一对应</span><br>df = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:filenames,<br>    <span class=\"hljs-string\">&#x27;category&#x27;</span>:categories<br>&#125;)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看前十行数据内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看前十行内容</span><br>df.head(<span class=\"hljs-number\">10</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109194724331.png\" class=\"\" title=\"image-20230109194724331\">\n</li>\n<li><p>随机打开一张图片样本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 随机打开一张图片样本</span><br>sample = random.choice(filenames)<br>image = load_img(<span class=\"hljs-string\">&#x27;train/&#x27;</span>+sample)<br>plt.imshow(image)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109194800246.png\" class=\"\" title=\"image-20230109194800246\">\n</li>\n<li><p>处理数据标签</p>\n<ul>\n<li>生成训练数据</li>\n<li>划分训练集和验证集</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">df[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(&#123;<span class=\"hljs-number\">0</span>: <span class=\"hljs-string\">&#x27;cat&#x27;</span>, <span class=\"hljs-number\">1</span>: <span class=\"hljs-string\">&#x27;dog&#x27;</span>&#125;)<br><span class=\"hljs-comment\"># 划分训练集和验证集</span><br>df_train, df_valid = train_test_split(df, test_size=<span class=\"hljs-number\">0.2</span>, random_state=<span class=\"hljs-number\">42</span>)<br>df_train = df_train.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>df_valid = df_valid.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br><br><span class=\"hljs-comment\"># 设置Batch Size与训练和验证样本数</span><br>total_train = df_train.shape[<span class=\"hljs-number\">0</span>]<br>total_valid = df_valid.shape[<span class=\"hljs-number\">0</span>]<br>batch_size = <span class=\"hljs-number\">128</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>数据生成器</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练集数据生成</span><br>train_datagen = ImageDataGenerator(<br>    rotation_range=<span class=\"hljs-number\">5</span>,<br>    rescale=<span class=\"hljs-number\">1.</span>/<span class=\"hljs-number\">255</span>,<br>    shear_range=<span class=\"hljs-number\">0.1</span>,<br>    zoom_range=<span class=\"hljs-number\">0.2</span>,<br>    horizontal_flip=<span class=\"hljs-literal\">True</span>,<br>    width_shift_range=<span class=\"hljs-number\">0.1</span>,<br>    height_shift_range=<span class=\"hljs-number\">0.1</span><br>)<br><br>train_generator = train_datagen.flow_from_dataframe(<br>    df_train,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span>,<br>    batch_size=batch_size<br>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证机数据生成</span><br>valid_datagen = ImageDataGenerator(rescale=<span class=\"hljs-number\">1.</span>/<span class=\"hljs-number\">255</span>)<br>valid_generator = valid_datagen.flow_from_dataframe(<br>    df_valid,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span>,<br>    batch_size=batch_size<br>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看数据生成样本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看数据生成样例</span><br>df_example = df_train.sample(n=<span class=\"hljs-number\">1</span>).reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>example_generator = train_datagen.flow_from_dataframe(<br>    df_example,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span><br>)<br><br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>,<span class=\"hljs-number\">12</span>))<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">15</span>):<br>    plt.subplot(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, i+<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-keyword\">for</span> X_batch, Y_batch <span class=\"hljs-keyword\">in</span> example_generator:<br>        image = X_batch[<span class=\"hljs-number\">0</span>]<br>        plt.imshow(image)<br>        <span class=\"hljs-keyword\">break</span><br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195226820.png\" class=\"\" title=\"image-20230109195226820\">\n</li>\n<li><p>建立模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> tensorflow.keras.models <span class=\"hljs-keyword\">import</span> Sequential<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.layers <span class=\"hljs-keyword\">import</span> Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization<br><br>model = Sequential()<br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Flatten())<br>model.add(Dense(<span class=\"hljs-number\">512</span>, activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(Dropout(<span class=\"hljs-number\">0.1</span>))<br>model.add(Dense(<span class=\"hljs-number\">2</span>, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>))<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义损失函数</p>\n<blockquote>\n<p>使用交叉熵损失函数</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.<span class=\"hljs-built_in\">compile</span>(loss=<span class=\"hljs-string\">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class=\"hljs-string\">&#x27;sgd&#x27;</span>, metrics=[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>])<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看深度学习网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.summary()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195428838.png\" class=\"\" title=\"image-20230109195428838\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 回调：在模型训练期间的某些点调用的实用程序</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> EarlyStopping, ReduceLROnPlateau<br><br>earlystop = EarlyStopping(patience=<span class=\"hljs-number\">10</span>)<br>learning_rate_reduction = ReduceLROnPlateau(monitor = <span class=\"hljs-string\">&#x27;val_accuracy&#x27;</span>,<br>                                            patience=<span class=\"hljs-number\">5</span>,<br>                                            verbose=<span class=\"hljs-number\">1</span>,<br>                                            factor=<span class=\"hljs-number\">0.5</span>,<br>                                            min_lr=<span class=\"hljs-number\">0.00001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">callbacks = [earlystop, learning_rate_reduction]<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>开始训练模型</p>\n<blockquote>\n<p>一共完成50个epoch训练，每个epoch含有156个steps</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br>FAST_RUN = <span class=\"hljs-literal\">False</span><br>epochs = <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">if</span> FAST_RUN <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">50</span><br><br>history = model.fit(train_generator,<br>                   epochs=epochs,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195525256.png\" class=\"\" title=\"image-20230109195525256\">\n</li>\n<li><p>保存模型</p>\n<blockquote>\n<p>利用model.save_weights与model.load_weights先训练10个epoch，保存模型后，再次加载继续训练20个epoch</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练10个epoch并保存模型</span><br>FAST_RUN = <span class=\"hljs-literal\">False</span><br>epochs = <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">if</span> FAST_RUN <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">50</span><br><br>history = model.fit(train_generator,<br>                   epochs=<span class=\"hljs-number\">10</span>,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br><br>model.save_weights(<span class=\"hljs-string\">&#x27;weights.ckpt&#x27;</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109204708818.png\" class=\"\" title=\"image-20230109204708818\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 重新加载模型</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;weights.ckpt&#x27;</span>)<br><span class=\"hljs-comment\"># 继续训练20个epoch</span><br>history1 = model.fit(train_generator,<br>                   epochs=<span class=\"hljs-number\">20</span>,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109214257445.png\" class=\"\" title=\"image-20230109214257445\">\n</li>\n<li><p>对训练的结果进行可视化</p>\n<blockquote>\n<p>对存储的损失值和精度值拟合成曲线</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 可视化训练结果</span><br>fig, (ax1, ax2) = plt.subplots(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">12</span>))<br>ax1.plot(history.history[<span class=\"hljs-string\">&#x27;loss&#x27;</span>], color=<span class=\"hljs-string\">&#x27;b&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Training loss&#x27;</span>)<br>ax1.plot(history.history[<span class=\"hljs-string\">&#x27;val_loss&#x27;</span>], color=<span class=\"hljs-string\">&#x27;r&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Validation loss&#x27;</span>)<br>ax1.set_xticks(np.arange(<span class=\"hljs-number\">1</span>, epochs, <span class=\"hljs-number\">1</span>))<br>ax1.set_yticks(np.arange(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0.1</span>))<br>ax1.legend(loc=<span class=\"hljs-string\">&#x27;best&#x27;</span>, shadow=<span class=\"hljs-literal\">True</span>)<br><br>ax2.plot(history.history[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>], color=<span class=\"hljs-string\">&#x27;b&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Training accuracy&#x27;</span>)<br>ax2.plot(history.history[<span class=\"hljs-string\">&#x27;val_accuracy&#x27;</span>], color=<span class=\"hljs-string\">&#x27;r&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Validation accuracy&#x27;</span>)<br>ax2.set_xticks(np.arange(<span class=\"hljs-number\">1</span>, epochs, <span class=\"hljs-number\">1</span>))<br><br>legend = plt.legend(loc=<span class=\"hljs-string\">&#x27;best&#x27;</span>, shadow=<span class=\"hljs-literal\">True</span>)<br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205151944.png\" class=\"\" title=\"image-20230109205151944\">\n</li>\n<li><p>准备测试集</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 准备测试集以及创建测试机</span><br>test_filenames = os.listdir(<span class=\"hljs-string\">&#x27;test1&#x27;</span>)<br>df_test = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:test_filenames<br>&#125;)<br>nb_samples = df_test.shape[<span class=\"hljs-number\">0</span>]<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">test_datagen = ImageDataGenerator(<span class=\"hljs-attribute\">rescale</span>=1./255)<br>test_generator = test_datagen.flow_from_dataframe(<br>    df_test,<br>    <span class=\"hljs-string\">&#x27;test1/&#x27;</span>,<br>    <span class=\"hljs-attribute\">x_col</span>=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    <span class=\"hljs-attribute\">y_col</span>=None,<br>    <span class=\"hljs-attribute\">class_mode</span>=None,<br>    <span class=\"hljs-attribute\">target_size</span>=IMAGE_SIZE,<br>    <span class=\"hljs-attribute\">batch_size</span>=batch_size,<br>    <span class=\"hljs-attribute\">shuffle</span>=<span class=\"hljs-literal\">False</span><br>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>预测</p>\n<blockquote>\n<p>通过神经网络，对测试集的数据进行预测</p>\n<p>选择输出概率最高的做为预测结果</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">predict = model.predict(test_generator,<br>                       steps=np.ceil(nb_samples/batch_size),<br>                       workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = np.argmax(predict, axis=-<span class=\"hljs-number\">1</span>)<br><br>label_map = <span class=\"hljs-built_in\">dict</span>((v,k) <span class=\"hljs-keyword\">for</span> k,v <span class=\"hljs-keyword\">in</span> train_generator.class_indices.items())<br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(label_map)<br><br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(&#123;<span class=\"hljs-string\">&#x27;dog&#x27;</span>:<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">&#x27;cat&#x27;</span>:<span class=\"hljs-number\">0</span>&#125;)<br><br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].value_counts().plot.bar()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205407961.png\" class=\"\" title=\"image-20230109205407961\">\n</li>\n<li><p>查看预测结果</p>\n<blockquote>\n<p>可视化了前三十个预测结果，只有1002一张图片预测错误</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">sample_test = df_test.head(<span class=\"hljs-number\">30</span>)<br>sample_test.head()<br>dict_1 = &#123;<span class=\"hljs-number\">1</span>:<span class=\"hljs-string\">&#x27;dog&#x27;</span>, <span class=\"hljs-number\">0</span>:<span class=\"hljs-string\">&#x27;cat&#x27;</span>&#125;<br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">24</span>))<br><span class=\"hljs-keyword\">for</span> index, row <span class=\"hljs-keyword\">in</span> sample_test.iterrows():<br>    filename = row[<span class=\"hljs-string\">&#x27;filename&#x27;</span>]<br>    category = row[<span class=\"hljs-string\">&#x27;category&#x27;</span>]<br>    img = load_img(<span class=\"hljs-string\">&#x27;test1/&#x27;</span> + filename, target_size=IMAGE_SIZE)<br>    plt.subplot(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">3</span>, index+<span class=\"hljs-number\">1</span>)<br>    plt.imshow(img)<br>    plt.xlabel(filename + <span class=\"hljs-string\">&#x27;(&#x27;</span> + <span class=\"hljs-string\">&#x27;&#123;&#125;&#x27;</span>.<span class=\"hljs-built_in\">format</span>(category) + <span class=\"hljs-string\">&#x27;)&#x27;</span> + dict_1[category])<br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205438300.png\" class=\"\" title=\"image-20230109205438300\">\n<img src=\"/2023/02/02/AI-lab01/image-20230109205453040.png\" class=\"\" title=\"image-20230109205453040\">\n</li>\n</ul>\n<h4 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h4><ul>\n<li><p>叙述从逻辑回归到神经元工作原理</p>\n<p>逻辑回归工作原理：逻辑回归用于二分类问题，将输入的数据进行处理过后得到一个输出数据，再通过sigmoid函数，通过阈值的设置来判断将输出的数据映射为0，或者是1.</p>\n<p>神经元工作原理：神经元的每一个输入都会对应一个相应的权值，通过神经元后，再经过激活函数，产生输出，常见的激活函数有sigmoid函数，relu函数。</p>\n</li>\n<li><p>两种常用的激活函数</p>\n<p>Sigmoid激活函数、Relu激活函数</p>\n</li>\n<li><p>两种池化方式</p>\n<p>最大池化：将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。</p>\n<p>平均池化：将输入的图像划分为若干个矩形区域，对每个子区域输出所有元素的平均值</p>\n</li>\n<li><p>卷积神经网络要素：卷积核、池化、特征图</p>\n<p>卷积核：卷积核，是卷积层中用于与输入的矩阵进行卷积运算的单元，通过与卷积核的卷积运算能够提取出原始图像中的一些特征属性。</p>\n<p>池化：池化的重要的目的在于进一步降低网络的整体计算代价，同时也能够在一定程度上降低网络出现过拟合的风险，能够将原始图像矩阵通过一定的池化方式进行压缩。</p>\n<p>特征图：通过卷积层进行与卷积核运算过后所得到的图就称为提取特征后的特征图。</p>\n</li>\n<li><p>实验用到的模型图示，给出实验中的关键代码并解释</p>\n<img src=\"/2023/02/02/AI-lab01/image-20230109222224342.png\" class=\"\" title=\"image-20230109222224342\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model = Sequential()<br><span class=\"hljs-comment\"># 卷积层1，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br><br><span class=\"hljs-comment\"># 对数据进行标准化，加快训练速度</span><br>model.add(BatchNormalization())<br><br><span class=\"hljs-comment\"># 池化层1，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 卷积层2，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br><span class=\"hljs-comment\"># 池化层2，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 卷积层3，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(BatchNormalization())<br><span class=\"hljs-comment\"># 池化层3，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 扁平层，将多维数据一维化</span><br>model.add(Flatten())<br><span class=\"hljs-comment\"># 全连接层2，将输入的数据转化为512维度</span><br>model.add(Dense(<span class=\"hljs-number\">512</span>, activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br><span class=\"hljs-comment\"># 删除10%的神经元，将其置为0，防止过拟合</span><br>model.add(Dropout(<span class=\"hljs-number\">0.1</span>))<br><span class=\"hljs-comment\"># 全连接层2，将数据最终转化为2为数据，通过softmax映射成概率值</span><br>model.add(Dense(<span class=\"hljs-number\">2</span>, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>))<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>问答</p>\n<p>问题：在训练过程中，学习率是怎样进行调整的？</p>\n<p>回答：使用ReduceLROnPlateau和EarlyStopping配合动态调整学习率，ReduceLRonPlateau函数中有一些列参数可以搭配使用来动态调整学习率。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">monitor：监测的值，可以是accuracy，val_loss,val_accuracy<br>factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少<br>patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发<br>mode：‘auto’，‘<span class=\"hljs-built_in\">min</span>’，‘<span class=\"hljs-built_in\">max</span>’之一 默认‘auto’就行<br>epsilon：阈值，用来确定是否进入检测值的“平原区”<br>cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作<br>min_lr：学习率最小值，能缩小到的下限<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"实验三、基于tensorflow的猫狗分类\"><a href=\"#实验三、基于tensorflow的猫狗分类\" class=\"headerlink\" title=\"实验三、基于tensorflow的猫狗分类\"></a>实验三、基于tensorflow的猫狗分类</h2><h3 id=\"一、实验目的\"><a href=\"#一、实验目的\" class=\"headerlink\" title=\"一、实验目的\"></a>一、实验目的</h3><ul>\n<li>掌握如何使用tensorflow/pytorch编程实现模型，并会使用JupyterNotebook或Pycharm完成项目</li>\n</ul>\n<h3 id=\"二、实验内容\"><a href=\"#二、实验内容\" class=\"headerlink\" title=\"二、实验内容\"></a>二、实验内容</h3><ul>\n<li>完成猫狗分类的模型的编码实现和模型训练</li>\n</ul>\n<h3 id=\"三、实验步骤\"><a href=\"#三、实验步骤\" class=\"headerlink\" title=\"三、实验步骤\"></a>三、实验步骤</h3><ul>\n<li><p>导入需要的函数包</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.preprocessing.image <span class=\"hljs-keyword\">import</span> ImageDataGenerator, load_img<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> to_categorical<br><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split<br><br><span class=\"hljs-keyword\">import</span> matplotlib.pylab <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> os<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义常量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">FAST_RUN = <span class=\"hljs-literal\">False</span><br>IMAGE_WIDTH = <span class=\"hljs-number\">128</span><br>IMAGE_HEIGHT = <span class=\"hljs-number\">128</span><br>IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)<br>IMAGE_CHANNELS = <span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>处理数据集文件夹</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 处理数据集</span><br>filenames = os.listdir(<span class=\"hljs-string\">&#x27;train&#x27;</span>)<br>categories = []<br><span class=\"hljs-keyword\">for</span> filename <span class=\"hljs-keyword\">in</span> filenames:<br>    category = filename.split(<span class=\"hljs-string\">&#x27;.&#x27;</span>)[<span class=\"hljs-number\">0</span>]<br>    <span class=\"hljs-comment\"># 将所有图片按照顺序打上标签，如果是dog标记为1，如果是cat标记为0</span><br>    <span class=\"hljs-keyword\">if</span> category == <span class=\"hljs-string\">&#x27;dog&#x27;</span>:<br>        categories.append(<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-keyword\">else</span>:<br>        categories.append(<span class=\"hljs-number\">0</span>)<br><br><span class=\"hljs-comment\"># 将文件名与标签一一对应</span><br>df = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:filenames,<br>    <span class=\"hljs-string\">&#x27;category&#x27;</span>:categories<br>&#125;)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看前十行数据内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看前十行内容</span><br>df.head(<span class=\"hljs-number\">10</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109194724331.png\" class=\"\" title=\"image-20230109194724331\">\n</li>\n<li><p>随机打开一张图片样本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 随机打开一张图片样本</span><br>sample = random.choice(filenames)<br>image = load_img(<span class=\"hljs-string\">&#x27;train/&#x27;</span>+sample)<br>plt.imshow(image)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109194800246.png\" class=\"\" title=\"image-20230109194800246\">\n</li>\n<li><p>处理数据标签</p>\n<ul>\n<li>生成训练数据</li>\n<li>划分训练集和验证集</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">df[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(&#123;<span class=\"hljs-number\">0</span>: <span class=\"hljs-string\">&#x27;cat&#x27;</span>, <span class=\"hljs-number\">1</span>: <span class=\"hljs-string\">&#x27;dog&#x27;</span>&#125;)<br><span class=\"hljs-comment\"># 划分训练集和验证集</span><br>df_train, df_valid = train_test_split(df, test_size=<span class=\"hljs-number\">0.2</span>, random_state=<span class=\"hljs-number\">42</span>)<br>df_train = df_train.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>df_valid = df_valid.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br><br><span class=\"hljs-comment\"># 设置Batch Size与训练和验证样本数</span><br>total_train = df_train.shape[<span class=\"hljs-number\">0</span>]<br>total_valid = df_valid.shape[<span class=\"hljs-number\">0</span>]<br>batch_size = <span class=\"hljs-number\">128</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>数据生成器</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练集数据生成</span><br>train_datagen = ImageDataGenerator(<br>    rotation_range=<span class=\"hljs-number\">5</span>,<br>    rescale=<span class=\"hljs-number\">1.</span>/<span class=\"hljs-number\">255</span>,<br>    shear_range=<span class=\"hljs-number\">0.1</span>,<br>    zoom_range=<span class=\"hljs-number\">0.2</span>,<br>    horizontal_flip=<span class=\"hljs-literal\">True</span>,<br>    width_shift_range=<span class=\"hljs-number\">0.1</span>,<br>    height_shift_range=<span class=\"hljs-number\">0.1</span><br>)<br><br>train_generator = train_datagen.flow_from_dataframe(<br>    df_train,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span>,<br>    batch_size=batch_size<br>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证机数据生成</span><br>valid_datagen = ImageDataGenerator(rescale=<span class=\"hljs-number\">1.</span>/<span class=\"hljs-number\">255</span>)<br>valid_generator = valid_datagen.flow_from_dataframe(<br>    df_valid,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span>,<br>    batch_size=batch_size<br>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看数据生成样本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看数据生成样例</span><br>df_example = df_train.sample(n=<span class=\"hljs-number\">1</span>).reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>example_generator = train_datagen.flow_from_dataframe(<br>    df_example,<br>    <span class=\"hljs-string\">&#x27;train/&#x27;</span>,<br>    x_col=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    y_col=<span class=\"hljs-string\">&#x27;category&#x27;</span>,<br>    target_size=IMAGE_SIZE,<br>    class_mode=<span class=\"hljs-string\">&#x27;categorical&#x27;</span><br>)<br><br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>,<span class=\"hljs-number\">12</span>))<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">15</span>):<br>    plt.subplot(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, i+<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-keyword\">for</span> X_batch, Y_batch <span class=\"hljs-keyword\">in</span> example_generator:<br>        image = X_batch[<span class=\"hljs-number\">0</span>]<br>        plt.imshow(image)<br>        <span class=\"hljs-keyword\">break</span><br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195226820.png\" class=\"\" title=\"image-20230109195226820\">\n</li>\n<li><p>建立模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> tensorflow.keras.models <span class=\"hljs-keyword\">import</span> Sequential<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.layers <span class=\"hljs-keyword\">import</span> Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization<br><br>model = Sequential()<br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(BatchNormalization())<br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br>model.add(Flatten())<br>model.add(Dense(<span class=\"hljs-number\">512</span>, activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(Dropout(<span class=\"hljs-number\">0.1</span>))<br>model.add(Dense(<span class=\"hljs-number\">2</span>, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>))<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义损失函数</p>\n<blockquote>\n<p>使用交叉熵损失函数</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.<span class=\"hljs-built_in\">compile</span>(loss=<span class=\"hljs-string\">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class=\"hljs-string\">&#x27;sgd&#x27;</span>, metrics=[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>])<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看深度学习网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.summary()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195428838.png\" class=\"\" title=\"image-20230109195428838\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 回调：在模型训练期间的某些点调用的实用程序</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> EarlyStopping, ReduceLROnPlateau<br><br>earlystop = EarlyStopping(patience=<span class=\"hljs-number\">10</span>)<br>learning_rate_reduction = ReduceLROnPlateau(monitor = <span class=\"hljs-string\">&#x27;val_accuracy&#x27;</span>,<br>                                            patience=<span class=\"hljs-number\">5</span>,<br>                                            verbose=<span class=\"hljs-number\">1</span>,<br>                                            factor=<span class=\"hljs-number\">0.5</span>,<br>                                            min_lr=<span class=\"hljs-number\">0.00001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">callbacks = [earlystop, learning_rate_reduction]<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>开始训练模型</p>\n<blockquote>\n<p>一共完成50个epoch训练，每个epoch含有156个steps</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br>FAST_RUN = <span class=\"hljs-literal\">False</span><br>epochs = <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">if</span> FAST_RUN <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">50</span><br><br>history = model.fit(train_generator,<br>                   epochs=epochs,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109195525256.png\" class=\"\" title=\"image-20230109195525256\">\n</li>\n<li><p>保存模型</p>\n<blockquote>\n<p>利用model.save_weights与model.load_weights先训练10个epoch，保存模型后，再次加载继续训练20个epoch</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练10个epoch并保存模型</span><br>FAST_RUN = <span class=\"hljs-literal\">False</span><br>epochs = <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">if</span> FAST_RUN <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">50</span><br><br>history = model.fit(train_generator,<br>                   epochs=<span class=\"hljs-number\">10</span>,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br><br>model.save_weights(<span class=\"hljs-string\">&#x27;weights.ckpt&#x27;</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109204708818.png\" class=\"\" title=\"image-20230109204708818\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 重新加载模型</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;weights.ckpt&#x27;</span>)<br><span class=\"hljs-comment\"># 继续训练20个epoch</span><br>history1 = model.fit(train_generator,<br>                   epochs=<span class=\"hljs-number\">20</span>,<br>                   validation_data=valid_generator,<br>                   validation_steps=total_valid//batch_size,<br>                   steps_per_epoch=total_train//batch_size,<br>                   callbacks=callbacks,<br>                   workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109214257445.png\" class=\"\" title=\"image-20230109214257445\">\n</li>\n<li><p>对训练的结果进行可视化</p>\n<blockquote>\n<p>对存储的损失值和精度值拟合成曲线</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 可视化训练结果</span><br>fig, (ax1, ax2) = plt.subplots(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">12</span>))<br>ax1.plot(history.history[<span class=\"hljs-string\">&#x27;loss&#x27;</span>], color=<span class=\"hljs-string\">&#x27;b&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Training loss&#x27;</span>)<br>ax1.plot(history.history[<span class=\"hljs-string\">&#x27;val_loss&#x27;</span>], color=<span class=\"hljs-string\">&#x27;r&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Validation loss&#x27;</span>)<br>ax1.set_xticks(np.arange(<span class=\"hljs-number\">1</span>, epochs, <span class=\"hljs-number\">1</span>))<br>ax1.set_yticks(np.arange(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0.1</span>))<br>ax1.legend(loc=<span class=\"hljs-string\">&#x27;best&#x27;</span>, shadow=<span class=\"hljs-literal\">True</span>)<br><br>ax2.plot(history.history[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>], color=<span class=\"hljs-string\">&#x27;b&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Training accuracy&#x27;</span>)<br>ax2.plot(history.history[<span class=\"hljs-string\">&#x27;val_accuracy&#x27;</span>], color=<span class=\"hljs-string\">&#x27;r&#x27;</span>, label=<span class=\"hljs-string\">&#x27;Validation accuracy&#x27;</span>)<br>ax2.set_xticks(np.arange(<span class=\"hljs-number\">1</span>, epochs, <span class=\"hljs-number\">1</span>))<br><br>legend = plt.legend(loc=<span class=\"hljs-string\">&#x27;best&#x27;</span>, shadow=<span class=\"hljs-literal\">True</span>)<br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205151944.png\" class=\"\" title=\"image-20230109205151944\">\n</li>\n<li><p>准备测试集</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 准备测试集以及创建测试机</span><br>test_filenames = os.listdir(<span class=\"hljs-string\">&#x27;test1&#x27;</span>)<br>df_test = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:test_filenames<br>&#125;)<br>nb_samples = df_test.shape[<span class=\"hljs-number\">0</span>]<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">test_datagen = ImageDataGenerator(<span class=\"hljs-attribute\">rescale</span>=1./255)<br>test_generator = test_datagen.flow_from_dataframe(<br>    df_test,<br>    <span class=\"hljs-string\">&#x27;test1/&#x27;</span>,<br>    <span class=\"hljs-attribute\">x_col</span>=<span class=\"hljs-string\">&#x27;filename&#x27;</span>,<br>    <span class=\"hljs-attribute\">y_col</span>=None,<br>    <span class=\"hljs-attribute\">class_mode</span>=None,<br>    <span class=\"hljs-attribute\">target_size</span>=IMAGE_SIZE,<br>    <span class=\"hljs-attribute\">batch_size</span>=batch_size,<br>    <span class=\"hljs-attribute\">shuffle</span>=<span class=\"hljs-literal\">False</span><br>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>预测</p>\n<blockquote>\n<p>通过神经网络，对测试集的数据进行预测</p>\n<p>选择输出概率最高的做为预测结果</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">predict = model.predict(test_generator,<br>                       steps=np.ceil(nb_samples/batch_size),<br>                       workers=<span class=\"hljs-number\">12</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = np.argmax(predict, axis=-<span class=\"hljs-number\">1</span>)<br><br>label_map = <span class=\"hljs-built_in\">dict</span>((v,k) <span class=\"hljs-keyword\">for</span> k,v <span class=\"hljs-keyword\">in</span> train_generator.class_indices.items())<br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(label_map)<br><br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>] = df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].replace(&#123;<span class=\"hljs-string\">&#x27;dog&#x27;</span>:<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">&#x27;cat&#x27;</span>:<span class=\"hljs-number\">0</span>&#125;)<br><br>df_test[<span class=\"hljs-string\">&#x27;category&#x27;</span>].value_counts().plot.bar()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205407961.png\" class=\"\" title=\"image-20230109205407961\">\n</li>\n<li><p>查看预测结果</p>\n<blockquote>\n<p>可视化了前三十个预测结果，只有1002一张图片预测错误</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">sample_test = df_test.head(<span class=\"hljs-number\">30</span>)<br>sample_test.head()<br>dict_1 = &#123;<span class=\"hljs-number\">1</span>:<span class=\"hljs-string\">&#x27;dog&#x27;</span>, <span class=\"hljs-number\">0</span>:<span class=\"hljs-string\">&#x27;cat&#x27;</span>&#125;<br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">24</span>))<br><span class=\"hljs-keyword\">for</span> index, row <span class=\"hljs-keyword\">in</span> sample_test.iterrows():<br>    filename = row[<span class=\"hljs-string\">&#x27;filename&#x27;</span>]<br>    category = row[<span class=\"hljs-string\">&#x27;category&#x27;</span>]<br>    img = load_img(<span class=\"hljs-string\">&#x27;test1/&#x27;</span> + filename, target_size=IMAGE_SIZE)<br>    plt.subplot(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">3</span>, index+<span class=\"hljs-number\">1</span>)<br>    plt.imshow(img)<br>    plt.xlabel(filename + <span class=\"hljs-string\">&#x27;(&#x27;</span> + <span class=\"hljs-string\">&#x27;&#123;&#125;&#x27;</span>.<span class=\"hljs-built_in\">format</span>(category) + <span class=\"hljs-string\">&#x27;)&#x27;</span> + dict_1[category])<br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/AI-lab01/image-20230109205438300.png\" class=\"\" title=\"image-20230109205438300\">\n<img src=\"/2023/02/02/AI-lab01/image-20230109205453040.png\" class=\"\" title=\"image-20230109205453040\">\n</li>\n</ul>\n<h4 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h4><ul>\n<li><p>叙述从逻辑回归到神经元工作原理</p>\n<p>逻辑回归工作原理：逻辑回归用于二分类问题，将输入的数据进行处理过后得到一个输出数据，再通过sigmoid函数，通过阈值的设置来判断将输出的数据映射为0，或者是1.</p>\n<p>神经元工作原理：神经元的每一个输入都会对应一个相应的权值，通过神经元后，再经过激活函数，产生输出，常见的激活函数有sigmoid函数，relu函数。</p>\n</li>\n<li><p>两种常用的激活函数</p>\n<p>Sigmoid激活函数、Relu激活函数</p>\n</li>\n<li><p>两种池化方式</p>\n<p>最大池化：将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。</p>\n<p>平均池化：将输入的图像划分为若干个矩形区域，对每个子区域输出所有元素的平均值</p>\n</li>\n<li><p>卷积神经网络要素：卷积核、池化、特征图</p>\n<p>卷积核：卷积核，是卷积层中用于与输入的矩阵进行卷积运算的单元，通过与卷积核的卷积运算能够提取出原始图像中的一些特征属性。</p>\n<p>池化：池化的重要的目的在于进一步降低网络的整体计算代价，同时也能够在一定程度上降低网络出现过拟合的风险，能够将原始图像矩阵通过一定的池化方式进行压缩。</p>\n<p>特征图：通过卷积层进行与卷积核运算过后所得到的图就称为提取特征后的特征图。</p>\n</li>\n<li><p>实验用到的模型图示，给出实验中的关键代码并解释</p>\n<img src=\"/2023/02/02/AI-lab01/image-20230109222224342.png\" class=\"\" title=\"image-20230109222224342\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model = Sequential()<br><span class=\"hljs-comment\"># 卷积层1，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br><br><span class=\"hljs-comment\"># 对数据进行标准化，加快训练速度</span><br>model.add(BatchNormalization())<br><br><span class=\"hljs-comment\"># 池化层1，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 卷积层2，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>))<br>model.add(BatchNormalization())<br><span class=\"hljs-comment\"># 池化层2，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 卷积层3，卷积核的大小为（3，3），使用relu激活函数</span><br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br>model.add(BatchNormalization())<br><span class=\"hljs-comment\"># 池化层3，使用最大池化的方法，池化尺寸为（2，2）</span><br>model.add(MaxPooling2D(pool_size=(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>)))<br><br><span class=\"hljs-comment\"># 扁平层，将多维数据一维化</span><br>model.add(Flatten())<br><span class=\"hljs-comment\"># 全连接层2，将输入的数据转化为512维度</span><br>model.add(Dense(<span class=\"hljs-number\">512</span>, activation=<span class=\"hljs-string\">&#x27;relu&#x27;</span>))<br><span class=\"hljs-comment\"># 删除10%的神经元，将其置为0，防止过拟合</span><br>model.add(Dropout(<span class=\"hljs-number\">0.1</span>))<br><span class=\"hljs-comment\"># 全连接层2，将数据最终转化为2为数据，通过softmax映射成概率值</span><br>model.add(Dense(<span class=\"hljs-number\">2</span>, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>))<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>问答</p>\n<p>问题：在训练过程中，学习率是怎样进行调整的？</p>\n<p>回答：使用ReduceLROnPlateau和EarlyStopping配合动态调整学习率，ReduceLRonPlateau函数中有一些列参数可以搭配使用来动态调整学习率。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">monitor：监测的值，可以是accuracy，val_loss,val_accuracy<br>factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少<br>patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发<br>mode：‘auto’，‘<span class=\"hljs-built_in\">min</span>’，‘<span class=\"hljs-built_in\">max</span>’之一 默认‘auto’就行<br>epsilon：阈值，用来确定是否进入检测值的“平原区”<br>cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作<br>min_lr：学习率最小值，能缩小到的下限<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"人工智能实验-花卉图像分类实验","date":"2023-02-12T11:02:41.000Z","cover":"/img/default_cover01.jpg","top_img":null,"_content":"## 实验二、花卉图像分类实验\n\n### 一、实验目的\n\n> 1、掌握如何使用MindSpore进行卷积神经网络的开发\n>\n> 2、了解如何使用MindSpore进行花卉图片分类任务的训练\n>\n> 3、了解如何使用MindSpore进行花卉图片分类任务的测试\n\n### 二、实验步骤\n\n* **华为云环境的配置**\n\n  > 使用ModelArts，并建立Notebook\n\n  * 进入ModelArts\n\n  ![image-20230108225530690](AI-lab02/image-20230108225530690.png)\n\n  * 点击管理控制台\n\n  ![image-20230108225641834](AI-lab02/image-20230108225641834.png)\n\n  * 创建Notebook\n\n  ![image-20230108225724739](AI-lab02/image-20230108225724739.png)\n\n  * 本次实验选择的是以下配置\n\n  > mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04\n  >\n  > GPU: 1*V100(32GB)|CPU: 8核 64GB\n  >\n  > 在华为的GPU上运行\n\n  ![image-20230108225829669](AI-lab02/image-20230108225829669.png)\n\n  * 创建过后便可从列表中进行相关操作\n\n  ![image-20230108230000075](AI-lab02/image-20230108230000075.png)\n\n* **实验步骤**\n\n  * 导入相关函数\n\n  ```python\n  from easydict import EasyDict as edict\n  import glob\n  import os\n  import numpy as np\n  import matplotlib.pyplot as plt\n  import mindspore\n  import mindspore.dataset as ds\n  import mindspore.dataset.vision.c_transforms as CV\n  import mindspore.dataset.transforms.c_transforms as C\n  from mindspore.common import dtype as mstype\n  from mindspore import nn\n  from mindspore.common.initializer import TruncatedNormal\n  from mindspore import context\n  from mindspore.train import Model\n  from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n  from mindspore.train.serialization import load_checkpoint, load_param_into_net\n  from mindspore import Tensor、\n  \n  # 设置Mindspore的执行模式和设备\n  context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n  ```\n  \n  * 定义实验中使用的变量\n  \n  ```python\n  cfg = edict({\n      'data_path':'flower_photos',\n      'data_size':3670,\n      'image_width':100,\n      'image_height':100,\n      'batch_size':32,\n      'channel':3,\n      'num_class':5,\n      'weight_decay':0.01,\n      'lr':0.0001,\n      'dropout_radio':0.5,\n      'epoch_size':400,\n      'sigma':0.01,\n      \n      'save_checkpoint_steps':1,\n      'keep_checkpoint_max':1,\n      'output_directory':'./',\n      'output_prefix':\"checkpoint_classification\"\n  })\n  ```\n  \n  * 下载并解压数据\n  \n  > 数据来源于qq群提供的下载链接https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n  \n  ```python\n  # 解压数据集，运行一次即可\n  # !wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n  # !tar -zxvf flower_photos.tgz\n  ```\n  \n  * 数据处理\n  \n  > 包含数据预处理和训练集和测试集的划分\n  \n  ```python\n  de_dataset = ds.ImageFolderDataset(cfg.data_path,\n                                     class_indexing={'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4})\n  \n  transform_img = CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height],scale=(0.08,1.0),ratio=(0.75,1.333))\n  \n  hwc2chw_op = CV.HWC2CHW()\n  \n  type_cast_op = C.TypeCast(mstype.float32)\n  \n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=transform_img)\n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=hwc2chw_op)\n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=type_cast_op)\n  de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)\n  \n  # 划分训练集和测试集\n  (de_train, de_test) = de_dataset.split([0.8,0.2])\n  de_train = de_train.batch(cfg.batch_size, drop_remainder=True)\n  \n  de_test = de_test.batch(cfg.batch_size, drop_remainder=True)\n  print('训练数据集数量：', de_train.get_dataset_size()*cfg.batch_size)\n  print('测试数据集数量：', de_test.get_dataset_size()*cfg.batch_size)\n  \n  data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()\n  print('通道数/图像长/宽：', data_next['image'].shape)\n  print('一张图像的标签样式:', data_next['label'])\n  print(data_next['image'][0,...].shape)\n  \n  plt.figure()\n  plt.imshow(data_next['image'][1,...])\n  plt.colorbar()\n  plt.grid(False)\n  plt.show()\n  ```\n  \n  ![image-20230108230820413](AI-lab02/image-20230108230820413.png)\n  \n  * 定义CNN图像识别网络\n  \n  > 定义的网络包含4个卷积层，4个池化层，2个全连接层\n  \n  ```python\n  class Identification_Net(nn.Cell):\n      def __init__(self, num_class=5, channel=3, dropout_ratio=0.5, trun_sigma=0.01):\n          super(Identification_Net, self).__init__()\n          self.num_class = num_class\n          self.channel = channel\n          self.dropout_ratio = dropout_ratio\n          # 卷积层\n          self.conv1 = nn.Conv2d(self.channel, 32,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          \n          # 设置Relu激活函数\n          self.relu = nn.ReLU()\n          \n          # 设置最大池化层\n          self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid')\n          self.conv2 = nn.Conv2d(32, 64,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          self.conv3 = nn.Conv2d(64, 128,\n                                 kernel_size=3, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          self.conv4 = nn.Conv2d(128, 128,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          \n          self.flatten = nn.Flatten()\n          self.fc1 = nn.Dense(6*6*128, 1024, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          self.dropout = nn.Dropout(self.dropout_ratio)\n          self.fc2 = nn.Dense(1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          self.fc3= nn.Dense(512, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          \n      # 构建模型\n      def construct(self, x):\n          x = self.conv1(x)\n          x = self.relu(x)\n          x = self.max_pool2d(x)\n          x = self.conv2(x)\n          x = self.relu(x)\n          x = self.max_pool2d(x)\n          x = self.conv3(x)\n          x = self.max_pool2d(x)\n          x = self.conv4(x)\n          x = self.max_pool2d(x)\n          x = self.flatten(x)\n          x = self.fc1(x)\n          x = self.relu(x)\n          x = self.dropout(x)\n          x = self.fc2(x)\n          x = self.relu(x)\n          x = self.dropout(x)\n          x = self.fc3(x)\n          return x\n  ```\n  \n  * 模型训练和预测\n  \n  > 使用交叉熵损失函数，epoch_size为400，batch_size为32，学习率为0.0001，sigma为0.01\n  \n  ```python\n  net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_radio)\n  \n  net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n  \n  fc_weghit_params = list(filter(lambda x:'fc' in x.name and 'weight' in x.name, net.trainable_params()))\n  other_params=list(filter(lambda x:'fc' not in x.name or 'weight' not in x.name, net.trainable_params()))\n  \n  group_params = [{'params':fc_weghit_params, 'weight_decay':cfg.weight_decay},\n                  {'params':other_params},\n                  {'order_params':net.trainable_params()}]\n  \n  net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)\n  \n  model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={'acc'})\n  \n  loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*10)\n  config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n                               keep_checkpoint_max=cfg.keep_checkpoint_max)\n  ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config= config_ck)\n  print(\"=================开始训练==================\")\n  \n  model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True)\n  \n  # 使用测试集评估模型，打印总体准确率\n  metric = model.eval(de_test)\n  print(metric)\n  ```\n  \n  > 总体准确率为0.9432\n  \n  ![image-20230108232000280](AI-lab02/image-20230108232000280.png)\n  \n  * 对具体样本进行预测\n  \n  ```python\n  import os\n  CKPT = os.path.join(cfg.output_directory, cfg.output_prefix+\n                      '-'+str(cfg.epoch_size)+'_'+str(de_train.get_dataset_size())+'.ckpt')\n  \n  net = Identification_Net(num_class=cfg.num_class,channel=cfg.channel,dropout_ratio=cfg.dropout_radio)\n  \n  load_checkpoint(CKPT, net=net)\n  \n  model = Model(net)\n  \n  class_names = {0:'daisy', 1:'dandelion', 2:'roses', 3:'sunflowers', 4:'tulips'}\n  test_ = de_test.create_dict_iterator().__next__()\n  \n  test = Tensor(test_['image'], mindspore.float32)\n  \n  predictions = model.predict(test)\n  predictions = predictions.asnumpy()\n  true_label = test_['label'].asnumpy()\n  \n  for i in range(9):\n      p_np = predictions[i, :]\n      pre_label = np.argmax(p_np)\n      print('第' + str(i) + '个sample预测结果：', class_names[pre_label], '真实结果：', class_names[true_label[i]])\n  ```\n  \n  ![image-20230108232106204](AI-lab02/image-20230108232106204.png)\n  \n  * 模型保存\n  \n  ![image-20230108232154796](AI-lab02/image-20230108232154796.png)\n\n#### 三、总结\n\n​\t\t实验利用华为云平台完成了对于花卉分类实验，首先第一方面，对华为云平台以及华为开发的MindSpore深度学习框架有了进一步的了解。在华为云平台上可以为我们提供一些项目开发平台，具有一套完整的开发体系，如：OBS用于存储对象，ModelArts用于AI开发，训练模型等等。能够提供一些相对来说比较适宜的计算机算力，华为的GPU以及Ascend都可以通过云开发平台很好的运用。同时，对于MindSpore来说，和Tensorflow，Pytorch这一类框架一样，都是以Tensor张量做为数据基础，通过MindSpore能够很好的搭建相关网络，完成训练，梯度下降，等等运算。\n\n​\t\t本次实验解决的是花卉分类问题，是一个多分类的问题，对于多分类的问题了解更为深刻，多分类问题和二分类问题不一样的是，多分类问题会使用交叉熵损失函数，并在输出之前使用softmax函数进行处理，目的是将预测值映射为一个概率值，对比概率值最大的即作为最后的输出结果。同时对于卷积层，池化层，全连接层，这一些在图像处理当中常用到的网络加深了理解，通俗来讲，卷积层目的在于特征提取，池化层的目的在于优化参数，全连接层的目的则是特征整合。而在完成深度学习的过程中，重要的一点还有参数的设置，参数的设置，对于训练时长，训练效果也有较大的影响。\n\n#### 四、实验中遇到的一些问题\n\n* 应该选择Relu函数还是Sigmoid函数？\n\n  解决方案：本次实验使用的时Relu函数做为激活函数，相对于Sigmoid来说，Relu函数不存在梯度消失的问题，能够尽可能多的进行迭代，降低损失值。\n\n#### 五、实验验收过程中问到的相关问题\n\n* 问题1：该实验解决的是一个什么问题？设计的网络输出的向量是一个几维的？\n\n  回答：本次实验解决的是一个多分类问题，再具体来说，是一个五分类问题，完成的是识别给出的图片属于已知五类花卉中的哪一种，因此输出的向量是5维的。\n\n* 问题2：该实验使用的是什么损失函数？\n\n  回答：使用的是交叉熵损失函数，在交叉熵前面会有一个softmax处理，softmax的处理过程就是将输入的数据映射到（0，1）之间的范围当中，并且使得输出的所有值累加和为1，从某种意义上来说，这也是相当于一种概率。\n","source":"_posts/AI-lab02.md","raw":"---\ntitle: 人工智能实验-花卉图像分类实验\ncategories: 算法实践\ndate: 2023-02-12 19:02:41\ntags: [人工智能, 深度学习]\ncover:\ntop_img:\n---\n## 实验二、花卉图像分类实验\n\n### 一、实验目的\n\n> 1、掌握如何使用MindSpore进行卷积神经网络的开发\n>\n> 2、了解如何使用MindSpore进行花卉图片分类任务的训练\n>\n> 3、了解如何使用MindSpore进行花卉图片分类任务的测试\n\n### 二、实验步骤\n\n* **华为云环境的配置**\n\n  > 使用ModelArts，并建立Notebook\n\n  * 进入ModelArts\n\n  ![image-20230108225530690](AI-lab02/image-20230108225530690.png)\n\n  * 点击管理控制台\n\n  ![image-20230108225641834](AI-lab02/image-20230108225641834.png)\n\n  * 创建Notebook\n\n  ![image-20230108225724739](AI-lab02/image-20230108225724739.png)\n\n  * 本次实验选择的是以下配置\n\n  > mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04\n  >\n  > GPU: 1*V100(32GB)|CPU: 8核 64GB\n  >\n  > 在华为的GPU上运行\n\n  ![image-20230108225829669](AI-lab02/image-20230108225829669.png)\n\n  * 创建过后便可从列表中进行相关操作\n\n  ![image-20230108230000075](AI-lab02/image-20230108230000075.png)\n\n* **实验步骤**\n\n  * 导入相关函数\n\n  ```python\n  from easydict import EasyDict as edict\n  import glob\n  import os\n  import numpy as np\n  import matplotlib.pyplot as plt\n  import mindspore\n  import mindspore.dataset as ds\n  import mindspore.dataset.vision.c_transforms as CV\n  import mindspore.dataset.transforms.c_transforms as C\n  from mindspore.common import dtype as mstype\n  from mindspore import nn\n  from mindspore.common.initializer import TruncatedNormal\n  from mindspore import context\n  from mindspore.train import Model\n  from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n  from mindspore.train.serialization import load_checkpoint, load_param_into_net\n  from mindspore import Tensor、\n  \n  # 设置Mindspore的执行模式和设备\n  context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n  ```\n  \n  * 定义实验中使用的变量\n  \n  ```python\n  cfg = edict({\n      'data_path':'flower_photos',\n      'data_size':3670,\n      'image_width':100,\n      'image_height':100,\n      'batch_size':32,\n      'channel':3,\n      'num_class':5,\n      'weight_decay':0.01,\n      'lr':0.0001,\n      'dropout_radio':0.5,\n      'epoch_size':400,\n      'sigma':0.01,\n      \n      'save_checkpoint_steps':1,\n      'keep_checkpoint_max':1,\n      'output_directory':'./',\n      'output_prefix':\"checkpoint_classification\"\n  })\n  ```\n  \n  * 下载并解压数据\n  \n  > 数据来源于qq群提供的下载链接https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n  \n  ```python\n  # 解压数据集，运行一次即可\n  # !wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n  # !tar -zxvf flower_photos.tgz\n  ```\n  \n  * 数据处理\n  \n  > 包含数据预处理和训练集和测试集的划分\n  \n  ```python\n  de_dataset = ds.ImageFolderDataset(cfg.data_path,\n                                     class_indexing={'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4})\n  \n  transform_img = CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height],scale=(0.08,1.0),ratio=(0.75,1.333))\n  \n  hwc2chw_op = CV.HWC2CHW()\n  \n  type_cast_op = C.TypeCast(mstype.float32)\n  \n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=transform_img)\n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=hwc2chw_op)\n  de_dataset = de_dataset.map(input_columns='image', num_parallel_workers=8, operations=type_cast_op)\n  de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)\n  \n  # 划分训练集和测试集\n  (de_train, de_test) = de_dataset.split([0.8,0.2])\n  de_train = de_train.batch(cfg.batch_size, drop_remainder=True)\n  \n  de_test = de_test.batch(cfg.batch_size, drop_remainder=True)\n  print('训练数据集数量：', de_train.get_dataset_size()*cfg.batch_size)\n  print('测试数据集数量：', de_test.get_dataset_size()*cfg.batch_size)\n  \n  data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()\n  print('通道数/图像长/宽：', data_next['image'].shape)\n  print('一张图像的标签样式:', data_next['label'])\n  print(data_next['image'][0,...].shape)\n  \n  plt.figure()\n  plt.imshow(data_next['image'][1,...])\n  plt.colorbar()\n  plt.grid(False)\n  plt.show()\n  ```\n  \n  ![image-20230108230820413](AI-lab02/image-20230108230820413.png)\n  \n  * 定义CNN图像识别网络\n  \n  > 定义的网络包含4个卷积层，4个池化层，2个全连接层\n  \n  ```python\n  class Identification_Net(nn.Cell):\n      def __init__(self, num_class=5, channel=3, dropout_ratio=0.5, trun_sigma=0.01):\n          super(Identification_Net, self).__init__()\n          self.num_class = num_class\n          self.channel = channel\n          self.dropout_ratio = dropout_ratio\n          # 卷积层\n          self.conv1 = nn.Conv2d(self.channel, 32,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          \n          # 设置Relu激活函数\n          self.relu = nn.ReLU()\n          \n          # 设置最大池化层\n          self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid')\n          self.conv2 = nn.Conv2d(32, 64,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          self.conv3 = nn.Conv2d(64, 128,\n                                 kernel_size=3, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          self.conv4 = nn.Conv2d(128, 128,\n                                 kernel_size=5, stride=1, padding=0,\n                                 has_bias=True, pad_mode='same',\n                                 weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\n          \n          self.flatten = nn.Flatten()\n          self.fc1 = nn.Dense(6*6*128, 1024, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          self.dropout = nn.Dropout(self.dropout_ratio)\n          self.fc2 = nn.Dense(1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          self.fc3= nn.Dense(512, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=0.1)\n          \n      # 构建模型\n      def construct(self, x):\n          x = self.conv1(x)\n          x = self.relu(x)\n          x = self.max_pool2d(x)\n          x = self.conv2(x)\n          x = self.relu(x)\n          x = self.max_pool2d(x)\n          x = self.conv3(x)\n          x = self.max_pool2d(x)\n          x = self.conv4(x)\n          x = self.max_pool2d(x)\n          x = self.flatten(x)\n          x = self.fc1(x)\n          x = self.relu(x)\n          x = self.dropout(x)\n          x = self.fc2(x)\n          x = self.relu(x)\n          x = self.dropout(x)\n          x = self.fc3(x)\n          return x\n  ```\n  \n  * 模型训练和预测\n  \n  > 使用交叉熵损失函数，epoch_size为400，batch_size为32，学习率为0.0001，sigma为0.01\n  \n  ```python\n  net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_radio)\n  \n  net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n  \n  fc_weghit_params = list(filter(lambda x:'fc' in x.name and 'weight' in x.name, net.trainable_params()))\n  other_params=list(filter(lambda x:'fc' not in x.name or 'weight' not in x.name, net.trainable_params()))\n  \n  group_params = [{'params':fc_weghit_params, 'weight_decay':cfg.weight_decay},\n                  {'params':other_params},\n                  {'order_params':net.trainable_params()}]\n  \n  net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)\n  \n  model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={'acc'})\n  \n  loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*10)\n  config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n                               keep_checkpoint_max=cfg.keep_checkpoint_max)\n  ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config= config_ck)\n  print(\"=================开始训练==================\")\n  \n  model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True)\n  \n  # 使用测试集评估模型，打印总体准确率\n  metric = model.eval(de_test)\n  print(metric)\n  ```\n  \n  > 总体准确率为0.9432\n  \n  ![image-20230108232000280](AI-lab02/image-20230108232000280.png)\n  \n  * 对具体样本进行预测\n  \n  ```python\n  import os\n  CKPT = os.path.join(cfg.output_directory, cfg.output_prefix+\n                      '-'+str(cfg.epoch_size)+'_'+str(de_train.get_dataset_size())+'.ckpt')\n  \n  net = Identification_Net(num_class=cfg.num_class,channel=cfg.channel,dropout_ratio=cfg.dropout_radio)\n  \n  load_checkpoint(CKPT, net=net)\n  \n  model = Model(net)\n  \n  class_names = {0:'daisy', 1:'dandelion', 2:'roses', 3:'sunflowers', 4:'tulips'}\n  test_ = de_test.create_dict_iterator().__next__()\n  \n  test = Tensor(test_['image'], mindspore.float32)\n  \n  predictions = model.predict(test)\n  predictions = predictions.asnumpy()\n  true_label = test_['label'].asnumpy()\n  \n  for i in range(9):\n      p_np = predictions[i, :]\n      pre_label = np.argmax(p_np)\n      print('第' + str(i) + '个sample预测结果：', class_names[pre_label], '真实结果：', class_names[true_label[i]])\n  ```\n  \n  ![image-20230108232106204](AI-lab02/image-20230108232106204.png)\n  \n  * 模型保存\n  \n  ![image-20230108232154796](AI-lab02/image-20230108232154796.png)\n\n#### 三、总结\n\n​\t\t实验利用华为云平台完成了对于花卉分类实验，首先第一方面，对华为云平台以及华为开发的MindSpore深度学习框架有了进一步的了解。在华为云平台上可以为我们提供一些项目开发平台，具有一套完整的开发体系，如：OBS用于存储对象，ModelArts用于AI开发，训练模型等等。能够提供一些相对来说比较适宜的计算机算力，华为的GPU以及Ascend都可以通过云开发平台很好的运用。同时，对于MindSpore来说，和Tensorflow，Pytorch这一类框架一样，都是以Tensor张量做为数据基础，通过MindSpore能够很好的搭建相关网络，完成训练，梯度下降，等等运算。\n\n​\t\t本次实验解决的是花卉分类问题，是一个多分类的问题，对于多分类的问题了解更为深刻，多分类问题和二分类问题不一样的是，多分类问题会使用交叉熵损失函数，并在输出之前使用softmax函数进行处理，目的是将预测值映射为一个概率值，对比概率值最大的即作为最后的输出结果。同时对于卷积层，池化层，全连接层，这一些在图像处理当中常用到的网络加深了理解，通俗来讲，卷积层目的在于特征提取，池化层的目的在于优化参数，全连接层的目的则是特征整合。而在完成深度学习的过程中，重要的一点还有参数的设置，参数的设置，对于训练时长，训练效果也有较大的影响。\n\n#### 四、实验中遇到的一些问题\n\n* 应该选择Relu函数还是Sigmoid函数？\n\n  解决方案：本次实验使用的时Relu函数做为激活函数，相对于Sigmoid来说，Relu函数不存在梯度消失的问题，能够尽可能多的进行迭代，降低损失值。\n\n#### 五、实验验收过程中问到的相关问题\n\n* 问题1：该实验解决的是一个什么问题？设计的网络输出的向量是一个几维的？\n\n  回答：本次实验解决的是一个多分类问题，再具体来说，是一个五分类问题，完成的是识别给出的图片属于已知五类花卉中的哪一种，因此输出的向量是5维的。\n\n* 问题2：该实验使用的是什么损失函数？\n\n  回答：使用的是交叉熵损失函数，在交叉熵前面会有一个softmax处理，softmax的处理过程就是将输入的数据映射到（0，1）之间的范围当中，并且使得输出的所有值累加和为1，从某种意义上来说，这也是相当于一种概率。\n","slug":"AI-lab02","published":1,"updated":"2024-06-05T09:03:03.500Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttf000b08jv9t4ccfzm","content":"<h2 id=\"实验二、花卉图像分类实验\"><a href=\"#实验二、花卉图像分类实验\" class=\"headerlink\" title=\"实验二、花卉图像分类实验\"></a>实验二、花卉图像分类实验</h2><h3 id=\"一、实验目的\"><a href=\"#一、实验目的\" class=\"headerlink\" title=\"一、实验目的\"></a>一、实验目的</h3><blockquote>\n<p>1、掌握如何使用MindSpore进行卷积神经网络的开发</p>\n<p>2、了解如何使用MindSpore进行花卉图片分类任务的训练</p>\n<p>3、了解如何使用MindSpore进行花卉图片分类任务的测试</p>\n</blockquote>\n<h3 id=\"二、实验步骤\"><a href=\"#二、实验步骤\" class=\"headerlink\" title=\"二、实验步骤\"></a>二、实验步骤</h3><ul>\n<li><p><strong>华为云环境的配置</strong></p>\n<blockquote>\n<p>使用ModelArts，并建立Notebook</p>\n</blockquote>\n<ul>\n<li>进入ModelArts</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225530690.png\" class=\"\" title=\"image-20230108225530690\">\n<ul>\n<li>点击管理控制台</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225641834.png\" class=\"\" title=\"image-20230108225641834\">\n<ul>\n<li>创建Notebook</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225724739.png\" class=\"\" title=\"image-20230108225724739\">\n<ul>\n<li>本次实验选择的是以下配置</li>\n</ul>\n<blockquote>\n<p>mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04</p>\n<p>GPU: 1*V100(32GB)|CPU: 8核 64GB</p>\n<p>在华为的GPU上运行</p>\n</blockquote>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225829669.png\" class=\"\" title=\"image-20230108225829669\">\n<ul>\n<li>创建过后便可从列表中进行相关操作</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108230000075.png\" class=\"\" title=\"image-20230108230000075\">\n</li>\n<li><p><strong>实验步骤</strong></p>\n<ul>\n<li>导入相关函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> easydict <span class=\"hljs-keyword\">import</span> EasyDict <span class=\"hljs-keyword\">as</span> edict<br><span class=\"hljs-keyword\">import</span> glob<br><span class=\"hljs-keyword\">import</span> os<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> mindspore<br><span class=\"hljs-keyword\">import</span> mindspore.dataset <span class=\"hljs-keyword\">as</span> ds<br><span class=\"hljs-keyword\">import</span> mindspore.dataset.vision.c_transforms <span class=\"hljs-keyword\">as</span> CV<br><span class=\"hljs-keyword\">import</span> mindspore.dataset.transforms.c_transforms <span class=\"hljs-keyword\">as</span> C<br><span class=\"hljs-keyword\">from</span> mindspore.common <span class=\"hljs-keyword\">import</span> dtype <span class=\"hljs-keyword\">as</span> mstype<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> nn<br><span class=\"hljs-keyword\">from</span> mindspore.common.initializer <span class=\"hljs-keyword\">import</span> TruncatedNormal<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> context<br><span class=\"hljs-keyword\">from</span> mindspore.train <span class=\"hljs-keyword\">import</span> Model<br><span class=\"hljs-keyword\">from</span> mindspore.train.callback <span class=\"hljs-keyword\">import</span> ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor<br><span class=\"hljs-keyword\">from</span> mindspore.train.serialization <span class=\"hljs-keyword\">import</span> load_checkpoint, load_param_into_net<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> Tensor、<br><br><span class=\"hljs-comment\"># 设置Mindspore的执行模式和设备</span><br>context.set_context(mode=context.GRAPH_MODE, device_target=<span class=\"hljs-string\">&quot;GPU&quot;</span>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>定义实验中使用的变量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">cfg = edict(&#123;<br>    <span class=\"hljs-string\">&#x27;data_path&#x27;</span>:<span class=\"hljs-string\">&#x27;flower_photos&#x27;</span>,<br>    <span class=\"hljs-string\">&#x27;data_size&#x27;</span>:<span class=\"hljs-number\">3670</span>,<br>    <span class=\"hljs-string\">&#x27;image_width&#x27;</span>:<span class=\"hljs-number\">100</span>,<br>    <span class=\"hljs-string\">&#x27;image_height&#x27;</span>:<span class=\"hljs-number\">100</span>,<br>    <span class=\"hljs-string\">&#x27;batch_size&#x27;</span>:<span class=\"hljs-number\">32</span>,<br>    <span class=\"hljs-string\">&#x27;channel&#x27;</span>:<span class=\"hljs-number\">3</span>,<br>    <span class=\"hljs-string\">&#x27;num_class&#x27;</span>:<span class=\"hljs-number\">5</span>,<br>    <span class=\"hljs-string\">&#x27;weight_decay&#x27;</span>:<span class=\"hljs-number\">0.01</span>,<br>    <span class=\"hljs-string\">&#x27;lr&#x27;</span>:<span class=\"hljs-number\">0.0001</span>,<br>    <span class=\"hljs-string\">&#x27;dropout_radio&#x27;</span>:<span class=\"hljs-number\">0.5</span>,<br>    <span class=\"hljs-string\">&#x27;epoch_size&#x27;</span>:<span class=\"hljs-number\">400</span>,<br>    <span class=\"hljs-string\">&#x27;sigma&#x27;</span>:<span class=\"hljs-number\">0.01</span>,<br>    <br>    <span class=\"hljs-string\">&#x27;save_checkpoint_steps&#x27;</span>:<span class=\"hljs-number\">1</span>,<br>    <span class=\"hljs-string\">&#x27;keep_checkpoint_max&#x27;</span>:<span class=\"hljs-number\">1</span>,<br>    <span class=\"hljs-string\">&#x27;output_directory&#x27;</span>:<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>    <span class=\"hljs-string\">&#x27;output_prefix&#x27;</span>:<span class=\"hljs-string\">&quot;checkpoint_classification&quot;</span><br>&#125;)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>下载并解压数据</li>\n</ul>\n<blockquote>\n<p>数据来源于qq群提供的下载链接<a href=\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\">https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</a></p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 解压数据集，运行一次即可</span><br><span class=\"hljs-comment\"># !wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span><br><span class=\"hljs-comment\"># !tar -zxvf flower_photos.tgz</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>数据处理</li>\n</ul>\n<blockquote>\n<p>包含数据预处理和训练集和测试集的划分</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">de_dataset = ds.ImageFolderDataset(cfg.data_path,<br>                                   class_indexing=&#123;<span class=\"hljs-string\">&#x27;daisy&#x27;</span>:<span class=\"hljs-number\">0</span>,<span class=\"hljs-string\">&#x27;dandelion&#x27;</span>:<span class=\"hljs-number\">1</span>,<span class=\"hljs-string\">&#x27;roses&#x27;</span>:<span class=\"hljs-number\">2</span>,<span class=\"hljs-string\">&#x27;sunflowers&#x27;</span>:<span class=\"hljs-number\">3</span>,<span class=\"hljs-string\">&#x27;tulips&#x27;</span>:<span class=\"hljs-number\">4</span>&#125;)<br><br>transform_img = CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height],scale=(<span class=\"hljs-number\">0.08</span>,<span class=\"hljs-number\">1.0</span>),ratio=(<span class=\"hljs-number\">0.75</span>,<span class=\"hljs-number\">1.333</span>))<br><br>hwc2chw_op = CV.HWC2CHW()<br><br>type_cast_op = C.TypeCast(mstype.float32)<br><br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=transform_img)<br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=hwc2chw_op)<br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=type_cast_op)<br>de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)<br><br><span class=\"hljs-comment\"># 划分训练集和测试集</span><br>(de_train, de_test) = de_dataset.split([<span class=\"hljs-number\">0.8</span>,<span class=\"hljs-number\">0.2</span>])<br>de_train = de_train.batch(cfg.batch_size, drop_remainder=<span class=\"hljs-literal\">True</span>)<br><br>de_test = de_test.batch(cfg.batch_size, drop_remainder=<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;训练数据集数量：&#x27;</span>, de_train.get_dataset_size()*cfg.batch_size)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;测试数据集数量：&#x27;</span>, de_test.get_dataset_size()*cfg.batch_size)<br><br>data_next = de_dataset.create_dict_iterator(output_numpy=<span class=\"hljs-literal\">True</span>).__next__()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;通道数/图像长/宽：&#x27;</span>, data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>].shape)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;一张图像的标签样式:&#x27;</span>, data_next[<span class=\"hljs-string\">&#x27;label&#x27;</span>])<br><span class=\"hljs-built_in\">print</span>(data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>][<span class=\"hljs-number\">0</span>,...].shape)<br><br>plt.figure()<br>plt.imshow(data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>][<span class=\"hljs-number\">1</span>,...])<br>plt.colorbar()<br>plt.grid(<span class=\"hljs-literal\">False</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/12/AI-lab02/image-20230108230820413.png\" class=\"\" title=\"image-20230108230820413\">\n<ul>\n<li>定义CNN图像识别网络</li>\n</ul>\n<blockquote>\n<p>定义的网络包含4个卷积层，4个池化层，2个全连接层</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Identification_Net</span>(nn.Cell):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, num_class=<span class=\"hljs-number\">5</span>, channel=<span class=\"hljs-number\">3</span>, dropout_ratio=<span class=\"hljs-number\">0.5</span>, trun_sigma=<span class=\"hljs-number\">0.01</span></span>):<br>        <span class=\"hljs-built_in\">super</span>(Identification_Net, self).__init__()<br>        self.num_class = num_class<br>        self.channel = channel<br>        self.dropout_ratio = dropout_ratio<br>        <span class=\"hljs-comment\"># 卷积层</span><br>        self.conv1 = nn.Conv2d(self.channel, <span class=\"hljs-number\">32</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        <br>        <span class=\"hljs-comment\"># 设置Relu激活函数</span><br>        self.relu = nn.ReLU()<br>        <br>        <span class=\"hljs-comment\"># 设置最大池化层</span><br>        self.max_pool2d = nn.MaxPool2d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>, pad_mode=<span class=\"hljs-string\">&#x27;valid&#x27;</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        self.conv3 = nn.Conv2d(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">128</span>,<br>                               kernel_size=<span class=\"hljs-number\">3</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        self.conv4 = nn.Conv2d(<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">128</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        <br>        self.flatten = nn.Flatten()<br>        self.fc1 = nn.Dense(<span class=\"hljs-number\">6</span>*<span class=\"hljs-number\">6</span>*<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">1024</span>, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        self.dropout = nn.Dropout(self.dropout_ratio)<br>        self.fc2 = nn.Dense(<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">512</span>, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        self.fc3= nn.Dense(<span class=\"hljs-number\">512</span>, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        <br>    <span class=\"hljs-comment\"># 构建模型</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">construct</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.conv1(x)<br>        x = self.relu(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv2(x)<br>        x = self.relu(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv3(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv4(x)<br>        x = self.max_pool2d(x)<br>        x = self.flatten(x)<br>        x = self.fc1(x)<br>        x = self.relu(x)<br>        x = self.dropout(x)<br>        x = self.fc2(x)<br>        x = self.relu(x)<br>        x = self.dropout(x)<br>        x = self.fc3(x)<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<ul>\n<li>模型训练和预测</li>\n</ul>\n<blockquote>\n<p>使用交叉熵损失函数，epoch_size为400，batch_size为32，学习率为0.0001，sigma为0.01</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_radio)<br><br>net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=<span class=\"hljs-literal\">True</span>, reduction=<span class=\"hljs-string\">&quot;mean&quot;</span>)<br><br>fc_weghit_params = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">filter</span>(<span class=\"hljs-keyword\">lambda</span> x:<span class=\"hljs-string\">&#x27;fc&#x27;</span> <span class=\"hljs-keyword\">in</span> x.name <span class=\"hljs-keyword\">and</span> <span class=\"hljs-string\">&#x27;weight&#x27;</span> <span class=\"hljs-keyword\">in</span> x.name, net.trainable_params()))<br>other_params=<span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">filter</span>(<span class=\"hljs-keyword\">lambda</span> x:<span class=\"hljs-string\">&#x27;fc&#x27;</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> x.name <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;weight&#x27;</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> x.name, net.trainable_params()))<br><br>group_params = [&#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:fc_weghit_params, <span class=\"hljs-string\">&#x27;weight_decay&#x27;</span>:cfg.weight_decay&#125;,<br>                &#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:other_params&#125;,<br>                &#123;<span class=\"hljs-string\">&#x27;order_params&#x27;</span>:net.trainable_params()&#125;]<br><br>net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=<span class=\"hljs-number\">0.0</span>)<br><br>model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics=&#123;<span class=\"hljs-string\">&#x27;acc&#x27;</span>&#125;)<br><br>loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*<span class=\"hljs-number\">10</span>)<br>config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,<br>                             keep_checkpoint_max=cfg.keep_checkpoint_max)<br>ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config= config_ck)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;=================开始训练==================&quot;</span>)<br><br>model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=<span class=\"hljs-literal\">True</span>)<br><br><span class=\"hljs-comment\"># 使用测试集评估模型，打印总体准确率</span><br>metric = model.<span class=\"hljs-built_in\">eval</span>(de_test)<br><span class=\"hljs-built_in\">print</span>(metric)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>总体准确率为0.9432</p>\n</blockquote>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232000280.png\" class=\"\" title=\"image-20230108232000280\">\n<ul>\n<li>对具体样本进行预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> os<br>CKPT = os.path.join(cfg.output_directory, cfg.output_prefix+<br>                    <span class=\"hljs-string\">&#x27;-&#x27;</span>+<span class=\"hljs-built_in\">str</span>(cfg.epoch_size)+<span class=\"hljs-string\">&#x27;_&#x27;</span>+<span class=\"hljs-built_in\">str</span>(de_train.get_dataset_size())+<span class=\"hljs-string\">&#x27;.ckpt&#x27;</span>)<br><br>net = Identification_Net(num_class=cfg.num_class,channel=cfg.channel,dropout_ratio=cfg.dropout_radio)<br><br>load_checkpoint(CKPT, net=net)<br><br>model = Model(net)<br><br>class_names = &#123;<span class=\"hljs-number\">0</span>:<span class=\"hljs-string\">&#x27;daisy&#x27;</span>, <span class=\"hljs-number\">1</span>:<span class=\"hljs-string\">&#x27;dandelion&#x27;</span>, <span class=\"hljs-number\">2</span>:<span class=\"hljs-string\">&#x27;roses&#x27;</span>, <span class=\"hljs-number\">3</span>:<span class=\"hljs-string\">&#x27;sunflowers&#x27;</span>, <span class=\"hljs-number\">4</span>:<span class=\"hljs-string\">&#x27;tulips&#x27;</span>&#125;<br>test_ = de_test.create_dict_iterator().__next__()<br><br>test = Tensor(test_[<span class=\"hljs-string\">&#x27;image&#x27;</span>], mindspore.float32)<br><br>predictions = model.predict(test)<br>predictions = predictions.asnumpy()<br>true_label = test_[<span class=\"hljs-string\">&#x27;label&#x27;</span>].asnumpy()<br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">9</span>):<br>    p_np = predictions[i, :]<br>    pre_label = np.argmax(p_np)<br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span> + <span class=\"hljs-built_in\">str</span>(i) + <span class=\"hljs-string\">&#x27;个sample预测结果：&#x27;</span>, class_names[pre_label], <span class=\"hljs-string\">&#x27;真实结果：&#x27;</span>, class_names[true_label[i]])<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232106204.png\" class=\"\" title=\"image-20230108232106204\">\n<ul>\n<li>模型保存</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232154796.png\" class=\"\" title=\"image-20230108232154796\">\n</li>\n</ul>\n<h4 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h4><p>​        实验利用华为云平台完成了对于花卉分类实验，首先第一方面，对华为云平台以及华为开发的MindSpore深度学习框架有了进一步的了解。在华为云平台上可以为我们提供一些项目开发平台，具有一套完整的开发体系，如：OBS用于存储对象，ModelArts用于AI开发，训练模型等等。能够提供一些相对来说比较适宜的计算机算力，华为的GPU以及Ascend都可以通过云开发平台很好的运用。同时，对于MindSpore来说，和Tensorflow，Pytorch这一类框架一样，都是以Tensor张量做为数据基础，通过MindSpore能够很好的搭建相关网络，完成训练，梯度下降，等等运算。</p>\n<p>​        本次实验解决的是花卉分类问题，是一个多分类的问题，对于多分类的问题了解更为深刻，多分类问题和二分类问题不一样的是，多分类问题会使用交叉熵损失函数，并在输出之前使用softmax函数进行处理，目的是将预测值映射为一个概率值，对比概率值最大的即作为最后的输出结果。同时对于卷积层，池化层，全连接层，这一些在图像处理当中常用到的网络加深了理解，通俗来讲，卷积层目的在于特征提取，池化层的目的在于优化参数，全连接层的目的则是特征整合。而在完成深度学习的过程中，重要的一点还有参数的设置，参数的设置，对于训练时长，训练效果也有较大的影响。</p>\n<h4 id=\"四、实验中遇到的一些问题\"><a href=\"#四、实验中遇到的一些问题\" class=\"headerlink\" title=\"四、实验中遇到的一些问题\"></a>四、实验中遇到的一些问题</h4><ul>\n<li><p>应该选择Relu函数还是Sigmoid函数？</p>\n<p>解决方案：本次实验使用的时Relu函数做为激活函数，相对于Sigmoid来说，Relu函数不存在梯度消失的问题，能够尽可能多的进行迭代，降低损失值。</p>\n</li>\n</ul>\n<h4 id=\"五、实验验收过程中问到的相关问题\"><a href=\"#五、实验验收过程中问到的相关问题\" class=\"headerlink\" title=\"五、实验验收过程中问到的相关问题\"></a>五、实验验收过程中问到的相关问题</h4><ul>\n<li><p>问题1：该实验解决的是一个什么问题？设计的网络输出的向量是一个几维的？</p>\n<p>回答：本次实验解决的是一个多分类问题，再具体来说，是一个五分类问题，完成的是识别给出的图片属于已知五类花卉中的哪一种，因此输出的向量是5维的。</p>\n</li>\n<li><p>问题2：该实验使用的是什么损失函数？</p>\n<p>回答：使用的是交叉熵损失函数，在交叉熵前面会有一个softmax处理，softmax的处理过程就是将输入的数据映射到（0，1）之间的范围当中，并且使得输出的所有值累加和为1，从某种意义上来说，这也是相当于一种概率。</p>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"实验二、花卉图像分类实验\"><a href=\"#实验二、花卉图像分类实验\" class=\"headerlink\" title=\"实验二、花卉图像分类实验\"></a>实验二、花卉图像分类实验</h2><h3 id=\"一、实验目的\"><a href=\"#一、实验目的\" class=\"headerlink\" title=\"一、实验目的\"></a>一、实验目的</h3><blockquote>\n<p>1、掌握如何使用MindSpore进行卷积神经网络的开发</p>\n<p>2、了解如何使用MindSpore进行花卉图片分类任务的训练</p>\n<p>3、了解如何使用MindSpore进行花卉图片分类任务的测试</p>\n</blockquote>\n<h3 id=\"二、实验步骤\"><a href=\"#二、实验步骤\" class=\"headerlink\" title=\"二、实验步骤\"></a>二、实验步骤</h3><ul>\n<li><p><strong>华为云环境的配置</strong></p>\n<blockquote>\n<p>使用ModelArts，并建立Notebook</p>\n</blockquote>\n<ul>\n<li>进入ModelArts</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225530690.png\" class=\"\" title=\"image-20230108225530690\">\n<ul>\n<li>点击管理控制台</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225641834.png\" class=\"\" title=\"image-20230108225641834\">\n<ul>\n<li>创建Notebook</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225724739.png\" class=\"\" title=\"image-20230108225724739\">\n<ul>\n<li>本次实验选择的是以下配置</li>\n</ul>\n<blockquote>\n<p>mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04</p>\n<p>GPU: 1*V100(32GB)|CPU: 8核 64GB</p>\n<p>在华为的GPU上运行</p>\n</blockquote>\n<img src=\"/2023/02/12/AI-lab02/image-20230108225829669.png\" class=\"\" title=\"image-20230108225829669\">\n<ul>\n<li>创建过后便可从列表中进行相关操作</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108230000075.png\" class=\"\" title=\"image-20230108230000075\">\n</li>\n<li><p><strong>实验步骤</strong></p>\n<ul>\n<li>导入相关函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> easydict <span class=\"hljs-keyword\">import</span> EasyDict <span class=\"hljs-keyword\">as</span> edict<br><span class=\"hljs-keyword\">import</span> glob<br><span class=\"hljs-keyword\">import</span> os<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> mindspore<br><span class=\"hljs-keyword\">import</span> mindspore.dataset <span class=\"hljs-keyword\">as</span> ds<br><span class=\"hljs-keyword\">import</span> mindspore.dataset.vision.c_transforms <span class=\"hljs-keyword\">as</span> CV<br><span class=\"hljs-keyword\">import</span> mindspore.dataset.transforms.c_transforms <span class=\"hljs-keyword\">as</span> C<br><span class=\"hljs-keyword\">from</span> mindspore.common <span class=\"hljs-keyword\">import</span> dtype <span class=\"hljs-keyword\">as</span> mstype<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> nn<br><span class=\"hljs-keyword\">from</span> mindspore.common.initializer <span class=\"hljs-keyword\">import</span> TruncatedNormal<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> context<br><span class=\"hljs-keyword\">from</span> mindspore.train <span class=\"hljs-keyword\">import</span> Model<br><span class=\"hljs-keyword\">from</span> mindspore.train.callback <span class=\"hljs-keyword\">import</span> ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor<br><span class=\"hljs-keyword\">from</span> mindspore.train.serialization <span class=\"hljs-keyword\">import</span> load_checkpoint, load_param_into_net<br><span class=\"hljs-keyword\">from</span> mindspore <span class=\"hljs-keyword\">import</span> Tensor、<br><br><span class=\"hljs-comment\"># 设置Mindspore的执行模式和设备</span><br>context.set_context(mode=context.GRAPH_MODE, device_target=<span class=\"hljs-string\">&quot;GPU&quot;</span>)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>定义实验中使用的变量</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">cfg = edict(&#123;<br>    <span class=\"hljs-string\">&#x27;data_path&#x27;</span>:<span class=\"hljs-string\">&#x27;flower_photos&#x27;</span>,<br>    <span class=\"hljs-string\">&#x27;data_size&#x27;</span>:<span class=\"hljs-number\">3670</span>,<br>    <span class=\"hljs-string\">&#x27;image_width&#x27;</span>:<span class=\"hljs-number\">100</span>,<br>    <span class=\"hljs-string\">&#x27;image_height&#x27;</span>:<span class=\"hljs-number\">100</span>,<br>    <span class=\"hljs-string\">&#x27;batch_size&#x27;</span>:<span class=\"hljs-number\">32</span>,<br>    <span class=\"hljs-string\">&#x27;channel&#x27;</span>:<span class=\"hljs-number\">3</span>,<br>    <span class=\"hljs-string\">&#x27;num_class&#x27;</span>:<span class=\"hljs-number\">5</span>,<br>    <span class=\"hljs-string\">&#x27;weight_decay&#x27;</span>:<span class=\"hljs-number\">0.01</span>,<br>    <span class=\"hljs-string\">&#x27;lr&#x27;</span>:<span class=\"hljs-number\">0.0001</span>,<br>    <span class=\"hljs-string\">&#x27;dropout_radio&#x27;</span>:<span class=\"hljs-number\">0.5</span>,<br>    <span class=\"hljs-string\">&#x27;epoch_size&#x27;</span>:<span class=\"hljs-number\">400</span>,<br>    <span class=\"hljs-string\">&#x27;sigma&#x27;</span>:<span class=\"hljs-number\">0.01</span>,<br>    <br>    <span class=\"hljs-string\">&#x27;save_checkpoint_steps&#x27;</span>:<span class=\"hljs-number\">1</span>,<br>    <span class=\"hljs-string\">&#x27;keep_checkpoint_max&#x27;</span>:<span class=\"hljs-number\">1</span>,<br>    <span class=\"hljs-string\">&#x27;output_directory&#x27;</span>:<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>    <span class=\"hljs-string\">&#x27;output_prefix&#x27;</span>:<span class=\"hljs-string\">&quot;checkpoint_classification&quot;</span><br>&#125;)<br></code></pre></td></tr></table></figure>\n<ul>\n<li>下载并解压数据</li>\n</ul>\n<blockquote>\n<p>数据来源于qq群提供的下载链接<a href=\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\">https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</a></p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 解压数据集，运行一次即可</span><br><span class=\"hljs-comment\"># !wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span><br><span class=\"hljs-comment\"># !tar -zxvf flower_photos.tgz</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>数据处理</li>\n</ul>\n<blockquote>\n<p>包含数据预处理和训练集和测试集的划分</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">de_dataset = ds.ImageFolderDataset(cfg.data_path,<br>                                   class_indexing=&#123;<span class=\"hljs-string\">&#x27;daisy&#x27;</span>:<span class=\"hljs-number\">0</span>,<span class=\"hljs-string\">&#x27;dandelion&#x27;</span>:<span class=\"hljs-number\">1</span>,<span class=\"hljs-string\">&#x27;roses&#x27;</span>:<span class=\"hljs-number\">2</span>,<span class=\"hljs-string\">&#x27;sunflowers&#x27;</span>:<span class=\"hljs-number\">3</span>,<span class=\"hljs-string\">&#x27;tulips&#x27;</span>:<span class=\"hljs-number\">4</span>&#125;)<br><br>transform_img = CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height],scale=(<span class=\"hljs-number\">0.08</span>,<span class=\"hljs-number\">1.0</span>),ratio=(<span class=\"hljs-number\">0.75</span>,<span class=\"hljs-number\">1.333</span>))<br><br>hwc2chw_op = CV.HWC2CHW()<br><br>type_cast_op = C.TypeCast(mstype.float32)<br><br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=transform_img)<br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=hwc2chw_op)<br>de_dataset = de_dataset.<span class=\"hljs-built_in\">map</span>(input_columns=<span class=\"hljs-string\">&#x27;image&#x27;</span>, num_parallel_workers=<span class=\"hljs-number\">8</span>, operations=type_cast_op)<br>de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)<br><br><span class=\"hljs-comment\"># 划分训练集和测试集</span><br>(de_train, de_test) = de_dataset.split([<span class=\"hljs-number\">0.8</span>,<span class=\"hljs-number\">0.2</span>])<br>de_train = de_train.batch(cfg.batch_size, drop_remainder=<span class=\"hljs-literal\">True</span>)<br><br>de_test = de_test.batch(cfg.batch_size, drop_remainder=<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;训练数据集数量：&#x27;</span>, de_train.get_dataset_size()*cfg.batch_size)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;测试数据集数量：&#x27;</span>, de_test.get_dataset_size()*cfg.batch_size)<br><br>data_next = de_dataset.create_dict_iterator(output_numpy=<span class=\"hljs-literal\">True</span>).__next__()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;通道数/图像长/宽：&#x27;</span>, data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>].shape)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;一张图像的标签样式:&#x27;</span>, data_next[<span class=\"hljs-string\">&#x27;label&#x27;</span>])<br><span class=\"hljs-built_in\">print</span>(data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>][<span class=\"hljs-number\">0</span>,...].shape)<br><br>plt.figure()<br>plt.imshow(data_next[<span class=\"hljs-string\">&#x27;image&#x27;</span>][<span class=\"hljs-number\">1</span>,...])<br>plt.colorbar()<br>plt.grid(<span class=\"hljs-literal\">False</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/12/AI-lab02/image-20230108230820413.png\" class=\"\" title=\"image-20230108230820413\">\n<ul>\n<li>定义CNN图像识别网络</li>\n</ul>\n<blockquote>\n<p>定义的网络包含4个卷积层，4个池化层，2个全连接层</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Identification_Net</span>(nn.Cell):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, num_class=<span class=\"hljs-number\">5</span>, channel=<span class=\"hljs-number\">3</span>, dropout_ratio=<span class=\"hljs-number\">0.5</span>, trun_sigma=<span class=\"hljs-number\">0.01</span></span>):<br>        <span class=\"hljs-built_in\">super</span>(Identification_Net, self).__init__()<br>        self.num_class = num_class<br>        self.channel = channel<br>        self.dropout_ratio = dropout_ratio<br>        <span class=\"hljs-comment\"># 卷积层</span><br>        self.conv1 = nn.Conv2d(self.channel, <span class=\"hljs-number\">32</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        <br>        <span class=\"hljs-comment\"># 设置Relu激活函数</span><br>        self.relu = nn.ReLU()<br>        <br>        <span class=\"hljs-comment\"># 设置最大池化层</span><br>        self.max_pool2d = nn.MaxPool2d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>, pad_mode=<span class=\"hljs-string\">&#x27;valid&#x27;</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        self.conv3 = nn.Conv2d(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">128</span>,<br>                               kernel_size=<span class=\"hljs-number\">3</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        self.conv4 = nn.Conv2d(<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">128</span>,<br>                               kernel_size=<span class=\"hljs-number\">5</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">0</span>,<br>                               has_bias=<span class=\"hljs-literal\">True</span>, pad_mode=<span class=\"hljs-string\">&#x27;same&#x27;</span>,<br>                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=<span class=\"hljs-string\">&#x27;zeros&#x27;</span>)<br>        <br>        self.flatten = nn.Flatten()<br>        self.fc1 = nn.Dense(<span class=\"hljs-number\">6</span>*<span class=\"hljs-number\">6</span>*<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">1024</span>, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        self.dropout = nn.Dropout(self.dropout_ratio)<br>        self.fc2 = nn.Dense(<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">512</span>, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        self.fc3= nn.Dense(<span class=\"hljs-number\">512</span>, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma),bias_init=<span class=\"hljs-number\">0.1</span>)<br>        <br>    <span class=\"hljs-comment\"># 构建模型</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">construct</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.conv1(x)<br>        x = self.relu(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv2(x)<br>        x = self.relu(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv3(x)<br>        x = self.max_pool2d(x)<br>        x = self.conv4(x)<br>        x = self.max_pool2d(x)<br>        x = self.flatten(x)<br>        x = self.fc1(x)<br>        x = self.relu(x)<br>        x = self.dropout(x)<br>        x = self.fc2(x)<br>        x = self.relu(x)<br>        x = self.dropout(x)<br>        x = self.fc3(x)<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<ul>\n<li>模型训练和预测</li>\n</ul>\n<blockquote>\n<p>使用交叉熵损失函数，epoch_size为400，batch_size为32，学习率为0.0001，sigma为0.01</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_radio)<br><br>net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=<span class=\"hljs-literal\">True</span>, reduction=<span class=\"hljs-string\">&quot;mean&quot;</span>)<br><br>fc_weghit_params = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">filter</span>(<span class=\"hljs-keyword\">lambda</span> x:<span class=\"hljs-string\">&#x27;fc&#x27;</span> <span class=\"hljs-keyword\">in</span> x.name <span class=\"hljs-keyword\">and</span> <span class=\"hljs-string\">&#x27;weight&#x27;</span> <span class=\"hljs-keyword\">in</span> x.name, net.trainable_params()))<br>other_params=<span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">filter</span>(<span class=\"hljs-keyword\">lambda</span> x:<span class=\"hljs-string\">&#x27;fc&#x27;</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> x.name <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">&#x27;weight&#x27;</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> x.name, net.trainable_params()))<br><br>group_params = [&#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:fc_weghit_params, <span class=\"hljs-string\">&#x27;weight_decay&#x27;</span>:cfg.weight_decay&#125;,<br>                &#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:other_params&#125;,<br>                &#123;<span class=\"hljs-string\">&#x27;order_params&#x27;</span>:net.trainable_params()&#125;]<br><br>net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=<span class=\"hljs-number\">0.0</span>)<br><br>model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics=&#123;<span class=\"hljs-string\">&#x27;acc&#x27;</span>&#125;)<br><br>loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*<span class=\"hljs-number\">10</span>)<br>config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,<br>                             keep_checkpoint_max=cfg.keep_checkpoint_max)<br>ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config= config_ck)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;=================开始训练==================&quot;</span>)<br><br>model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=<span class=\"hljs-literal\">True</span>)<br><br><span class=\"hljs-comment\"># 使用测试集评估模型，打印总体准确率</span><br>metric = model.<span class=\"hljs-built_in\">eval</span>(de_test)<br><span class=\"hljs-built_in\">print</span>(metric)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>总体准确率为0.9432</p>\n</blockquote>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232000280.png\" class=\"\" title=\"image-20230108232000280\">\n<ul>\n<li>对具体样本进行预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> os<br>CKPT = os.path.join(cfg.output_directory, cfg.output_prefix+<br>                    <span class=\"hljs-string\">&#x27;-&#x27;</span>+<span class=\"hljs-built_in\">str</span>(cfg.epoch_size)+<span class=\"hljs-string\">&#x27;_&#x27;</span>+<span class=\"hljs-built_in\">str</span>(de_train.get_dataset_size())+<span class=\"hljs-string\">&#x27;.ckpt&#x27;</span>)<br><br>net = Identification_Net(num_class=cfg.num_class,channel=cfg.channel,dropout_ratio=cfg.dropout_radio)<br><br>load_checkpoint(CKPT, net=net)<br><br>model = Model(net)<br><br>class_names = &#123;<span class=\"hljs-number\">0</span>:<span class=\"hljs-string\">&#x27;daisy&#x27;</span>, <span class=\"hljs-number\">1</span>:<span class=\"hljs-string\">&#x27;dandelion&#x27;</span>, <span class=\"hljs-number\">2</span>:<span class=\"hljs-string\">&#x27;roses&#x27;</span>, <span class=\"hljs-number\">3</span>:<span class=\"hljs-string\">&#x27;sunflowers&#x27;</span>, <span class=\"hljs-number\">4</span>:<span class=\"hljs-string\">&#x27;tulips&#x27;</span>&#125;<br>test_ = de_test.create_dict_iterator().__next__()<br><br>test = Tensor(test_[<span class=\"hljs-string\">&#x27;image&#x27;</span>], mindspore.float32)<br><br>predictions = model.predict(test)<br>predictions = predictions.asnumpy()<br>true_label = test_[<span class=\"hljs-string\">&#x27;label&#x27;</span>].asnumpy()<br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">9</span>):<br>    p_np = predictions[i, :]<br>    pre_label = np.argmax(p_np)<br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span> + <span class=\"hljs-built_in\">str</span>(i) + <span class=\"hljs-string\">&#x27;个sample预测结果：&#x27;</span>, class_names[pre_label], <span class=\"hljs-string\">&#x27;真实结果：&#x27;</span>, class_names[true_label[i]])<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232106204.png\" class=\"\" title=\"image-20230108232106204\">\n<ul>\n<li>模型保存</li>\n</ul>\n<img src=\"/2023/02/12/AI-lab02/image-20230108232154796.png\" class=\"\" title=\"image-20230108232154796\">\n</li>\n</ul>\n<h4 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h4><p>​        实验利用华为云平台完成了对于花卉分类实验，首先第一方面，对华为云平台以及华为开发的MindSpore深度学习框架有了进一步的了解。在华为云平台上可以为我们提供一些项目开发平台，具有一套完整的开发体系，如：OBS用于存储对象，ModelArts用于AI开发，训练模型等等。能够提供一些相对来说比较适宜的计算机算力，华为的GPU以及Ascend都可以通过云开发平台很好的运用。同时，对于MindSpore来说，和Tensorflow，Pytorch这一类框架一样，都是以Tensor张量做为数据基础，通过MindSpore能够很好的搭建相关网络，完成训练，梯度下降，等等运算。</p>\n<p>​        本次实验解决的是花卉分类问题，是一个多分类的问题，对于多分类的问题了解更为深刻，多分类问题和二分类问题不一样的是，多分类问题会使用交叉熵损失函数，并在输出之前使用softmax函数进行处理，目的是将预测值映射为一个概率值，对比概率值最大的即作为最后的输出结果。同时对于卷积层，池化层，全连接层，这一些在图像处理当中常用到的网络加深了理解，通俗来讲，卷积层目的在于特征提取，池化层的目的在于优化参数，全连接层的目的则是特征整合。而在完成深度学习的过程中，重要的一点还有参数的设置，参数的设置，对于训练时长，训练效果也有较大的影响。</p>\n<h4 id=\"四、实验中遇到的一些问题\"><a href=\"#四、实验中遇到的一些问题\" class=\"headerlink\" title=\"四、实验中遇到的一些问题\"></a>四、实验中遇到的一些问题</h4><ul>\n<li><p>应该选择Relu函数还是Sigmoid函数？</p>\n<p>解决方案：本次实验使用的时Relu函数做为激活函数，相对于Sigmoid来说，Relu函数不存在梯度消失的问题，能够尽可能多的进行迭代，降低损失值。</p>\n</li>\n</ul>\n<h4 id=\"五、实验验收过程中问到的相关问题\"><a href=\"#五、实验验收过程中问到的相关问题\" class=\"headerlink\" title=\"五、实验验收过程中问到的相关问题\"></a>五、实验验收过程中问到的相关问题</h4><ul>\n<li><p>问题1：该实验解决的是一个什么问题？设计的网络输出的向量是一个几维的？</p>\n<p>回答：本次实验解决的是一个多分类问题，再具体来说，是一个五分类问题，完成的是识别给出的图片属于已知五类花卉中的哪一种，因此输出的向量是5维的。</p>\n</li>\n<li><p>问题2：该实验使用的是什么损失函数？</p>\n<p>回答：使用的是交叉熵损失函数，在交叉熵前面会有一个softmax处理，softmax的处理过程就是将输入的数据映射到（0，1）之间的范围当中，并且使得输出的所有值累加和为1，从某种意义上来说，这也是相当于一种概率。</p>\n</li>\n</ul>\n"},{"title":"人工智能实验-基于LSTM+CTC的验证码","date":"2023-02-18T11:02:41.000Z","cover":"/img/default_cover06.jpg","top_img":null,"_content":"## 实验4-基于LSTM+CTC的验证码\n\n### 1、实验目的\n\n* 会利用循环网络模型解决序列数据的相关问题\n\n### 2、实验内容\n\n* 使用循环网络，自主实现效验码中多个数字字符的识别，并使用深度学习框架完成模型的训练\n\n### 3、实验步骤\n\n> 实验一共分为两个实践，第一个实践是CAPTCHA识别实践，第二个实践是基于LSTM+CTC的验证码识别是实践，本次实验第一个实践在CPU上完成，第二个实践则在GPU上完成\n\n#### 3.1 CAPTCHA识别实践\n\n* 获取数据集\n\n  > tqdm用于显示进度条，captcha用于生成验证码数据集，一共生成100000个验证码图片\n\n  ```python\n  # 获取数据集\n  from captcha.image import ImageCaptcha\n  from tqdm import tqdm\n  import random\n  import os\n  \n  H, W, C = 100, 120, 3\n  N_LABELS = 10\n  D = 4\n  \n  def generate_captcha_images(datasets_path, num_images, width=200, height=100):\n      images_path = os.path.join(datasets_path, 'image')\n      if not os.path.exists(images_path):\n          os.makedirs(images_path)\n          \n      label_file =  open(os.path.join(datasets_path, 'labels.txt'), 'w')\n      image = ImageCaptcha(width=width, height=height)\n      alphabet = '0123456789'\n      for i in tqdm(range(num_images)):\n          # 生成随机4位数字的效验码内容\n          captcha_text = random.choices(alphabet, k=4)\n          label = ''.join(captcha_text)\n          # 文件名与输出路径\n          image_filename = f'%d.' % i + 'jpg'\n          output_path = os.path.join(images_path, image_filename)\n          # 保存图片和写入标签\n          image.write(label, output_path)\n          label_file.write(image_filename + ',' + label + '\\n')\n      label_file.close()\n  ```\n\n  ```python\n  # 生成以后将改行设为注释\n  # generate_captcha_images('train1', 100000, width=120, height=100)\n  ```\n\n  ![image-20230111212922711](AI-lab03/image-20230111212922711.png)\n\n* 获取图片对应的标签值\n\n  ```python\n  # 获取图片对应的标签值\n  import numpy as np\n  import pandas as pd\n  import os\n  \n  filenames_file = os.listdir('train1/image/')\n  label_file = open('train1/labels.txt')\n  \n  filenames = []\n  labels = []\n  \n  for line in label_file:\n      line_split = line.strip().split(',')\n      filename, label = line_split[0], line_split[1]\n      filenames.append(filename)\n      labels.append(label)\n      \n  # 将文件名和标签一一对应\n  df = pd.DataFrame({\n      'filename':filenames,\n      'label':labels\n  })\n  \n  df.head(1)\n  ```\n\n  ![image-20230111213029737](AI-lab03/image-20230111213029737.png)\n\n* 划分训练集和测试集\n\n  > 按照8训练集：2训练集的比例进行划分\n\n  ````python\n  # 划分数据集\n  from sklearn.model_selection import train_test_split\n  \n  df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42)\n  df_train = df_train.reset_index(drop=True)\n  df_valid = df_valid.reset_index(drop=True)\n  \n  total_train = df_train.shape[0]\n  total_valid = df_valid.shape[0]\n  ````\n\n* 构造data_generator\n\n  ```python\n  # 构造data_generator\n  from tensorflow.keras.utils import to_categorical\n  from PIL import Image\n  \n  def get_data_generator(df, num, for_training, batch_size=16):\n      images, labels = [], []\n      while True:\n          for i in range(num):\n              r = df.iloc[i]\n              file, label = os.path.join('train1', 'image', r['filename']), r['label']\n              im = Image.open(file)\n              im = np.array(im) / 255.0\n              images.append(np.array(im))\n              labels.append(np.array([np.array(to_categorical(int(i), N_LABELS)) for i in label]))\n              if len(images) > batch_size:\n                  yield np.array(images), np.array(labels)\n                  images, labels = [], []\n              if not for_training:\n                  break\n  ```\n\n* 查看所生成的数据样例\n\n  ```python\n  # 查看生成数据样例\n  from matplotlib import pyplot as plt\n  \n  for v in get_data_generator(df_train, total_train, True):\n      X, y = v\n      break\n  print(X.shape, y.shape)\n  plt.imshow(X[0], interpolation='nearest')\n  print(y[0])\n  ```\n\n  ![image-20230111213218547](AI-lab03/image-20230111213218547.png)\n\n  ```python\n  batch_size = 64\n  valid_batch_size = 64\n  train_gen = get_data_generator(df_train, total_train, for_training=True, batch_size=batch_size)\n  valid_gen = get_data_generator(df_valid, total_valid, for_training=True, batch_size=valid_batch_size)\n  ```\n\n* 构建网络，定义损失函数\n\n  ```python\n  # 构建网络\n  import tensorflow as tf\n  from tensorflow.keras import Sequential\n  from tensorflow.keras import Input\n  from tensorflow.keras.layers import Conv2D, PReLU, MaxPooling2D, Flatten, Dense, Reshape, Softmax\n  \n  model = Sequential()\n  \n  model.add(Input(shape=(H, W, C)))\n  model.add(Conv2D(32, (3, 3)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Conv2D(64, (5, 5)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Conv2D(128, (5, 5,)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Flatten())\n  model.add(Dense(D * N_LABELS))\n  model.add(Reshape([D, N_LABELS]))\n  \n  model.add(Softmax())\n  \n  model.compile(optimizer='Adam', metrics=['accuracy'], loss='categorical_crossentropy')\n  ```\n\n* 查看网络结构\n\n  ```python\n  model.summary()\n  ```\n\n  ![image-20230111213428993](AI-lab03/image-20230111213428993.png)\n\n* 开始训练\n\n  > 一共完成5个epoches，每个epoches含有1250步\n\n  ```python\n  histort = model.fit(train_gen,\n                     steps_per_epoch=total_train//batch_size,\n                     epochs=5,\n                     validation_data=valid_gen,\n                     validation_steps=total_valid//valid_batch_size)\n  ```\n\n  ![image-20230111213530417](AI-lab03/image-20230111213530417.png)\n\n* 测试验证\n\n  ```python\n  test = get_data_generator(df_valid, total_valid, True)\n  X_test, y_test = next(test)\n  \n  plt.imshow(X_test[0], interpolation='nearest')\n  print(y[0])\n  \n  y_pred = model.predict_on_batch(X_test)\n  y_true = tf.math.argmax(y_test, axis=-1)\n  y_pred = tf.math.argmax(y_pred, axis=-1)\n  print('y_true:', y_true[0].numpy())\n  print('y_pred:', y_pred[0].numpy())\n  ```\n\n  ![image-20230111215240888](AI-lab03/image-20230111215240888.png)\n\n#### 3.2 基于LSTM+CTC的验证码识别\n\n* 导入相关库函数，定义常量\n\n  ```python\n  # 导入必要的库\n  from captcha.image import ImageCaptcha\n  from matplotlib import pyplot as plt\n  import numpy as np\n  import pandas as pd\n  import random\n  import tensorflow as tf\n  import tensorflow.keras.backend as K\n  import string\n  \n  %matplotlib inline\n  %config InlineBackend.figure_format = 'retina'\n  \n  characters = string.digits + string.ascii_uppercase\n  print(characters)\n  \n  width = 128\n  height = 64\n  n_len = 4\n  n_class = len(characters) + 1\n  ```\n\n* 定义CTC损失函数\n\n  ```python\n  # 定义CTC Loss\n  def ctc_lambda_func(args):\n      y_pred, labels, input_length, label_length = args\n      return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n  ```\n\n* 定义网络结构\n\n  ```python\n  input_tensor = Input((height, width, 3))\n  x = input_tensor\n  for i, n_cnn in enumerate([2, 2, 2, 2, 2]):\n      for j in range(n_cnn):\n          x = Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n          x = BatchNormalization()(x)\n          x = Activation('relu')(x)\n      x = MaxPooling2D(2 if i < 3 else (2, 1))(x)\n  x = Permute((2, 1, 3))(x)\n  x = TimeDistributed(Flatten())(x)\n  \n  rnn_size = 128\n  x = Bidirectional(GRU(rnn_size, return_sequences=True))(x)\n  x = Bidirectional(GRU(rnn_size, return_sequences=True))(x)\n  x = Dense(n_class, activation='softmax')(x)\n  \n  base_model = Model(inputs=input_tensor, outputs=x)\n  ```\n\n  ```python\n  labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n  input_length = Input(name='input_length', shape=[1], dtype='int64')\n  label_length = Input(name='label_length', shape=[1], dtype='int64')\n  loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([x, labels, input_length, label_length])\n  \n  model = Model(inputs=[input_tensor, labels, input_length, label_length], outputs=loss_out)\n  ```\n\n* 生成数据\n\n  ```python\n  # 数据生成\n  from tensorflow.keras.utils import Sequence\n  \n  class CaptchaSequence(Sequence):\n      def __init__(self, characters, batch_size, steps, n_len=4, width=128, height=64,\n                   input_length=16, label_length=4):\n          self.characters = characters\n          self.batch_size = batch_size\n          self.steps = steps\n          self.n_len = n_len\n          self.width = width\n          self.height = height\n          self.input_length = input_length\n          self.label_length = label_length\n          self.n_class = len(characters)\n          self.generator = ImageCaptcha(width=width, height=height)\n      \n      def __len__(self):\n          return self.steps\n      \n      def __getitem__(self, idx):\n          X = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\n          y = np.zeros((self.batch_size, self.n_len), dtype=np.uint8)\n          input_length = np.ones(self.batch_size)*self.input_length\n          label_length = np.ones(self.batch_size)*self.label_length\n          for i in range(self.batch_size):\n              rand_str = ''.join([random.choice(self.characters) for j in range(self.n_len)])\n              X[i] = np.array(self.generator.generate_image(rand_str))/255.0\n              y[i] = [self.characters.find(x) for x in rand_str]\n          return [X, y, input_length, label_length], np.ones(self.batch_size)\n  ```\n\n  ```python\n  # 查看生成的图片\n  data = CaptchaSequence(characters, batch_size=1, steps=1)\n  [X_test, y_test, _, _], _ = data[0]\n  plt.imshow(X_test[0])\n  plt.title(''.join([characters[x] for x in y_test[0]]))\n  print(input_length, label_length)\n  ```\n\n  ![image-20230111221331595](AI-lab03/image-20230111221331595.png)\n\n* 准确率回调\n\n  ```python\n  # 准确率回调函数\n  from tqdm import tqdm\n  def evaluate(model, batch_size=128, steps=20):\n      batch_acc = 0\n      valid_data = CaptchaSequence(characters, batch_size, steps)\n      for [X_test, y_test, _, _], _ in valid_data:\n          y_pred = base_model.predict(X_test)\n          shape = y_pred.shape\n          out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[0][0])[:, :4]\n          if out.shape[1] == 4:\n              batch_acc += (y_test == out).all(axis=1).mean()\n              \n      return batch_acc / steps\n      \n  from tensorflow.keras.callbacks import Callback\n  \n  class Evaluate(Callback):\n      def __init__(self):\n          self.accs = []\n          \n      def on_epoch_end(self, epoch, logs=None):\n          logs = logs or {}\n          acc = evaluate(base_model)\n          logs['val_acc'] = acc\n          self.accs.append(acc)\n          print(f'\\nacc:{acc*100:.4f}')\n  ```\n\n* 训练模型\n\n  > 由于使用了EarlyStopping，当训练到第13个epoch时，损失值的减少已经小于1e-3，所以会提前停止训练\n\n  ```python\n  # 模型训练\n  from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n  from tensorflow.keras.optimizers import *\n  \n  train_data = CaptchaSequence(characters, batch_size=128, steps=1000)\n  valid_data = CaptchaSequence(characters, batch_size=128, steps=100)\n  \n  callbacks = [EarlyStopping(patience=5), Evaluate(),\n               CSVLogger('ctc.csv'), ModelCheckpoint('ctc_best.h5', save_best_only=True)]\n  \n  model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(1e-3, amsgrad=True))\n  \n  # 查看GPU设备\n  tf.config.experimental.list_physical_devices('GPU')\n  \n  with tf.device('GPU:0'):\n      model.fit(train_data, epochs=100, validation_data=valid_data, workers=4,\n                callbacks=callbacks)\n  ```\n\n  ![image-20230111221612234](AI-lab03/image-20230111221612234.png)\n\n* 提高精度，再次训练\n\n  > 这一次在第24epoch时停止了训练\n\n  ```python\n  # 提前停止了，继续载入参数训练一会\n  model.load_weights('ctc_best.h5')\n  \n  callbacks = [EarlyStopping(patience=5), Evaluate(),\n               CSVLogger('ctc.csv', append=True), ModelCheckpoint('ctc_best.h5', save_best_only=True)]\n  \n  model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(1e-4, amsgrad=True))\n  \n  with tf.device('GPU:0'):\n      model.fit(train_data, epochs=100, validation_data=valid_data, workers=4,\n                callbacks=callbacks)\n  ```\n\n  ![image-20230111221801614](AI-lab03/image-20230111221801614.png)\n\n* 模型测试\n\n  ```python\n  # 模型测试\n  model.load_weights('ctc_best.h5')\n  characters2 = characters + ' '\n  [X_test, y_test, _, _], _ = data[0]\n  y_pred = base_model.predict(X_test)\n  out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.shape[1], )[0][0])[:, :4]\n  out = ''.join([characters[x] for x in out[0]])\n  y_true = ''.join([characters[x] for x in y_test[0]])\n  \n  plt.imshow(X_test[0])\n  plt.title('pred:' + str(out) + '\\ntrue' + str(y_true))\n  \n  argmax = np.argmax(y_pred, axis=2)[0]\n  list(zip(argmax, ''.join([characters2[x] for x in argmax])))\n  ```\n\n  ![image-20230111221851068](AI-lab03/image-20230111221851068.png)\n\n* 计算总体准确度\n\n  ```python\n  # 计算模型总体准确度\n  evaluate(base_model)\n  ```\n\n  ![image-20230111221914620](AI-lab03/image-20230111221914620.png)\n\n* 保存模型\n\n  ```python\n  # 保存模型\n  base_model.save('ctc.h5', include_optimizer=False)\n  ```\n\n* 可视化训练曲线\n\n  ```python\n  # 可视化训练曲线\n  df = pd.read_csv('ctc.csv')\n  df[['loss', 'val_loss']].plot()\n  ```\n\n  ![image-20230111221947792](AI-lab03/image-20230111221947792.png)\n\n### 4、总结\n\n* 对LSTM的理解\n\n  Long Short Term Memory networks（以下简称LSTMs），一种特殊的RNN网络，该网络设计出来是为了解决长依赖问题。\n\n  所有循环神经网络都具有神经网络的重复模块链的形式。 在标准的RNN中，该重复模块将具有非常简单的结构，例如单个tanh层。\n\n  ![img](https://upload-images.jianshu.io/upload_images/6983308-2f0d4a87883d2c8c.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)\n\n  LSTMs也具有这种链式结构，但是它的重复单元不同于标准RNN网络里的单元只有一个网络层，它的内部有四个网络层。\n\n  ![img](https://upload-images.jianshu.io/upload_images/6983308-169c41fa64ff202f.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)\n\n* 对CTC的理解\n\n  CTC（Connectionist Temporal Classifier，联接时间分类器），主要用于解决输入特征与输出标签的对齐问题。由于文字的不同间隔或变形等问题，导致同个文字有不同的表现形式，但实际上都是同一个文字。在识别时会将输入图像分块后再去识别，得出每块属于某个字符的概率（无法识别的标记为特殊字符”-”）。由于字符变形等原因，导致对输入图像分块识别时，相邻块可能会识别为同个结果，字符重复出现。因此，通过CTC来解决对齐问题，模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次。\n\n* 实验所涉及的问题\n\n  * 问题1：两个实验运用的模型有什么差别？\n\n    第一个实验的模型单纯的运用了卷积神经网络，而第二个实验的模型还用到了LSTM+CTC的机制。\n\n  * 问题2：第二个实验运用的模型更适合哪一类任务？\n\n    第二个实验更适合解决对于序列任务的识别，特征之间有依赖关系的这一类任务。\n\n  * 问题3：LSTM为什么能够适用于这一类任务？\n\n    LSTM网络能通过一种被称为门的结构对细胞状态进行删除或者添加信息。门能够有选择性的决定让哪些信息通过，包含记忆门：决定给细胞状态添加哪些新的信息，遗忘门：选择忘记旧细胞信息的一部分，输出门：决定最终的输出。\n\n  * 问题4：对CTC的理解，CTC有什么作用？\n\n    主要用于解决输入特征与输出标签的对齐问题，在本次实验中，图片识别过程中，会将一些无关的特征识别成空白，同时对输出标签进行定长后再提取最终信息。\n\n","source":"_posts/AI-lab03.md","raw":"---\ntitle: 人工智能实验-基于LSTM+CTC的验证码\ncategories: 算法实践\ndate: 2023-02-18 19:02:41\ntags: [人工智能, 深度学习]\ncover:\ntop_img:\n---\n## 实验4-基于LSTM+CTC的验证码\n\n### 1、实验目的\n\n* 会利用循环网络模型解决序列数据的相关问题\n\n### 2、实验内容\n\n* 使用循环网络，自主实现效验码中多个数字字符的识别，并使用深度学习框架完成模型的训练\n\n### 3、实验步骤\n\n> 实验一共分为两个实践，第一个实践是CAPTCHA识别实践，第二个实践是基于LSTM+CTC的验证码识别是实践，本次实验第一个实践在CPU上完成，第二个实践则在GPU上完成\n\n#### 3.1 CAPTCHA识别实践\n\n* 获取数据集\n\n  > tqdm用于显示进度条，captcha用于生成验证码数据集，一共生成100000个验证码图片\n\n  ```python\n  # 获取数据集\n  from captcha.image import ImageCaptcha\n  from tqdm import tqdm\n  import random\n  import os\n  \n  H, W, C = 100, 120, 3\n  N_LABELS = 10\n  D = 4\n  \n  def generate_captcha_images(datasets_path, num_images, width=200, height=100):\n      images_path = os.path.join(datasets_path, 'image')\n      if not os.path.exists(images_path):\n          os.makedirs(images_path)\n          \n      label_file =  open(os.path.join(datasets_path, 'labels.txt'), 'w')\n      image = ImageCaptcha(width=width, height=height)\n      alphabet = '0123456789'\n      for i in tqdm(range(num_images)):\n          # 生成随机4位数字的效验码内容\n          captcha_text = random.choices(alphabet, k=4)\n          label = ''.join(captcha_text)\n          # 文件名与输出路径\n          image_filename = f'%d.' % i + 'jpg'\n          output_path = os.path.join(images_path, image_filename)\n          # 保存图片和写入标签\n          image.write(label, output_path)\n          label_file.write(image_filename + ',' + label + '\\n')\n      label_file.close()\n  ```\n\n  ```python\n  # 生成以后将改行设为注释\n  # generate_captcha_images('train1', 100000, width=120, height=100)\n  ```\n\n  ![image-20230111212922711](AI-lab03/image-20230111212922711.png)\n\n* 获取图片对应的标签值\n\n  ```python\n  # 获取图片对应的标签值\n  import numpy as np\n  import pandas as pd\n  import os\n  \n  filenames_file = os.listdir('train1/image/')\n  label_file = open('train1/labels.txt')\n  \n  filenames = []\n  labels = []\n  \n  for line in label_file:\n      line_split = line.strip().split(',')\n      filename, label = line_split[0], line_split[1]\n      filenames.append(filename)\n      labels.append(label)\n      \n  # 将文件名和标签一一对应\n  df = pd.DataFrame({\n      'filename':filenames,\n      'label':labels\n  })\n  \n  df.head(1)\n  ```\n\n  ![image-20230111213029737](AI-lab03/image-20230111213029737.png)\n\n* 划分训练集和测试集\n\n  > 按照8训练集：2训练集的比例进行划分\n\n  ````python\n  # 划分数据集\n  from sklearn.model_selection import train_test_split\n  \n  df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42)\n  df_train = df_train.reset_index(drop=True)\n  df_valid = df_valid.reset_index(drop=True)\n  \n  total_train = df_train.shape[0]\n  total_valid = df_valid.shape[0]\n  ````\n\n* 构造data_generator\n\n  ```python\n  # 构造data_generator\n  from tensorflow.keras.utils import to_categorical\n  from PIL import Image\n  \n  def get_data_generator(df, num, for_training, batch_size=16):\n      images, labels = [], []\n      while True:\n          for i in range(num):\n              r = df.iloc[i]\n              file, label = os.path.join('train1', 'image', r['filename']), r['label']\n              im = Image.open(file)\n              im = np.array(im) / 255.0\n              images.append(np.array(im))\n              labels.append(np.array([np.array(to_categorical(int(i), N_LABELS)) for i in label]))\n              if len(images) > batch_size:\n                  yield np.array(images), np.array(labels)\n                  images, labels = [], []\n              if not for_training:\n                  break\n  ```\n\n* 查看所生成的数据样例\n\n  ```python\n  # 查看生成数据样例\n  from matplotlib import pyplot as plt\n  \n  for v in get_data_generator(df_train, total_train, True):\n      X, y = v\n      break\n  print(X.shape, y.shape)\n  plt.imshow(X[0], interpolation='nearest')\n  print(y[0])\n  ```\n\n  ![image-20230111213218547](AI-lab03/image-20230111213218547.png)\n\n  ```python\n  batch_size = 64\n  valid_batch_size = 64\n  train_gen = get_data_generator(df_train, total_train, for_training=True, batch_size=batch_size)\n  valid_gen = get_data_generator(df_valid, total_valid, for_training=True, batch_size=valid_batch_size)\n  ```\n\n* 构建网络，定义损失函数\n\n  ```python\n  # 构建网络\n  import tensorflow as tf\n  from tensorflow.keras import Sequential\n  from tensorflow.keras import Input\n  from tensorflow.keras.layers import Conv2D, PReLU, MaxPooling2D, Flatten, Dense, Reshape, Softmax\n  \n  model = Sequential()\n  \n  model.add(Input(shape=(H, W, C)))\n  model.add(Conv2D(32, (3, 3)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Conv2D(64, (5, 5)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Conv2D(128, (5, 5,)))\n  model.add(PReLU())\n  model.add(MaxPooling2D((2, 2), strides=2))\n  \n  model.add(Flatten())\n  model.add(Dense(D * N_LABELS))\n  model.add(Reshape([D, N_LABELS]))\n  \n  model.add(Softmax())\n  \n  model.compile(optimizer='Adam', metrics=['accuracy'], loss='categorical_crossentropy')\n  ```\n\n* 查看网络结构\n\n  ```python\n  model.summary()\n  ```\n\n  ![image-20230111213428993](AI-lab03/image-20230111213428993.png)\n\n* 开始训练\n\n  > 一共完成5个epoches，每个epoches含有1250步\n\n  ```python\n  histort = model.fit(train_gen,\n                     steps_per_epoch=total_train//batch_size,\n                     epochs=5,\n                     validation_data=valid_gen,\n                     validation_steps=total_valid//valid_batch_size)\n  ```\n\n  ![image-20230111213530417](AI-lab03/image-20230111213530417.png)\n\n* 测试验证\n\n  ```python\n  test = get_data_generator(df_valid, total_valid, True)\n  X_test, y_test = next(test)\n  \n  plt.imshow(X_test[0], interpolation='nearest')\n  print(y[0])\n  \n  y_pred = model.predict_on_batch(X_test)\n  y_true = tf.math.argmax(y_test, axis=-1)\n  y_pred = tf.math.argmax(y_pred, axis=-1)\n  print('y_true:', y_true[0].numpy())\n  print('y_pred:', y_pred[0].numpy())\n  ```\n\n  ![image-20230111215240888](AI-lab03/image-20230111215240888.png)\n\n#### 3.2 基于LSTM+CTC的验证码识别\n\n* 导入相关库函数，定义常量\n\n  ```python\n  # 导入必要的库\n  from captcha.image import ImageCaptcha\n  from matplotlib import pyplot as plt\n  import numpy as np\n  import pandas as pd\n  import random\n  import tensorflow as tf\n  import tensorflow.keras.backend as K\n  import string\n  \n  %matplotlib inline\n  %config InlineBackend.figure_format = 'retina'\n  \n  characters = string.digits + string.ascii_uppercase\n  print(characters)\n  \n  width = 128\n  height = 64\n  n_len = 4\n  n_class = len(characters) + 1\n  ```\n\n* 定义CTC损失函数\n\n  ```python\n  # 定义CTC Loss\n  def ctc_lambda_func(args):\n      y_pred, labels, input_length, label_length = args\n      return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n  ```\n\n* 定义网络结构\n\n  ```python\n  input_tensor = Input((height, width, 3))\n  x = input_tensor\n  for i, n_cnn in enumerate([2, 2, 2, 2, 2]):\n      for j in range(n_cnn):\n          x = Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n          x = BatchNormalization()(x)\n          x = Activation('relu')(x)\n      x = MaxPooling2D(2 if i < 3 else (2, 1))(x)\n  x = Permute((2, 1, 3))(x)\n  x = TimeDistributed(Flatten())(x)\n  \n  rnn_size = 128\n  x = Bidirectional(GRU(rnn_size, return_sequences=True))(x)\n  x = Bidirectional(GRU(rnn_size, return_sequences=True))(x)\n  x = Dense(n_class, activation='softmax')(x)\n  \n  base_model = Model(inputs=input_tensor, outputs=x)\n  ```\n\n  ```python\n  labels = Input(name='the_labels', shape=[n_len], dtype='float32')\n  input_length = Input(name='input_length', shape=[1], dtype='int64')\n  label_length = Input(name='label_length', shape=[1], dtype='int64')\n  loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([x, labels, input_length, label_length])\n  \n  model = Model(inputs=[input_tensor, labels, input_length, label_length], outputs=loss_out)\n  ```\n\n* 生成数据\n\n  ```python\n  # 数据生成\n  from tensorflow.keras.utils import Sequence\n  \n  class CaptchaSequence(Sequence):\n      def __init__(self, characters, batch_size, steps, n_len=4, width=128, height=64,\n                   input_length=16, label_length=4):\n          self.characters = characters\n          self.batch_size = batch_size\n          self.steps = steps\n          self.n_len = n_len\n          self.width = width\n          self.height = height\n          self.input_length = input_length\n          self.label_length = label_length\n          self.n_class = len(characters)\n          self.generator = ImageCaptcha(width=width, height=height)\n      \n      def __len__(self):\n          return self.steps\n      \n      def __getitem__(self, idx):\n          X = np.zeros((self.batch_size, self.height, self.width, 3), dtype=np.float32)\n          y = np.zeros((self.batch_size, self.n_len), dtype=np.uint8)\n          input_length = np.ones(self.batch_size)*self.input_length\n          label_length = np.ones(self.batch_size)*self.label_length\n          for i in range(self.batch_size):\n              rand_str = ''.join([random.choice(self.characters) for j in range(self.n_len)])\n              X[i] = np.array(self.generator.generate_image(rand_str))/255.0\n              y[i] = [self.characters.find(x) for x in rand_str]\n          return [X, y, input_length, label_length], np.ones(self.batch_size)\n  ```\n\n  ```python\n  # 查看生成的图片\n  data = CaptchaSequence(characters, batch_size=1, steps=1)\n  [X_test, y_test, _, _], _ = data[0]\n  plt.imshow(X_test[0])\n  plt.title(''.join([characters[x] for x in y_test[0]]))\n  print(input_length, label_length)\n  ```\n\n  ![image-20230111221331595](AI-lab03/image-20230111221331595.png)\n\n* 准确率回调\n\n  ```python\n  # 准确率回调函数\n  from tqdm import tqdm\n  def evaluate(model, batch_size=128, steps=20):\n      batch_acc = 0\n      valid_data = CaptchaSequence(characters, batch_size, steps)\n      for [X_test, y_test, _, _], _ in valid_data:\n          y_pred = base_model.predict(X_test)\n          shape = y_pred.shape\n          out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[0])*shape[1])[0][0])[:, :4]\n          if out.shape[1] == 4:\n              batch_acc += (y_test == out).all(axis=1).mean()\n              \n      return batch_acc / steps\n      \n  from tensorflow.keras.callbacks import Callback\n  \n  class Evaluate(Callback):\n      def __init__(self):\n          self.accs = []\n          \n      def on_epoch_end(self, epoch, logs=None):\n          logs = logs or {}\n          acc = evaluate(base_model)\n          logs['val_acc'] = acc\n          self.accs.append(acc)\n          print(f'\\nacc:{acc*100:.4f}')\n  ```\n\n* 训练模型\n\n  > 由于使用了EarlyStopping，当训练到第13个epoch时，损失值的减少已经小于1e-3，所以会提前停止训练\n\n  ```python\n  # 模型训练\n  from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n  from tensorflow.keras.optimizers import *\n  \n  train_data = CaptchaSequence(characters, batch_size=128, steps=1000)\n  valid_data = CaptchaSequence(characters, batch_size=128, steps=100)\n  \n  callbacks = [EarlyStopping(patience=5), Evaluate(),\n               CSVLogger('ctc.csv'), ModelCheckpoint('ctc_best.h5', save_best_only=True)]\n  \n  model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(1e-3, amsgrad=True))\n  \n  # 查看GPU设备\n  tf.config.experimental.list_physical_devices('GPU')\n  \n  with tf.device('GPU:0'):\n      model.fit(train_data, epochs=100, validation_data=valid_data, workers=4,\n                callbacks=callbacks)\n  ```\n\n  ![image-20230111221612234](AI-lab03/image-20230111221612234.png)\n\n* 提高精度，再次训练\n\n  > 这一次在第24epoch时停止了训练\n\n  ```python\n  # 提前停止了，继续载入参数训练一会\n  model.load_weights('ctc_best.h5')\n  \n  callbacks = [EarlyStopping(patience=5), Evaluate(),\n               CSVLogger('ctc.csv', append=True), ModelCheckpoint('ctc_best.h5', save_best_only=True)]\n  \n  model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(1e-4, amsgrad=True))\n  \n  with tf.device('GPU:0'):\n      model.fit(train_data, epochs=100, validation_data=valid_data, workers=4,\n                callbacks=callbacks)\n  ```\n\n  ![image-20230111221801614](AI-lab03/image-20230111221801614.png)\n\n* 模型测试\n\n  ```python\n  # 模型测试\n  model.load_weights('ctc_best.h5')\n  characters2 = characters + ' '\n  [X_test, y_test, _, _], _ = data[0]\n  y_pred = base_model.predict(X_test)\n  out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.shape[1], )[0][0])[:, :4]\n  out = ''.join([characters[x] for x in out[0]])\n  y_true = ''.join([characters[x] for x in y_test[0]])\n  \n  plt.imshow(X_test[0])\n  plt.title('pred:' + str(out) + '\\ntrue' + str(y_true))\n  \n  argmax = np.argmax(y_pred, axis=2)[0]\n  list(zip(argmax, ''.join([characters2[x] for x in argmax])))\n  ```\n\n  ![image-20230111221851068](AI-lab03/image-20230111221851068.png)\n\n* 计算总体准确度\n\n  ```python\n  # 计算模型总体准确度\n  evaluate(base_model)\n  ```\n\n  ![image-20230111221914620](AI-lab03/image-20230111221914620.png)\n\n* 保存模型\n\n  ```python\n  # 保存模型\n  base_model.save('ctc.h5', include_optimizer=False)\n  ```\n\n* 可视化训练曲线\n\n  ```python\n  # 可视化训练曲线\n  df = pd.read_csv('ctc.csv')\n  df[['loss', 'val_loss']].plot()\n  ```\n\n  ![image-20230111221947792](AI-lab03/image-20230111221947792.png)\n\n### 4、总结\n\n* 对LSTM的理解\n\n  Long Short Term Memory networks（以下简称LSTMs），一种特殊的RNN网络，该网络设计出来是为了解决长依赖问题。\n\n  所有循环神经网络都具有神经网络的重复模块链的形式。 在标准的RNN中，该重复模块将具有非常简单的结构，例如单个tanh层。\n\n  ![img](https://upload-images.jianshu.io/upload_images/6983308-2f0d4a87883d2c8c.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)\n\n  LSTMs也具有这种链式结构，但是它的重复单元不同于标准RNN网络里的单元只有一个网络层，它的内部有四个网络层。\n\n  ![img](https://upload-images.jianshu.io/upload_images/6983308-169c41fa64ff202f.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)\n\n* 对CTC的理解\n\n  CTC（Connectionist Temporal Classifier，联接时间分类器），主要用于解决输入特征与输出标签的对齐问题。由于文字的不同间隔或变形等问题，导致同个文字有不同的表现形式，但实际上都是同一个文字。在识别时会将输入图像分块后再去识别，得出每块属于某个字符的概率（无法识别的标记为特殊字符”-”）。由于字符变形等原因，导致对输入图像分块识别时，相邻块可能会识别为同个结果，字符重复出现。因此，通过CTC来解决对齐问题，模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次。\n\n* 实验所涉及的问题\n\n  * 问题1：两个实验运用的模型有什么差别？\n\n    第一个实验的模型单纯的运用了卷积神经网络，而第二个实验的模型还用到了LSTM+CTC的机制。\n\n  * 问题2：第二个实验运用的模型更适合哪一类任务？\n\n    第二个实验更适合解决对于序列任务的识别，特征之间有依赖关系的这一类任务。\n\n  * 问题3：LSTM为什么能够适用于这一类任务？\n\n    LSTM网络能通过一种被称为门的结构对细胞状态进行删除或者添加信息。门能够有选择性的决定让哪些信息通过，包含记忆门：决定给细胞状态添加哪些新的信息，遗忘门：选择忘记旧细胞信息的一部分，输出门：决定最终的输出。\n\n  * 问题4：对CTC的理解，CTC有什么作用？\n\n    主要用于解决输入特征与输出标签的对齐问题，在本次实验中，图片识别过程中，会将一些无关的特征识别成空白，同时对输出标签进行定长后再提取最终信息。\n\n","slug":"AI-lab03","published":1,"updated":"2024-06-05T09:03:03.511Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttg000c08jv4wce27d7","content":"<h2 id=\"实验4-基于LSTM-CTC的验证码\"><a href=\"#实验4-基于LSTM-CTC的验证码\" class=\"headerlink\" title=\"实验4-基于LSTM+CTC的验证码\"></a>实验4-基于LSTM+CTC的验证码</h2><h3 id=\"1、实验目的\"><a href=\"#1、实验目的\" class=\"headerlink\" title=\"1、实验目的\"></a>1、实验目的</h3><ul>\n<li>会利用循环网络模型解决序列数据的相关问题</li>\n</ul>\n<h3 id=\"2、实验内容\"><a href=\"#2、实验内容\" class=\"headerlink\" title=\"2、实验内容\"></a>2、实验内容</h3><ul>\n<li>使用循环网络，自主实现效验码中多个数字字符的识别，并使用深度学习框架完成模型的训练</li>\n</ul>\n<h3 id=\"3、实验步骤\"><a href=\"#3、实验步骤\" class=\"headerlink\" title=\"3、实验步骤\"></a>3、实验步骤</h3><blockquote>\n<p>实验一共分为两个实践，第一个实践是CAPTCHA识别实践，第二个实践是基于LSTM+CTC的验证码识别是实践，本次实验第一个实践在CPU上完成，第二个实践则在GPU上完成</p>\n</blockquote>\n<h4 id=\"3-1-CAPTCHA识别实践\"><a href=\"#3-1-CAPTCHA识别实践\" class=\"headerlink\" title=\"3.1 CAPTCHA识别实践\"></a>3.1 CAPTCHA识别实践</h4><ul>\n<li><p>获取数据集</p>\n<blockquote>\n<p>tqdm用于显示进度条，captcha用于生成验证码数据集，一共生成100000个验证码图片</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取数据集</span><br><span class=\"hljs-keyword\">from</span> captcha.image <span class=\"hljs-keyword\">import</span> ImageCaptcha<br><span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> os<br><br>H, W, C = <span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">120</span>, <span class=\"hljs-number\">3</span><br>N_LABELS = <span class=\"hljs-number\">10</span><br>D = <span class=\"hljs-number\">4</span><br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">generate_captcha_images</span>(<span class=\"hljs-params\">datasets_path, num_images, width=<span class=\"hljs-number\">200</span>, height=<span class=\"hljs-number\">100</span></span>):<br>    images_path = os.path.join(datasets_path, <span class=\"hljs-string\">&#x27;image&#x27;</span>)<br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(images_path):<br>        os.makedirs(images_path)<br>        <br>    label_file =  <span class=\"hljs-built_in\">open</span>(os.path.join(datasets_path, <span class=\"hljs-string\">&#x27;labels.txt&#x27;</span>), <span class=\"hljs-string\">&#x27;w&#x27;</span>)<br>    image = ImageCaptcha(width=width, height=height)<br>    alphabet = <span class=\"hljs-string\">&#x27;0123456789&#x27;</span><br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> tqdm(<span class=\"hljs-built_in\">range</span>(num_images)):<br>        <span class=\"hljs-comment\"># 生成随机4位数字的效验码内容</span><br>        captcha_text = random.choices(alphabet, k=<span class=\"hljs-number\">4</span>)<br>        label = <span class=\"hljs-string\">&#x27;&#x27;</span>.join(captcha_text)<br>        <span class=\"hljs-comment\"># 文件名与输出路径</span><br>        image_filename = <span class=\"hljs-string\">f&#x27;%d.&#x27;</span> % i + <span class=\"hljs-string\">&#x27;jpg&#x27;</span><br>        output_path = os.path.join(images_path, image_filename)<br>        <span class=\"hljs-comment\"># 保存图片和写入标签</span><br>        image.write(label, output_path)<br>        label_file.write(image_filename + <span class=\"hljs-string\">&#x27;,&#x27;</span> + label + <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br>    label_file.close()<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成以后将改行设为注释</span><br><span class=\"hljs-comment\"># generate_captcha_images(&#x27;train1&#x27;, 100000, width=120, height=100)</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111212922711.png\" class=\"\" title=\"image-20230111212922711\">\n</li>\n<li><p>获取图片对应的标签值</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取图片对应的标签值</span><br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> os<br><br>filenames_file = os.listdir(<span class=\"hljs-string\">&#x27;train1/image/&#x27;</span>)<br>label_file = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&#x27;train1/labels.txt&#x27;</span>)<br><br>filenames = []<br>labels = []<br><br><span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> label_file:<br>    line_split = line.strip().split(<span class=\"hljs-string\">&#x27;,&#x27;</span>)<br>    filename, label = line_split[<span class=\"hljs-number\">0</span>], line_split[<span class=\"hljs-number\">1</span>]<br>    filenames.append(filename)<br>    labels.append(label)<br>    <br><span class=\"hljs-comment\"># 将文件名和标签一一对应</span><br>df = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:filenames,<br>    <span class=\"hljs-string\">&#x27;label&#x27;</span>:labels<br>&#125;)<br><br>df.head(<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213029737.png\" class=\"\" title=\"image-20230111213029737\">\n</li>\n<li><p>划分训练集和测试集</p>\n<blockquote>\n<p>按照8训练集：2训练集的比例进行划分</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 划分数据集</span><br><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split<br><br>df_train, df_valid = train_test_split(df, test_size=<span class=\"hljs-number\">0.2</span>, random_state=<span class=\"hljs-number\">42</span>)<br>df_train = df_train.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>df_valid = df_valid.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br><br>total_train = df_train.shape[<span class=\"hljs-number\">0</span>]<br>total_valid = df_valid.shape[<span class=\"hljs-number\">0</span>]<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>构造data_generator</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构造data_generator</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> to_categorical<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_data_generator</span>(<span class=\"hljs-params\">df, num, for_training, batch_size=<span class=\"hljs-number\">16</span></span>):<br>    images, labels = [], []<br>    <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num):<br>            r = df.iloc[i]<br>            file, label = os.path.join(<span class=\"hljs-string\">&#x27;train1&#x27;</span>, <span class=\"hljs-string\">&#x27;image&#x27;</span>, r[<span class=\"hljs-string\">&#x27;filename&#x27;</span>]), r[<span class=\"hljs-string\">&#x27;label&#x27;</span>]<br>            im = Image.<span class=\"hljs-built_in\">open</span>(file)<br>            im = np.array(im) / <span class=\"hljs-number\">255.0</span><br>            images.append(np.array(im))<br>            labels.append(np.array([np.array(to_categorical(<span class=\"hljs-built_in\">int</span>(i), N_LABELS)) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> label]))<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(images) &gt; batch_size:<br>                <span class=\"hljs-keyword\">yield</span> np.array(images), np.array(labels)<br>                images, labels = [], []<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> for_training:<br>                <span class=\"hljs-keyword\">break</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看所生成的数据样例</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看生成数据样例</span><br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><br><span class=\"hljs-keyword\">for</span> v <span class=\"hljs-keyword\">in</span> get_data_generator(df_train, total_train, <span class=\"hljs-literal\">True</span>):<br>    X, y = v<br>    <span class=\"hljs-keyword\">break</span><br><span class=\"hljs-built_in\">print</span>(X.shape, y.shape)<br>plt.imshow(X[<span class=\"hljs-number\">0</span>], interpolation=<span class=\"hljs-string\">&#x27;nearest&#x27;</span>)<br><span class=\"hljs-built_in\">print</span>(y[<span class=\"hljs-number\">0</span>])<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213218547.png\" class=\"\" title=\"image-20230111213218547\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">batch_size = <span class=\"hljs-number\">64</span><br>valid_batch_size = <span class=\"hljs-number\">64</span><br>train_gen = get_data_generator(df_train, total_train, for_training=<span class=\"hljs-literal\">True</span>, batch_size=batch_size)<br>valid_gen = get_data_generator(df_valid, total_valid, for_training=<span class=\"hljs-literal\">True</span>, batch_size=valid_batch_size)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>构建网络，定义损失函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建网络</span><br><span class=\"hljs-keyword\">import</span> tensorflow <span class=\"hljs-keyword\">as</span> tf<br><span class=\"hljs-keyword\">from</span> tensorflow.keras <span class=\"hljs-keyword\">import</span> Sequential<br><span class=\"hljs-keyword\">from</span> tensorflow.keras <span class=\"hljs-keyword\">import</span> Input<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.layers <span class=\"hljs-keyword\">import</span> Conv2D, PReLU, MaxPooling2D, Flatten, Dense, Reshape, Softmax<br><br>model = Sequential()<br><br>model.add(Input(shape=(H, W, C)))<br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Conv2D(<span class=\"hljs-number\">64</span>, (<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Conv2D(<span class=\"hljs-number\">128</span>, (<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>,)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Flatten())<br>model.add(Dense(D * N_LABELS))<br>model.add(Reshape([D, N_LABELS]))<br><br>model.add(Softmax())<br><br>model.<span class=\"hljs-built_in\">compile</span>(optimizer=<span class=\"hljs-string\">&#x27;Adam&#x27;</span>, metrics=[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>], loss=<span class=\"hljs-string\">&#x27;categorical_crossentropy&#x27;</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看网络结构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.summary()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213428993.png\" class=\"\" title=\"image-20230111213428993\">\n</li>\n<li><p>开始训练</p>\n<blockquote>\n<p>一共完成5个epoches，每个epoches含有1250步</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">histort = model.fit(train_gen,<br>                   steps_per_epoch=total_train//batch_size,<br>                   epochs=<span class=\"hljs-number\">5</span>,<br>                   validation_data=valid_gen,<br>                   validation_steps=total_valid//valid_batch_size)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213530417.png\" class=\"\" title=\"image-20230111213530417\">\n</li>\n<li><p>测试验证</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">test = get_data_generator(df_valid, total_valid, <span class=\"hljs-literal\">True</span>)<br>X_test, y_test = <span class=\"hljs-built_in\">next</span>(test)<br><br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>], interpolation=<span class=\"hljs-string\">&#x27;nearest&#x27;</span>)<br><span class=\"hljs-built_in\">print</span>(y[<span class=\"hljs-number\">0</span>])<br><br>y_pred = model.predict_on_batch(X_test)<br>y_true = tf.math.argmax(y_test, axis=-<span class=\"hljs-number\">1</span>)<br>y_pred = tf.math.argmax(y_pred, axis=-<span class=\"hljs-number\">1</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;y_true:&#x27;</span>, y_true[<span class=\"hljs-number\">0</span>].numpy())<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;y_pred:&#x27;</span>, y_pred[<span class=\"hljs-number\">0</span>].numpy())<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111215240888.png\" class=\"\" title=\"image-20230111215240888\">\n</li>\n</ul>\n<h4 id=\"3-2-基于LSTM-CTC的验证码识别\"><a href=\"#3-2-基于LSTM-CTC的验证码识别\" class=\"headerlink\" title=\"3.2 基于LSTM+CTC的验证码识别\"></a>3.2 基于LSTM+CTC的验证码识别</h4><ul>\n<li><p>导入相关库函数，定义常量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入必要的库</span><br><span class=\"hljs-keyword\">from</span> captcha.image <span class=\"hljs-keyword\">import</span> ImageCaptcha<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> tensorflow <span class=\"hljs-keyword\">as</span> tf<br><span class=\"hljs-keyword\">import</span> tensorflow.keras.backend <span class=\"hljs-keyword\">as</span> K<br><span class=\"hljs-keyword\">import</span> string<br><br>%matplotlib inline<br>%config InlineBackend.figure_format = <span class=\"hljs-string\">&#x27;retina&#x27;</span><br><br>characters = string.digits + string.ascii_uppercase<br><span class=\"hljs-built_in\">print</span>(characters)<br><br>width = <span class=\"hljs-number\">128</span><br>height = <span class=\"hljs-number\">64</span><br>n_len = <span class=\"hljs-number\">4</span><br>n_class = <span class=\"hljs-built_in\">len</span>(characters) + <span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义CTC损失函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义CTC Loss</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">ctc_lambda_func</span>(<span class=\"hljs-params\">args</span>):<br>    y_pred, labels, input_length, label_length = args<br>    <span class=\"hljs-keyword\">return</span> K.ctc_batch_cost(labels, y_pred, input_length, label_length)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义网络结构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">input_tensor = Input((height, width, <span class=\"hljs-number\">3</span>))<br>x = input_tensor<br><span class=\"hljs-keyword\">for</span> i, n_cnn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>([<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>]):<br>    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n_cnn):<br>        x = Conv2D(<span class=\"hljs-number\">32</span>*<span class=\"hljs-number\">2</span>**<span class=\"hljs-built_in\">min</span>(i, <span class=\"hljs-number\">3</span>), kernel_size=<span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>, kernel_initializer=<span class=\"hljs-string\">&#x27;he_uniform&#x27;</span>)(x)<br>        x = BatchNormalization()(x)<br>        x = Activation(<span class=\"hljs-string\">&#x27;relu&#x27;</span>)(x)<br>    x = MaxPooling2D(<span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">if</span> i &lt; <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">else</span> (<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>))(x)<br>x = Permute((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>))(x)<br>x = TimeDistributed(Flatten())(x)<br><br>rnn_size = <span class=\"hljs-number\">128</span><br>x = Bidirectional(GRU(rnn_size, return_sequences=<span class=\"hljs-literal\">True</span>))(x)<br>x = Bidirectional(GRU(rnn_size, return_sequences=<span class=\"hljs-literal\">True</span>))(x)<br>x = Dense(n_class, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>)(x)<br><br>base_model = Model(inputs=input_tensor, outputs=x)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">labels = Input(name=<span class=\"hljs-string\">&#x27;the_labels&#x27;</span>, shape=[n_len], dtype=<span class=\"hljs-string\">&#x27;float32&#x27;</span>)<br>input_length = Input(name=<span class=\"hljs-string\">&#x27;input_length&#x27;</span>, shape=[<span class=\"hljs-number\">1</span>], dtype=<span class=\"hljs-string\">&#x27;int64&#x27;</span>)<br>label_length = Input(name=<span class=\"hljs-string\">&#x27;label_length&#x27;</span>, shape=[<span class=\"hljs-number\">1</span>], dtype=<span class=\"hljs-string\">&#x27;int64&#x27;</span>)<br>loss_out = Lambda(ctc_lambda_func, output_shape=(<span class=\"hljs-number\">1</span>,), name=<span class=\"hljs-string\">&#x27;ctc&#x27;</span>)([x, labels, input_length, label_length])<br><br>model = Model(inputs=[input_tensor, labels, input_length, label_length], outputs=loss_out)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>生成数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据生成</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">Sequence</span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CaptchaSequence</span>(<span class=\"hljs-title class_ inherited__\">Sequence</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, characters, batch_size, steps, n_len=<span class=\"hljs-number\">4</span>, width=<span class=\"hljs-number\">128</span>, height=<span class=\"hljs-number\">64</span>,</span><br><span class=\"hljs-params\">                 input_length=<span class=\"hljs-number\">16</span>, label_length=<span class=\"hljs-number\">4</span></span>):<br>        self.characters = characters<br>        self.batch_size = batch_size<br>        self.steps = steps<br>        self.n_len = n_len<br>        self.width = width<br>        self.height = height<br>        self.input_length = input_length<br>        self.label_length = label_length<br>        self.n_class = <span class=\"hljs-built_in\">len</span>(characters)<br>        self.generator = ImageCaptcha(width=width, height=height)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-keyword\">return</span> self.steps<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):<br>        X = np.zeros((self.batch_size, self.height, self.width, <span class=\"hljs-number\">3</span>), dtype=np.float32)<br>        y = np.zeros((self.batch_size, self.n_len), dtype=np.uint8)<br>        input_length = np.ones(self.batch_size)*self.input_length<br>        label_length = np.ones(self.batch_size)*self.label_length<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.batch_size):<br>            rand_str = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([random.choice(self.characters) <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.n_len)])<br>            X[i] = np.array(self.generator.generate_image(rand_str))/<span class=\"hljs-number\">255.0</span><br>            y[i] = [self.characters.find(x) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> rand_str]<br>        <span class=\"hljs-keyword\">return</span> [X, y, input_length, label_length], np.ones(self.batch_size)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看生成的图片</span><br>data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">1</span>, steps=<span class=\"hljs-number\">1</span>)<br>[X_test, y_test, _, _], _ = data[<span class=\"hljs-number\">0</span>]<br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>])<br>plt.title(<span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> y_test[<span class=\"hljs-number\">0</span>]]))<br><span class=\"hljs-built_in\">print</span>(input_length, label_length)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221331595.png\" class=\"\" title=\"image-20230111221331595\">\n</li>\n<li><p>准确率回调</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 准确率回调函数</span><br><span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm<br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">evaluate</span>(<span class=\"hljs-params\">model, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">20</span></span>):<br>    batch_acc = <span class=\"hljs-number\">0</span><br>    valid_data = CaptchaSequence(characters, batch_size, steps)<br>    <span class=\"hljs-keyword\">for</span> [X_test, y_test, _, _], _ <span class=\"hljs-keyword\">in</span> valid_data:<br>        y_pred = base_model.predict(X_test)<br>        shape = y_pred.shape<br>        out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[<span class=\"hljs-number\">0</span>])*shape[<span class=\"hljs-number\">1</span>])[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>])[:, :<span class=\"hljs-number\">4</span>]<br>        <span class=\"hljs-keyword\">if</span> out.shape[<span class=\"hljs-number\">1</span>] == <span class=\"hljs-number\">4</span>:<br>            batch_acc += (y_test == out).<span class=\"hljs-built_in\">all</span>(axis=<span class=\"hljs-number\">1</span>).mean()<br>            <br>    <span class=\"hljs-keyword\">return</span> batch_acc / steps<br>    <br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> Callback<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Evaluate</span>(<span class=\"hljs-title class_ inherited__\">Callback</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        self.accs = []<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_epoch_end</span>(<span class=\"hljs-params\">self, epoch, logs=<span class=\"hljs-literal\">None</span></span>):<br>        logs = logs <span class=\"hljs-keyword\">or</span> &#123;&#125;<br>        acc = evaluate(base_model)<br>        logs[<span class=\"hljs-string\">&#x27;val_acc&#x27;</span>] = acc<br>        self.accs.append(acc)<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&#x27;\\nacc:<span class=\"hljs-subst\">&#123;acc*<span class=\"hljs-number\">100</span>:<span class=\"hljs-number\">.4</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>训练模型</p>\n<blockquote>\n<p>由于使用了EarlyStopping，当训练到第13个epoch时，损失值的减少已经小于1e-3，所以会提前停止训练</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> EarlyStopping, CSVLogger, ModelCheckpoint<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.optimizers <span class=\"hljs-keyword\">import</span> *<br><br>train_data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">1000</span>)<br>valid_data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">100</span>)<br><br>callbacks = [EarlyStopping(patience=<span class=\"hljs-number\">5</span>), Evaluate(),<br>             CSVLogger(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>), ModelCheckpoint(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>, save_best_only=<span class=\"hljs-literal\">True</span>)]<br><br>model.<span class=\"hljs-built_in\">compile</span>(loss=&#123;<span class=\"hljs-string\">&#x27;ctc&#x27;</span>: <span class=\"hljs-keyword\">lambda</span> y_true, y_pred: y_pred&#125;, optimizer=Adam(<span class=\"hljs-number\">1e-3</span>, amsgrad=<span class=\"hljs-literal\">True</span>))<br><br><span class=\"hljs-comment\"># 查看GPU设备</span><br>tf.config.experimental.list_physical_devices(<span class=\"hljs-string\">&#x27;GPU&#x27;</span>)<br><br><span class=\"hljs-keyword\">with</span> tf.device(<span class=\"hljs-string\">&#x27;GPU:0&#x27;</span>):<br>    model.fit(train_data, epochs=<span class=\"hljs-number\">100</span>, validation_data=valid_data, workers=<span class=\"hljs-number\">4</span>,<br>              callbacks=callbacks)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221612234.png\" class=\"\" title=\"image-20230111221612234\">\n</li>\n<li><p>提高精度，再次训练</p>\n<blockquote>\n<p>这一次在第24epoch时停止了训练</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 提前停止了，继续载入参数训练一会</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>)<br><br>callbacks = [EarlyStopping(patience=<span class=\"hljs-number\">5</span>), Evaluate(),<br>             CSVLogger(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>, append=<span class=\"hljs-literal\">True</span>), ModelCheckpoint(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>, save_best_only=<span class=\"hljs-literal\">True</span>)]<br><br>model.<span class=\"hljs-built_in\">compile</span>(loss=&#123;<span class=\"hljs-string\">&#x27;ctc&#x27;</span>: <span class=\"hljs-keyword\">lambda</span> y_true, y_pred: y_pred&#125;, optimizer=Adam(<span class=\"hljs-number\">1e-4</span>, amsgrad=<span class=\"hljs-literal\">True</span>))<br><br><span class=\"hljs-keyword\">with</span> tf.device(<span class=\"hljs-string\">&#x27;GPU:0&#x27;</span>):<br>    model.fit(train_data, epochs=<span class=\"hljs-number\">100</span>, validation_data=valid_data, workers=<span class=\"hljs-number\">4</span>,<br>              callbacks=callbacks)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221801614.png\" class=\"\" title=\"image-20230111221801614\">\n</li>\n<li><p>模型测试</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型测试</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>)<br>characters2 = characters + <span class=\"hljs-string\">&#x27; &#x27;</span><br>[X_test, y_test, _, _], _ = data[<span class=\"hljs-number\">0</span>]<br>y_pred = base_model.predict(X_test)<br>out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[<span class=\"hljs-number\">0</span>])*y_pred.shape[<span class=\"hljs-number\">1</span>], )[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>])[:, :<span class=\"hljs-number\">4</span>]<br>out = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> out[<span class=\"hljs-number\">0</span>]])<br>y_true = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> y_test[<span class=\"hljs-number\">0</span>]])<br><br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>])<br>plt.title(<span class=\"hljs-string\">&#x27;pred:&#x27;</span> + <span class=\"hljs-built_in\">str</span>(out) + <span class=\"hljs-string\">&#x27;\\ntrue&#x27;</span> + <span class=\"hljs-built_in\">str</span>(y_true))<br><br>argmax = np.argmax(y_pred, axis=<span class=\"hljs-number\">2</span>)[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">zip</span>(argmax, <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters2[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> argmax])))<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221851068.png\" class=\"\" title=\"image-20230111221851068\">\n</li>\n<li><p>计算总体准确度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 计算模型总体准确度</span><br>evaluate(base_model)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221914620.png\" class=\"\" title=\"image-20230111221914620\">\n</li>\n<li><p>保存模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 保存模型</span><br>base_model.save(<span class=\"hljs-string\">&#x27;ctc.h5&#x27;</span>, include_optimizer=<span class=\"hljs-literal\">False</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>可视化训练曲线</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 可视化训练曲线</span><br>df = pd.read_csv(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>)<br>df[[<span class=\"hljs-string\">&#x27;loss&#x27;</span>, <span class=\"hljs-string\">&#x27;val_loss&#x27;</span>]].plot()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221947792.png\" class=\"\" title=\"image-20230111221947792\">\n</li>\n</ul>\n<h3 id=\"4、总结\"><a href=\"#4、总结\" class=\"headerlink\" title=\"4、总结\"></a>4、总结</h3><ul>\n<li><p>对LSTM的理解</p>\n<p>Long Short Term Memory networks（以下简称LSTMs），一种特殊的RNN网络，该网络设计出来是为了解决长依赖问题。</p>\n<p>所有循环神经网络都具有神经网络的重复模块链的形式。 在标准的RNN中，该重复模块将具有非常简单的结构，例如单个tanh层。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/6983308-2f0d4a87883d2c8c.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp\" alt=\"img\"></p>\n<p>LSTMs也具有这种链式结构，但是它的重复单元不同于标准RNN网络里的单元只有一个网络层，它的内部有四个网络层。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/6983308-169c41fa64ff202f.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp\" alt=\"img\"></p>\n</li>\n<li><p>对CTC的理解</p>\n<p>CTC（Connectionist Temporal Classifier，联接时间分类器），主要用于解决输入特征与输出标签的对齐问题。由于文字的不同间隔或变形等问题，导致同个文字有不同的表现形式，但实际上都是同一个文字。在识别时会将输入图像分块后再去识别，得出每块属于某个字符的概率（无法识别的标记为特殊字符”-”）。由于字符变形等原因，导致对输入图像分块识别时，相邻块可能会识别为同个结果，字符重复出现。因此，通过CTC来解决对齐问题，模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次。</p>\n</li>\n<li><p>实验所涉及的问题</p>\n<ul>\n<li><p>问题1：两个实验运用的模型有什么差别？</p>\n<p>第一个实验的模型单纯的运用了卷积神经网络，而第二个实验的模型还用到了LSTM+CTC的机制。</p>\n</li>\n<li><p>问题2：第二个实验运用的模型更适合哪一类任务？</p>\n<p>第二个实验更适合解决对于序列任务的识别，特征之间有依赖关系的这一类任务。</p>\n</li>\n<li><p>问题3：LSTM为什么能够适用于这一类任务？</p>\n<p>LSTM网络能通过一种被称为门的结构对细胞状态进行删除或者添加信息。门能够有选择性的决定让哪些信息通过，包含记忆门：决定给细胞状态添加哪些新的信息，遗忘门：选择忘记旧细胞信息的一部分，输出门：决定最终的输出。</p>\n</li>\n<li><p>问题4：对CTC的理解，CTC有什么作用？</p>\n<p>主要用于解决输入特征与输出标签的对齐问题，在本次实验中，图片识别过程中，会将一些无关的特征识别成空白，同时对输出标签进行定长后再提取最终信息。</p>\n</li>\n</ul>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"实验4-基于LSTM-CTC的验证码\"><a href=\"#实验4-基于LSTM-CTC的验证码\" class=\"headerlink\" title=\"实验4-基于LSTM+CTC的验证码\"></a>实验4-基于LSTM+CTC的验证码</h2><h3 id=\"1、实验目的\"><a href=\"#1、实验目的\" class=\"headerlink\" title=\"1、实验目的\"></a>1、实验目的</h3><ul>\n<li>会利用循环网络模型解决序列数据的相关问题</li>\n</ul>\n<h3 id=\"2、实验内容\"><a href=\"#2、实验内容\" class=\"headerlink\" title=\"2、实验内容\"></a>2、实验内容</h3><ul>\n<li>使用循环网络，自主实现效验码中多个数字字符的识别，并使用深度学习框架完成模型的训练</li>\n</ul>\n<h3 id=\"3、实验步骤\"><a href=\"#3、实验步骤\" class=\"headerlink\" title=\"3、实验步骤\"></a>3、实验步骤</h3><blockquote>\n<p>实验一共分为两个实践，第一个实践是CAPTCHA识别实践，第二个实践是基于LSTM+CTC的验证码识别是实践，本次实验第一个实践在CPU上完成，第二个实践则在GPU上完成</p>\n</blockquote>\n<h4 id=\"3-1-CAPTCHA识别实践\"><a href=\"#3-1-CAPTCHA识别实践\" class=\"headerlink\" title=\"3.1 CAPTCHA识别实践\"></a>3.1 CAPTCHA识别实践</h4><ul>\n<li><p>获取数据集</p>\n<blockquote>\n<p>tqdm用于显示进度条，captcha用于生成验证码数据集，一共生成100000个验证码图片</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取数据集</span><br><span class=\"hljs-keyword\">from</span> captcha.image <span class=\"hljs-keyword\">import</span> ImageCaptcha<br><span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> os<br><br>H, W, C = <span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">120</span>, <span class=\"hljs-number\">3</span><br>N_LABELS = <span class=\"hljs-number\">10</span><br>D = <span class=\"hljs-number\">4</span><br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">generate_captcha_images</span>(<span class=\"hljs-params\">datasets_path, num_images, width=<span class=\"hljs-number\">200</span>, height=<span class=\"hljs-number\">100</span></span>):<br>    images_path = os.path.join(datasets_path, <span class=\"hljs-string\">&#x27;image&#x27;</span>)<br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(images_path):<br>        os.makedirs(images_path)<br>        <br>    label_file =  <span class=\"hljs-built_in\">open</span>(os.path.join(datasets_path, <span class=\"hljs-string\">&#x27;labels.txt&#x27;</span>), <span class=\"hljs-string\">&#x27;w&#x27;</span>)<br>    image = ImageCaptcha(width=width, height=height)<br>    alphabet = <span class=\"hljs-string\">&#x27;0123456789&#x27;</span><br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> tqdm(<span class=\"hljs-built_in\">range</span>(num_images)):<br>        <span class=\"hljs-comment\"># 生成随机4位数字的效验码内容</span><br>        captcha_text = random.choices(alphabet, k=<span class=\"hljs-number\">4</span>)<br>        label = <span class=\"hljs-string\">&#x27;&#x27;</span>.join(captcha_text)<br>        <span class=\"hljs-comment\"># 文件名与输出路径</span><br>        image_filename = <span class=\"hljs-string\">f&#x27;%d.&#x27;</span> % i + <span class=\"hljs-string\">&#x27;jpg&#x27;</span><br>        output_path = os.path.join(images_path, image_filename)<br>        <span class=\"hljs-comment\"># 保存图片和写入标签</span><br>        image.write(label, output_path)<br>        label_file.write(image_filename + <span class=\"hljs-string\">&#x27;,&#x27;</span> + label + <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br>    label_file.close()<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成以后将改行设为注释</span><br><span class=\"hljs-comment\"># generate_captcha_images(&#x27;train1&#x27;, 100000, width=120, height=100)</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111212922711.png\" class=\"\" title=\"image-20230111212922711\">\n</li>\n<li><p>获取图片对应的标签值</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取图片对应的标签值</span><br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> os<br><br>filenames_file = os.listdir(<span class=\"hljs-string\">&#x27;train1/image/&#x27;</span>)<br>label_file = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&#x27;train1/labels.txt&#x27;</span>)<br><br>filenames = []<br>labels = []<br><br><span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> label_file:<br>    line_split = line.strip().split(<span class=\"hljs-string\">&#x27;,&#x27;</span>)<br>    filename, label = line_split[<span class=\"hljs-number\">0</span>], line_split[<span class=\"hljs-number\">1</span>]<br>    filenames.append(filename)<br>    labels.append(label)<br>    <br><span class=\"hljs-comment\"># 将文件名和标签一一对应</span><br>df = pd.DataFrame(&#123;<br>    <span class=\"hljs-string\">&#x27;filename&#x27;</span>:filenames,<br>    <span class=\"hljs-string\">&#x27;label&#x27;</span>:labels<br>&#125;)<br><br>df.head(<span class=\"hljs-number\">1</span>)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213029737.png\" class=\"\" title=\"image-20230111213029737\">\n</li>\n<li><p>划分训练集和测试集</p>\n<blockquote>\n<p>按照8训练集：2训练集的比例进行划分</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 划分数据集</span><br><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split<br><br>df_train, df_valid = train_test_split(df, test_size=<span class=\"hljs-number\">0.2</span>, random_state=<span class=\"hljs-number\">42</span>)<br>df_train = df_train.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br>df_valid = df_valid.reset_index(drop=<span class=\"hljs-literal\">True</span>)<br><br>total_train = df_train.shape[<span class=\"hljs-number\">0</span>]<br>total_valid = df_valid.shape[<span class=\"hljs-number\">0</span>]<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>构造data_generator</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构造data_generator</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> to_categorical<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_data_generator</span>(<span class=\"hljs-params\">df, num, for_training, batch_size=<span class=\"hljs-number\">16</span></span>):<br>    images, labels = [], []<br>    <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num):<br>            r = df.iloc[i]<br>            file, label = os.path.join(<span class=\"hljs-string\">&#x27;train1&#x27;</span>, <span class=\"hljs-string\">&#x27;image&#x27;</span>, r[<span class=\"hljs-string\">&#x27;filename&#x27;</span>]), r[<span class=\"hljs-string\">&#x27;label&#x27;</span>]<br>            im = Image.<span class=\"hljs-built_in\">open</span>(file)<br>            im = np.array(im) / <span class=\"hljs-number\">255.0</span><br>            images.append(np.array(im))<br>            labels.append(np.array([np.array(to_categorical(<span class=\"hljs-built_in\">int</span>(i), N_LABELS)) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> label]))<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(images) &gt; batch_size:<br>                <span class=\"hljs-keyword\">yield</span> np.array(images), np.array(labels)<br>                images, labels = [], []<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> for_training:<br>                <span class=\"hljs-keyword\">break</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看所生成的数据样例</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看生成数据样例</span><br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><br><span class=\"hljs-keyword\">for</span> v <span class=\"hljs-keyword\">in</span> get_data_generator(df_train, total_train, <span class=\"hljs-literal\">True</span>):<br>    X, y = v<br>    <span class=\"hljs-keyword\">break</span><br><span class=\"hljs-built_in\">print</span>(X.shape, y.shape)<br>plt.imshow(X[<span class=\"hljs-number\">0</span>], interpolation=<span class=\"hljs-string\">&#x27;nearest&#x27;</span>)<br><span class=\"hljs-built_in\">print</span>(y[<span class=\"hljs-number\">0</span>])<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213218547.png\" class=\"\" title=\"image-20230111213218547\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">batch_size = <span class=\"hljs-number\">64</span><br>valid_batch_size = <span class=\"hljs-number\">64</span><br>train_gen = get_data_generator(df_train, total_train, for_training=<span class=\"hljs-literal\">True</span>, batch_size=batch_size)<br>valid_gen = get_data_generator(df_valid, total_valid, for_training=<span class=\"hljs-literal\">True</span>, batch_size=valid_batch_size)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>构建网络，定义损失函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建网络</span><br><span class=\"hljs-keyword\">import</span> tensorflow <span class=\"hljs-keyword\">as</span> tf<br><span class=\"hljs-keyword\">from</span> tensorflow.keras <span class=\"hljs-keyword\">import</span> Sequential<br><span class=\"hljs-keyword\">from</span> tensorflow.keras <span class=\"hljs-keyword\">import</span> Input<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.layers <span class=\"hljs-keyword\">import</span> Conv2D, PReLU, MaxPooling2D, Flatten, Dense, Reshape, Softmax<br><br>model = Sequential()<br><br>model.add(Input(shape=(H, W, C)))<br>model.add(Conv2D(<span class=\"hljs-number\">32</span>, (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Conv2D(<span class=\"hljs-number\">64</span>, (<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Conv2D(<span class=\"hljs-number\">128</span>, (<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>,)))<br>model.add(PReLU())<br>model.add(MaxPooling2D((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), strides=<span class=\"hljs-number\">2</span>))<br><br>model.add(Flatten())<br>model.add(Dense(D * N_LABELS))<br>model.add(Reshape([D, N_LABELS]))<br><br>model.add(Softmax())<br><br>model.<span class=\"hljs-built_in\">compile</span>(optimizer=<span class=\"hljs-string\">&#x27;Adam&#x27;</span>, metrics=[<span class=\"hljs-string\">&#x27;accuracy&#x27;</span>], loss=<span class=\"hljs-string\">&#x27;categorical_crossentropy&#x27;</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>查看网络结构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">model.summary()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213428993.png\" class=\"\" title=\"image-20230111213428993\">\n</li>\n<li><p>开始训练</p>\n<blockquote>\n<p>一共完成5个epoches，每个epoches含有1250步</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">histort = model.fit(train_gen,<br>                   steps_per_epoch=total_train//batch_size,<br>                   epochs=<span class=\"hljs-number\">5</span>,<br>                   validation_data=valid_gen,<br>                   validation_steps=total_valid//valid_batch_size)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111213530417.png\" class=\"\" title=\"image-20230111213530417\">\n</li>\n<li><p>测试验证</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">test = get_data_generator(df_valid, total_valid, <span class=\"hljs-literal\">True</span>)<br>X_test, y_test = <span class=\"hljs-built_in\">next</span>(test)<br><br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>], interpolation=<span class=\"hljs-string\">&#x27;nearest&#x27;</span>)<br><span class=\"hljs-built_in\">print</span>(y[<span class=\"hljs-number\">0</span>])<br><br>y_pred = model.predict_on_batch(X_test)<br>y_true = tf.math.argmax(y_test, axis=-<span class=\"hljs-number\">1</span>)<br>y_pred = tf.math.argmax(y_pred, axis=-<span class=\"hljs-number\">1</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;y_true:&#x27;</span>, y_true[<span class=\"hljs-number\">0</span>].numpy())<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;y_pred:&#x27;</span>, y_pred[<span class=\"hljs-number\">0</span>].numpy())<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111215240888.png\" class=\"\" title=\"image-20230111215240888\">\n</li>\n</ul>\n<h4 id=\"3-2-基于LSTM-CTC的验证码识别\"><a href=\"#3-2-基于LSTM-CTC的验证码识别\" class=\"headerlink\" title=\"3.2 基于LSTM+CTC的验证码识别\"></a>3.2 基于LSTM+CTC的验证码识别</h4><ul>\n<li><p>导入相关库函数，定义常量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入必要的库</span><br><span class=\"hljs-keyword\">from</span> captcha.image <span class=\"hljs-keyword\">import</span> ImageCaptcha<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> tensorflow <span class=\"hljs-keyword\">as</span> tf<br><span class=\"hljs-keyword\">import</span> tensorflow.keras.backend <span class=\"hljs-keyword\">as</span> K<br><span class=\"hljs-keyword\">import</span> string<br><br>%matplotlib inline<br>%config InlineBackend.figure_format = <span class=\"hljs-string\">&#x27;retina&#x27;</span><br><br>characters = string.digits + string.ascii_uppercase<br><span class=\"hljs-built_in\">print</span>(characters)<br><br>width = <span class=\"hljs-number\">128</span><br>height = <span class=\"hljs-number\">64</span><br>n_len = <span class=\"hljs-number\">4</span><br>n_class = <span class=\"hljs-built_in\">len</span>(characters) + <span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义CTC损失函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义CTC Loss</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">ctc_lambda_func</span>(<span class=\"hljs-params\">args</span>):<br>    y_pred, labels, input_length, label_length = args<br>    <span class=\"hljs-keyword\">return</span> K.ctc_batch_cost(labels, y_pred, input_length, label_length)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>定义网络结构</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">input_tensor = Input((height, width, <span class=\"hljs-number\">3</span>))<br>x = input_tensor<br><span class=\"hljs-keyword\">for</span> i, n_cnn <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>([<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>]):<br>    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n_cnn):<br>        x = Conv2D(<span class=\"hljs-number\">32</span>*<span class=\"hljs-number\">2</span>**<span class=\"hljs-built_in\">min</span>(i, <span class=\"hljs-number\">3</span>), kernel_size=<span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-string\">&#x27;same&#x27;</span>, kernel_initializer=<span class=\"hljs-string\">&#x27;he_uniform&#x27;</span>)(x)<br>        x = BatchNormalization()(x)<br>        x = Activation(<span class=\"hljs-string\">&#x27;relu&#x27;</span>)(x)<br>    x = MaxPooling2D(<span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">if</span> i &lt; <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">else</span> (<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>))(x)<br>x = Permute((<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>))(x)<br>x = TimeDistributed(Flatten())(x)<br><br>rnn_size = <span class=\"hljs-number\">128</span><br>x = Bidirectional(GRU(rnn_size, return_sequences=<span class=\"hljs-literal\">True</span>))(x)<br>x = Bidirectional(GRU(rnn_size, return_sequences=<span class=\"hljs-literal\">True</span>))(x)<br>x = Dense(n_class, activation=<span class=\"hljs-string\">&#x27;softmax&#x27;</span>)(x)<br><br>base_model = Model(inputs=input_tensor, outputs=x)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">labels = Input(name=<span class=\"hljs-string\">&#x27;the_labels&#x27;</span>, shape=[n_len], dtype=<span class=\"hljs-string\">&#x27;float32&#x27;</span>)<br>input_length = Input(name=<span class=\"hljs-string\">&#x27;input_length&#x27;</span>, shape=[<span class=\"hljs-number\">1</span>], dtype=<span class=\"hljs-string\">&#x27;int64&#x27;</span>)<br>label_length = Input(name=<span class=\"hljs-string\">&#x27;label_length&#x27;</span>, shape=[<span class=\"hljs-number\">1</span>], dtype=<span class=\"hljs-string\">&#x27;int64&#x27;</span>)<br>loss_out = Lambda(ctc_lambda_func, output_shape=(<span class=\"hljs-number\">1</span>,), name=<span class=\"hljs-string\">&#x27;ctc&#x27;</span>)([x, labels, input_length, label_length])<br><br>model = Model(inputs=[input_tensor, labels, input_length, label_length], outputs=loss_out)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>生成数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据生成</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.utils <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">Sequence</span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CaptchaSequence</span>(<span class=\"hljs-title class_ inherited__\">Sequence</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, characters, batch_size, steps, n_len=<span class=\"hljs-number\">4</span>, width=<span class=\"hljs-number\">128</span>, height=<span class=\"hljs-number\">64</span>,</span><br><span class=\"hljs-params\">                 input_length=<span class=\"hljs-number\">16</span>, label_length=<span class=\"hljs-number\">4</span></span>):<br>        self.characters = characters<br>        self.batch_size = batch_size<br>        self.steps = steps<br>        self.n_len = n_len<br>        self.width = width<br>        self.height = height<br>        self.input_length = input_length<br>        self.label_length = label_length<br>        self.n_class = <span class=\"hljs-built_in\">len</span>(characters)<br>        self.generator = ImageCaptcha(width=width, height=height)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-keyword\">return</span> self.steps<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):<br>        X = np.zeros((self.batch_size, self.height, self.width, <span class=\"hljs-number\">3</span>), dtype=np.float32)<br>        y = np.zeros((self.batch_size, self.n_len), dtype=np.uint8)<br>        input_length = np.ones(self.batch_size)*self.input_length<br>        label_length = np.ones(self.batch_size)*self.label_length<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.batch_size):<br>            rand_str = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([random.choice(self.characters) <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.n_len)])<br>            X[i] = np.array(self.generator.generate_image(rand_str))/<span class=\"hljs-number\">255.0</span><br>            y[i] = [self.characters.find(x) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> rand_str]<br>        <span class=\"hljs-keyword\">return</span> [X, y, input_length, label_length], np.ones(self.batch_size)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看生成的图片</span><br>data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">1</span>, steps=<span class=\"hljs-number\">1</span>)<br>[X_test, y_test, _, _], _ = data[<span class=\"hljs-number\">0</span>]<br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>])<br>plt.title(<span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> y_test[<span class=\"hljs-number\">0</span>]]))<br><span class=\"hljs-built_in\">print</span>(input_length, label_length)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221331595.png\" class=\"\" title=\"image-20230111221331595\">\n</li>\n<li><p>准确率回调</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 准确率回调函数</span><br><span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm<br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">evaluate</span>(<span class=\"hljs-params\">model, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">20</span></span>):<br>    batch_acc = <span class=\"hljs-number\">0</span><br>    valid_data = CaptchaSequence(characters, batch_size, steps)<br>    <span class=\"hljs-keyword\">for</span> [X_test, y_test, _, _], _ <span class=\"hljs-keyword\">in</span> valid_data:<br>        y_pred = base_model.predict(X_test)<br>        shape = y_pred.shape<br>        out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(shape[<span class=\"hljs-number\">0</span>])*shape[<span class=\"hljs-number\">1</span>])[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>])[:, :<span class=\"hljs-number\">4</span>]<br>        <span class=\"hljs-keyword\">if</span> out.shape[<span class=\"hljs-number\">1</span>] == <span class=\"hljs-number\">4</span>:<br>            batch_acc += (y_test == out).<span class=\"hljs-built_in\">all</span>(axis=<span class=\"hljs-number\">1</span>).mean()<br>            <br>    <span class=\"hljs-keyword\">return</span> batch_acc / steps<br>    <br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> Callback<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Evaluate</span>(<span class=\"hljs-title class_ inherited__\">Callback</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        self.accs = []<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_epoch_end</span>(<span class=\"hljs-params\">self, epoch, logs=<span class=\"hljs-literal\">None</span></span>):<br>        logs = logs <span class=\"hljs-keyword\">or</span> &#123;&#125;<br>        acc = evaluate(base_model)<br>        logs[<span class=\"hljs-string\">&#x27;val_acc&#x27;</span>] = acc<br>        self.accs.append(acc)<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&#x27;\\nacc:<span class=\"hljs-subst\">&#123;acc*<span class=\"hljs-number\">100</span>:<span class=\"hljs-number\">.4</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>训练模型</p>\n<blockquote>\n<p>由于使用了EarlyStopping，当训练到第13个epoch时，损失值的减少已经小于1e-3，所以会提前停止训练</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br><span class=\"hljs-keyword\">from</span> tensorflow.keras.callbacks <span class=\"hljs-keyword\">import</span> EarlyStopping, CSVLogger, ModelCheckpoint<br><span class=\"hljs-keyword\">from</span> tensorflow.keras.optimizers <span class=\"hljs-keyword\">import</span> *<br><br>train_data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">1000</span>)<br>valid_data = CaptchaSequence(characters, batch_size=<span class=\"hljs-number\">128</span>, steps=<span class=\"hljs-number\">100</span>)<br><br>callbacks = [EarlyStopping(patience=<span class=\"hljs-number\">5</span>), Evaluate(),<br>             CSVLogger(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>), ModelCheckpoint(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>, save_best_only=<span class=\"hljs-literal\">True</span>)]<br><br>model.<span class=\"hljs-built_in\">compile</span>(loss=&#123;<span class=\"hljs-string\">&#x27;ctc&#x27;</span>: <span class=\"hljs-keyword\">lambda</span> y_true, y_pred: y_pred&#125;, optimizer=Adam(<span class=\"hljs-number\">1e-3</span>, amsgrad=<span class=\"hljs-literal\">True</span>))<br><br><span class=\"hljs-comment\"># 查看GPU设备</span><br>tf.config.experimental.list_physical_devices(<span class=\"hljs-string\">&#x27;GPU&#x27;</span>)<br><br><span class=\"hljs-keyword\">with</span> tf.device(<span class=\"hljs-string\">&#x27;GPU:0&#x27;</span>):<br>    model.fit(train_data, epochs=<span class=\"hljs-number\">100</span>, validation_data=valid_data, workers=<span class=\"hljs-number\">4</span>,<br>              callbacks=callbacks)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221612234.png\" class=\"\" title=\"image-20230111221612234\">\n</li>\n<li><p>提高精度，再次训练</p>\n<blockquote>\n<p>这一次在第24epoch时停止了训练</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 提前停止了，继续载入参数训练一会</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>)<br><br>callbacks = [EarlyStopping(patience=<span class=\"hljs-number\">5</span>), Evaluate(),<br>             CSVLogger(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>, append=<span class=\"hljs-literal\">True</span>), ModelCheckpoint(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>, save_best_only=<span class=\"hljs-literal\">True</span>)]<br><br>model.<span class=\"hljs-built_in\">compile</span>(loss=&#123;<span class=\"hljs-string\">&#x27;ctc&#x27;</span>: <span class=\"hljs-keyword\">lambda</span> y_true, y_pred: y_pred&#125;, optimizer=Adam(<span class=\"hljs-number\">1e-4</span>, amsgrad=<span class=\"hljs-literal\">True</span>))<br><br><span class=\"hljs-keyword\">with</span> tf.device(<span class=\"hljs-string\">&#x27;GPU:0&#x27;</span>):<br>    model.fit(train_data, epochs=<span class=\"hljs-number\">100</span>, validation_data=valid_data, workers=<span class=\"hljs-number\">4</span>,<br>              callbacks=callbacks)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221801614.png\" class=\"\" title=\"image-20230111221801614\">\n</li>\n<li><p>模型测试</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型测试</span><br>model.load_weights(<span class=\"hljs-string\">&#x27;ctc_best.h5&#x27;</span>)<br>characters2 = characters + <span class=\"hljs-string\">&#x27; &#x27;</span><br>[X_test, y_test, _, _], _ = data[<span class=\"hljs-number\">0</span>]<br>y_pred = base_model.predict(X_test)<br>out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[<span class=\"hljs-number\">0</span>])*y_pred.shape[<span class=\"hljs-number\">1</span>], )[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>])[:, :<span class=\"hljs-number\">4</span>]<br>out = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> out[<span class=\"hljs-number\">0</span>]])<br>y_true = <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> y_test[<span class=\"hljs-number\">0</span>]])<br><br>plt.imshow(X_test[<span class=\"hljs-number\">0</span>])<br>plt.title(<span class=\"hljs-string\">&#x27;pred:&#x27;</span> + <span class=\"hljs-built_in\">str</span>(out) + <span class=\"hljs-string\">&#x27;\\ntrue&#x27;</span> + <span class=\"hljs-built_in\">str</span>(y_true))<br><br>argmax = np.argmax(y_pred, axis=<span class=\"hljs-number\">2</span>)[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">zip</span>(argmax, <span class=\"hljs-string\">&#x27;&#x27;</span>.join([characters2[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> argmax])))<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221851068.png\" class=\"\" title=\"image-20230111221851068\">\n</li>\n<li><p>计算总体准确度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 计算模型总体准确度</span><br>evaluate(base_model)<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221914620.png\" class=\"\" title=\"image-20230111221914620\">\n</li>\n<li><p>保存模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 保存模型</span><br>base_model.save(<span class=\"hljs-string\">&#x27;ctc.h5&#x27;</span>, include_optimizer=<span class=\"hljs-literal\">False</span>)<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>可视化训练曲线</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 可视化训练曲线</span><br>df = pd.read_csv(<span class=\"hljs-string\">&#x27;ctc.csv&#x27;</span>)<br>df[[<span class=\"hljs-string\">&#x27;loss&#x27;</span>, <span class=\"hljs-string\">&#x27;val_loss&#x27;</span>]].plot()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/18/AI-lab03/image-20230111221947792.png\" class=\"\" title=\"image-20230111221947792\">\n</li>\n</ul>\n<h3 id=\"4、总结\"><a href=\"#4、总结\" class=\"headerlink\" title=\"4、总结\"></a>4、总结</h3><ul>\n<li><p>对LSTM的理解</p>\n<p>Long Short Term Memory networks（以下简称LSTMs），一种特殊的RNN网络，该网络设计出来是为了解决长依赖问题。</p>\n<p>所有循环神经网络都具有神经网络的重复模块链的形式。 在标准的RNN中，该重复模块将具有非常简单的结构，例如单个tanh层。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/6983308-2f0d4a87883d2c8c.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp\" alt=\"img\"></p>\n<p>LSTMs也具有这种链式结构，但是它的重复单元不同于标准RNN网络里的单元只有一个网络层，它的内部有四个网络层。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/6983308-169c41fa64ff202f.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp\" alt=\"img\"></p>\n</li>\n<li><p>对CTC的理解</p>\n<p>CTC（Connectionist Temporal Classifier，联接时间分类器），主要用于解决输入特征与输出标签的对齐问题。由于文字的不同间隔或变形等问题，导致同个文字有不同的表现形式，但实际上都是同一个文字。在识别时会将输入图像分块后再去识别，得出每块属于某个字符的概率（无法识别的标记为特殊字符”-”）。由于字符变形等原因，导致对输入图像分块识别时，相邻块可能会识别为同个结果，字符重复出现。因此，通过CTC来解决对齐问题，模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次。</p>\n</li>\n<li><p>实验所涉及的问题</p>\n<ul>\n<li><p>问题1：两个实验运用的模型有什么差别？</p>\n<p>第一个实验的模型单纯的运用了卷积神经网络，而第二个实验的模型还用到了LSTM+CTC的机制。</p>\n</li>\n<li><p>问题2：第二个实验运用的模型更适合哪一类任务？</p>\n<p>第二个实验更适合解决对于序列任务的识别，特征之间有依赖关系的这一类任务。</p>\n</li>\n<li><p>问题3：LSTM为什么能够适用于这一类任务？</p>\n<p>LSTM网络能通过一种被称为门的结构对细胞状态进行删除或者添加信息。门能够有选择性的决定让哪些信息通过，包含记忆门：决定给细胞状态添加哪些新的信息，遗忘门：选择忘记旧细胞信息的一部分，输出门：决定最终的输出。</p>\n</li>\n<li><p>问题4：对CTC的理解，CTC有什么作用？</p>\n<p>主要用于解决输入特征与输出标签的对齐问题，在本次实验中，图片识别过程中，会将一些无关的特征识别成空白，同时对输出标签进行定长后再提取最终信息。</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"C++使用zlib库来压缩文件","date":"2024-01-26T02:34:44.000Z","cover":"/img/default_cover02.jpg","top_img":null,"_content":"\n## C++使用zlib库来压缩文件\n\nzlib压缩库提供内存压缩和解压缩功能，包括对未压缩的完整性检查数据，提供支持的压缩方法为：deflation，默认使用压缩数据格式为zlib格式。\n\nzlib库支持读取和写入gzip(.gz)格式的文件，zlib格式旨在紧凑且快速，可用于内存和通信渠道。gzip格式设计用于文件系统上的单文件压缩，比zlib具有更大的头部以维护目录信息，并且使用与zlib不同且更慢的检查方法。\n\n该库不安装任何信号处理程序。解码器检查压缩数据的一致性，因此即使在输入损坏的情况下，库也不应崩溃。\n\n### 数据流结构\n\n```\ntypedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);\ntypedef void   (*free_func)(voidpf opaque, voidpf address);\n```\n\n* `typedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);`这个函数指针通常用于内存分配，允许用户自定义的内存分配函数\n* `typedef void   (*free_func)(voidpf opaque, voidpf address);`这个函数指针通常用于内存释放，允许用户自定义的内存释放函数\n\n### 基本功能\n\n```\nZEXTERN int ZEXPORT deflateInit(z_streamp strm, int level);\n```\n\n* `level`表示压缩级别，要么为`Z_DEFAULT_COMPRESSION`，要么介于0-9之间，1表示最佳速度，9表示最佳压缩，0表示没有压缩，`Z_DEFAULT_COMPRESSION`默认在6级别。\n* `deflateInit` 返回 `Z_OK` 如果成功，则返回 `Z_MEM_ERROR` 如果没有 足够的内存，`Z_STREAM_ERROR` `level` 不是有效的压缩级别，`Z_VERSION_ERROR` *zlib* 库版本 （`zlib_version`） 不兼容 替换为调用方 （`ZLIB_VERSION`） 假定的版本。如果没有错误消息，`则 msg` 设置为 null。`deflateInit` 不 执行任何压缩：这将由 `deflate（）` 完成。\n\n```\nZEXTERN int ZEXPORT deflate(z_streamp strm, int flush);\n```\n\n","source":"_posts/C-使用zlib库来压缩文件.md","raw":"---\ntitle: C++使用zlib库来压缩文件\ndate: 2024-01-26 10:34:44\ntags: [C++, zlib]\ncategories: 技术研究\ncover: /img/default_cover02.jpg\ntop_img:\n---\n\n## C++使用zlib库来压缩文件\n\nzlib压缩库提供内存压缩和解压缩功能，包括对未压缩的完整性检查数据，提供支持的压缩方法为：deflation，默认使用压缩数据格式为zlib格式。\n\nzlib库支持读取和写入gzip(.gz)格式的文件，zlib格式旨在紧凑且快速，可用于内存和通信渠道。gzip格式设计用于文件系统上的单文件压缩，比zlib具有更大的头部以维护目录信息，并且使用与zlib不同且更慢的检查方法。\n\n该库不安装任何信号处理程序。解码器检查压缩数据的一致性，因此即使在输入损坏的情况下，库也不应崩溃。\n\n### 数据流结构\n\n```\ntypedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);\ntypedef void   (*free_func)(voidpf opaque, voidpf address);\n```\n\n* `typedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);`这个函数指针通常用于内存分配，允许用户自定义的内存分配函数\n* `typedef void   (*free_func)(voidpf opaque, voidpf address);`这个函数指针通常用于内存释放，允许用户自定义的内存释放函数\n\n### 基本功能\n\n```\nZEXTERN int ZEXPORT deflateInit(z_streamp strm, int level);\n```\n\n* `level`表示压缩级别，要么为`Z_DEFAULT_COMPRESSION`，要么介于0-9之间，1表示最佳速度，9表示最佳压缩，0表示没有压缩，`Z_DEFAULT_COMPRESSION`默认在6级别。\n* `deflateInit` 返回 `Z_OK` 如果成功，则返回 `Z_MEM_ERROR` 如果没有 足够的内存，`Z_STREAM_ERROR` `level` 不是有效的压缩级别，`Z_VERSION_ERROR` *zlib* 库版本 （`zlib_version`） 不兼容 替换为调用方 （`ZLIB_VERSION`） 假定的版本。如果没有错误消息，`则 msg` 设置为 null。`deflateInit` 不 执行任何压缩：这将由 `deflate（）` 完成。\n\n```\nZEXTERN int ZEXPORT deflate(z_streamp strm, int flush);\n```\n\n","slug":"C-使用zlib库来压缩文件","published":1,"updated":"2024-06-05T09:03:03.518Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttg000d08jva4934yz2","content":"<h2 id=\"C-使用zlib库来压缩文件\"><a href=\"#C-使用zlib库来压缩文件\" class=\"headerlink\" title=\"C++使用zlib库来压缩文件\"></a>C++使用zlib库来压缩文件</h2><p>zlib压缩库提供内存压缩和解压缩功能，包括对未压缩的完整性检查数据，提供支持的压缩方法为：deflation，默认使用压缩数据格式为zlib格式。</p>\n<p>zlib库支持读取和写入gzip(.gz)格式的文件，zlib格式旨在紧凑且快速，可用于内存和通信渠道。gzip格式设计用于文件系统上的单文件压缩，比zlib具有更大的头部以维护目录信息，并且使用与zlib不同且更慢的检查方法。</p>\n<p>该库不安装任何信号处理程序。解码器检查压缩数据的一致性，因此即使在输入损坏的情况下，库也不应崩溃。</p>\n<h3 id=\"数据流结构\"><a href=\"#数据流结构\" class=\"headerlink\" title=\"数据流结构\"></a>数据流结构</h3><figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-built_in\">void</span>pf (*alloc_func)(<span class=\"hljs-built_in\">void</span>pf opaque, uInt items, uInt size);<br><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-built_in\">void</span>   (*free_func)(<span class=\"hljs-built_in\">void</span>pf opaque, <span class=\"hljs-built_in\">void</span>pf address);<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>typedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);</code>这个函数指针通常用于内存分配，允许用户自定义的内存分配函数</li>\n<li><code>typedef void   (*free_func)(voidpf opaque, voidpf address);</code>这个函数指针通常用于内存释放，允许用户自定义的内存释放函数</li>\n</ul>\n<h3 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h3><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-function\">ZEXTERN <span class=\"hljs-type\">int</span> ZEXPORT <span class=\"hljs-title\">deflateInit</span><span class=\"hljs-params\">(z_streamp strm, <span class=\"hljs-type\">int</span> level)</span></span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>level</code>表示压缩级别，要么为<code>Z_DEFAULT_COMPRESSION</code>，要么介于0-9之间，1表示最佳速度，9表示最佳压缩，0表示没有压缩，<code>Z_DEFAULT_COMPRESSION</code>默认在6级别。</li>\n<li><code>deflateInit</code> 返回 <code>Z_OK</code> 如果成功，则返回 <code>Z_MEM_ERROR</code> 如果没有 足够的内存，<code>Z_STREAM_ERROR</code> <code>level</code> 不是有效的压缩级别，<code>Z_VERSION_ERROR</code> <em>zlib</em> 库版本 （<code>zlib_version</code>） 不兼容 替换为调用方 （<code>ZLIB_VERSION</code>） 假定的版本。如果没有错误消息，<code>则 msg</code> 设置为 null。<code>deflateInit</code> 不 执行任何压缩：这将由 <code>deflate（）</code> 完成。</li>\n</ul>\n<figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-function\">ZEXTERN <span class=\"hljs-type\">int</span> ZEXPORT <span class=\"hljs-title\">deflate</span><span class=\"hljs-params\">(z_streamp strm, <span class=\"hljs-type\">int</span> flush)</span></span>;<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"C-使用zlib库来压缩文件\"><a href=\"#C-使用zlib库来压缩文件\" class=\"headerlink\" title=\"C++使用zlib库来压缩文件\"></a>C++使用zlib库来压缩文件</h2><p>zlib压缩库提供内存压缩和解压缩功能，包括对未压缩的完整性检查数据，提供支持的压缩方法为：deflation，默认使用压缩数据格式为zlib格式。</p>\n<p>zlib库支持读取和写入gzip(.gz)格式的文件，zlib格式旨在紧凑且快速，可用于内存和通信渠道。gzip格式设计用于文件系统上的单文件压缩，比zlib具有更大的头部以维护目录信息，并且使用与zlib不同且更慢的检查方法。</p>\n<p>该库不安装任何信号处理程序。解码器检查压缩数据的一致性，因此即使在输入损坏的情况下，库也不应崩溃。</p>\n<h3 id=\"数据流结构\"><a href=\"#数据流结构\" class=\"headerlink\" title=\"数据流结构\"></a>数据流结构</h3><figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-built_in\">void</span>pf (*alloc_func)(<span class=\"hljs-built_in\">void</span>pf opaque, uInt items, uInt size);<br><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-built_in\">void</span>   (*free_func)(<span class=\"hljs-built_in\">void</span>pf opaque, <span class=\"hljs-built_in\">void</span>pf address);<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>typedef voidpf (*alloc_func)(voidpf opaque, uInt items, uInt size);</code>这个函数指针通常用于内存分配，允许用户自定义的内存分配函数</li>\n<li><code>typedef void   (*free_func)(voidpf opaque, voidpf address);</code>这个函数指针通常用于内存释放，允许用户自定义的内存释放函数</li>\n</ul>\n<h3 id=\"基本功能\"><a href=\"#基本功能\" class=\"headerlink\" title=\"基本功能\"></a>基本功能</h3><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-function\">ZEXTERN <span class=\"hljs-type\">int</span> ZEXPORT <span class=\"hljs-title\">deflateInit</span><span class=\"hljs-params\">(z_streamp strm, <span class=\"hljs-type\">int</span> level)</span></span>;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>level</code>表示压缩级别，要么为<code>Z_DEFAULT_COMPRESSION</code>，要么介于0-9之间，1表示最佳速度，9表示最佳压缩，0表示没有压缩，<code>Z_DEFAULT_COMPRESSION</code>默认在6级别。</li>\n<li><code>deflateInit</code> 返回 <code>Z_OK</code> 如果成功，则返回 <code>Z_MEM_ERROR</code> 如果没有 足够的内存，<code>Z_STREAM_ERROR</code> <code>level</code> 不是有效的压缩级别，<code>Z_VERSION_ERROR</code> <em>zlib</em> 库版本 （<code>zlib_version</code>） 不兼容 替换为调用方 （<code>ZLIB_VERSION</code>） 假定的版本。如果没有错误消息，<code>则 msg</code> 设置为 null。<code>deflateInit</code> 不 执行任何压缩：这将由 <code>deflate（）</code> 完成。</li>\n</ul>\n<figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-function\">ZEXTERN <span class=\"hljs-type\">int</span> ZEXPORT <span class=\"hljs-title\">deflate</span><span class=\"hljs-params\">(z_streamp strm, <span class=\"hljs-type\">int</span> flush)</span></span>;<br></code></pre></td></tr></table></figure>\n"},{"title":"Modern C++学习笔记","date":"2023-08-15T05:14:50.000Z","cover":"/img/default_cover02.jpg","top_img":null,"_content":"## Effective Modern C++学习笔记\n\n> 重点掌握auto、智能指针、移动构造、lambda\n\n### 第一章、类型推导\n\n#### 条款1、模板类型推导\n\n```\n情况一、按值传递，传入副本\ntemplate<typename T>\nvoid f(T param)\n\n情况二、引用传递，传入地址\ntemplate<typename T>\nvoid f(const T& param)\n\n情况三、指针传递\ntemplate<typename T>\nvoid f(T* param)\n\n万能引用，即也可以引用右值\n情况四、万能引用，如果是右值，则传入的是右值的地址\ntemplate<typename T>\nvoid f(T&& param)\n```\n\n\n\n> 当向引用型别的形参传入const对象时，他们期望该对象保持其不可该修改的属性，即const引用\n>\n> 因此向持有T&型别的模板传入const对象时安全的\n\n* 当使用万能引用时，型别推导规则会区分实参是左值还是右值，如果是左值就是单个引用情况“&”，如果是右值则是“&&”情况\n\n* 如果是按值传递，则传入的是一个副本，无论做什么操作都无法改变原始的数据\n\n```\nconst char name[] = \"sda\"\nconst char* ptrToName = name\n\ntemplate<typename T>\nvoid f(T param)\nf(name)\n\nT会推到成const char*的类型\n```\n\n#### 条款2、auto类型推导\n\n> auto类型推导就是模板类型推导，当某一个变量采用auto来声明时，auto则扮演模板中的角色，通过表达式的右边的值推出左边。\n\nC++14允许auto来说明函数返回值需要推导\n\n#### 条款3、decltype\n\ndecltype可以声明返回值型别依赖于形参性别的函数模板，因为函数模板的数据类型不确定，通过使用decltype引用一个模板类型的数据，可以推出该函数模板的类型，通过尾序返回值可返回该数据类型的结果。\n\n在对万能引用进行推导时，返回值需要加上std::forward\n\n\n\n### 第二章、auto\n\n> 优先使用auto定义，而非使用显式定义，可以防止对象忘记初始化的错误。\n\nauto优点\n\n* 1、避免初始化变量和冗余的变量声明（如，迭代器声明）\n* 2、在不同位的操作系统移植过程中可以避免参数位数表达不一致的问题\n\nauto不能用在vector< bool >中，在单个返回operator[]时返回的是bool的引用。\n\n\n\n### 第三章——模板还是有点晦涩难懂\n\n#### 条款7、创建对象注意区分（）和{}\n\n```\n// 使用大括号初始化容器会强烈优先选择带有std::initializer_list类别形参的构造函数\nvector<int> v{1, 3, 5}\n```\n\n空大括号表达的是没有形参，如果使用list的话，应该在小括号在再加一个大括号。\n\n#### 条款8、优先使用nullptr\n\n作为指针传入参数时，传入空指针优先使用nullptr，因为nullptr指代明确，不像0和NULL既可以指代整型也可以指代空指针。\n\nnullptr可以隐式的转化为所有指针类型。\n\n#### 条款9、优先使用别名声明，而非typedef---------回头看\n\nusing作用可以等效于typedef用于别名的声明，使用using的优势在于，可以将其与模板进行结合起来，别名模板。\n\n\n\n#### 条款10、优先使用限定作用域的枚举\n\n> enum class name{}；使用class关键词限定作用域，又称为枚举类。\n\n使用枚举的成员需要用到`name::`来取。\n\n* 使用限定作用域的枚举的枚举量是更强型别的，不限范围的枚举型别中的枚举量可以隐式转化到整数类别。\n* 强类型的参数不能够和非同类型的参数进行比较，也不能进行隐式转换，必须通过强制转化才能够进行比较。\n* 限定作用域的枚举型别可以进行前置声明。不限定作用域的枚举要想进行前置声明，则可以进行对底层型别的声明：enum color: std::uint8_t\n\n```\n// 条款10、优先使用限定作用域的枚举\nenum color {\n\tblack,\n\twhite,\n\tred\n};\n\n// 重定义报错\n// auto white = false;\n\n// 枚举类，限定作用域在color2中\nenum class color2 {\n\tblack1,\n\twhite1,\n\tred1\n};\n\nauto white1 = false;\nauto c = color2::red1;\n```\n\n\n\n#### 条款11、优先选用删除函数\n\n在类里面的函数后面加上`=delete`可以组x织客户去调用函数，说明该函数已经失效。\n\n任何函数都可以成为删除函数，但只有成员函数能声明为private。\n\n####  条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\n\n函数重写的必要条件：\n\n* 基类中的函数必须是虚函数\n* 函数名字必须完全相同（析构函数例外）\n* 函数形参型别完全相同\n* 函数常量性必须完全相同\n* 函数返回值和异常规格必须兼容\n* 引用饰词必须完全相同\n\n成员函数引用饰词的作用就是针对发起成员函数调用的现象，加一些区分度。\n\n#### 条款13、优先选用const_iterator\n\n```\n// 建立iterator并插入\nstd::vector<int>::iterator it = std::find(values.begin(), values.end(), 1983);\nvalues.insert(it, 1998)\n```\n\n容器的cbegin和cend都返回的是const_iterator型别，不能修改，但是可以通过insert插入元素到列表中。\n\n将const元素传入begin函数中，会产生一个const_iterator\n\n```\n// 条款13、优先选用const_iterator\nvoid demo13() {\n\tstd::vector<int> vec{ 1,2,3,4,5 };\n\n\tfor (std::vector<int>::iterator iter = vec.begin(); iter != vec.end(); ++iter) {\n\t\tstd::cout << \"old element:\" << *iter;\t\t\t\t// 打印元素\n\n\t\t(*iter) += 1;\t\t\t\t\t\t\t\t\t\t// 通过迭代器修改对应元素\n\t\tstd::cout << \", new:\" << *iter << std::endl;\n\n\t}\n\n\tauto it = std::find(vec.cbegin(), vec.cend(), 3);\n\tvec.insert(it, 1);\n\n\tfor (std::vector<int>::const_iterator iter = vec.cbegin(); iter != vec.cend(); ++iter) {\n\t\tstd::cout << \"old element:\" << *iter << std::endl;\t\t\t\t// 打印元素\n\n\t}\n}\n```\n\n* 优先使用begin，end等，而非成员函数版本\n\n#### 条款14、对于确保不发生异常的函数，加上noexcept声明\n\n在C++98中，出现异常后，调用栈会开解至异常出现的调用方，C++11中，中止前只是可能会解开。因此优化器不需要再异常传出函数的前提下，将执行期间栈保持在开解状态，也不用在异常溢出函数的前提下，保证所有对象的构造顺序的逆序完成解析。\n\n`push_back`中采用的原则是：能移动则移动，必须复制才复制。具有强异常性质。\n\n使用`noexcept`能够极大程度的便于编译器优化。\n\n析构函数和内存释放函数都隐式的具备又noexcept的性质。\n\n#### 条款15、使用constexpr\n\nconst：表示“只读”的含义，被const修饰的变量不能够修改，可以定义编译器和运行期的常量\n\nconstexpr：表示“常量”的含义，只能够定义编译器的常量，可以提高运行效率\n\n* constexpr修饰的函数在编译过程展开，被隐式的转化为了内联函数\n* 如果要修改const修饰的变量的值，需要加上关键字volatile\n\nconstexpr函数仅限于掺入和返回字面型别：在编译器就可以确定的数据类型。\n\n#### 条款16、使用const成员函数的线程安全性\n\n#### 条款17、\n\n\n\n### 第四章、智能指针\n\n> 智能指针是用来管理内存泄漏的，内存泄漏：在为对象动态申请内存空间后，如存在忘记释放内存，或者运行过程中程序中断的问题，导致申请的内存空间被占用造成内存泄漏。\n\n#### 条款18、使用unique_ptr管理具备专属所有权的资源\n\n智能指针`unique_ptr`\n\n* 独享它的对象\n* 包含头文件#include<memory>\n* 可以高效的转化为`shared_ptr`\n\nunique_ptr和裸指针在默认情况下有着相同的尺寸，实现的是专属所有权语义，\n\n工厂函数返回的是一个`unique_ptr`指针，可以用auto来接收。\n\n* 将一个裸指针赋值给`unique_ptr`将不会通过编译\n\n```\n// 智能指针用法\nclass AA {\npublic:\n\tstd::string _name;\n\tAA() {\n\t\tstd::cout << _name << \"调用构造函数1\\n\";\n\t}\n\tAA(const std::string& m_name) :_name(m_name) {\n\n\t\tstd::cout << _name << \"调用构造函数2\\n\";\n\t}\n\t~AA() {\n\n\t\tstd::cout << \"调用析构函数\\n\";\n\t}\n};\n\nvoid demo19() {\n\tusing std::unique_ptr;\n\tusing std::make_unique;\n\tunique_ptr<AA> p0(new AA(\"xiaoli\"));\n\tunique_ptr<AA> p1 = std::make_unique<AA>(\"xiaowang\");\n\tunique_ptr<int> pp1 = make_unique<int>();         // 数据类型为int。\n\tunique_ptr<AA> pp2 = make_unique<AA>();       // 数据类型为AA，默认构造函数。\n\tunique_ptr<AA> pp3 = make_unique<AA>(\"xiaoxi\");  // 数据类型为AA，一个参数的构造函数。\n}\n```\n\n\n\n#### 条款19、使用shared_ptr管理具备共享所有权的资源\n\nRAII思想（Resource Acquisition Is Initialization）资源获取即初始化。将获取的资源和对象的生命周期绑定在一起。\n\n* 设计RAII类的四个步骤\n  * 设计一个类封装资源，资源可以是内存、文件、socket、锁等等一切\n  * 在构造函数中执行资源的初始化，比如申请内存、打开文件、申请锁\n  * 在析构函数中执行销毁操作，比如释放内存、关闭文件、释放锁\n  * 使用时声明一个该对象的类，一般在你希望的作用域声明即可，比如在函数开始，或者作为类的成员变量\n\n引用计数带来的一些性能问题：\n\n* 尺寸是裸指针的两倍\n* 引用计数的内存必须动态分配\n* 引用计数的递增和递减必须是原子操作\n\n从一个已有shared_ptr移动构造一个新的shared_ptr会将源shared_ptr置空，不会增加引用计数。\n\n使用shared_ptr如果出现了循环引用则会导致计数用于也无法回到0，资源将无法被释放。使用`weak_ptr`配合使用便可以解决这个问题，因为`weak_ptr`不会控制对象的生命周期，但是知道对象释放的时间，会和对象共同消失。\n\n#### 条款20、weak_ptr使用\n\n1、使用`weak_ptr`代替可能空悬的`shared_ptr`\n\n2、`weak_ptr`可以用于缓存，观察者列表，以及避免shared_ptr指针环路\n\n#### 条款21、优先使用make_...ptr而不是直接使用new\n\n1、使用new的代码更加冗余\n\n2、使用new会触发两次内存分配，而使用make系列则只用触发一次内存分配\n\n#### 条款22、Pimpl用法\n\n将类内的数据成员使用struct结构体打包起来，并使用一个智能指针指向该结构体，在.cpp文件中对这些数据进行操作，能够极大便利的降低类的客户和类的实现者之间的依赖。\n\n### 右值引用、移动语义和完美转发\n\n* 移动语义可以使得编译器能够使用移动操作代替昂贵的复制操作。\n* 完美转发使得人们可以撰写接收任意实参的函数模板，并将其转发到其它函数，目标函数会接收到与转发函数所接收到的完全相同的实参。\n\n#### 条款23、理解std::move和std::forward\n\n使用move可以将参数强制转化为右值\n\n如果想要取得对某一个对象执行移动操作的能力，则不要将其声明为常量，因为针对常量对象执行的移动操作将会变化为复制操作。\n\nforward是一个有条件的强制转化，只有当实参是使用右值完成初始化时，它才会执行向右值型别的强制转化。如果需要选择性的对某一些形参进行左值或者右值引用，则可以用forward来进行标识。\n\n#### 条款24、区分万能引用和右值引用\n\n在模板和类型推导中出现`& &`很大可能就是万能引用：即表达式或者传入的实参，既可以是左值也可以时右值。\n\n#### 条款25、针对右值引用使用move，针对万能引用使用forward\n\n因为万能引用使用`forward`它可以有条件的自动转化传入的实参作为左值还是右值。\n\n#### \n\n#### 条例30、完美转发失败的情形\n\n完美转发的含义：一个函数把自己的形参传递（转发）给另一个函数，为了使得第二个函数接受第一个函数所接受的同一个对象。\n\n完美转发不仅仅转发对象，还转发其显著的特征：型别、是左值还是右值，是否带有const或者volatile修饰词。\n\n转发失败的定义：使用某特定实参调用转发函数会执行某操作，但使用同一实参调用其封装后的函数会执行不同的操作。即右值引用成功，但是万能引用失败。\n\n具体形参：\n\n* 大括号初始化的列表\n* 0或者NULL用作空指针\n* 仅有声明的整型static const成员变量\n* 重载的函数名字和模板名字\n* 位域\n\n### 第五章、lambda表达式\n\nlambda运行期的对象是`闭包`，根据不同的捕获模式，闭包会持有数据的副本或引用。\n\n闭包类就是实例化闭包的类，每个lambda式都会触发编译器生成一个独一无二的闭包类。闭包中的语句会变成它的闭包类成员函数的可执行指令。\n\n#### 条款31、避免默认捕获模式\n\nC++11有两种默认捕获模式：按值或按引用。按引用的默认捕获模式可能导致空悬引用。\n\n按引用捕获会导致闭包包含指涉到局部变量的引用，或者指涉到定义lambda式作用域内的形参的引用。一旦lambda式所创建的闭包越过了该局部变量或者形参的生命周期，那么闭包内的引用就会悬空。\n\n","source":"_posts/Effective-Modern-C-notes.md","raw":"---\ntitle: Modern C++学习笔记\ncategories: 学习笔记\ndate: 2023-08-15 13:14:50\ntags: [C++, C++新特性]\ncover:\ntop_img:\n---\n## Effective Modern C++学习笔记\n\n> 重点掌握auto、智能指针、移动构造、lambda\n\n### 第一章、类型推导\n\n#### 条款1、模板类型推导\n\n```\n情况一、按值传递，传入副本\ntemplate<typename T>\nvoid f(T param)\n\n情况二、引用传递，传入地址\ntemplate<typename T>\nvoid f(const T& param)\n\n情况三、指针传递\ntemplate<typename T>\nvoid f(T* param)\n\n万能引用，即也可以引用右值\n情况四、万能引用，如果是右值，则传入的是右值的地址\ntemplate<typename T>\nvoid f(T&& param)\n```\n\n\n\n> 当向引用型别的形参传入const对象时，他们期望该对象保持其不可该修改的属性，即const引用\n>\n> 因此向持有T&型别的模板传入const对象时安全的\n\n* 当使用万能引用时，型别推导规则会区分实参是左值还是右值，如果是左值就是单个引用情况“&”，如果是右值则是“&&”情况\n\n* 如果是按值传递，则传入的是一个副本，无论做什么操作都无法改变原始的数据\n\n```\nconst char name[] = \"sda\"\nconst char* ptrToName = name\n\ntemplate<typename T>\nvoid f(T param)\nf(name)\n\nT会推到成const char*的类型\n```\n\n#### 条款2、auto类型推导\n\n> auto类型推导就是模板类型推导，当某一个变量采用auto来声明时，auto则扮演模板中的角色，通过表达式的右边的值推出左边。\n\nC++14允许auto来说明函数返回值需要推导\n\n#### 条款3、decltype\n\ndecltype可以声明返回值型别依赖于形参性别的函数模板，因为函数模板的数据类型不确定，通过使用decltype引用一个模板类型的数据，可以推出该函数模板的类型，通过尾序返回值可返回该数据类型的结果。\n\n在对万能引用进行推导时，返回值需要加上std::forward\n\n\n\n### 第二章、auto\n\n> 优先使用auto定义，而非使用显式定义，可以防止对象忘记初始化的错误。\n\nauto优点\n\n* 1、避免初始化变量和冗余的变量声明（如，迭代器声明）\n* 2、在不同位的操作系统移植过程中可以避免参数位数表达不一致的问题\n\nauto不能用在vector< bool >中，在单个返回operator[]时返回的是bool的引用。\n\n\n\n### 第三章——模板还是有点晦涩难懂\n\n#### 条款7、创建对象注意区分（）和{}\n\n```\n// 使用大括号初始化容器会强烈优先选择带有std::initializer_list类别形参的构造函数\nvector<int> v{1, 3, 5}\n```\n\n空大括号表达的是没有形参，如果使用list的话，应该在小括号在再加一个大括号。\n\n#### 条款8、优先使用nullptr\n\n作为指针传入参数时，传入空指针优先使用nullptr，因为nullptr指代明确，不像0和NULL既可以指代整型也可以指代空指针。\n\nnullptr可以隐式的转化为所有指针类型。\n\n#### 条款9、优先使用别名声明，而非typedef---------回头看\n\nusing作用可以等效于typedef用于别名的声明，使用using的优势在于，可以将其与模板进行结合起来，别名模板。\n\n\n\n#### 条款10、优先使用限定作用域的枚举\n\n> enum class name{}；使用class关键词限定作用域，又称为枚举类。\n\n使用枚举的成员需要用到`name::`来取。\n\n* 使用限定作用域的枚举的枚举量是更强型别的，不限范围的枚举型别中的枚举量可以隐式转化到整数类别。\n* 强类型的参数不能够和非同类型的参数进行比较，也不能进行隐式转换，必须通过强制转化才能够进行比较。\n* 限定作用域的枚举型别可以进行前置声明。不限定作用域的枚举要想进行前置声明，则可以进行对底层型别的声明：enum color: std::uint8_t\n\n```\n// 条款10、优先使用限定作用域的枚举\nenum color {\n\tblack,\n\twhite,\n\tred\n};\n\n// 重定义报错\n// auto white = false;\n\n// 枚举类，限定作用域在color2中\nenum class color2 {\n\tblack1,\n\twhite1,\n\tred1\n};\n\nauto white1 = false;\nauto c = color2::red1;\n```\n\n\n\n#### 条款11、优先选用删除函数\n\n在类里面的函数后面加上`=delete`可以组x织客户去调用函数，说明该函数已经失效。\n\n任何函数都可以成为删除函数，但只有成员函数能声明为private。\n\n####  条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\n\n函数重写的必要条件：\n\n* 基类中的函数必须是虚函数\n* 函数名字必须完全相同（析构函数例外）\n* 函数形参型别完全相同\n* 函数常量性必须完全相同\n* 函数返回值和异常规格必须兼容\n* 引用饰词必须完全相同\n\n成员函数引用饰词的作用就是针对发起成员函数调用的现象，加一些区分度。\n\n#### 条款13、优先选用const_iterator\n\n```\n// 建立iterator并插入\nstd::vector<int>::iterator it = std::find(values.begin(), values.end(), 1983);\nvalues.insert(it, 1998)\n```\n\n容器的cbegin和cend都返回的是const_iterator型别，不能修改，但是可以通过insert插入元素到列表中。\n\n将const元素传入begin函数中，会产生一个const_iterator\n\n```\n// 条款13、优先选用const_iterator\nvoid demo13() {\n\tstd::vector<int> vec{ 1,2,3,4,5 };\n\n\tfor (std::vector<int>::iterator iter = vec.begin(); iter != vec.end(); ++iter) {\n\t\tstd::cout << \"old element:\" << *iter;\t\t\t\t// 打印元素\n\n\t\t(*iter) += 1;\t\t\t\t\t\t\t\t\t\t// 通过迭代器修改对应元素\n\t\tstd::cout << \", new:\" << *iter << std::endl;\n\n\t}\n\n\tauto it = std::find(vec.cbegin(), vec.cend(), 3);\n\tvec.insert(it, 1);\n\n\tfor (std::vector<int>::const_iterator iter = vec.cbegin(); iter != vec.cend(); ++iter) {\n\t\tstd::cout << \"old element:\" << *iter << std::endl;\t\t\t\t// 打印元素\n\n\t}\n}\n```\n\n* 优先使用begin，end等，而非成员函数版本\n\n#### 条款14、对于确保不发生异常的函数，加上noexcept声明\n\n在C++98中，出现异常后，调用栈会开解至异常出现的调用方，C++11中，中止前只是可能会解开。因此优化器不需要再异常传出函数的前提下，将执行期间栈保持在开解状态，也不用在异常溢出函数的前提下，保证所有对象的构造顺序的逆序完成解析。\n\n`push_back`中采用的原则是：能移动则移动，必须复制才复制。具有强异常性质。\n\n使用`noexcept`能够极大程度的便于编译器优化。\n\n析构函数和内存释放函数都隐式的具备又noexcept的性质。\n\n#### 条款15、使用constexpr\n\nconst：表示“只读”的含义，被const修饰的变量不能够修改，可以定义编译器和运行期的常量\n\nconstexpr：表示“常量”的含义，只能够定义编译器的常量，可以提高运行效率\n\n* constexpr修饰的函数在编译过程展开，被隐式的转化为了内联函数\n* 如果要修改const修饰的变量的值，需要加上关键字volatile\n\nconstexpr函数仅限于掺入和返回字面型别：在编译器就可以确定的数据类型。\n\n#### 条款16、使用const成员函数的线程安全性\n\n#### 条款17、\n\n\n\n### 第四章、智能指针\n\n> 智能指针是用来管理内存泄漏的，内存泄漏：在为对象动态申请内存空间后，如存在忘记释放内存，或者运行过程中程序中断的问题，导致申请的内存空间被占用造成内存泄漏。\n\n#### 条款18、使用unique_ptr管理具备专属所有权的资源\n\n智能指针`unique_ptr`\n\n* 独享它的对象\n* 包含头文件#include<memory>\n* 可以高效的转化为`shared_ptr`\n\nunique_ptr和裸指针在默认情况下有着相同的尺寸，实现的是专属所有权语义，\n\n工厂函数返回的是一个`unique_ptr`指针，可以用auto来接收。\n\n* 将一个裸指针赋值给`unique_ptr`将不会通过编译\n\n```\n// 智能指针用法\nclass AA {\npublic:\n\tstd::string _name;\n\tAA() {\n\t\tstd::cout << _name << \"调用构造函数1\\n\";\n\t}\n\tAA(const std::string& m_name) :_name(m_name) {\n\n\t\tstd::cout << _name << \"调用构造函数2\\n\";\n\t}\n\t~AA() {\n\n\t\tstd::cout << \"调用析构函数\\n\";\n\t}\n};\n\nvoid demo19() {\n\tusing std::unique_ptr;\n\tusing std::make_unique;\n\tunique_ptr<AA> p0(new AA(\"xiaoli\"));\n\tunique_ptr<AA> p1 = std::make_unique<AA>(\"xiaowang\");\n\tunique_ptr<int> pp1 = make_unique<int>();         // 数据类型为int。\n\tunique_ptr<AA> pp2 = make_unique<AA>();       // 数据类型为AA，默认构造函数。\n\tunique_ptr<AA> pp3 = make_unique<AA>(\"xiaoxi\");  // 数据类型为AA，一个参数的构造函数。\n}\n```\n\n\n\n#### 条款19、使用shared_ptr管理具备共享所有权的资源\n\nRAII思想（Resource Acquisition Is Initialization）资源获取即初始化。将获取的资源和对象的生命周期绑定在一起。\n\n* 设计RAII类的四个步骤\n  * 设计一个类封装资源，资源可以是内存、文件、socket、锁等等一切\n  * 在构造函数中执行资源的初始化，比如申请内存、打开文件、申请锁\n  * 在析构函数中执行销毁操作，比如释放内存、关闭文件、释放锁\n  * 使用时声明一个该对象的类，一般在你希望的作用域声明即可，比如在函数开始，或者作为类的成员变量\n\n引用计数带来的一些性能问题：\n\n* 尺寸是裸指针的两倍\n* 引用计数的内存必须动态分配\n* 引用计数的递增和递减必须是原子操作\n\n从一个已有shared_ptr移动构造一个新的shared_ptr会将源shared_ptr置空，不会增加引用计数。\n\n使用shared_ptr如果出现了循环引用则会导致计数用于也无法回到0，资源将无法被释放。使用`weak_ptr`配合使用便可以解决这个问题，因为`weak_ptr`不会控制对象的生命周期，但是知道对象释放的时间，会和对象共同消失。\n\n#### 条款20、weak_ptr使用\n\n1、使用`weak_ptr`代替可能空悬的`shared_ptr`\n\n2、`weak_ptr`可以用于缓存，观察者列表，以及避免shared_ptr指针环路\n\n#### 条款21、优先使用make_...ptr而不是直接使用new\n\n1、使用new的代码更加冗余\n\n2、使用new会触发两次内存分配，而使用make系列则只用触发一次内存分配\n\n#### 条款22、Pimpl用法\n\n将类内的数据成员使用struct结构体打包起来，并使用一个智能指针指向该结构体，在.cpp文件中对这些数据进行操作，能够极大便利的降低类的客户和类的实现者之间的依赖。\n\n### 右值引用、移动语义和完美转发\n\n* 移动语义可以使得编译器能够使用移动操作代替昂贵的复制操作。\n* 完美转发使得人们可以撰写接收任意实参的函数模板，并将其转发到其它函数，目标函数会接收到与转发函数所接收到的完全相同的实参。\n\n#### 条款23、理解std::move和std::forward\n\n使用move可以将参数强制转化为右值\n\n如果想要取得对某一个对象执行移动操作的能力，则不要将其声明为常量，因为针对常量对象执行的移动操作将会变化为复制操作。\n\nforward是一个有条件的强制转化，只有当实参是使用右值完成初始化时，它才会执行向右值型别的强制转化。如果需要选择性的对某一些形参进行左值或者右值引用，则可以用forward来进行标识。\n\n#### 条款24、区分万能引用和右值引用\n\n在模板和类型推导中出现`& &`很大可能就是万能引用：即表达式或者传入的实参，既可以是左值也可以时右值。\n\n#### 条款25、针对右值引用使用move，针对万能引用使用forward\n\n因为万能引用使用`forward`它可以有条件的自动转化传入的实参作为左值还是右值。\n\n#### \n\n#### 条例30、完美转发失败的情形\n\n完美转发的含义：一个函数把自己的形参传递（转发）给另一个函数，为了使得第二个函数接受第一个函数所接受的同一个对象。\n\n完美转发不仅仅转发对象，还转发其显著的特征：型别、是左值还是右值，是否带有const或者volatile修饰词。\n\n转发失败的定义：使用某特定实参调用转发函数会执行某操作，但使用同一实参调用其封装后的函数会执行不同的操作。即右值引用成功，但是万能引用失败。\n\n具体形参：\n\n* 大括号初始化的列表\n* 0或者NULL用作空指针\n* 仅有声明的整型static const成员变量\n* 重载的函数名字和模板名字\n* 位域\n\n### 第五章、lambda表达式\n\nlambda运行期的对象是`闭包`，根据不同的捕获模式，闭包会持有数据的副本或引用。\n\n闭包类就是实例化闭包的类，每个lambda式都会触发编译器生成一个独一无二的闭包类。闭包中的语句会变成它的闭包类成员函数的可执行指令。\n\n#### 条款31、避免默认捕获模式\n\nC++11有两种默认捕获模式：按值或按引用。按引用的默认捕获模式可能导致空悬引用。\n\n按引用捕获会导致闭包包含指涉到局部变量的引用，或者指涉到定义lambda式作用域内的形参的引用。一旦lambda式所创建的闭包越过了该局部变量或者形参的生命周期，那么闭包内的引用就会悬空。\n\n","slug":"Effective-Modern-C-notes","published":1,"updated":"2024-06-05T09:03:03.518Z","comments":1,"layout":"post","photos":[],"_id":"clyfintth000g08jv8e5qdnby","content":"<h2 id=\"Effective-Modern-C-学习笔记\"><a href=\"#Effective-Modern-C-学习笔记\" class=\"headerlink\" title=\"Effective Modern C++学习笔记\"></a>Effective Modern C++学习笔记</h2><blockquote>\n<p>重点掌握auto、智能指针、移动构造、lambda</p>\n</blockquote>\n<h3 id=\"第一章、类型推导\"><a href=\"#第一章、类型推导\" class=\"headerlink\" title=\"第一章、类型推导\"></a>第一章、类型推导</h3><h4 id=\"条款1、模板类型推导\"><a href=\"#条款1、模板类型推导\" class=\"headerlink\" title=\"条款1、模板类型推导\"></a>条款1、模板类型推导</h4><figure class=\"highlight d\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs d\">情况一、按值传递，传入副本<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T param)<br><br>情况二、引用传递，传入地址<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(<span class=\"hljs-keyword\">const</span> T&amp; param)<br><br>情况三、指针传递<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T* param)<br><br>万能引用，即也可以引用右值<br>情况四、万能引用，如果是右值，则传入的是右值的地址<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T&amp;&amp; param)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>当向引用型别的形参传入const对象时，他们期望该对象保持其不可该修改的属性，即const引用</p>\n<p>因此向持有T&amp;型别的模板传入const对象时安全的</p>\n</blockquote>\n<ul>\n<li><p>当使用万能引用时，型别推导规则会区分实参是左值还是右值，如果是左值就是单个引用情况“&amp;”，如果是右值则是“&amp;&amp;”情况</p>\n</li>\n<li><p>如果是按值传递，则传入的是一个副本，无论做什么操作都无法改变原始的数据</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> name[] = <span class=\"hljs-string\">&quot;sda&quot;</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>* ptrToName = name<br><br><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-type\">void</span> <span class=\"hljs-built_in\">f</span>(T param)<br><span class=\"hljs-built_in\">f</span>(name)<br><br>T会推到成<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>*的类型<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款2、auto类型推导\"><a href=\"#条款2、auto类型推导\" class=\"headerlink\" title=\"条款2、auto类型推导\"></a>条款2、auto类型推导</h4><blockquote>\n<p>auto类型推导就是模板类型推导，当某一个变量采用auto来声明时，auto则扮演模板中的角色，通过表达式的右边的值推出左边。</p>\n</blockquote>\n<p>C++14允许auto来说明函数返回值需要推导</p>\n<h4 id=\"条款3、decltype\"><a href=\"#条款3、decltype\" class=\"headerlink\" title=\"条款3、decltype\"></a>条款3、decltype</h4><p>decltype可以声明返回值型别依赖于形参性别的函数模板，因为函数模板的数据类型不确定，通过使用decltype引用一个模板类型的数据，可以推出该函数模板的类型，通过尾序返回值可返回该数据类型的结果。</p>\n<p>在对万能引用进行推导时，返回值需要加上std::forward</p>\n<h3 id=\"第二章、auto\"><a href=\"#第二章、auto\" class=\"headerlink\" title=\"第二章、auto\"></a>第二章、auto</h3><blockquote>\n<p>优先使用auto定义，而非使用显式定义，可以防止对象忘记初始化的错误。</p>\n</blockquote>\n<p>auto优点</p>\n<ul>\n<li>1、避免初始化变量和冗余的变量声明（如，迭代器声明）</li>\n<li>2、在不同位的操作系统移植过程中可以避免参数位数表达不一致的问题</li>\n</ul>\n<p>auto不能用在vector&lt; bool &gt;中，在单个返回operator[]时返回的是bool的引用。</p>\n<h3 id=\"第三章——模板还是有点晦涩难懂\"><a href=\"#第三章——模板还是有点晦涩难懂\" class=\"headerlink\" title=\"第三章——模板还是有点晦涩难懂\"></a>第三章——模板还是有点晦涩难懂</h3><h4 id=\"条款7、创建对象注意区分（）和\"><a href=\"#条款7、创建对象注意区分（）和\" class=\"headerlink\" title=\"条款7、创建对象注意区分（）和{}\"></a>条款7、创建对象注意区分（）和{}</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 使用大括号初始化容器会强烈优先选择带有std::initializer_list类别形参的构造函数</span><br>vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">5</span>&#125;<br></code></pre></td></tr></table></figure>\n<p>空大括号表达的是没有形参，如果使用list的话，应该在小括号在再加一个大括号。</p>\n<h4 id=\"条款8、优先使用nullptr\"><a href=\"#条款8、优先使用nullptr\" class=\"headerlink\" title=\"条款8、优先使用nullptr\"></a>条款8、优先使用nullptr</h4><p>作为指针传入参数时，传入空指针优先使用nullptr，因为nullptr指代明确，不像0和NULL既可以指代整型也可以指代空指针。</p>\n<p>nullptr可以隐式的转化为所有指针类型。</p>\n<h4 id=\"条款9、优先使用别名声明，而非typedef————-回头看\"><a href=\"#条款9、优先使用别名声明，而非typedef————-回头看\" class=\"headerlink\" title=\"条款9、优先使用别名声明，而非typedef————-回头看\"></a>条款9、优先使用别名声明，而非typedef————-回头看</h4><p>using作用可以等效于typedef用于别名的声明，使用using的优势在于，可以将其与模板进行结合起来，别名模板。</p>\n<h4 id=\"条款10、优先使用限定作用域的枚举\"><a href=\"#条款10、优先使用限定作用域的枚举\" class=\"headerlink\" title=\"条款10、优先使用限定作用域的枚举\"></a>条款10、优先使用限定作用域的枚举</h4><blockquote>\n<p>enum class name{}；使用class关键词限定作用域，又称为枚举类。</p>\n</blockquote>\n<p>使用枚举的成员需要用到<code>name::</code>来取。</p>\n<ul>\n<li>使用限定作用域的枚举的枚举量是更强型别的，不限范围的枚举型别中的枚举量可以隐式转化到整数类别。</li>\n<li>强类型的参数不能够和非同类型的参数进行比较，也不能进行隐式转换，必须通过强制转化才能够进行比较。</li>\n<li>限定作用域的枚举型别可以进行前置声明。不限定作用域的枚举要想进行前置声明，则可以进行对底层型别的声明：enum color: std::uint8_t</li>\n</ul>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-comment\">// 条款10、优先使用限定作用域的枚举</span><br><span class=\"hljs-keyword\">enum</span> color &#123;<br>\tblack,<br>\twhite,<br>\tred<br>&#125;;<br><br><span class=\"hljs-comment\">// 重定义报错</span><br><span class=\"hljs-comment\">// auto white = false;</span><br><br><span class=\"hljs-comment\">// 枚举类，限定作用域在color2中</span><br><span class=\"hljs-keyword\">enum</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-symbol\">color2</span> &#123;<br>\tblack1,<br>\twhite1,<br>\tred1<br>&#125;;<br><br><span class=\"hljs-built_in\">auto</span> white1 = <span class=\"hljs-literal\">false</span>;<br><span class=\"hljs-built_in\">auto</span> c = color2::red1;<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款11、优先选用删除函数\"><a href=\"#条款11、优先选用删除函数\" class=\"headerlink\" title=\"条款11、优先选用删除函数\"></a>条款11、优先选用删除函数</h4><p>在类里面的函数后面加上<code>=delete</code>可以组x织客户去调用函数，说明该函数已经失效。</p>\n<p>任何函数都可以成为删除函数，但只有成员函数能声明为private。</p>\n<h4 id=\"条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\"><a href=\"#条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\" class=\"headerlink\" title=\"条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\"></a>条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数</h4><p>函数重写的必要条件：</p>\n<ul>\n<li>基类中的函数必须是虚函数</li>\n<li>函数名字必须完全相同（析构函数例外）</li>\n<li>函数形参型别完全相同</li>\n<li>函数常量性必须完全相同</li>\n<li>函数返回值和异常规格必须兼容</li>\n<li>引用饰词必须完全相同</li>\n</ul>\n<p>成员函数引用饰词的作用就是针对发起成员函数调用的现象，加一些区分度。</p>\n<h4 id=\"条款13、优先选用const-iterator\"><a href=\"#条款13、优先选用const-iterator\" class=\"headerlink\" title=\"条款13、优先选用const_iterator\"></a>条款13、优先选用const_iterator</h4><figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">// 建立iterator并插入<br>std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::iterator it = std::find(<span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">begin</span>(), <span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">end</span>(), <span class=\"hljs-number\">1983</span>);<br><span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">insert</span>(it, <span class=\"hljs-number\">1998</span>)<br></code></pre></td></tr></table></figure>\n<p>容器的cbegin和cend都返回的是const_iterator型别，不能修改，但是可以通过insert插入元素到列表中。</p>\n<p>将const元素传入begin函数中，会产生一个const_iterator</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 条款13、优先选用const_iterator</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">demo13</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\tstd::vector&lt;<span class=\"hljs-type\">int</span>&gt; vec&#123; <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">5</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::iterator iter = vec.<span class=\"hljs-built_in\">begin</span>(); iter != vec.<span class=\"hljs-built_in\">end</span>(); ++iter) &#123;<br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;old element:&quot;</span> &lt;&lt; *iter;\t\t\t\t<span class=\"hljs-comment\">// 打印元素</span><br><br>\t\t(*iter) += <span class=\"hljs-number\">1</span>;\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">// 通过迭代器修改对应元素</span><br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;, new:&quot;</span> &lt;&lt; *iter &lt;&lt; std::endl;<br><br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">auto</span> it = std::<span class=\"hljs-built_in\">find</span>(vec.<span class=\"hljs-built_in\">cbegin</span>(), vec.<span class=\"hljs-built_in\">cend</span>(), <span class=\"hljs-number\">3</span>);<br>\tvec.<span class=\"hljs-built_in\">insert</span>(it, <span class=\"hljs-number\">1</span>);<br><br>\t<span class=\"hljs-keyword\">for</span> (std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::const_iterator iter = vec.<span class=\"hljs-built_in\">cbegin</span>(); iter != vec.<span class=\"hljs-built_in\">cend</span>(); ++iter) &#123;<br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;old element:&quot;</span> &lt;&lt; *iter &lt;&lt; std::endl;\t\t\t\t<span class=\"hljs-comment\">// 打印元素</span><br><br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>优先使用begin，end等，而非成员函数版本</li>\n</ul>\n<h4 id=\"条款14、对于确保不发生异常的函数，加上noexcept声明\"><a href=\"#条款14、对于确保不发生异常的函数，加上noexcept声明\" class=\"headerlink\" title=\"条款14、对于确保不发生异常的函数，加上noexcept声明\"></a>条款14、对于确保不发生异常的函数，加上noexcept声明</h4><p>在C++98中，出现异常后，调用栈会开解至异常出现的调用方，C++11中，中止前只是可能会解开。因此优化器不需要再异常传出函数的前提下，将执行期间栈保持在开解状态，也不用在异常溢出函数的前提下，保证所有对象的构造顺序的逆序完成解析。</p>\n<p><code>push_back</code>中采用的原则是：能移动则移动，必须复制才复制。具有强异常性质。</p>\n<p>使用<code>noexcept</code>能够极大程度的便于编译器优化。</p>\n<p>析构函数和内存释放函数都隐式的具备又noexcept的性质。</p>\n<h4 id=\"条款15、使用constexpr\"><a href=\"#条款15、使用constexpr\" class=\"headerlink\" title=\"条款15、使用constexpr\"></a>条款15、使用constexpr</h4><p>const：表示“只读”的含义，被const修饰的变量不能够修改，可以定义编译器和运行期的常量</p>\n<p>constexpr：表示“常量”的含义，只能够定义编译器的常量，可以提高运行效率</p>\n<ul>\n<li>constexpr修饰的函数在编译过程展开，被隐式的转化为了内联函数</li>\n<li>如果要修改const修饰的变量的值，需要加上关键字volatile</li>\n</ul>\n<p>constexpr函数仅限于掺入和返回字面型别：在编译器就可以确定的数据类型。</p>\n<h4 id=\"条款16、使用const成员函数的线程安全性\"><a href=\"#条款16、使用const成员函数的线程安全性\" class=\"headerlink\" title=\"条款16、使用const成员函数的线程安全性\"></a>条款16、使用const成员函数的线程安全性</h4><h4 id=\"条款17、\"><a href=\"#条款17、\" class=\"headerlink\" title=\"条款17、\"></a>条款17、</h4><h3 id=\"第四章、智能指针\"><a href=\"#第四章、智能指针\" class=\"headerlink\" title=\"第四章、智能指针\"></a>第四章、智能指针</h3><blockquote>\n<p>智能指针是用来管理内存泄漏的，内存泄漏：在为对象动态申请内存空间后，如存在忘记释放内存，或者运行过程中程序中断的问题，导致申请的内存空间被占用造成内存泄漏。</p>\n</blockquote>\n<h4 id=\"条款18、使用unique-ptr管理具备专属所有权的资源\"><a href=\"#条款18、使用unique-ptr管理具备专属所有权的资源\" class=\"headerlink\" title=\"条款18、使用unique_ptr管理具备专属所有权的资源\"></a>条款18、使用unique_ptr管理具备专属所有权的资源</h4><p>智能指针<code>unique_ptr</code></p>\n<ul>\n<li>独享它的对象</li>\n<li>包含头文件#include<memory></li>\n<li>可以高效的转化为<code>shared_ptr</code></li>\n</ul>\n<p>unique_ptr和裸指针在默认情况下有着相同的尺寸，实现的是专属所有权语义，</p>\n<p>工厂函数返回的是一个<code>unique_ptr</code>指针，可以用auto来接收。</p>\n<ul>\n<li>将一个裸指针赋值给<code>unique_ptr</code>将不会通过编译</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 智能指针用法</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AA</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>\tstd::string _name;<br>\t<span class=\"hljs-built_in\">AA</span>() &#123;<br>\t\tstd::cout &lt;&lt; _name &lt;&lt; <span class=\"hljs-string\">&quot;调用构造函数1\\n&quot;</span>;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">AA</span>(<span class=\"hljs-type\">const</span> std::string&amp; m_name) :_name(m_name) &#123;<br><br>\t\tstd::cout &lt;&lt; _name &lt;&lt; <span class=\"hljs-string\">&quot;调用构造函数2\\n&quot;</span>;<br>\t&#125;<br>\t~<span class=\"hljs-built_in\">AA</span>() &#123;<br><br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;调用析构函数\\n&quot;</span>;<br>\t&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">demo19</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">using</span> std::unique_ptr;<br>\t<span class=\"hljs-keyword\">using</span> std::make_unique;<br>\t<span class=\"hljs-function\">unique_ptr&lt;AA&gt; <span class=\"hljs-title\">p0</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">new</span> AA(<span class=\"hljs-string\">&quot;xiaoli&quot;</span>))</span></span>;<br>\tunique_ptr&lt;AA&gt; p1 = std::<span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;(<span class=\"hljs-string\">&quot;xiaowang&quot;</span>);<br>\tunique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; pp1 = <span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;();         <span class=\"hljs-comment\">// 数据类型为int。</span><br>\tunique_ptr&lt;AA&gt; pp2 = <span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;();       <span class=\"hljs-comment\">// 数据类型为AA，默认构造函数。</span><br>\tunique_ptr&lt;AA&gt; pp3 = <span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;(<span class=\"hljs-string\">&quot;xiaoxi&quot;</span>);  <span class=\"hljs-comment\">// 数据类型为AA，一个参数的构造函数。</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款19、使用shared-ptr管理具备共享所有权的资源\"><a href=\"#条款19、使用shared-ptr管理具备共享所有权的资源\" class=\"headerlink\" title=\"条款19、使用shared_ptr管理具备共享所有权的资源\"></a>条款19、使用shared_ptr管理具备共享所有权的资源</h4><p>RAII思想（Resource Acquisition Is Initialization）资源获取即初始化。将获取的资源和对象的生命周期绑定在一起。</p>\n<ul>\n<li>设计RAII类的四个步骤<ul>\n<li>设计一个类封装资源，资源可以是内存、文件、socket、锁等等一切</li>\n<li>在构造函数中执行资源的初始化，比如申请内存、打开文件、申请锁</li>\n<li>在析构函数中执行销毁操作，比如释放内存、关闭文件、释放锁</li>\n<li>使用时声明一个该对象的类，一般在你希望的作用域声明即可，比如在函数开始，或者作为类的成员变量</li>\n</ul>\n</li>\n</ul>\n<p>引用计数带来的一些性能问题：</p>\n<ul>\n<li>尺寸是裸指针的两倍</li>\n<li>引用计数的内存必须动态分配</li>\n<li>引用计数的递增和递减必须是原子操作</li>\n</ul>\n<p>从一个已有shared_ptr移动构造一个新的shared_ptr会将源shared_ptr置空，不会增加引用计数。</p>\n<p>使用shared_ptr如果出现了循环引用则会导致计数用于也无法回到0，资源将无法被释放。使用<code>weak_ptr</code>配合使用便可以解决这个问题，因为<code>weak_ptr</code>不会控制对象的生命周期，但是知道对象释放的时间，会和对象共同消失。</p>\n<h4 id=\"条款20、weak-ptr使用\"><a href=\"#条款20、weak-ptr使用\" class=\"headerlink\" title=\"条款20、weak_ptr使用\"></a>条款20、weak_ptr使用</h4><p>1、使用<code>weak_ptr</code>代替可能空悬的<code>shared_ptr</code></p>\n<p>2、<code>weak_ptr</code>可以用于缓存，观察者列表，以及避免shared_ptr指针环路</p>\n<h4 id=\"条款21、优先使用make-…ptr而不是直接使用new\"><a href=\"#条款21、优先使用make-…ptr而不是直接使用new\" class=\"headerlink\" title=\"条款21、优先使用make_…ptr而不是直接使用new\"></a>条款21、优先使用make_…ptr而不是直接使用new</h4><p>1、使用new的代码更加冗余</p>\n<p>2、使用new会触发两次内存分配，而使用make系列则只用触发一次内存分配</p>\n<h4 id=\"条款22、Pimpl用法\"><a href=\"#条款22、Pimpl用法\" class=\"headerlink\" title=\"条款22、Pimpl用法\"></a>条款22、Pimpl用法</h4><p>将类内的数据成员使用struct结构体打包起来，并使用一个智能指针指向该结构体，在.cpp文件中对这些数据进行操作，能够极大便利的降低类的客户和类的实现者之间的依赖。</p>\n<h3 id=\"右值引用、移动语义和完美转发\"><a href=\"#右值引用、移动语义和完美转发\" class=\"headerlink\" title=\"右值引用、移动语义和完美转发\"></a>右值引用、移动语义和完美转发</h3><ul>\n<li>移动语义可以使得编译器能够使用移动操作代替昂贵的复制操作。</li>\n<li>完美转发使得人们可以撰写接收任意实参的函数模板，并将其转发到其它函数，目标函数会接收到与转发函数所接收到的完全相同的实参。</li>\n</ul>\n<h4 id=\"条款23、理解std-move和std-forward\"><a href=\"#条款23、理解std-move和std-forward\" class=\"headerlink\" title=\"条款23、理解std::move和std::forward\"></a>条款23、理解std::move和std::forward</h4><p>使用move可以将参数强制转化为右值</p>\n<p>如果想要取得对某一个对象执行移动操作的能力，则不要将其声明为常量，因为针对常量对象执行的移动操作将会变化为复制操作。</p>\n<p>forward是一个有条件的强制转化，只有当实参是使用右值完成初始化时，它才会执行向右值型别的强制转化。如果需要选择性的对某一些形参进行左值或者右值引用，则可以用forward来进行标识。</p>\n<h4 id=\"条款24、区分万能引用和右值引用\"><a href=\"#条款24、区分万能引用和右值引用\" class=\"headerlink\" title=\"条款24、区分万能引用和右值引用\"></a>条款24、区分万能引用和右值引用</h4><p>在模板和类型推导中出现<code>&amp; &amp;</code>很大可能就是万能引用：即表达式或者传入的实参，既可以是左值也可以时右值。</p>\n<h4 id=\"条款25、针对右值引用使用move，针对万能引用使用forward\"><a href=\"#条款25、针对右值引用使用move，针对万能引用使用forward\" class=\"headerlink\" title=\"条款25、针对右值引用使用move，针对万能引用使用forward\"></a>条款25、针对右值引用使用move，针对万能引用使用forward</h4><p>因为万能引用使用<code>forward</code>它可以有条件的自动转化传入的实参作为左值还是右值。</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h4><h4 id=\"条例30、完美转发失败的情形\"><a href=\"#条例30、完美转发失败的情形\" class=\"headerlink\" title=\"条例30、完美转发失败的情形\"></a>条例30、完美转发失败的情形</h4><p>完美转发的含义：一个函数把自己的形参传递（转发）给另一个函数，为了使得第二个函数接受第一个函数所接受的同一个对象。</p>\n<p>完美转发不仅仅转发对象，还转发其显著的特征：型别、是左值还是右值，是否带有const或者volatile修饰词。</p>\n<p>转发失败的定义：使用某特定实参调用转发函数会执行某操作，但使用同一实参调用其封装后的函数会执行不同的操作。即右值引用成功，但是万能引用失败。</p>\n<p>具体形参：</p>\n<ul>\n<li>大括号初始化的列表</li>\n<li>0或者NULL用作空指针</li>\n<li>仅有声明的整型static const成员变量</li>\n<li>重载的函数名字和模板名字</li>\n<li>位域</li>\n</ul>\n<h3 id=\"第五章、lambda表达式\"><a href=\"#第五章、lambda表达式\" class=\"headerlink\" title=\"第五章、lambda表达式\"></a>第五章、lambda表达式</h3><p>lambda运行期的对象是<code>闭包</code>，根据不同的捕获模式，闭包会持有数据的副本或引用。</p>\n<p>闭包类就是实例化闭包的类，每个lambda式都会触发编译器生成一个独一无二的闭包类。闭包中的语句会变成它的闭包类成员函数的可执行指令。</p>\n<h4 id=\"条款31、避免默认捕获模式\"><a href=\"#条款31、避免默认捕获模式\" class=\"headerlink\" title=\"条款31、避免默认捕获模式\"></a>条款31、避免默认捕获模式</h4><p>C++11有两种默认捕获模式：按值或按引用。按引用的默认捕获模式可能导致空悬引用。</p>\n<p>按引用捕获会导致闭包包含指涉到局部变量的引用，或者指涉到定义lambda式作用域内的形参的引用。一旦lambda式所创建的闭包越过了该局部变量或者形参的生命周期，那么闭包内的引用就会悬空。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"Effective-Modern-C-学习笔记\"><a href=\"#Effective-Modern-C-学习笔记\" class=\"headerlink\" title=\"Effective Modern C++学习笔记\"></a>Effective Modern C++学习笔记</h2><blockquote>\n<p>重点掌握auto、智能指针、移动构造、lambda</p>\n</blockquote>\n<h3 id=\"第一章、类型推导\"><a href=\"#第一章、类型推导\" class=\"headerlink\" title=\"第一章、类型推导\"></a>第一章、类型推导</h3><h4 id=\"条款1、模板类型推导\"><a href=\"#条款1、模板类型推导\" class=\"headerlink\" title=\"条款1、模板类型推导\"></a>条款1、模板类型推导</h4><figure class=\"highlight d\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs d\">情况一、按值传递，传入副本<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T param)<br><br>情况二、引用传递，传入地址<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(<span class=\"hljs-keyword\">const</span> T&amp; param)<br><br>情况三、指针传递<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T* param)<br><br>万能引用，即也可以引用右值<br>情况四、万能引用，如果是右值，则传入的是右值的地址<br><span class=\"hljs-keyword\">template</span>&lt;typename T&gt;<br><span class=\"hljs-keyword\">void</span> f(T&amp;&amp; param)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>当向引用型别的形参传入const对象时，他们期望该对象保持其不可该修改的属性，即const引用</p>\n<p>因此向持有T&amp;型别的模板传入const对象时安全的</p>\n</blockquote>\n<ul>\n<li><p>当使用万能引用时，型别推导规则会区分实参是左值还是右值，如果是左值就是单个引用情况“&amp;”，如果是右值则是“&amp;&amp;”情况</p>\n</li>\n<li><p>如果是按值传递，则传入的是一个副本，无论做什么操作都无法改变原始的数据</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> name[] = <span class=\"hljs-string\">&quot;sda&quot;</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>* ptrToName = name<br><br><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-type\">void</span> <span class=\"hljs-built_in\">f</span>(T param)<br><span class=\"hljs-built_in\">f</span>(name)<br><br>T会推到成<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>*的类型<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款2、auto类型推导\"><a href=\"#条款2、auto类型推导\" class=\"headerlink\" title=\"条款2、auto类型推导\"></a>条款2、auto类型推导</h4><blockquote>\n<p>auto类型推导就是模板类型推导，当某一个变量采用auto来声明时，auto则扮演模板中的角色，通过表达式的右边的值推出左边。</p>\n</blockquote>\n<p>C++14允许auto来说明函数返回值需要推导</p>\n<h4 id=\"条款3、decltype\"><a href=\"#条款3、decltype\" class=\"headerlink\" title=\"条款3、decltype\"></a>条款3、decltype</h4><p>decltype可以声明返回值型别依赖于形参性别的函数模板，因为函数模板的数据类型不确定，通过使用decltype引用一个模板类型的数据，可以推出该函数模板的类型，通过尾序返回值可返回该数据类型的结果。</p>\n<p>在对万能引用进行推导时，返回值需要加上std::forward</p>\n<h3 id=\"第二章、auto\"><a href=\"#第二章、auto\" class=\"headerlink\" title=\"第二章、auto\"></a>第二章、auto</h3><blockquote>\n<p>优先使用auto定义，而非使用显式定义，可以防止对象忘记初始化的错误。</p>\n</blockquote>\n<p>auto优点</p>\n<ul>\n<li>1、避免初始化变量和冗余的变量声明（如，迭代器声明）</li>\n<li>2、在不同位的操作系统移植过程中可以避免参数位数表达不一致的问题</li>\n</ul>\n<p>auto不能用在vector&lt; bool &gt;中，在单个返回operator[]时返回的是bool的引用。</p>\n<h3 id=\"第三章——模板还是有点晦涩难懂\"><a href=\"#第三章——模板还是有点晦涩难懂\" class=\"headerlink\" title=\"第三章——模板还是有点晦涩难懂\"></a>第三章——模板还是有点晦涩难懂</h3><h4 id=\"条款7、创建对象注意区分（）和\"><a href=\"#条款7、创建对象注意区分（）和\" class=\"headerlink\" title=\"条款7、创建对象注意区分（）和{}\"></a>条款7、创建对象注意区分（）和{}</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 使用大括号初始化容器会强烈优先选择带有std::initializer_list类别形参的构造函数</span><br>vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">5</span>&#125;<br></code></pre></td></tr></table></figure>\n<p>空大括号表达的是没有形参，如果使用list的话，应该在小括号在再加一个大括号。</p>\n<h4 id=\"条款8、优先使用nullptr\"><a href=\"#条款8、优先使用nullptr\" class=\"headerlink\" title=\"条款8、优先使用nullptr\"></a>条款8、优先使用nullptr</h4><p>作为指针传入参数时，传入空指针优先使用nullptr，因为nullptr指代明确，不像0和NULL既可以指代整型也可以指代空指针。</p>\n<p>nullptr可以隐式的转化为所有指针类型。</p>\n<h4 id=\"条款9、优先使用别名声明，而非typedef————-回头看\"><a href=\"#条款9、优先使用别名声明，而非typedef————-回头看\" class=\"headerlink\" title=\"条款9、优先使用别名声明，而非typedef————-回头看\"></a>条款9、优先使用别名声明，而非typedef————-回头看</h4><p>using作用可以等效于typedef用于别名的声明，使用using的优势在于，可以将其与模板进行结合起来，别名模板。</p>\n<h4 id=\"条款10、优先使用限定作用域的枚举\"><a href=\"#条款10、优先使用限定作用域的枚举\" class=\"headerlink\" title=\"条款10、优先使用限定作用域的枚举\"></a>条款10、优先使用限定作用域的枚举</h4><blockquote>\n<p>enum class name{}；使用class关键词限定作用域，又称为枚举类。</p>\n</blockquote>\n<p>使用枚举的成员需要用到<code>name::</code>来取。</p>\n<ul>\n<li>使用限定作用域的枚举的枚举量是更强型别的，不限范围的枚举型别中的枚举量可以隐式转化到整数类别。</li>\n<li>强类型的参数不能够和非同类型的参数进行比较，也不能进行隐式转换，必须通过强制转化才能够进行比较。</li>\n<li>限定作用域的枚举型别可以进行前置声明。不限定作用域的枚举要想进行前置声明，则可以进行对底层型别的声明：enum color: std::uint8_t</li>\n</ul>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-comment\">// 条款10、优先使用限定作用域的枚举</span><br><span class=\"hljs-keyword\">enum</span> color &#123;<br>\tblack,<br>\twhite,<br>\tred<br>&#125;;<br><br><span class=\"hljs-comment\">// 重定义报错</span><br><span class=\"hljs-comment\">// auto white = false;</span><br><br><span class=\"hljs-comment\">// 枚举类，限定作用域在color2中</span><br><span class=\"hljs-keyword\">enum</span> <span class=\"hljs-keyword\">class</span> <span class=\"hljs-symbol\">color2</span> &#123;<br>\tblack1,<br>\twhite1,<br>\tred1<br>&#125;;<br><br><span class=\"hljs-built_in\">auto</span> white1 = <span class=\"hljs-literal\">false</span>;<br><span class=\"hljs-built_in\">auto</span> c = color2::red1;<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款11、优先选用删除函数\"><a href=\"#条款11、优先选用删除函数\" class=\"headerlink\" title=\"条款11、优先选用删除函数\"></a>条款11、优先选用删除函数</h4><p>在类里面的函数后面加上<code>=delete</code>可以组x织客户去调用函数，说明该函数已经失效。</p>\n<p>任何函数都可以成为删除函数，但只有成员函数能声明为private。</p>\n<h4 id=\"条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\"><a href=\"#条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\" class=\"headerlink\" title=\"条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数\"></a>条款12、在需要改写的函数添后面加上override声明表示子类需要改写这个函数</h4><p>函数重写的必要条件：</p>\n<ul>\n<li>基类中的函数必须是虚函数</li>\n<li>函数名字必须完全相同（析构函数例外）</li>\n<li>函数形参型别完全相同</li>\n<li>函数常量性必须完全相同</li>\n<li>函数返回值和异常规格必须兼容</li>\n<li>引用饰词必须完全相同</li>\n</ul>\n<p>成员函数引用饰词的作用就是针对发起成员函数调用的现象，加一些区分度。</p>\n<h4 id=\"条款13、优先选用const-iterator\"><a href=\"#条款13、优先选用const-iterator\" class=\"headerlink\" title=\"条款13、优先选用const_iterator\"></a>条款13、优先选用const_iterator</h4><figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">// 建立iterator并插入<br>std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::iterator it = std::find(<span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">begin</span>(), <span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">end</span>(), <span class=\"hljs-number\">1983</span>);<br><span class=\"hljs-keyword\">values</span>.<span class=\"hljs-keyword\">insert</span>(it, <span class=\"hljs-number\">1998</span>)<br></code></pre></td></tr></table></figure>\n<p>容器的cbegin和cend都返回的是const_iterator型别，不能修改，但是可以通过insert插入元素到列表中。</p>\n<p>将const元素传入begin函数中，会产生一个const_iterator</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 条款13、优先选用const_iterator</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">demo13</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\tstd::vector&lt;<span class=\"hljs-type\">int</span>&gt; vec&#123; <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">5</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::iterator iter = vec.<span class=\"hljs-built_in\">begin</span>(); iter != vec.<span class=\"hljs-built_in\">end</span>(); ++iter) &#123;<br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;old element:&quot;</span> &lt;&lt; *iter;\t\t\t\t<span class=\"hljs-comment\">// 打印元素</span><br><br>\t\t(*iter) += <span class=\"hljs-number\">1</span>;\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">// 通过迭代器修改对应元素</span><br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;, new:&quot;</span> &lt;&lt; *iter &lt;&lt; std::endl;<br><br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">auto</span> it = std::<span class=\"hljs-built_in\">find</span>(vec.<span class=\"hljs-built_in\">cbegin</span>(), vec.<span class=\"hljs-built_in\">cend</span>(), <span class=\"hljs-number\">3</span>);<br>\tvec.<span class=\"hljs-built_in\">insert</span>(it, <span class=\"hljs-number\">1</span>);<br><br>\t<span class=\"hljs-keyword\">for</span> (std::vector&lt;<span class=\"hljs-type\">int</span>&gt;::const_iterator iter = vec.<span class=\"hljs-built_in\">cbegin</span>(); iter != vec.<span class=\"hljs-built_in\">cend</span>(); ++iter) &#123;<br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;old element:&quot;</span> &lt;&lt; *iter &lt;&lt; std::endl;\t\t\t\t<span class=\"hljs-comment\">// 打印元素</span><br><br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>优先使用begin，end等，而非成员函数版本</li>\n</ul>\n<h4 id=\"条款14、对于确保不发生异常的函数，加上noexcept声明\"><a href=\"#条款14、对于确保不发生异常的函数，加上noexcept声明\" class=\"headerlink\" title=\"条款14、对于确保不发生异常的函数，加上noexcept声明\"></a>条款14、对于确保不发生异常的函数，加上noexcept声明</h4><p>在C++98中，出现异常后，调用栈会开解至异常出现的调用方，C++11中，中止前只是可能会解开。因此优化器不需要再异常传出函数的前提下，将执行期间栈保持在开解状态，也不用在异常溢出函数的前提下，保证所有对象的构造顺序的逆序完成解析。</p>\n<p><code>push_back</code>中采用的原则是：能移动则移动，必须复制才复制。具有强异常性质。</p>\n<p>使用<code>noexcept</code>能够极大程度的便于编译器优化。</p>\n<p>析构函数和内存释放函数都隐式的具备又noexcept的性质。</p>\n<h4 id=\"条款15、使用constexpr\"><a href=\"#条款15、使用constexpr\" class=\"headerlink\" title=\"条款15、使用constexpr\"></a>条款15、使用constexpr</h4><p>const：表示“只读”的含义，被const修饰的变量不能够修改，可以定义编译器和运行期的常量</p>\n<p>constexpr：表示“常量”的含义，只能够定义编译器的常量，可以提高运行效率</p>\n<ul>\n<li>constexpr修饰的函数在编译过程展开，被隐式的转化为了内联函数</li>\n<li>如果要修改const修饰的变量的值，需要加上关键字volatile</li>\n</ul>\n<p>constexpr函数仅限于掺入和返回字面型别：在编译器就可以确定的数据类型。</p>\n<h4 id=\"条款16、使用const成员函数的线程安全性\"><a href=\"#条款16、使用const成员函数的线程安全性\" class=\"headerlink\" title=\"条款16、使用const成员函数的线程安全性\"></a>条款16、使用const成员函数的线程安全性</h4><h4 id=\"条款17、\"><a href=\"#条款17、\" class=\"headerlink\" title=\"条款17、\"></a>条款17、</h4><h3 id=\"第四章、智能指针\"><a href=\"#第四章、智能指针\" class=\"headerlink\" title=\"第四章、智能指针\"></a>第四章、智能指针</h3><blockquote>\n<p>智能指针是用来管理内存泄漏的，内存泄漏：在为对象动态申请内存空间后，如存在忘记释放内存，或者运行过程中程序中断的问题，导致申请的内存空间被占用造成内存泄漏。</p>\n</blockquote>\n<h4 id=\"条款18、使用unique-ptr管理具备专属所有权的资源\"><a href=\"#条款18、使用unique-ptr管理具备专属所有权的资源\" class=\"headerlink\" title=\"条款18、使用unique_ptr管理具备专属所有权的资源\"></a>条款18、使用unique_ptr管理具备专属所有权的资源</h4><p>智能指针<code>unique_ptr</code></p>\n<ul>\n<li>独享它的对象</li>\n<li>包含头文件#include<memory></li>\n<li>可以高效的转化为<code>shared_ptr</code></li>\n</ul>\n<p>unique_ptr和裸指针在默认情况下有着相同的尺寸，实现的是专属所有权语义，</p>\n<p>工厂函数返回的是一个<code>unique_ptr</code>指针，可以用auto来接收。</p>\n<ul>\n<li>将一个裸指针赋值给<code>unique_ptr</code>将不会通过编译</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 智能指针用法</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AA</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>\tstd::string _name;<br>\t<span class=\"hljs-built_in\">AA</span>() &#123;<br>\t\tstd::cout &lt;&lt; _name &lt;&lt; <span class=\"hljs-string\">&quot;调用构造函数1\\n&quot;</span>;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">AA</span>(<span class=\"hljs-type\">const</span> std::string&amp; m_name) :_name(m_name) &#123;<br><br>\t\tstd::cout &lt;&lt; _name &lt;&lt; <span class=\"hljs-string\">&quot;调用构造函数2\\n&quot;</span>;<br>\t&#125;<br>\t~<span class=\"hljs-built_in\">AA</span>() &#123;<br><br>\t\tstd::cout &lt;&lt; <span class=\"hljs-string\">&quot;调用析构函数\\n&quot;</span>;<br>\t&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">demo19</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">using</span> std::unique_ptr;<br>\t<span class=\"hljs-keyword\">using</span> std::make_unique;<br>\t<span class=\"hljs-function\">unique_ptr&lt;AA&gt; <span class=\"hljs-title\">p0</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">new</span> AA(<span class=\"hljs-string\">&quot;xiaoli&quot;</span>))</span></span>;<br>\tunique_ptr&lt;AA&gt; p1 = std::<span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;(<span class=\"hljs-string\">&quot;xiaowang&quot;</span>);<br>\tunique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; pp1 = <span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;();         <span class=\"hljs-comment\">// 数据类型为int。</span><br>\tunique_ptr&lt;AA&gt; pp2 = <span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;();       <span class=\"hljs-comment\">// 数据类型为AA，默认构造函数。</span><br>\tunique_ptr&lt;AA&gt; pp3 = <span class=\"hljs-built_in\">make_unique</span>&lt;AA&gt;(<span class=\"hljs-string\">&quot;xiaoxi&quot;</span>);  <span class=\"hljs-comment\">// 数据类型为AA，一个参数的构造函数。</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<h4 id=\"条款19、使用shared-ptr管理具备共享所有权的资源\"><a href=\"#条款19、使用shared-ptr管理具备共享所有权的资源\" class=\"headerlink\" title=\"条款19、使用shared_ptr管理具备共享所有权的资源\"></a>条款19、使用shared_ptr管理具备共享所有权的资源</h4><p>RAII思想（Resource Acquisition Is Initialization）资源获取即初始化。将获取的资源和对象的生命周期绑定在一起。</p>\n<ul>\n<li>设计RAII类的四个步骤<ul>\n<li>设计一个类封装资源，资源可以是内存、文件、socket、锁等等一切</li>\n<li>在构造函数中执行资源的初始化，比如申请内存、打开文件、申请锁</li>\n<li>在析构函数中执行销毁操作，比如释放内存、关闭文件、释放锁</li>\n<li>使用时声明一个该对象的类，一般在你希望的作用域声明即可，比如在函数开始，或者作为类的成员变量</li>\n</ul>\n</li>\n</ul>\n<p>引用计数带来的一些性能问题：</p>\n<ul>\n<li>尺寸是裸指针的两倍</li>\n<li>引用计数的内存必须动态分配</li>\n<li>引用计数的递增和递减必须是原子操作</li>\n</ul>\n<p>从一个已有shared_ptr移动构造一个新的shared_ptr会将源shared_ptr置空，不会增加引用计数。</p>\n<p>使用shared_ptr如果出现了循环引用则会导致计数用于也无法回到0，资源将无法被释放。使用<code>weak_ptr</code>配合使用便可以解决这个问题，因为<code>weak_ptr</code>不会控制对象的生命周期，但是知道对象释放的时间，会和对象共同消失。</p>\n<h4 id=\"条款20、weak-ptr使用\"><a href=\"#条款20、weak-ptr使用\" class=\"headerlink\" title=\"条款20、weak_ptr使用\"></a>条款20、weak_ptr使用</h4><p>1、使用<code>weak_ptr</code>代替可能空悬的<code>shared_ptr</code></p>\n<p>2、<code>weak_ptr</code>可以用于缓存，观察者列表，以及避免shared_ptr指针环路</p>\n<h4 id=\"条款21、优先使用make-…ptr而不是直接使用new\"><a href=\"#条款21、优先使用make-…ptr而不是直接使用new\" class=\"headerlink\" title=\"条款21、优先使用make_…ptr而不是直接使用new\"></a>条款21、优先使用make_…ptr而不是直接使用new</h4><p>1、使用new的代码更加冗余</p>\n<p>2、使用new会触发两次内存分配，而使用make系列则只用触发一次内存分配</p>\n<h4 id=\"条款22、Pimpl用法\"><a href=\"#条款22、Pimpl用法\" class=\"headerlink\" title=\"条款22、Pimpl用法\"></a>条款22、Pimpl用法</h4><p>将类内的数据成员使用struct结构体打包起来，并使用一个智能指针指向该结构体，在.cpp文件中对这些数据进行操作，能够极大便利的降低类的客户和类的实现者之间的依赖。</p>\n<h3 id=\"右值引用、移动语义和完美转发\"><a href=\"#右值引用、移动语义和完美转发\" class=\"headerlink\" title=\"右值引用、移动语义和完美转发\"></a>右值引用、移动语义和完美转发</h3><ul>\n<li>移动语义可以使得编译器能够使用移动操作代替昂贵的复制操作。</li>\n<li>完美转发使得人们可以撰写接收任意实参的函数模板，并将其转发到其它函数，目标函数会接收到与转发函数所接收到的完全相同的实参。</li>\n</ul>\n<h4 id=\"条款23、理解std-move和std-forward\"><a href=\"#条款23、理解std-move和std-forward\" class=\"headerlink\" title=\"条款23、理解std::move和std::forward\"></a>条款23、理解std::move和std::forward</h4><p>使用move可以将参数强制转化为右值</p>\n<p>如果想要取得对某一个对象执行移动操作的能力，则不要将其声明为常量，因为针对常量对象执行的移动操作将会变化为复制操作。</p>\n<p>forward是一个有条件的强制转化，只有当实参是使用右值完成初始化时，它才会执行向右值型别的强制转化。如果需要选择性的对某一些形参进行左值或者右值引用，则可以用forward来进行标识。</p>\n<h4 id=\"条款24、区分万能引用和右值引用\"><a href=\"#条款24、区分万能引用和右值引用\" class=\"headerlink\" title=\"条款24、区分万能引用和右值引用\"></a>条款24、区分万能引用和右值引用</h4><p>在模板和类型推导中出现<code>&amp; &amp;</code>很大可能就是万能引用：即表达式或者传入的实参，既可以是左值也可以时右值。</p>\n<h4 id=\"条款25、针对右值引用使用move，针对万能引用使用forward\"><a href=\"#条款25、针对右值引用使用move，针对万能引用使用forward\" class=\"headerlink\" title=\"条款25、针对右值引用使用move，针对万能引用使用forward\"></a>条款25、针对右值引用使用move，针对万能引用使用forward</h4><p>因为万能引用使用<code>forward</code>它可以有条件的自动转化传入的实参作为左值还是右值。</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h4><h4 id=\"条例30、完美转发失败的情形\"><a href=\"#条例30、完美转发失败的情形\" class=\"headerlink\" title=\"条例30、完美转发失败的情形\"></a>条例30、完美转发失败的情形</h4><p>完美转发的含义：一个函数把自己的形参传递（转发）给另一个函数，为了使得第二个函数接受第一个函数所接受的同一个对象。</p>\n<p>完美转发不仅仅转发对象，还转发其显著的特征：型别、是左值还是右值，是否带有const或者volatile修饰词。</p>\n<p>转发失败的定义：使用某特定实参调用转发函数会执行某操作，但使用同一实参调用其封装后的函数会执行不同的操作。即右值引用成功，但是万能引用失败。</p>\n<p>具体形参：</p>\n<ul>\n<li>大括号初始化的列表</li>\n<li>0或者NULL用作空指针</li>\n<li>仅有声明的整型static const成员变量</li>\n<li>重载的函数名字和模板名字</li>\n<li>位域</li>\n</ul>\n<h3 id=\"第五章、lambda表达式\"><a href=\"#第五章、lambda表达式\" class=\"headerlink\" title=\"第五章、lambda表达式\"></a>第五章、lambda表达式</h3><p>lambda运行期的对象是<code>闭包</code>，根据不同的捕获模式，闭包会持有数据的副本或引用。</p>\n<p>闭包类就是实例化闭包的类，每个lambda式都会触发编译器生成一个独一无二的闭包类。闭包中的语句会变成它的闭包类成员函数的可执行指令。</p>\n<h4 id=\"条款31、避免默认捕获模式\"><a href=\"#条款31、避免默认捕获模式\" class=\"headerlink\" title=\"条款31、避免默认捕获模式\"></a>条款31、避免默认捕获模式</h4><p>C++11有两种默认捕获模式：按值或按引用。按引用的默认捕获模式可能导致空悬引用。</p>\n<p>按引用捕获会导致闭包包含指涉到局部变量的引用，或者指涉到定义lambda式作用域内的形参的引用。一旦lambda式所创建的闭包越过了该局部变量或者形参的生命周期，那么闭包内的引用就会悬空。</p>\n"},{"title":"GAMES101现代计算机图形学入门-01","date":"2023-12-15T06:40:01.000Z","cover":"2023/12/15/GAMES101现代计算机图形学入门-01/games101.png","top_img":"2023/12/15/GAMES101现代计算机图形学入门-01/games101.png","_content":"\n\n## 计算机图形学01\n\n> 应用场景：电影，动画，可视化，家具，模拟，虚拟现实（VR），GUI（图形用户接口），字体\n\n* 好的画面：足够亮（全局光照）\n\n```\n1、光栅化\tResterization\n2、曲线曲面（几何）\tCurves and Meshes\n3、光线追踪\tRay\tTracing\n4、动画/模拟\tAnimation/Simulation\n```\n\n### 计算机图形学 VS 计算机视觉\n\n![image-20231104113151777](GAMES101现代计算机图形学入门-01/image-20231104113151777-17084112899531.png)\n\n* MODEL，计算机画（图形学）\n\n  正向箭头：将三维空间的图形在二维中展示出来，特指图像渲染\n\n  自我箭头：MODEL的自我渲染，与图像无关\n\n* IMAGE，计算机看（计算机视觉）\n\n  反向箭头：从图形中推导和识别出图像的特征\n\n  自我箭头：依赖深度学习对图像进行处理\n\n作业相关\n\n```\n1、作业链接：http://games-cn.org/forums/topic/allhw/\n2、作业使用的系统：smartchair\n3、Use IDE：集成开发环境\n```\n\n\n\n### 线性代数——A Swift and Brutal Introduction to Linear Algebra\n\n> 数学：线性代数，微积分，统计，物理：光学，力学，信号处理，数值分析\n\n#### 向量Vectors\n\n方向、长度、向量的模、单位向量、点乘、余弦值\n\n* 点乘的重要性\n\n  使用向量的点积便于计算一个向量在另一个向量上的投影（光的投影）\n\n  衡量两个向量的接近程度\n\n  分解一个向量（使用投影可以进行加减运算）分解为垂直方向和水平方向\n\n  确定向量的基本方向，大于零同方向，小于零反方向\n\n![image-20231104150955701](GAMES101现代计算机图形学入门-01/image-20231104150955701-17084112899532.png)\n\n* 叉乘的重要性（使用右手螺旋定则可以确定叉乘的方向）\n\n  叉乘可以建立一个三位空间的直角坐标系\n\n  任意的三维空间向量都可以分解到三位的单位向量中\n\n![image-20231104164704660](GAMES101现代计算机图形学入门-01/image-20231104164704660-17084112899533.png)\n\n​\t\t叉乘的代数表示（矩阵相乘）\n\n![image-20231104164849274](GAMES101现代计算机图形学入门-01/image-20231104164849274-17084112899534.png)\n\n**Q&A:判断一个点是否在三角形的内部**\n\n对三角形做逆时针，分别做三条边之间的向量，三个顶点分别于需要判断的点进行叉乘，如AB叉乘AP，如果都大于0，则说明在三角形内部。\n\n结论比较简单，很容易在计算机中使用公式实现出来。\n\n![image-20231104165645532](GAMES101现代计算机图形学入门-01/image-20231104165645532-17084112899535.png)\n\n* 矩阵的重要性\n\n  图像转换，旋转，平移，剪切，数乘\n\n  * 矩阵的乘积（第一个矩阵的列数等于第二个矩阵的行数）\n\n    ![image-20231116154858801](GAMES101现代计算机图形学入门-01/image-20231116154858801-17084112899536.png)\n\n    **矩阵的乘积没有任何交换律**，但是有结合律\n\n  * 矩阵与向量的乘积（列向量，可以表示为点的坐标）\n\n    可以利用矩阵乘积做一些变化操作（如下：将x，y变化为-x，y）\n\n    ![image-20231116155210293](GAMES101现代计算机图形学入门-01/image-20231116155210293-17084112899537.png)\n\n  * 转置矩阵、单位矩阵（对角矩阵）","source":"_posts/GAMES101现代计算机图形学入门-01.md","raw":"---\ntitle: GAMES101现代计算机图形学入门-01\ndate: 2023-12-15 14:40:01\ntags: [计算机图形学, GAMES101]\ncategories: 学习笔记\ncover: games101.png\ntop_img: games101.png\n---\n\n\n## 计算机图形学01\n\n> 应用场景：电影，动画，可视化，家具，模拟，虚拟现实（VR），GUI（图形用户接口），字体\n\n* 好的画面：足够亮（全局光照）\n\n```\n1、光栅化\tResterization\n2、曲线曲面（几何）\tCurves and Meshes\n3、光线追踪\tRay\tTracing\n4、动画/模拟\tAnimation/Simulation\n```\n\n### 计算机图形学 VS 计算机视觉\n\n![image-20231104113151777](GAMES101现代计算机图形学入门-01/image-20231104113151777-17084112899531.png)\n\n* MODEL，计算机画（图形学）\n\n  正向箭头：将三维空间的图形在二维中展示出来，特指图像渲染\n\n  自我箭头：MODEL的自我渲染，与图像无关\n\n* IMAGE，计算机看（计算机视觉）\n\n  反向箭头：从图形中推导和识别出图像的特征\n\n  自我箭头：依赖深度学习对图像进行处理\n\n作业相关\n\n```\n1、作业链接：http://games-cn.org/forums/topic/allhw/\n2、作业使用的系统：smartchair\n3、Use IDE：集成开发环境\n```\n\n\n\n### 线性代数——A Swift and Brutal Introduction to Linear Algebra\n\n> 数学：线性代数，微积分，统计，物理：光学，力学，信号处理，数值分析\n\n#### 向量Vectors\n\n方向、长度、向量的模、单位向量、点乘、余弦值\n\n* 点乘的重要性\n\n  使用向量的点积便于计算一个向量在另一个向量上的投影（光的投影）\n\n  衡量两个向量的接近程度\n\n  分解一个向量（使用投影可以进行加减运算）分解为垂直方向和水平方向\n\n  确定向量的基本方向，大于零同方向，小于零反方向\n\n![image-20231104150955701](GAMES101现代计算机图形学入门-01/image-20231104150955701-17084112899532.png)\n\n* 叉乘的重要性（使用右手螺旋定则可以确定叉乘的方向）\n\n  叉乘可以建立一个三位空间的直角坐标系\n\n  任意的三维空间向量都可以分解到三位的单位向量中\n\n![image-20231104164704660](GAMES101现代计算机图形学入门-01/image-20231104164704660-17084112899533.png)\n\n​\t\t叉乘的代数表示（矩阵相乘）\n\n![image-20231104164849274](GAMES101现代计算机图形学入门-01/image-20231104164849274-17084112899534.png)\n\n**Q&A:判断一个点是否在三角形的内部**\n\n对三角形做逆时针，分别做三条边之间的向量，三个顶点分别于需要判断的点进行叉乘，如AB叉乘AP，如果都大于0，则说明在三角形内部。\n\n结论比较简单，很容易在计算机中使用公式实现出来。\n\n![image-20231104165645532](GAMES101现代计算机图形学入门-01/image-20231104165645532-17084112899535.png)\n\n* 矩阵的重要性\n\n  图像转换，旋转，平移，剪切，数乘\n\n  * 矩阵的乘积（第一个矩阵的列数等于第二个矩阵的行数）\n\n    ![image-20231116154858801](GAMES101现代计算机图形学入门-01/image-20231116154858801-17084112899536.png)\n\n    **矩阵的乘积没有任何交换律**，但是有结合律\n\n  * 矩阵与向量的乘积（列向量，可以表示为点的坐标）\n\n    可以利用矩阵乘积做一些变化操作（如下：将x，y变化为-x，y）\n\n    ![image-20231116155210293](GAMES101现代计算机图形学入门-01/image-20231116155210293-17084112899537.png)\n\n  * 转置矩阵、单位矩阵（对角矩阵）","slug":"GAMES101现代计算机图形学入门-01","published":1,"updated":"2024-06-05T09:03:03.520Z","comments":1,"layout":"post","photos":[],"_id":"clyfintti000h08jv79qw46au","content":"<h2 id=\"计算机图形学01\"><a href=\"#计算机图形学01\" class=\"headerlink\" title=\"计算机图形学01\"></a>计算机图形学01</h2><blockquote>\n<p>应用场景：电影，动画，可视化，家具，模拟，虚拟现实（VR），GUI（图形用户接口），字体</p>\n</blockquote>\n<ul>\n<li>好的画面：足够亮（全局光照）</li>\n</ul>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs armasm\"><span class=\"hljs-number\">1</span>、光栅化\tResterization<br><span class=\"hljs-number\">2</span>、曲线曲面（几何）\tCurves <span class=\"hljs-keyword\">and</span> Meshes<br><span class=\"hljs-number\">3</span>、光线追踪\tRay\tTracing<br><span class=\"hljs-number\">4</span>、动画/模拟\tAnimation/Simulation<br></code></pre></td></tr></table></figure>\n<h3 id=\"计算机图形学-VS-计算机视觉\"><a href=\"#计算机图形学-VS-计算机视觉\" class=\"headerlink\" title=\"计算机图形学 VS 计算机视觉\"></a>计算机图形学 VS 计算机视觉</h3><img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104113151777-17084112899531.png\" class=\"\" title=\"image-20231104113151777\">\n<ul>\n<li><p>MODEL，计算机画（图形学）</p>\n<p>正向箭头：将三维空间的图形在二维中展示出来，特指图像渲染</p>\n<p>自我箭头：MODEL的自我渲染，与图像无关</p>\n</li>\n<li><p>IMAGE，计算机看（计算机视觉）</p>\n<p>反向箭头：从图形中推导和识别出图像的特征</p>\n<p>自我箭头：依赖深度学习对图像进行处理</p>\n</li>\n</ul>\n<p>作业相关</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-number\">1</span>、作业链接：http:<span class=\"hljs-regexp\">//g</span>ames-cn.org<span class=\"hljs-regexp\">/forums/</span>topic<span class=\"hljs-regexp\">/allhw/</span><br><span class=\"hljs-number\">2</span>、作业使用的系统：smartchair<br><span class=\"hljs-number\">3</span>、Use IDE：集成开发环境<br></code></pre></td></tr></table></figure>\n<h3 id=\"线性代数——A-Swift-and-Brutal-Introduction-to-Linear-Algebra\"><a href=\"#线性代数——A-Swift-and-Brutal-Introduction-to-Linear-Algebra\" class=\"headerlink\" title=\"线性代数——A Swift and Brutal Introduction to Linear Algebra\"></a>线性代数——A Swift and Brutal Introduction to Linear Algebra</h3><blockquote>\n<p>数学：线性代数，微积分，统计，物理：光学，力学，信号处理，数值分析</p>\n</blockquote>\n<h4 id=\"向量Vectors\"><a href=\"#向量Vectors\" class=\"headerlink\" title=\"向量Vectors\"></a>向量Vectors</h4><p>方向、长度、向量的模、单位向量、点乘、余弦值</p>\n<ul>\n<li><p>点乘的重要性</p>\n<p>使用向量的点积便于计算一个向量在另一个向量上的投影（光的投影）</p>\n<p>衡量两个向量的接近程度</p>\n<p>分解一个向量（使用投影可以进行加减运算）分解为垂直方向和水平方向</p>\n<p>确定向量的基本方向，大于零同方向，小于零反方向</p>\n</li>\n</ul>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104150955701-17084112899532.png\" class=\"\" title=\"image-20231104150955701\">\n<ul>\n<li><p>叉乘的重要性（使用右手螺旋定则可以确定叉乘的方向）</p>\n<p>叉乘可以建立一个三位空间的直角坐标系</p>\n<p>任意的三维空间向量都可以分解到三位的单位向量中</p>\n</li>\n</ul>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104164704660-17084112899533.png\" class=\"\" title=\"image-20231104164704660\">\n<p>​        叉乘的代数表示（矩阵相乘）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104164849274-17084112899534.png\" class=\"\" title=\"image-20231104164849274\">\n<p><strong>Q&amp;A:判断一个点是否在三角形的内部</strong></p>\n<p>对三角形做逆时针，分别做三条边之间的向量，三个顶点分别于需要判断的点进行叉乘，如AB叉乘AP，如果都大于0，则说明在三角形内部。</p>\n<p>结论比较简单，很容易在计算机中使用公式实现出来。</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104165645532-17084112899535.png\" class=\"\" title=\"image-20231104165645532\">\n<ul>\n<li><p>矩阵的重要性</p>\n<p>图像转换，旋转，平移，剪切，数乘</p>\n<ul>\n<li><p>矩阵的乘积（第一个矩阵的列数等于第二个矩阵的行数）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231116154858801-17084112899536.png\" class=\"\" title=\"image-20231116154858801\">\n<p><strong>矩阵的乘积没有任何交换律</strong>，但是有结合律</p>\n</li>\n<li><p>矩阵与向量的乘积（列向量，可以表示为点的坐标）</p>\n<p>可以利用矩阵乘积做一些变化操作（如下：将x，y变化为-x，y）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231116155210293-17084112899537.png\" class=\"\" title=\"image-20231116155210293\">\n</li>\n<li><p>转置矩阵、单位矩阵（对角矩阵）</p>\n</li>\n</ul>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"计算机图形学01\"><a href=\"#计算机图形学01\" class=\"headerlink\" title=\"计算机图形学01\"></a>计算机图形学01</h2><blockquote>\n<p>应用场景：电影，动画，可视化，家具，模拟，虚拟现实（VR），GUI（图形用户接口），字体</p>\n</blockquote>\n<ul>\n<li>好的画面：足够亮（全局光照）</li>\n</ul>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs armasm\"><span class=\"hljs-number\">1</span>、光栅化\tResterization<br><span class=\"hljs-number\">2</span>、曲线曲面（几何）\tCurves <span class=\"hljs-keyword\">and</span> Meshes<br><span class=\"hljs-number\">3</span>、光线追踪\tRay\tTracing<br><span class=\"hljs-number\">4</span>、动画/模拟\tAnimation/Simulation<br></code></pre></td></tr></table></figure>\n<h3 id=\"计算机图形学-VS-计算机视觉\"><a href=\"#计算机图形学-VS-计算机视觉\" class=\"headerlink\" title=\"计算机图形学 VS 计算机视觉\"></a>计算机图形学 VS 计算机视觉</h3><img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104113151777-17084112899531.png\" class=\"\" title=\"image-20231104113151777\">\n<ul>\n<li><p>MODEL，计算机画（图形学）</p>\n<p>正向箭头：将三维空间的图形在二维中展示出来，特指图像渲染</p>\n<p>自我箭头：MODEL的自我渲染，与图像无关</p>\n</li>\n<li><p>IMAGE，计算机看（计算机视觉）</p>\n<p>反向箭头：从图形中推导和识别出图像的特征</p>\n<p>自我箭头：依赖深度学习对图像进行处理</p>\n</li>\n</ul>\n<p>作业相关</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-number\">1</span>、作业链接：http:<span class=\"hljs-regexp\">//g</span>ames-cn.org<span class=\"hljs-regexp\">/forums/</span>topic<span class=\"hljs-regexp\">/allhw/</span><br><span class=\"hljs-number\">2</span>、作业使用的系统：smartchair<br><span class=\"hljs-number\">3</span>、Use IDE：集成开发环境<br></code></pre></td></tr></table></figure>\n<h3 id=\"线性代数——A-Swift-and-Brutal-Introduction-to-Linear-Algebra\"><a href=\"#线性代数——A-Swift-and-Brutal-Introduction-to-Linear-Algebra\" class=\"headerlink\" title=\"线性代数——A Swift and Brutal Introduction to Linear Algebra\"></a>线性代数——A Swift and Brutal Introduction to Linear Algebra</h3><blockquote>\n<p>数学：线性代数，微积分，统计，物理：光学，力学，信号处理，数值分析</p>\n</blockquote>\n<h4 id=\"向量Vectors\"><a href=\"#向量Vectors\" class=\"headerlink\" title=\"向量Vectors\"></a>向量Vectors</h4><p>方向、长度、向量的模、单位向量、点乘、余弦值</p>\n<ul>\n<li><p>点乘的重要性</p>\n<p>使用向量的点积便于计算一个向量在另一个向量上的投影（光的投影）</p>\n<p>衡量两个向量的接近程度</p>\n<p>分解一个向量（使用投影可以进行加减运算）分解为垂直方向和水平方向</p>\n<p>确定向量的基本方向，大于零同方向，小于零反方向</p>\n</li>\n</ul>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104150955701-17084112899532.png\" class=\"\" title=\"image-20231104150955701\">\n<ul>\n<li><p>叉乘的重要性（使用右手螺旋定则可以确定叉乘的方向）</p>\n<p>叉乘可以建立一个三位空间的直角坐标系</p>\n<p>任意的三维空间向量都可以分解到三位的单位向量中</p>\n</li>\n</ul>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104164704660-17084112899533.png\" class=\"\" title=\"image-20231104164704660\">\n<p>​        叉乘的代数表示（矩阵相乘）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104164849274-17084112899534.png\" class=\"\" title=\"image-20231104164849274\">\n<p><strong>Q&amp;A:判断一个点是否在三角形的内部</strong></p>\n<p>对三角形做逆时针，分别做三条边之间的向量，三个顶点分别于需要判断的点进行叉乘，如AB叉乘AP，如果都大于0，则说明在三角形内部。</p>\n<p>结论比较简单，很容易在计算机中使用公式实现出来。</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231104165645532-17084112899535.png\" class=\"\" title=\"image-20231104165645532\">\n<ul>\n<li><p>矩阵的重要性</p>\n<p>图像转换，旋转，平移，剪切，数乘</p>\n<ul>\n<li><p>矩阵的乘积（第一个矩阵的列数等于第二个矩阵的行数）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231116154858801-17084112899536.png\" class=\"\" title=\"image-20231116154858801\">\n<p><strong>矩阵的乘积没有任何交换律</strong>，但是有结合律</p>\n</li>\n<li><p>矩阵与向量的乘积（列向量，可以表示为点的坐标）</p>\n<p>可以利用矩阵乘积做一些变化操作（如下：将x，y变化为-x，y）</p>\n<img src=\"/2023/12/15/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-01/image-20231116155210293-17084112899537.png\" class=\"\" title=\"image-20231116155210293\">\n</li>\n<li><p>转置矩阵、单位矩阵（对角矩阵）</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"GAMES101现代计算机图形学入门-02","date":"2023-12-16T06:40:01.000Z","cover":"2023/12/16/GAMES101现代计算机图形学入门-02/games101_top.png","top_img":"2023/12/16/GAMES101现代计算机图形学入门-02/games101_top.png","_content":"\n\n## 计算机图形学02\n\n> Transform（变换），图形的变换\n\n```\n为什么学习变换\n2维变换：旋转、缩放、切变\n齐次坐标 Homogeneous coordinates\n组合变换\n3维变换\n```\n\n### 二维变换\n\n将矩阵和变换联系起来\n\n* 1、缩放\n\n  将坐标在向量左边乘一个对角矩阵\n\n  ![image-20231116161524873](GAMES101现代计算机图形学入门-02/image-20231116161524873-17084118809551.png)\n\n* 2、反射对称\n\n  ![image-20231116161727694](GAMES101现代计算机图形学入门-02/image-20231116161727694-17084118809562.png)\n\n* 3、切变（Shear Matrix）\n\n  水平方向坐标发生改变，竖直方向不变，水平的移动大小，按照Y的当前坐标成正比\n\n  ![image-20231116161842894](GAMES101现代计算机图形学入门-02/image-20231116161842894-17084118809563.png)\n\n* 4、旋转\n\n  ![image-20231116164956551](GAMES101现代计算机图形学入门-02/image-20231116164956551-17084118809564.png)\n\n  ![IMG_0318(C:/Users/zdon/Desktop/实习/job_files/self_study/计算机图形学/计算机图形学学习笔记/GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG)](GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG)\n\n通过矩阵乘积可以将一个输入图形的坐标转化为想要的输出矩阵的坐标，这样的变换都称为**线性变换**\n\n### 齐次坐标（homogeneous coordinates）\n\n> 平移操作无法使用线性变化即矩阵的乘法来获得，所以引入齐次坐标，增加一个维度\n>\n> 齐次坐标的矩阵操作，可以叫做仿射变换\n\n增加维度以后，通过与新增加列的运算就可以达到平移的变换\n\n![image-20231116165833300](GAMES101现代计算机图形学入门-02/image-20231116165833300-17084118809565.png)\n\n* Q：Why？将二维的点，增加一个1，将二维的向量，增加一个0\n\n  1、通过增加的维度可以标识当前的坐标表示点还是表示向量。可以保证向量具有平移不变性\n\n  2、最后一个维度的运算正好表示运算结果的性质\n\n  ![image-20231116170520355](GAMES101现代计算机图形学入门-02/image-20231116170520355-17084118809566.png)\n\n  3、点+点，得到的结果为两个点的终点，因为第三维为2，与两点之和相除便是中点\n\n**齐次坐标下的变换操作矩阵**\n\n![image-20231116171041924](GAMES101现代计算机图形学入门-02/image-20231116171041924-17084118809567.png)\n\n* 逆变换\n\n  乘以变化矩阵的逆矩阵，可以变换成原来的图片\n\n### 变换组合\n\n1、复杂变换可以通过简单的变化来得到\n\n2、变换的顺序不同，得到的结果不同\n\n3、变换的组合，等价于原始矩阵依次乘上按照一定顺序的齐次矩阵\n\n* 将一个变化还原，或者以任意一个点为中心进行变化，可以先移动到原点，再进行操作\n\n![image-20231116200444279](GAMES101现代计算机图形学入门-02/image-20231116200444279-17084118809568.png)\n\n### 三维变换\n\n* 三维点和三维向量\n\n  ![image-20231116201112834](GAMES101现代计算机图形学入门-02/image-20231116201112834-17084118809569.png)\n\n* 三维变换齐次矩阵\n\n  ![image-20231116201139440](GAMES101现代计算机图形学入门-02/image-20231116201139440-170841188095610.png)\n\n* 旋转\n\n  绕哪个轴旋转哪个轴保持不变\n\n  对于一般性的旋转，可以使用简单旋转的组合来完成\n\n  ![image-20231118142130480](GAMES101现代计算机图形学入门-02/image-20231118142130480-170841188095611.png)\n\n* 使用旋转公式\n\n  旋转角度定义为a\n\n  旋转轴定义为n\n\n  其中**I**表示为单位矩阵\n\n  表示为，沿着旋转轴n旋转a的角度得到的旋转矩阵\n\n  ![image-20231118142833380](GAMES101现代计算机图形学入门-02/image-20231118142833380-170841188095612.png)\n\n### 观测变换（Viewing transformation）\n\n> 视图变换、投影变换（正交投影，透视投影）\n\n ","source":"_posts/GAMES101现代计算机图形学入门-02.md","raw":"---\ntitle: GAMES101现代计算机图形学入门-02\ndate: 2023-12-16 14:40:01\ntags: [计算机图形学, GAMES101]\ncategories: 学习笔记\ncover: games101_top.png\ntop_img: games101_top.png\n---\n\n\n## 计算机图形学02\n\n> Transform（变换），图形的变换\n\n```\n为什么学习变换\n2维变换：旋转、缩放、切变\n齐次坐标 Homogeneous coordinates\n组合变换\n3维变换\n```\n\n### 二维变换\n\n将矩阵和变换联系起来\n\n* 1、缩放\n\n  将坐标在向量左边乘一个对角矩阵\n\n  ![image-20231116161524873](GAMES101现代计算机图形学入门-02/image-20231116161524873-17084118809551.png)\n\n* 2、反射对称\n\n  ![image-20231116161727694](GAMES101现代计算机图形学入门-02/image-20231116161727694-17084118809562.png)\n\n* 3、切变（Shear Matrix）\n\n  水平方向坐标发生改变，竖直方向不变，水平的移动大小，按照Y的当前坐标成正比\n\n  ![image-20231116161842894](GAMES101现代计算机图形学入门-02/image-20231116161842894-17084118809563.png)\n\n* 4、旋转\n\n  ![image-20231116164956551](GAMES101现代计算机图形学入门-02/image-20231116164956551-17084118809564.png)\n\n  ![IMG_0318(C:/Users/zdon/Desktop/实习/job_files/self_study/计算机图形学/计算机图形学学习笔记/GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG)](GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG)\n\n通过矩阵乘积可以将一个输入图形的坐标转化为想要的输出矩阵的坐标，这样的变换都称为**线性变换**\n\n### 齐次坐标（homogeneous coordinates）\n\n> 平移操作无法使用线性变化即矩阵的乘法来获得，所以引入齐次坐标，增加一个维度\n>\n> 齐次坐标的矩阵操作，可以叫做仿射变换\n\n增加维度以后，通过与新增加列的运算就可以达到平移的变换\n\n![image-20231116165833300](GAMES101现代计算机图形学入门-02/image-20231116165833300-17084118809565.png)\n\n* Q：Why？将二维的点，增加一个1，将二维的向量，增加一个0\n\n  1、通过增加的维度可以标识当前的坐标表示点还是表示向量。可以保证向量具有平移不变性\n\n  2、最后一个维度的运算正好表示运算结果的性质\n\n  ![image-20231116170520355](GAMES101现代计算机图形学入门-02/image-20231116170520355-17084118809566.png)\n\n  3、点+点，得到的结果为两个点的终点，因为第三维为2，与两点之和相除便是中点\n\n**齐次坐标下的变换操作矩阵**\n\n![image-20231116171041924](GAMES101现代计算机图形学入门-02/image-20231116171041924-17084118809567.png)\n\n* 逆变换\n\n  乘以变化矩阵的逆矩阵，可以变换成原来的图片\n\n### 变换组合\n\n1、复杂变换可以通过简单的变化来得到\n\n2、变换的顺序不同，得到的结果不同\n\n3、变换的组合，等价于原始矩阵依次乘上按照一定顺序的齐次矩阵\n\n* 将一个变化还原，或者以任意一个点为中心进行变化，可以先移动到原点，再进行操作\n\n![image-20231116200444279](GAMES101现代计算机图形学入门-02/image-20231116200444279-17084118809568.png)\n\n### 三维变换\n\n* 三维点和三维向量\n\n  ![image-20231116201112834](GAMES101现代计算机图形学入门-02/image-20231116201112834-17084118809569.png)\n\n* 三维变换齐次矩阵\n\n  ![image-20231116201139440](GAMES101现代计算机图形学入门-02/image-20231116201139440-170841188095610.png)\n\n* 旋转\n\n  绕哪个轴旋转哪个轴保持不变\n\n  对于一般性的旋转，可以使用简单旋转的组合来完成\n\n  ![image-20231118142130480](GAMES101现代计算机图形学入门-02/image-20231118142130480-170841188095611.png)\n\n* 使用旋转公式\n\n  旋转角度定义为a\n\n  旋转轴定义为n\n\n  其中**I**表示为单位矩阵\n\n  表示为，沿着旋转轴n旋转a的角度得到的旋转矩阵\n\n  ![image-20231118142833380](GAMES101现代计算机图形学入门-02/image-20231118142833380-170841188095612.png)\n\n### 观测变换（Viewing transformation）\n\n> 视图变换、投影变换（正交投影，透视投影）\n\n ","slug":"GAMES101现代计算机图形学入门-02","published":1,"updated":"2024-06-05T09:03:03.548Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttm000l08jv0wy7bbrm","content":"<h2 id=\"计算机图形学02\"><a href=\"#计算机图形学02\" class=\"headerlink\" title=\"计算机图形学02\"></a>计算机图形学02</h2><blockquote>\n<p>Transform（变换），图形的变换</p>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">为什么学习变换<br>2维变换：旋转、缩放、切变<br>齐次坐标 Homogeneous coordinates<br>组合变换<br>3维变换<br></code></pre></td></tr></table></figure>\n<h3 id=\"二维变换\"><a href=\"#二维变换\" class=\"headerlink\" title=\"二维变换\"></a>二维变换</h3><p>将矩阵和变换联系起来</p>\n<ul>\n<li><p>1、缩放</p>\n<p>将坐标在向量左边乘一个对角矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161524873-17084118809551.png\" class=\"\" title=\"image-20231116161524873\">\n</li>\n<li><p>2、反射对称</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161727694-17084118809562.png\" class=\"\" title=\"image-20231116161727694\">\n</li>\n<li><p>3、切变（Shear Matrix）</p>\n<p>水平方向坐标发生改变，竖直方向不变，水平的移动大小，按照Y的当前坐标成正比</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161842894-17084118809563.png\" class=\"\" title=\"image-20231116161842894\">\n</li>\n<li><p>4、旋转</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116164956551-17084118809564.png\" class=\"\" title=\"image-20231116164956551\">\n<p>.PNG)</p>\n</li>\n</ul>\n<p>通过矩阵乘积可以将一个输入图形的坐标转化为想要的输出矩阵的坐标，这样的变换都称为<strong>线性变换</strong></p>\n<h3 id=\"齐次坐标（homogeneous-coordinates）\"><a href=\"#齐次坐标（homogeneous-coordinates）\" class=\"headerlink\" title=\"齐次坐标（homogeneous coordinates）\"></a>齐次坐标（homogeneous coordinates）</h3><blockquote>\n<p>平移操作无法使用线性变化即矩阵的乘法来获得，所以引入齐次坐标，增加一个维度</p>\n<p>齐次坐标的矩阵操作，可以叫做仿射变换</p>\n</blockquote>\n<p>增加维度以后，通过与新增加列的运算就可以达到平移的变换</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116165833300-17084118809565.png\" class=\"\" title=\"image-20231116165833300\">\n<ul>\n<li><p>Q：Why？将二维的点，增加一个1，将二维的向量，增加一个0</p>\n<p>1、通过增加的维度可以标识当前的坐标表示点还是表示向量。可以保证向量具有平移不变性</p>\n<p>2、最后一个维度的运算正好表示运算结果的性质</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116170520355-17084118809566.png\" class=\"\" title=\"image-20231116170520355\">\n<p>3、点+点，得到的结果为两个点的终点，因为第三维为2，与两点之和相除便是中点</p>\n</li>\n</ul>\n<p><strong>齐次坐标下的变换操作矩阵</strong></p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116171041924-17084118809567.png\" class=\"\" title=\"image-20231116171041924\">\n<ul>\n<li><p>逆变换</p>\n<p>乘以变化矩阵的逆矩阵，可以变换成原来的图片</p>\n</li>\n</ul>\n<h3 id=\"变换组合\"><a href=\"#变换组合\" class=\"headerlink\" title=\"变换组合\"></a>变换组合</h3><p>1、复杂变换可以通过简单的变化来得到</p>\n<p>2、变换的顺序不同，得到的结果不同</p>\n<p>3、变换的组合，等价于原始矩阵依次乘上按照一定顺序的齐次矩阵</p>\n<ul>\n<li>将一个变化还原，或者以任意一个点为中心进行变化，可以先移动到原点，再进行操作</li>\n</ul>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116200444279-17084118809568.png\" class=\"\" title=\"image-20231116200444279\">\n<h3 id=\"三维变换\"><a href=\"#三维变换\" class=\"headerlink\" title=\"三维变换\"></a>三维变换</h3><ul>\n<li><p>三维点和三维向量</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116201112834-17084118809569.png\" class=\"\" title=\"image-20231116201112834\">\n</li>\n<li><p>三维变换齐次矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116201139440-170841188095610.png\" class=\"\" title=\"image-20231116201139440\">\n</li>\n<li><p>旋转</p>\n<p>绕哪个轴旋转哪个轴保持不变</p>\n<p>对于一般性的旋转，可以使用简单旋转的组合来完成</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231118142130480-170841188095611.png\" class=\"\" title=\"image-20231118142130480\">\n</li>\n<li><p>使用旋转公式</p>\n<p>旋转角度定义为a</p>\n<p>旋转轴定义为n</p>\n<p>其中<strong>I</strong>表示为单位矩阵</p>\n<p>表示为，沿着旋转轴n旋转a的角度得到的旋转矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231118142833380-170841188095612.png\" class=\"\" title=\"image-20231118142833380\">\n</li>\n</ul>\n<h3 id=\"观测变换（Viewing-transformation）\"><a href=\"#观测变换（Viewing-transformation）\" class=\"headerlink\" title=\"观测变换（Viewing transformation）\"></a>观测变换（Viewing transformation）</h3><blockquote>\n<p>视图变换、投影变换（正交投影，透视投影）</p>\n</blockquote>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"计算机图形学02\"><a href=\"#计算机图形学02\" class=\"headerlink\" title=\"计算机图形学02\"></a>计算机图形学02</h2><blockquote>\n<p>Transform（变换），图形的变换</p>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">为什么学习变换<br>2维变换：旋转、缩放、切变<br>齐次坐标 Homogeneous coordinates<br>组合变换<br>3维变换<br></code></pre></td></tr></table></figure>\n<h3 id=\"二维变换\"><a href=\"#二维变换\" class=\"headerlink\" title=\"二维变换\"></a>二维变换</h3><p>将矩阵和变换联系起来</p>\n<ul>\n<li><p>1、缩放</p>\n<p>将坐标在向量左边乘一个对角矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161524873-17084118809551.png\" class=\"\" title=\"image-20231116161524873\">\n</li>\n<li><p>2、反射对称</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161727694-17084118809562.png\" class=\"\" title=\"image-20231116161727694\">\n</li>\n<li><p>3、切变（Shear Matrix）</p>\n<p>水平方向坐标发生改变，竖直方向不变，水平的移动大小，按照Y的当前坐标成正比</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116161842894-17084118809563.png\" class=\"\" title=\"image-20231116161842894\">\n</li>\n<li><p>4、旋转</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116164956551-17084118809564.png\" class=\"\" title=\"image-20231116164956551\">\n<p>.PNG)</p>\n</li>\n</ul>\n<p>通过矩阵乘积可以将一个输入图形的坐标转化为想要的输出矩阵的坐标，这样的变换都称为<strong>线性变换</strong></p>\n<h3 id=\"齐次坐标（homogeneous-coordinates）\"><a href=\"#齐次坐标（homogeneous-coordinates）\" class=\"headerlink\" title=\"齐次坐标（homogeneous coordinates）\"></a>齐次坐标（homogeneous coordinates）</h3><blockquote>\n<p>平移操作无法使用线性变化即矩阵的乘法来获得，所以引入齐次坐标，增加一个维度</p>\n<p>齐次坐标的矩阵操作，可以叫做仿射变换</p>\n</blockquote>\n<p>增加维度以后，通过与新增加列的运算就可以达到平移的变换</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116165833300-17084118809565.png\" class=\"\" title=\"image-20231116165833300\">\n<ul>\n<li><p>Q：Why？将二维的点，增加一个1，将二维的向量，增加一个0</p>\n<p>1、通过增加的维度可以标识当前的坐标表示点还是表示向量。可以保证向量具有平移不变性</p>\n<p>2、最后一个维度的运算正好表示运算结果的性质</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116170520355-17084118809566.png\" class=\"\" title=\"image-20231116170520355\">\n<p>3、点+点，得到的结果为两个点的终点，因为第三维为2，与两点之和相除便是中点</p>\n</li>\n</ul>\n<p><strong>齐次坐标下的变换操作矩阵</strong></p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116171041924-17084118809567.png\" class=\"\" title=\"image-20231116171041924\">\n<ul>\n<li><p>逆变换</p>\n<p>乘以变化矩阵的逆矩阵，可以变换成原来的图片</p>\n</li>\n</ul>\n<h3 id=\"变换组合\"><a href=\"#变换组合\" class=\"headerlink\" title=\"变换组合\"></a>变换组合</h3><p>1、复杂变换可以通过简单的变化来得到</p>\n<p>2、变换的顺序不同，得到的结果不同</p>\n<p>3、变换的组合，等价于原始矩阵依次乘上按照一定顺序的齐次矩阵</p>\n<ul>\n<li>将一个变化还原，或者以任意一个点为中心进行变化，可以先移动到原点，再进行操作</li>\n</ul>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116200444279-17084118809568.png\" class=\"\" title=\"image-20231116200444279\">\n<h3 id=\"三维变换\"><a href=\"#三维变换\" class=\"headerlink\" title=\"三维变换\"></a>三维变换</h3><ul>\n<li><p>三维点和三维向量</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116201112834-17084118809569.png\" class=\"\" title=\"image-20231116201112834\">\n</li>\n<li><p>三维变换齐次矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231116201139440-170841188095610.png\" class=\"\" title=\"image-20231116201139440\">\n</li>\n<li><p>旋转</p>\n<p>绕哪个轴旋转哪个轴保持不变</p>\n<p>对于一般性的旋转，可以使用简单旋转的组合来完成</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231118142130480-170841188095611.png\" class=\"\" title=\"image-20231118142130480\">\n</li>\n<li><p>使用旋转公式</p>\n<p>旋转角度定义为a</p>\n<p>旋转轴定义为n</p>\n<p>其中<strong>I</strong>表示为单位矩阵</p>\n<p>表示为，沿着旋转轴n旋转a的角度得到的旋转矩阵</p>\n<img src=\"/2023/12/16/GAMES101%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%85%A5%E9%97%A8-02/image-20231118142833380-170841188095612.png\" class=\"\" title=\"image-20231118142833380\">\n</li>\n</ul>\n<h3 id=\"观测变换（Viewing-transformation）\"><a href=\"#观测变换（Viewing-transformation）\" class=\"headerlink\" title=\"观测变换（Viewing transformation）\"></a>观测变换（Viewing transformation）</h3><blockquote>\n<p>视图变换、投影变换（正交投影，透视投影）</p>\n</blockquote>\n"},{"title":"集成电路物理设计学习笔记","date":"2023-08-09T08:42:48.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"## 第一章、集成电路物理设计方法\n\n### 数字集成电路设计流程\n\n三个I年代，发明，实施和整合\n\nInnovation：布局布线的基本算法、时序分析和逻辑综合的发明\n\nImplementation：开始于FPGA中门阵列的实现，ASIC设计中同等高度标准逻辑单元库的设计\n\nIntegration：模块化\n\n**芯片的物理实施重点解决的问题**\n\n对于深亚微米芯片\n\n* 解决时序驱动设计\n\n* 防止工艺天线效应\n* 进行信号完整性分析\n\n对于纳米的设计，需要多考虑的问题\n\n* 功耗分析和低功耗设计，并要统一考虑它的功能验证，逻辑综合和形式验证\n* 实施纳米设计中的光学近似检查（OPC）和移相掩膜（PSM），增加设计产额和可制造性设计\n* 统计静态时序分析，多端角分析\n\n**展平式物理设计**\n\n> 标准逻辑门单元库的简历。采用自下向上的方法，设计晶体管-仿真-建立版图-对逻辑门单元仿真建模\n\n![](Physical-design/01.png)\n\n**硅虚拟原型设计**\n\n![](Physical-design/02.png)\n\n与展平化的物理设计流程区别\n\n* 布图阶段，考虑将整个设计进行分割\n* 布线时用了快速近似的试验布线法\n* 在做RC提取时，可以用集总电容模型\n\n**层次化物理设计**\n\n> 芯片设计的最终检查标准之一为是否实现了时序收敛\n\n自上而下的层次化物理设计：将设计分为数个分割块，对每个分割块进行展品化处理（独立的布局布线），在顶层完成组装设计\n\n![](Physical-design/03.png)\n\n优点：将很大的设计化成多个小设计，如果有时序问题可能存在于个别模块，再去重点解决，降低了复杂性。\n\n* 基于设计驱动时序图\n\n  在顶层设计和模块设计之间建立一个连接的时序图桥梁，从而避免当模块设计完成后回到顶层无法收敛而造成大量的设计迭代。\n\n  将模块级的实施分成多个阶段，如时钟树综合，详细布线阶段，布线优化阶段\n\n### 数字集成电路设计收敛\n\n> 设计时序收敛任务通过三大部分工作来完成：数据系统，优化引擎，分析引擎\n>\n> 数据系统：由读取、处理和存储\n>\n> 优化引擎：基于算法去实现逻辑优化，布局优化，和布线优化\n>\n> 分析引擎：由设计工程师借助EDA工具用于时序分析，功耗分析和噪声分析的EDA工具\n\n**时序收敛**\n\n静态时序分析最重要任务：寻找最长延时路径以及最坏情况下的延时\n\n总延时：由逻辑门延时和互连线延时组成\n\n静态时序路径：组合逻辑电路，时序逻辑电路形成的路径\n\n**功耗分析**\n\n* 静态功耗分析\n\n  使用时序库提供的器件功耗可以计算\n\n* 动态功耗分析\n\n  需要提供设计仿真的数据\n\n降低功耗的方式：多电源电压方法、门控电路方法、衬底电压偏执方法\n\n![](Physical-design/04.png)\n\n### 习题：\n\n* 1、讨论什么是数字电路的物理设计和物理实施？\n\n  集成电路的物理实施方法被概括为从RTL综合到最终完成GDSII数据的实现，RTL一种硬件描述语言，用于描述数字电路的逻辑功能和寄存器传输级别的行为。GDSII是一种电子设计自动化工具所使用的标准格式，用于描述芯片的物理布局和制造信息。\n\n  将RTL转换为GDSII是一个多步骤的过程，通常包括以下几个主要阶段：\n\n  * 1、逻辑综合：将RTL描述的电路转换为门级电路，生成门级网表。\n  * 2、时序优化：对门级网表进行优化，以减少电路的面积、功耗或者时钟延迟等。\n  * 3、布局：根据门级网表生成芯片的物理布局，包括各个组件的位置、尺寸和连线等。\n  * 4、布线：根据布局信息进行连线，确保电路的信号可以正确传输。\n  * 5、物理验证：对布局和布线结果进行物理验证，包括规则检查、电气特性分析等。\n    * 后面有一个提取阶段\n  * 6、转换为GDSII：将经过物理验证的布局和布线结果转化为GDSII格式，生成最终的物理设计数据\n\n* 2、什么是硅虚拟原型SVP？为什么要提出硅虚拟模型设计方法？\n\n  硅虚拟原型：是一种基于软件仿真和硬件加速的技术，用于验证和评估芯片设计的功能和新能。\n\n  采用硅虚拟模型设计方法能够尽早预估该设计能否大致实现时序收敛，具有更快的设计迭代速度和更低的开发成本。\n\n* 3、展平式物理设计与层次式物理设计的共同点和不同点是什么？\n\n  基本流程都具备，但是步骤顺序可能存在偏差\n\n  展平式设计是一种自下而上的模块化方法，从底层器件再到版图\n\n  层次化设计是一种自上而下的物理设计方法，从版图再往下\n\n* 4、设计收敛的实现与设计流程有关吗？\n\n  有关，设计流程可以提供一种系统化的方法和框架，能够有效地引导和管理设计的各个阶段，以实现设计收敛，使得设计能够按照预期目标收敛。\n\n* 5、当今EDA工具的设计所采用的主要的数据文件格式有哪些？数据库格式有哪些？常用的编程语言有哪些？\n\n  RTL：硬件描述语言编写的RTL代码\n\n  网表：描述芯片的逻辑电路结构和连接关系的文本文件\n\n  GDSII：用于描述芯片的物理布局和制造信息的二进制格式\n\n  LEF和DEF：用于描述芯片的物理布局和制造信息的二进制格式\n\n  SDC：用于定义时序约束的文本文件，指定电路的时序要求和约束条件\n\n## 第二章、物理设计建库与验证\n\n### 集成电路工艺与版图\n\n**CMOS工艺流程**\n\n晶圆—形成制造晶体管所需的衬底和阱区—形成晶体管栅层图形—形成源漏、衬底和阱接触等其它有源区—通过接触孔将需要连接的地方与第一层金属互连—进行其它几层金属互连—添加钝化层与外界隔离开\n\n**工艺技术文件**\n\n> 晶体代工厂提供给设计者用于后端版图设计的技术文件，用于与EDA工具交互工艺信息，内容包括图形定义及显示信息，互连线工艺信息和通孔工艺信息\n\n### 设计规则检查（DRC）\n\n主要目的：检查版图中所有因违反设计规则而引起潜在断路，短路或不良效应的物理验证过程\n\n**版图设计规则**\n\n> 晶圆代工厂对不同工艺参数制定出满足芯片制造良率的同一工艺层以及不同工艺层之间几何尺寸的最小值，这些最小值规划的集合就是版图设计规则。\n\n* 逻辑运算\n  * AND操作\n  * OR操作\n  * NOT操作，双目运算，A NOT B属于A，但不属于B的部分\n* 拓扑运算\n  * 重叠\n  * 包含\n  * 相切\n* 集合运算\n  * 面积\n  * 周长\n  * 间距\n\n### 电路规则检查\n\n> 1、所有信号的电气连接关系是否一致\n>\n> 2、器件类型尺寸是否一致\n>\n> LVS文件：期间提前规则、电路比较规则、器件捆绑规则\n\n**电路提取与比较**\n\n步骤：更具LVS提取规则，从版图中抽取出版图所需要的网表文件。将抽取出的网表文件与电路网表文件做对比。\n\n**器件类型和数目及尺寸检查**\n\n* 器件类型检查：电阻、电容、电感、双极晶体管、MOS管、二极管\n  * 通过从版图与原理图中寻找名称相一致的器件实现\n* 器件数目与尺寸检查\n  * 检查版图中对应节点上期间的数量以及每个器件的尺寸是否与原理图中对应结点的期间数量与尺寸一致\n\n**LVS在数字IC中的检查**\n\n常用的解决LVS错误的方法\n\n* 检查器件数目\n* 检查器件类型\n* 检查节点数量\n* 检查电源线和地线的连接\n* 从关键点找起\n\n### **版图寄生参数提取与设计仿真**\n\n**版图寄生参数提取**\n\n版图设计的完整寄生参数应当包括R（电阻）、C（电容）、L（电感）、K（互感）\n\nLPE（版图寄生参数提取）/PRE（寄生电阻提取）提取的主要参数包括MOS管源漏的周长、面积、电阻，沟道的长与宽，双极晶体管和二极管的结面积、结周长，以及结点寄生电容、互连线电容电阻、接触孔电阻等。\n\n**版图设计仿真**\n\n使用牛顿迭代法，用泰勒级数的前几项来寻找方程f(x)=0的根\n\n### 逻辑单元库的建立\n\n> 逻辑单元的建库流程归纳为以下5步\n>\n> 1、方案设计与论证\n>\n> 2、电路设计\n>\n> 3、版图设计与物流库生成\n>\n> 4、标准单元特性及库模型生成\n>\n> 5、设计验证\n\n**逻辑单元类别**\n\n完整的单元库根据在芯片中的应用可以分为三类\n\n* 标准单元(standard cell)\n\n  放置于芯片的核心区起逻辑功能粘接作用\n\n* 模块宏单元(macro block)\n\n  放置于芯片核心区，至少包括嵌入式存储器（RAM和ROM）、IP、COT模块\n\n  其它重要的宏单元模块：始终PLL模块，DSP模块\n\n* 输入输出单元(I/O pad cell)\n\n  放置于核区的周围，用于芯片信号的输入、输出和电源供给\n\n![](Physical-design/05.png)\n\n**逻辑单元电路**\n\n组合逻辑电路简称为组合电路包括\n\n* 反向逻辑电路：反向器、与非门、或非门\n* 非反向逻辑电路：缓冲器、与门、或门\n* 其它常用逻辑电路：数据选择门（MUX）、异或门、数据传输门（TBUF）、复合门（AOI）\n* 特殊功能的逻辑电路：加法器、乘法器、除法器\n\n时序逻辑电路也称为时序电路\n\n> 输出信号不但同但钱的输入相关还和上一时间的输出有关，具有记忆功能\n\n包括：\n\n* 锁存器（Latch）：专指电平敏感的时序电路\n* 寄存器类（flip flop）：时钟边沿出发\n\n**模块单元（宏单元模块）**\n\n存储单元ROM：NOR ROM、NAND ROM、EPROM、EEPROM、FAMOS ROM\n\n存储单元RAM：静态随机存储器SRAM、动态随机存储器DRAM\n\n专用模块：客户自由工具COT，专用标准产品ASSP，信号处理器DSP\n\n黑盒子商业IP模块：电路设计不公开\n\n模拟电路模块：时钟锁相环PLL模块\n\n**输入输出单元**\n\n> 包括输入信号、输出信号、三态门、双向、电源和接地单元\n\n对于输入单元要考虑静电放电的防护\n\n形成电阻的方法：n型扩散层、p型扩散层和多晶硅\n\n形成电容的方法：Poly、Mos栅电容\n\n**物理单元库与数据文件，LEF文件**\n\n![](Physical-design/01.png)\n\n标准单元建库的规则\n\n* 所有单元都等高的矩形，或者是基本高度的整数倍\n* 所有版图都用预先定义的模板进行设计\n* 所有单元的端口位置、大小、形状都尽量满足网格间距的要求\n* 电源线和地线一般位于单元的上下边界\n\n模块单元建库\n\n* 先建立RAM和ROM的基本单元\n* 根据比特和字长，自底向上堆砌生成版图\n\nI/O单元\n\n* IO拐角单元在芯LEF文档的单元类型中被定义为Endcap，分布在拐角处\n\n**时序单元建库与数据文件**\n\n器件延时：表示信号通过一个逻辑门时所经历的时间，反映了门对输入信号变化响应的快慢。通过输入信号电压变化的50%到输出信号电压变化的50%所需要的时间来定义门延时的大小。\n\n![](Physical-design/06.png)\n\n用于DSM设计的器件延时模型\n\n* 开关线性RC模型\n* 经验推导公式（K-Factor方程）\n* 非线性延时模型\n* 可伸缩多项式模型\n\n时序库文件\n\n![](Physical-design/07.png)\n\nEDA工具通常采用两种模型计算天线比率，一种时部分检查模型，另一种是积累检查模型\n\n### 习题：\n\n* 1、什么是标准单元库？它主要包括哪几类单元？它们分别在电路中起什么作用？\n\n  标准单元库是一种预先设计和验证的模块化的芯片单元集合，用于构建数字集成电路，包含了经过验证和优化的标准逻辑门和寄存器等基本单元，可以在芯片设计中重复使用，以节省设计时间和提高设计的可靠性。\n\n  主要包括：逻辑门、寄存器、编码解码器、算术逻辑单元、存储器单元\n\n  使用标准单元库可以提高设计的效率，降低设计风险，促进可重用性。\n\n* 2、标准单元有几种不同抽象级别的描述？为什么要采用不同抽象层描述同一电路单元？\n\n  逻辑级描述、电路级描述、物理级描述\n\n  采用不同抽象层描述同一电路单元可以更好的管理设计的不同方面，优化设计的性能和可靠性，并在设计复杂性和效率之间进行权衡。\n\n* 3、解释LEF库文件在物理实施布局布线中的作用和重要性，并说明它所定义的内容是如何知道EDA工具实现自动布局布线的。\n\n  LEF库文件定义了标准单元的物理特性，包括尺寸大小方向以及引脚位置和功能等等\n\n  EDA工具实现自动布局布线是通过读取和解析LEF库文件中的信息。工具可以根据LEF文件中定义的物理特性和约束，生成优化芯片的物理布局和连线。\n\n## 第三章、布图规划（芯片规划）和布局\n\n### 布图规划\n\n布图规划开始时，首先要准备好各种基本设计数据和相应的物理库、时序库文件，并输入到不图规划的工具环境中来\n\n![](Physical-design/08.png)\n\n布图规划主要内容包含对芯片大小的规划、芯片设计输入输出单元的规划、大量硬核或模块的规划\n\n**布图规划的主要目标**\n\n* 确定芯片的面积\n* 确保时序的收敛\n* 保证芯片的稳定\n* 满足布线的要求：保证布线通畅的同时，尽量缩短走线的长度\n\n**I/O接口单元的放置与供电**\n\n放置方式：1、pin点方式，2、pad条状方式，3、做成固定模块，将pad集成\n\n当芯片面积较大，芯片时序较为紧张时，I/O单元也可能均匀分布在芯片的内部\n\n\n\nI/O单元的供电：I/O单元分为信号接口和电源两种\n\n电源I/O单元分为3类：给模拟器件供电的I/O单元、给数字期间供电的、用于隔离数字供电和模拟供电\n\n数字I/O也分为两大组：一组是给I/O单元供电，一组是给核内的标准单元供电\n\n给I/O单元供电的供电单元数量由多种因素决定：I/O单元的消耗、输出I/O单元的驱动能力、同步开关噪声\n\n**布图规划方案与延迟预估**\n\n展平化设计\n\n因为还没有进入布线阶段，使用线负载模型预估当前布局的时序，展平式的方法会占用大量的内存，需要很长的运行时间。\n\n层次化设计\n\n> 思想是将大规模的顶层设计分解成多个子模块，每个子模块并行完成布局布线，最后在顶层组装。\n>\n> 大致分为三个步骤：芯片顶层设计规划、子模块分割与实现、芯片顶层组装时序\n\n在层次化设计的过程中，需要在布图和布局规划中对时钟进行预估，流程图如下：\n\n> 根据子模块大小，和子模块中的元件数量以及复杂度来进行预估\n\n![](Physical-design/09.png)\n\n**模块布放与布线通道**\n\n布线轨道：芯片内部专门用于布线的路径\n\n布线通道：每两条或多条布线轨道的空间，上面不可以摆放标准单元\n\n### 电源规划\n\n> 给整个芯片的供电设计出一个均匀的网络，电源规划在芯片布图规划后或在布图规划过程中交叉完成。\n>\n> 电源网络设置、数字模拟混合供电、单电源与多电源供电电压网络设置\n\n芯片供电是通过I/O单元来实现的，需要先完成电源预算，\n\n**电源网络设计**\n\n* 电源连接关系定义global net connect\n* 芯片核内部分的电源环设计power ring\n* 芯片内所包含的硬核（如 RAM、ROM以及IP、COT模块）的电源环设计\n* 芯片核内纵横交错的电源网络设计\n* 芯片的供电单元与电源环的连接\n* 芯片内部的电源网络与硬核电源环连接部分的设计\n* 将标准单元的供电网络和硬核电源环连接部分的设计\n* I/O供电单元电源环的设计\n\n1、全局电源\n\n电源的定义主要包括：全局电源的定义以及连接关系的定义。\n\n* 电源和接地网络：通过wire定义\n* 接高电压和接低电压网络\n* 电压和接地端口\n* 填充单元网络\n\n2、电源环线\n\n为了能够均匀供电，包围在标准单元周围的环形供电金属，是连接供电I/O单元和标准单元的桥梁\n\n电源网格可以平均分布电流，缩短电流回路，在有效减少电压降的同时，避免由于电流分布不均时造成的热点现象以及电迁移问题。\n\n3、电源条线\n\n芯片内部纵横交错的电源网格和电源条线设计有专门的理论和算法。\n\n![](Physical-design/10.png)\n\n纵向必须用偶数层走线，横向必须用奇数层走线。\n\n**数字与模拟混合供电**\n\n1、模拟模块的工作区域一般放置于芯片的某个角落\n\n2、模拟区域需要单独供电\n\n3、在模拟模块的周围布置保护隔离环，从而实现数字信号和模拟信号电源之间的隔离\n\n![](Physical-design/11.png)\n\n**多电源供电**（麻了，看不懂）\n\n### 布局\n\n> 因为此时以及将芯片的各个部分规划好了，需要在具体规划的区域中填充详细的模块\n\n**展平式布局**\n\n模块的摆放与布局\n\n标准单元的摆放和优化\n\n简单来说：放置模块和标准单元·\n\n**层次化布局**\n\n> 先分配子模块、作子模块的布局、所有子模块完成后在顶层组装\n\n* 约束类型确定\n\n  > 约束类型一般有三种：向导约束、区域约束和限制约束\n\n* 子模块大小位置的制定\n\n**布局目标预估**\n\n> 在标准单元布局优化完成后，需要对设计进行拥塞分析，静态时序分析，噪声分析，和电源分析以确定布局的好坏\n\n布局的目标\n\n* 各模块的位置相对确定\n* 满足设计规则的要求\n* 芯片的时序和供电较为良好\n\n**标准单元布局优化算法**\n\n> 布局优化的算法从步骤上可以分成三个阶段：结群布局、全局布局、详细布局\n\n1、布局优化的算法\n\n* 结群算法（clustering聚类算法）\n\n  选择一个单元作为种子，以各个种子为原始群不断结合与其最紧密的单元。\n\n* 模拟退火算法、KL算法、FM算法\n\n* 全局布局：最小切割法、模拟退火算法、贪心算法、力向量算法、NRG算法、HALO算法\n\n* 布局优化算法：纯标准单元布局算法、模块布局算法、混合单元布局算法\n\n2、从优化目标上优化算法\n\n* 基于布线拥塞的布局优化算法\n* 基于时序的布局算法\n* 预防噪声的布局算法\n\n### 扫描链重组\n\n> 扫描链是可测试性设计的重要内容，将芯片中所应用的普通寄存器替换成带扫描功能的多输入输出扫描寄存器，首位连接成串，从而实现附加的测试功能。\n\n将连接在扫描链上的在芯片内随机分布的扫描寄存器单元按照其物理位置，在不影响逻辑功能的前提下，重写进行连接，从而减少扫描链的走线长度。\n\n实现方法：\n\n* 本地化重组\n* 基于扫描DEF的扫描链重组方法\n\n### 物理设计网表文件\n\nDEF(design exchange format)文件：设计交换给格式\n\nPDEF(physical DEF)：物理设计交换格式\n\n## 第四章时钟树综合CTS\n\n### 时钟信号\n\n**时钟信号抖动**：时钟抖动定义为信号时间与理想事件时间的偏差，抖动中含有确定抖动成分和随机抖动成分。\n\n* 确定抖动：串扰、电磁干扰、同时开关输出引起\n* 随即抖动：服从高斯分布，通常由半导体晶体结构的热振动和半导体掺杂密度不均匀中共价电子引起\n\n### 时钟树综合的方法\n\n> 芯片设计中的时钟分为两类：真实时钟（real clock）和虚拟时钟（virtual clock）\n>\n> 真实时钟又有两种模式：时钟树综合前没有延时的理想时钟，时钟树综合后的传播时钟\n\n**时钟树综合与标准设计约束文件**：SDC文件（时序约束文件）\n\nSDC文件三部分：时钟定义、输入延迟、输出延迟\n\n通过工艺文件来约束时钟信号的相关属性\n\n时钟的定义将通过时钟树综合来实现，时钟延迟和时钟抖动或不确定性将在静态时序分析时进行检查。\n\n**时钟树结构**\n\n```\n时钟树：时钟信号在物理设计中的实现结果\n根节点：时钟信号的起点\n叶结点：时钟信号经过一系列分布结点最终到达寄存器时钟输入端或其它时钟终点\n根单元、分布单元、叶单元：根节点、分布节点和叶结点都依附于的逻辑单元\n```\n\n时钟网络从根节点逐级插入驱动器，从而到达其叶结点，按照芯片始终网络的约束要求产生时钟树的过程叫做是中暑综合。\n\n![image-20230809095839094](Physical-design/image-20230809095839094.png)\n\n时钟树根据其在芯片内的分布特征，可分为多种结构：H树、 X树、平衡树、疏状或脊椎状时钟网\n\n### 时钟树设计策略\n\n**时钟树综合策略**\n\n* 自我交叉\n* 相互交叉时钟\n* 有用偏差\n\n![image-20230809102800761](Physical-design/image-20230809102800761.png)\n\n* OVC片上误差分析法与CPPR共同路径悲观去除的应用\n\n* 与布局相结合的手动时钟树设计\n* 对时钟插入多驱动的buffer\n\n**异步时钟树设计**\n\n实际的SoC设计中，是以异步时钟设计来实现的，从而降低功耗\n\n![image-20230809105341276](Physical-design/image-20230809105341276.png)\n\n**门控时钟**\n\n门控时钟是降低功耗最常用的方法，使用一个控制信号控制时钟的开启。\n\n### 时钟树分析\n\n**时钟树与功耗分析**\n\n> 时钟树上的功耗由静态功耗、短路功耗和跳变功耗三部分组成\n\n* 静态功耗：各个buffer上静态功耗和，减少静态功耗的方法就是减少buffer的加权数\n* 短路功耗：与转换时间成正比，与阈值电压的3次方成反比\n* 跳变功耗：占比50%以上，由门的加权数值以及互连线总的电容决定\n\n降低功耗的方案\n\n* 1、减小时钟信号转换时间，信号从10%转化到90%所需要的时间\n* 2、降低结点电容\n\n## 第五章、布线\n\n> 将分布在芯片核内的模块、标准单元和输入输出接口单元按逻辑关系进行互联\n>\n> 要求百分百地完成它们之间的所有逻辑信号的互联，并为满足各种约束条件进行优化\n\n### 全局布线\n\n**全局布线目标**\n\n* 1、使总连线最短\n* 2、布线分散均匀不至于引起局部拥塞\n* 3、使关键路径延时最小，遵守时序规则\n* 4、理解信号完整性要求，避免串扰\n* 5、保持将BUS总线聚集相连等\n\n**全局布线规划**\n\n### 详细布线\n\n**详细布线的目标**\n\n* 1、理解所有的设计规则\n* 2、自动切换并综合利用多层金属作连线\n* 3、遵守时序规则，优先使关键路径的延时满足要求\n* 4、对总连线长度进行优化\n\n**详细布线与设计规则**\n\n* 设计规则\n* 通孔和最小面积要求\n* 密度要求\n* 掩膜光刻过程中的工艺天线效应\n* 串扰在布线中的预防和修复\n* 纳米布线规则\n* 对焦布线规则\n\n**布线修正**\n\n* 自动修正\n* 渐进修正\n* 局部修正\n\n## 第六章、静态时序分析\n\n> 做时序分析前，首先要对芯片的物理版图设计进行包括电阻、电感、电容参数的提取，在进行延时计算。\n\n### 延迟计算与布线参数提取\n\n**延迟计算模型**\n\n> 可以在布局之后进行，也可以在时钟树综合后进行。使用WLM区估算\n\n各种参数提取、各种物理公式：电阻电容电感\n\n### 寄生参数与延迟格式文件\n\n1、标准寄生参数格式文件\n\n* SPF-Standard Parasistic Format（File），标准寄生参数格式文件\n* DSPF-Detailed SPF，详细标准寄生参数格式文件\n* RSPF-Reduced SPF，简化标准寄生参数格式文件\n* SPEF-Standard Parasitic Exchange Format（File），标准寄生参数交换格式文件\n\n### 静态时序分析\n\n> 进行时序分析时，简单的说就是将某一段路径的时序与时序约束的要求进行比较。根本目的是为了检查在时钟的控制和要求的约束下，与其相关的数据能够符合时序要求被记录存储下来，这种时序检查就是一对常说的建立时间时序和保持时间时序。\n\nSetup定义：在时钟作用前沿到达前，同步输入信号D必须保持稳定的那段时间以使信号不至于丢失。\n\nHold定义：在时钟作用前沿到达后，同步输入信号D必须保持稳定的那段时间以使得信号不至于丢失。\n\n1、建立时序（Setup）的违例\n\n要求同步输入数据D必须在时钟信号前的某个时段到达且不发射变化，这样数据才会被成功的锁存。\n\n2、保存时序违例\n\n增长数据的路径延迟\n\n**时序分析与时钟特性**\n\n* 定义输入输出环境参数\n  * 1、确定驱动\n  * 2、确定驱动单元\n  * 3、确定负载\n  * 4、确定删除\n\n### 时序优化\n\n**造成时序违例的因素**\n\n* 1、系统设计的复杂性和抽象性，存在不合理的约束\n* 2、逻辑综合时依据了不合理的WLM\n* 3、设计太大，互连线的相互牵制引起时序违例\n* 4、设计做了不合理的布局\n\n### 习题\n\n1、什么是静态时序分析？描述它的分析步骤过程。\n\n* 静态时序分析是一种在设计和验证数字电路时用于评估电路时序特性的方法。主要用于分析电路中的时序路径，包括组合逻辑路径和时钟路径，以确保电路在给定的时钟频率下能够满足时序要求。是一种基于约束和路径分析的方法，用于评估电路的时序特性和性能。\n\n2、什么是建立时间和保持时间？什么是虚假路径、多周期路径？\n\n* 建立时间：在时钟上升沿到来之前，为了确保输入数据能够稳定的被采样，输入信号必须保持不变的最小时间。\n* 保持时间：在时钟上升沿到来之后，为了确保输入数据能够完整的写入，输入型号必须保持不变的最小时间。\n* 虚假路径：在时序分析中被认为不需要满足时序约束的路径。这些路径不会对电路的正常工作产生影响，因此可以被忽略。\n* 多周期路径：信号的传播时间可以超过一个周期。\n\n3、如何保证物理实施阶段的时序收敛？\n\n* 通过静态时序分析\n\n## 第七章、功耗分析\n\n> 动态分析：芯片工作过程中产生的功耗\n>\n> 静态分析：芯片在待机状态时产生的平均功耗\n\n### 静态功耗分析\n\n> 反偏二极管泄漏电流\n>\n> 门栅感应漏极泄漏电流\n>\n> 亚阈值泄漏电流\n>\n> 门栅泄漏电流\n\n### 动态功耗分析\n\n> 开关功耗+短路功耗\n\n### **电压降分析与电迁移分析**\n\n电迁移：在一定的制造工艺下，在它上面所能允许流过的最大电流是有一定限度的，否则过大的电流将会使金属连线断裂，导致芯片失效，这种由于电流引起的电路失效现象称为EM电迁移。\n\n电源网络的电迁移由平均电流密度、金属宽度以及孔的大小决定\n\n电迁移容限测量方法：漂移速度法、低频噪声法、电阻模型模拟、等，常用寿命测试法（测量一定数量的相同样品在规定条件下的失效时间）\n\n### 功耗分析数据文件\n\n> 功耗分析需要建立相应的数据库，并且借助于与功耗相关的文件来有效地控制和处理这些数据\n\n静态分析数据——TCF文件\n\n动态分析数据——输入多两个重要信息：电源凸点的位置分布信息和动态功耗仿真用的VCD文件+TWF文件\n\n**电源网格视图库**——PGV(power grid view)\n\n> 用于分析芯片电压降效应的一种库文档格式\n>\n> 使用PGV库计算功耗的精度不是很高\n>\n> 根据供电网络分布，首先分别提取电源网络的电阻和电流节点处的平均结点阀门电流，再建立电源网络视图库\n","source":"_posts/Physical-design.md","raw":"---\ntitle: 集成电路物理设计学习笔记\ncategories: 学习笔记\ndate: 2023-08-09 16:42:48\ntags: [集成电路, 物理设计, EDA, Pyhsical Design]\ncover:\ntop_img:\n---\n## 第一章、集成电路物理设计方法\n\n### 数字集成电路设计流程\n\n三个I年代，发明，实施和整合\n\nInnovation：布局布线的基本算法、时序分析和逻辑综合的发明\n\nImplementation：开始于FPGA中门阵列的实现，ASIC设计中同等高度标准逻辑单元库的设计\n\nIntegration：模块化\n\n**芯片的物理实施重点解决的问题**\n\n对于深亚微米芯片\n\n* 解决时序驱动设计\n\n* 防止工艺天线效应\n* 进行信号完整性分析\n\n对于纳米的设计，需要多考虑的问题\n\n* 功耗分析和低功耗设计，并要统一考虑它的功能验证，逻辑综合和形式验证\n* 实施纳米设计中的光学近似检查（OPC）和移相掩膜（PSM），增加设计产额和可制造性设计\n* 统计静态时序分析，多端角分析\n\n**展平式物理设计**\n\n> 标准逻辑门单元库的简历。采用自下向上的方法，设计晶体管-仿真-建立版图-对逻辑门单元仿真建模\n\n![](Physical-design/01.png)\n\n**硅虚拟原型设计**\n\n![](Physical-design/02.png)\n\n与展平化的物理设计流程区别\n\n* 布图阶段，考虑将整个设计进行分割\n* 布线时用了快速近似的试验布线法\n* 在做RC提取时，可以用集总电容模型\n\n**层次化物理设计**\n\n> 芯片设计的最终检查标准之一为是否实现了时序收敛\n\n自上而下的层次化物理设计：将设计分为数个分割块，对每个分割块进行展品化处理（独立的布局布线），在顶层完成组装设计\n\n![](Physical-design/03.png)\n\n优点：将很大的设计化成多个小设计，如果有时序问题可能存在于个别模块，再去重点解决，降低了复杂性。\n\n* 基于设计驱动时序图\n\n  在顶层设计和模块设计之间建立一个连接的时序图桥梁，从而避免当模块设计完成后回到顶层无法收敛而造成大量的设计迭代。\n\n  将模块级的实施分成多个阶段，如时钟树综合，详细布线阶段，布线优化阶段\n\n### 数字集成电路设计收敛\n\n> 设计时序收敛任务通过三大部分工作来完成：数据系统，优化引擎，分析引擎\n>\n> 数据系统：由读取、处理和存储\n>\n> 优化引擎：基于算法去实现逻辑优化，布局优化，和布线优化\n>\n> 分析引擎：由设计工程师借助EDA工具用于时序分析，功耗分析和噪声分析的EDA工具\n\n**时序收敛**\n\n静态时序分析最重要任务：寻找最长延时路径以及最坏情况下的延时\n\n总延时：由逻辑门延时和互连线延时组成\n\n静态时序路径：组合逻辑电路，时序逻辑电路形成的路径\n\n**功耗分析**\n\n* 静态功耗分析\n\n  使用时序库提供的器件功耗可以计算\n\n* 动态功耗分析\n\n  需要提供设计仿真的数据\n\n降低功耗的方式：多电源电压方法、门控电路方法、衬底电压偏执方法\n\n![](Physical-design/04.png)\n\n### 习题：\n\n* 1、讨论什么是数字电路的物理设计和物理实施？\n\n  集成电路的物理实施方法被概括为从RTL综合到最终完成GDSII数据的实现，RTL一种硬件描述语言，用于描述数字电路的逻辑功能和寄存器传输级别的行为。GDSII是一种电子设计自动化工具所使用的标准格式，用于描述芯片的物理布局和制造信息。\n\n  将RTL转换为GDSII是一个多步骤的过程，通常包括以下几个主要阶段：\n\n  * 1、逻辑综合：将RTL描述的电路转换为门级电路，生成门级网表。\n  * 2、时序优化：对门级网表进行优化，以减少电路的面积、功耗或者时钟延迟等。\n  * 3、布局：根据门级网表生成芯片的物理布局，包括各个组件的位置、尺寸和连线等。\n  * 4、布线：根据布局信息进行连线，确保电路的信号可以正确传输。\n  * 5、物理验证：对布局和布线结果进行物理验证，包括规则检查、电气特性分析等。\n    * 后面有一个提取阶段\n  * 6、转换为GDSII：将经过物理验证的布局和布线结果转化为GDSII格式，生成最终的物理设计数据\n\n* 2、什么是硅虚拟原型SVP？为什么要提出硅虚拟模型设计方法？\n\n  硅虚拟原型：是一种基于软件仿真和硬件加速的技术，用于验证和评估芯片设计的功能和新能。\n\n  采用硅虚拟模型设计方法能够尽早预估该设计能否大致实现时序收敛，具有更快的设计迭代速度和更低的开发成本。\n\n* 3、展平式物理设计与层次式物理设计的共同点和不同点是什么？\n\n  基本流程都具备，但是步骤顺序可能存在偏差\n\n  展平式设计是一种自下而上的模块化方法，从底层器件再到版图\n\n  层次化设计是一种自上而下的物理设计方法，从版图再往下\n\n* 4、设计收敛的实现与设计流程有关吗？\n\n  有关，设计流程可以提供一种系统化的方法和框架，能够有效地引导和管理设计的各个阶段，以实现设计收敛，使得设计能够按照预期目标收敛。\n\n* 5、当今EDA工具的设计所采用的主要的数据文件格式有哪些？数据库格式有哪些？常用的编程语言有哪些？\n\n  RTL：硬件描述语言编写的RTL代码\n\n  网表：描述芯片的逻辑电路结构和连接关系的文本文件\n\n  GDSII：用于描述芯片的物理布局和制造信息的二进制格式\n\n  LEF和DEF：用于描述芯片的物理布局和制造信息的二进制格式\n\n  SDC：用于定义时序约束的文本文件，指定电路的时序要求和约束条件\n\n## 第二章、物理设计建库与验证\n\n### 集成电路工艺与版图\n\n**CMOS工艺流程**\n\n晶圆—形成制造晶体管所需的衬底和阱区—形成晶体管栅层图形—形成源漏、衬底和阱接触等其它有源区—通过接触孔将需要连接的地方与第一层金属互连—进行其它几层金属互连—添加钝化层与外界隔离开\n\n**工艺技术文件**\n\n> 晶体代工厂提供给设计者用于后端版图设计的技术文件，用于与EDA工具交互工艺信息，内容包括图形定义及显示信息，互连线工艺信息和通孔工艺信息\n\n### 设计规则检查（DRC）\n\n主要目的：检查版图中所有因违反设计规则而引起潜在断路，短路或不良效应的物理验证过程\n\n**版图设计规则**\n\n> 晶圆代工厂对不同工艺参数制定出满足芯片制造良率的同一工艺层以及不同工艺层之间几何尺寸的最小值，这些最小值规划的集合就是版图设计规则。\n\n* 逻辑运算\n  * AND操作\n  * OR操作\n  * NOT操作，双目运算，A NOT B属于A，但不属于B的部分\n* 拓扑运算\n  * 重叠\n  * 包含\n  * 相切\n* 集合运算\n  * 面积\n  * 周长\n  * 间距\n\n### 电路规则检查\n\n> 1、所有信号的电气连接关系是否一致\n>\n> 2、器件类型尺寸是否一致\n>\n> LVS文件：期间提前规则、电路比较规则、器件捆绑规则\n\n**电路提取与比较**\n\n步骤：更具LVS提取规则，从版图中抽取出版图所需要的网表文件。将抽取出的网表文件与电路网表文件做对比。\n\n**器件类型和数目及尺寸检查**\n\n* 器件类型检查：电阻、电容、电感、双极晶体管、MOS管、二极管\n  * 通过从版图与原理图中寻找名称相一致的器件实现\n* 器件数目与尺寸检查\n  * 检查版图中对应节点上期间的数量以及每个器件的尺寸是否与原理图中对应结点的期间数量与尺寸一致\n\n**LVS在数字IC中的检查**\n\n常用的解决LVS错误的方法\n\n* 检查器件数目\n* 检查器件类型\n* 检查节点数量\n* 检查电源线和地线的连接\n* 从关键点找起\n\n### **版图寄生参数提取与设计仿真**\n\n**版图寄生参数提取**\n\n版图设计的完整寄生参数应当包括R（电阻）、C（电容）、L（电感）、K（互感）\n\nLPE（版图寄生参数提取）/PRE（寄生电阻提取）提取的主要参数包括MOS管源漏的周长、面积、电阻，沟道的长与宽，双极晶体管和二极管的结面积、结周长，以及结点寄生电容、互连线电容电阻、接触孔电阻等。\n\n**版图设计仿真**\n\n使用牛顿迭代法，用泰勒级数的前几项来寻找方程f(x)=0的根\n\n### 逻辑单元库的建立\n\n> 逻辑单元的建库流程归纳为以下5步\n>\n> 1、方案设计与论证\n>\n> 2、电路设计\n>\n> 3、版图设计与物流库生成\n>\n> 4、标准单元特性及库模型生成\n>\n> 5、设计验证\n\n**逻辑单元类别**\n\n完整的单元库根据在芯片中的应用可以分为三类\n\n* 标准单元(standard cell)\n\n  放置于芯片的核心区起逻辑功能粘接作用\n\n* 模块宏单元(macro block)\n\n  放置于芯片核心区，至少包括嵌入式存储器（RAM和ROM）、IP、COT模块\n\n  其它重要的宏单元模块：始终PLL模块，DSP模块\n\n* 输入输出单元(I/O pad cell)\n\n  放置于核区的周围，用于芯片信号的输入、输出和电源供给\n\n![](Physical-design/05.png)\n\n**逻辑单元电路**\n\n组合逻辑电路简称为组合电路包括\n\n* 反向逻辑电路：反向器、与非门、或非门\n* 非反向逻辑电路：缓冲器、与门、或门\n* 其它常用逻辑电路：数据选择门（MUX）、异或门、数据传输门（TBUF）、复合门（AOI）\n* 特殊功能的逻辑电路：加法器、乘法器、除法器\n\n时序逻辑电路也称为时序电路\n\n> 输出信号不但同但钱的输入相关还和上一时间的输出有关，具有记忆功能\n\n包括：\n\n* 锁存器（Latch）：专指电平敏感的时序电路\n* 寄存器类（flip flop）：时钟边沿出发\n\n**模块单元（宏单元模块）**\n\n存储单元ROM：NOR ROM、NAND ROM、EPROM、EEPROM、FAMOS ROM\n\n存储单元RAM：静态随机存储器SRAM、动态随机存储器DRAM\n\n专用模块：客户自由工具COT，专用标准产品ASSP，信号处理器DSP\n\n黑盒子商业IP模块：电路设计不公开\n\n模拟电路模块：时钟锁相环PLL模块\n\n**输入输出单元**\n\n> 包括输入信号、输出信号、三态门、双向、电源和接地单元\n\n对于输入单元要考虑静电放电的防护\n\n形成电阻的方法：n型扩散层、p型扩散层和多晶硅\n\n形成电容的方法：Poly、Mos栅电容\n\n**物理单元库与数据文件，LEF文件**\n\n![](Physical-design/01.png)\n\n标准单元建库的规则\n\n* 所有单元都等高的矩形，或者是基本高度的整数倍\n* 所有版图都用预先定义的模板进行设计\n* 所有单元的端口位置、大小、形状都尽量满足网格间距的要求\n* 电源线和地线一般位于单元的上下边界\n\n模块单元建库\n\n* 先建立RAM和ROM的基本单元\n* 根据比特和字长，自底向上堆砌生成版图\n\nI/O单元\n\n* IO拐角单元在芯LEF文档的单元类型中被定义为Endcap，分布在拐角处\n\n**时序单元建库与数据文件**\n\n器件延时：表示信号通过一个逻辑门时所经历的时间，反映了门对输入信号变化响应的快慢。通过输入信号电压变化的50%到输出信号电压变化的50%所需要的时间来定义门延时的大小。\n\n![](Physical-design/06.png)\n\n用于DSM设计的器件延时模型\n\n* 开关线性RC模型\n* 经验推导公式（K-Factor方程）\n* 非线性延时模型\n* 可伸缩多项式模型\n\n时序库文件\n\n![](Physical-design/07.png)\n\nEDA工具通常采用两种模型计算天线比率，一种时部分检查模型，另一种是积累检查模型\n\n### 习题：\n\n* 1、什么是标准单元库？它主要包括哪几类单元？它们分别在电路中起什么作用？\n\n  标准单元库是一种预先设计和验证的模块化的芯片单元集合，用于构建数字集成电路，包含了经过验证和优化的标准逻辑门和寄存器等基本单元，可以在芯片设计中重复使用，以节省设计时间和提高设计的可靠性。\n\n  主要包括：逻辑门、寄存器、编码解码器、算术逻辑单元、存储器单元\n\n  使用标准单元库可以提高设计的效率，降低设计风险，促进可重用性。\n\n* 2、标准单元有几种不同抽象级别的描述？为什么要采用不同抽象层描述同一电路单元？\n\n  逻辑级描述、电路级描述、物理级描述\n\n  采用不同抽象层描述同一电路单元可以更好的管理设计的不同方面，优化设计的性能和可靠性，并在设计复杂性和效率之间进行权衡。\n\n* 3、解释LEF库文件在物理实施布局布线中的作用和重要性，并说明它所定义的内容是如何知道EDA工具实现自动布局布线的。\n\n  LEF库文件定义了标准单元的物理特性，包括尺寸大小方向以及引脚位置和功能等等\n\n  EDA工具实现自动布局布线是通过读取和解析LEF库文件中的信息。工具可以根据LEF文件中定义的物理特性和约束，生成优化芯片的物理布局和连线。\n\n## 第三章、布图规划（芯片规划）和布局\n\n### 布图规划\n\n布图规划开始时，首先要准备好各种基本设计数据和相应的物理库、时序库文件，并输入到不图规划的工具环境中来\n\n![](Physical-design/08.png)\n\n布图规划主要内容包含对芯片大小的规划、芯片设计输入输出单元的规划、大量硬核或模块的规划\n\n**布图规划的主要目标**\n\n* 确定芯片的面积\n* 确保时序的收敛\n* 保证芯片的稳定\n* 满足布线的要求：保证布线通畅的同时，尽量缩短走线的长度\n\n**I/O接口单元的放置与供电**\n\n放置方式：1、pin点方式，2、pad条状方式，3、做成固定模块，将pad集成\n\n当芯片面积较大，芯片时序较为紧张时，I/O单元也可能均匀分布在芯片的内部\n\n\n\nI/O单元的供电：I/O单元分为信号接口和电源两种\n\n电源I/O单元分为3类：给模拟器件供电的I/O单元、给数字期间供电的、用于隔离数字供电和模拟供电\n\n数字I/O也分为两大组：一组是给I/O单元供电，一组是给核内的标准单元供电\n\n给I/O单元供电的供电单元数量由多种因素决定：I/O单元的消耗、输出I/O单元的驱动能力、同步开关噪声\n\n**布图规划方案与延迟预估**\n\n展平化设计\n\n因为还没有进入布线阶段，使用线负载模型预估当前布局的时序，展平式的方法会占用大量的内存，需要很长的运行时间。\n\n层次化设计\n\n> 思想是将大规模的顶层设计分解成多个子模块，每个子模块并行完成布局布线，最后在顶层组装。\n>\n> 大致分为三个步骤：芯片顶层设计规划、子模块分割与实现、芯片顶层组装时序\n\n在层次化设计的过程中，需要在布图和布局规划中对时钟进行预估，流程图如下：\n\n> 根据子模块大小，和子模块中的元件数量以及复杂度来进行预估\n\n![](Physical-design/09.png)\n\n**模块布放与布线通道**\n\n布线轨道：芯片内部专门用于布线的路径\n\n布线通道：每两条或多条布线轨道的空间，上面不可以摆放标准单元\n\n### 电源规划\n\n> 给整个芯片的供电设计出一个均匀的网络，电源规划在芯片布图规划后或在布图规划过程中交叉完成。\n>\n> 电源网络设置、数字模拟混合供电、单电源与多电源供电电压网络设置\n\n芯片供电是通过I/O单元来实现的，需要先完成电源预算，\n\n**电源网络设计**\n\n* 电源连接关系定义global net connect\n* 芯片核内部分的电源环设计power ring\n* 芯片内所包含的硬核（如 RAM、ROM以及IP、COT模块）的电源环设计\n* 芯片核内纵横交错的电源网络设计\n* 芯片的供电单元与电源环的连接\n* 芯片内部的电源网络与硬核电源环连接部分的设计\n* 将标准单元的供电网络和硬核电源环连接部分的设计\n* I/O供电单元电源环的设计\n\n1、全局电源\n\n电源的定义主要包括：全局电源的定义以及连接关系的定义。\n\n* 电源和接地网络：通过wire定义\n* 接高电压和接低电压网络\n* 电压和接地端口\n* 填充单元网络\n\n2、电源环线\n\n为了能够均匀供电，包围在标准单元周围的环形供电金属，是连接供电I/O单元和标准单元的桥梁\n\n电源网格可以平均分布电流，缩短电流回路，在有效减少电压降的同时，避免由于电流分布不均时造成的热点现象以及电迁移问题。\n\n3、电源条线\n\n芯片内部纵横交错的电源网格和电源条线设计有专门的理论和算法。\n\n![](Physical-design/10.png)\n\n纵向必须用偶数层走线，横向必须用奇数层走线。\n\n**数字与模拟混合供电**\n\n1、模拟模块的工作区域一般放置于芯片的某个角落\n\n2、模拟区域需要单独供电\n\n3、在模拟模块的周围布置保护隔离环，从而实现数字信号和模拟信号电源之间的隔离\n\n![](Physical-design/11.png)\n\n**多电源供电**（麻了，看不懂）\n\n### 布局\n\n> 因为此时以及将芯片的各个部分规划好了，需要在具体规划的区域中填充详细的模块\n\n**展平式布局**\n\n模块的摆放与布局\n\n标准单元的摆放和优化\n\n简单来说：放置模块和标准单元·\n\n**层次化布局**\n\n> 先分配子模块、作子模块的布局、所有子模块完成后在顶层组装\n\n* 约束类型确定\n\n  > 约束类型一般有三种：向导约束、区域约束和限制约束\n\n* 子模块大小位置的制定\n\n**布局目标预估**\n\n> 在标准单元布局优化完成后，需要对设计进行拥塞分析，静态时序分析，噪声分析，和电源分析以确定布局的好坏\n\n布局的目标\n\n* 各模块的位置相对确定\n* 满足设计规则的要求\n* 芯片的时序和供电较为良好\n\n**标准单元布局优化算法**\n\n> 布局优化的算法从步骤上可以分成三个阶段：结群布局、全局布局、详细布局\n\n1、布局优化的算法\n\n* 结群算法（clustering聚类算法）\n\n  选择一个单元作为种子，以各个种子为原始群不断结合与其最紧密的单元。\n\n* 模拟退火算法、KL算法、FM算法\n\n* 全局布局：最小切割法、模拟退火算法、贪心算法、力向量算法、NRG算法、HALO算法\n\n* 布局优化算法：纯标准单元布局算法、模块布局算法、混合单元布局算法\n\n2、从优化目标上优化算法\n\n* 基于布线拥塞的布局优化算法\n* 基于时序的布局算法\n* 预防噪声的布局算法\n\n### 扫描链重组\n\n> 扫描链是可测试性设计的重要内容，将芯片中所应用的普通寄存器替换成带扫描功能的多输入输出扫描寄存器，首位连接成串，从而实现附加的测试功能。\n\n将连接在扫描链上的在芯片内随机分布的扫描寄存器单元按照其物理位置，在不影响逻辑功能的前提下，重写进行连接，从而减少扫描链的走线长度。\n\n实现方法：\n\n* 本地化重组\n* 基于扫描DEF的扫描链重组方法\n\n### 物理设计网表文件\n\nDEF(design exchange format)文件：设计交换给格式\n\nPDEF(physical DEF)：物理设计交换格式\n\n## 第四章时钟树综合CTS\n\n### 时钟信号\n\n**时钟信号抖动**：时钟抖动定义为信号时间与理想事件时间的偏差，抖动中含有确定抖动成分和随机抖动成分。\n\n* 确定抖动：串扰、电磁干扰、同时开关输出引起\n* 随即抖动：服从高斯分布，通常由半导体晶体结构的热振动和半导体掺杂密度不均匀中共价电子引起\n\n### 时钟树综合的方法\n\n> 芯片设计中的时钟分为两类：真实时钟（real clock）和虚拟时钟（virtual clock）\n>\n> 真实时钟又有两种模式：时钟树综合前没有延时的理想时钟，时钟树综合后的传播时钟\n\n**时钟树综合与标准设计约束文件**：SDC文件（时序约束文件）\n\nSDC文件三部分：时钟定义、输入延迟、输出延迟\n\n通过工艺文件来约束时钟信号的相关属性\n\n时钟的定义将通过时钟树综合来实现，时钟延迟和时钟抖动或不确定性将在静态时序分析时进行检查。\n\n**时钟树结构**\n\n```\n时钟树：时钟信号在物理设计中的实现结果\n根节点：时钟信号的起点\n叶结点：时钟信号经过一系列分布结点最终到达寄存器时钟输入端或其它时钟终点\n根单元、分布单元、叶单元：根节点、分布节点和叶结点都依附于的逻辑单元\n```\n\n时钟网络从根节点逐级插入驱动器，从而到达其叶结点，按照芯片始终网络的约束要求产生时钟树的过程叫做是中暑综合。\n\n![image-20230809095839094](Physical-design/image-20230809095839094.png)\n\n时钟树根据其在芯片内的分布特征，可分为多种结构：H树、 X树、平衡树、疏状或脊椎状时钟网\n\n### 时钟树设计策略\n\n**时钟树综合策略**\n\n* 自我交叉\n* 相互交叉时钟\n* 有用偏差\n\n![image-20230809102800761](Physical-design/image-20230809102800761.png)\n\n* OVC片上误差分析法与CPPR共同路径悲观去除的应用\n\n* 与布局相结合的手动时钟树设计\n* 对时钟插入多驱动的buffer\n\n**异步时钟树设计**\n\n实际的SoC设计中，是以异步时钟设计来实现的，从而降低功耗\n\n![image-20230809105341276](Physical-design/image-20230809105341276.png)\n\n**门控时钟**\n\n门控时钟是降低功耗最常用的方法，使用一个控制信号控制时钟的开启。\n\n### 时钟树分析\n\n**时钟树与功耗分析**\n\n> 时钟树上的功耗由静态功耗、短路功耗和跳变功耗三部分组成\n\n* 静态功耗：各个buffer上静态功耗和，减少静态功耗的方法就是减少buffer的加权数\n* 短路功耗：与转换时间成正比，与阈值电压的3次方成反比\n* 跳变功耗：占比50%以上，由门的加权数值以及互连线总的电容决定\n\n降低功耗的方案\n\n* 1、减小时钟信号转换时间，信号从10%转化到90%所需要的时间\n* 2、降低结点电容\n\n## 第五章、布线\n\n> 将分布在芯片核内的模块、标准单元和输入输出接口单元按逻辑关系进行互联\n>\n> 要求百分百地完成它们之间的所有逻辑信号的互联，并为满足各种约束条件进行优化\n\n### 全局布线\n\n**全局布线目标**\n\n* 1、使总连线最短\n* 2、布线分散均匀不至于引起局部拥塞\n* 3、使关键路径延时最小，遵守时序规则\n* 4、理解信号完整性要求，避免串扰\n* 5、保持将BUS总线聚集相连等\n\n**全局布线规划**\n\n### 详细布线\n\n**详细布线的目标**\n\n* 1、理解所有的设计规则\n* 2、自动切换并综合利用多层金属作连线\n* 3、遵守时序规则，优先使关键路径的延时满足要求\n* 4、对总连线长度进行优化\n\n**详细布线与设计规则**\n\n* 设计规则\n* 通孔和最小面积要求\n* 密度要求\n* 掩膜光刻过程中的工艺天线效应\n* 串扰在布线中的预防和修复\n* 纳米布线规则\n* 对焦布线规则\n\n**布线修正**\n\n* 自动修正\n* 渐进修正\n* 局部修正\n\n## 第六章、静态时序分析\n\n> 做时序分析前，首先要对芯片的物理版图设计进行包括电阻、电感、电容参数的提取，在进行延时计算。\n\n### 延迟计算与布线参数提取\n\n**延迟计算模型**\n\n> 可以在布局之后进行，也可以在时钟树综合后进行。使用WLM区估算\n\n各种参数提取、各种物理公式：电阻电容电感\n\n### 寄生参数与延迟格式文件\n\n1、标准寄生参数格式文件\n\n* SPF-Standard Parasistic Format（File），标准寄生参数格式文件\n* DSPF-Detailed SPF，详细标准寄生参数格式文件\n* RSPF-Reduced SPF，简化标准寄生参数格式文件\n* SPEF-Standard Parasitic Exchange Format（File），标准寄生参数交换格式文件\n\n### 静态时序分析\n\n> 进行时序分析时，简单的说就是将某一段路径的时序与时序约束的要求进行比较。根本目的是为了检查在时钟的控制和要求的约束下，与其相关的数据能够符合时序要求被记录存储下来，这种时序检查就是一对常说的建立时间时序和保持时间时序。\n\nSetup定义：在时钟作用前沿到达前，同步输入信号D必须保持稳定的那段时间以使信号不至于丢失。\n\nHold定义：在时钟作用前沿到达后，同步输入信号D必须保持稳定的那段时间以使得信号不至于丢失。\n\n1、建立时序（Setup）的违例\n\n要求同步输入数据D必须在时钟信号前的某个时段到达且不发射变化，这样数据才会被成功的锁存。\n\n2、保存时序违例\n\n增长数据的路径延迟\n\n**时序分析与时钟特性**\n\n* 定义输入输出环境参数\n  * 1、确定驱动\n  * 2、确定驱动单元\n  * 3、确定负载\n  * 4、确定删除\n\n### 时序优化\n\n**造成时序违例的因素**\n\n* 1、系统设计的复杂性和抽象性，存在不合理的约束\n* 2、逻辑综合时依据了不合理的WLM\n* 3、设计太大，互连线的相互牵制引起时序违例\n* 4、设计做了不合理的布局\n\n### 习题\n\n1、什么是静态时序分析？描述它的分析步骤过程。\n\n* 静态时序分析是一种在设计和验证数字电路时用于评估电路时序特性的方法。主要用于分析电路中的时序路径，包括组合逻辑路径和时钟路径，以确保电路在给定的时钟频率下能够满足时序要求。是一种基于约束和路径分析的方法，用于评估电路的时序特性和性能。\n\n2、什么是建立时间和保持时间？什么是虚假路径、多周期路径？\n\n* 建立时间：在时钟上升沿到来之前，为了确保输入数据能够稳定的被采样，输入信号必须保持不变的最小时间。\n* 保持时间：在时钟上升沿到来之后，为了确保输入数据能够完整的写入，输入型号必须保持不变的最小时间。\n* 虚假路径：在时序分析中被认为不需要满足时序约束的路径。这些路径不会对电路的正常工作产生影响，因此可以被忽略。\n* 多周期路径：信号的传播时间可以超过一个周期。\n\n3、如何保证物理实施阶段的时序收敛？\n\n* 通过静态时序分析\n\n## 第七章、功耗分析\n\n> 动态分析：芯片工作过程中产生的功耗\n>\n> 静态分析：芯片在待机状态时产生的平均功耗\n\n### 静态功耗分析\n\n> 反偏二极管泄漏电流\n>\n> 门栅感应漏极泄漏电流\n>\n> 亚阈值泄漏电流\n>\n> 门栅泄漏电流\n\n### 动态功耗分析\n\n> 开关功耗+短路功耗\n\n### **电压降分析与电迁移分析**\n\n电迁移：在一定的制造工艺下，在它上面所能允许流过的最大电流是有一定限度的，否则过大的电流将会使金属连线断裂，导致芯片失效，这种由于电流引起的电路失效现象称为EM电迁移。\n\n电源网络的电迁移由平均电流密度、金属宽度以及孔的大小决定\n\n电迁移容限测量方法：漂移速度法、低频噪声法、电阻模型模拟、等，常用寿命测试法（测量一定数量的相同样品在规定条件下的失效时间）\n\n### 功耗分析数据文件\n\n> 功耗分析需要建立相应的数据库，并且借助于与功耗相关的文件来有效地控制和处理这些数据\n\n静态分析数据——TCF文件\n\n动态分析数据——输入多两个重要信息：电源凸点的位置分布信息和动态功耗仿真用的VCD文件+TWF文件\n\n**电源网格视图库**——PGV(power grid view)\n\n> 用于分析芯片电压降效应的一种库文档格式\n>\n> 使用PGV库计算功耗的精度不是很高\n>\n> 根据供电网络分布，首先分别提取电源网络的电阻和电流节点处的平均结点阀门电流，再建立电源网络视图库\n","slug":"Physical-design","published":1,"updated":"2024-06-05T09:03:03.582Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttm000n08jvg31sauo9","content":"<h2 id=\"第一章、集成电路物理设计方法\"><a href=\"#第一章、集成电路物理设计方法\" class=\"headerlink\" title=\"第一章、集成电路物理设计方法\"></a>第一章、集成电路物理设计方法</h2><h3 id=\"数字集成电路设计流程\"><a href=\"#数字集成电路设计流程\" class=\"headerlink\" title=\"数字集成电路设计流程\"></a>数字集成电路设计流程</h3><p>三个I年代，发明，实施和整合</p>\n<p>Innovation：布局布线的基本算法、时序分析和逻辑综合的发明</p>\n<p>Implementation：开始于FPGA中门阵列的实现，ASIC设计中同等高度标准逻辑单元库的设计</p>\n<p>Integration：模块化</p>\n<p><strong>芯片的物理实施重点解决的问题</strong></p>\n<p>对于深亚微米芯片</p>\n<ul>\n<li><p>解决时序驱动设计</p>\n</li>\n<li><p>防止工艺天线效应</p>\n</li>\n<li>进行信号完整性分析</li>\n</ul>\n<p>对于纳米的设计，需要多考虑的问题</p>\n<ul>\n<li>功耗分析和低功耗设计，并要统一考虑它的功能验证，逻辑综合和形式验证</li>\n<li>实施纳米设计中的光学近似检查（OPC）和移相掩膜（PSM），增加设计产额和可制造性设计</li>\n<li>统计静态时序分析，多端角分析</li>\n</ul>\n<p><strong>展平式物理设计</strong></p>\n<blockquote>\n<p>标准逻辑门单元库的简历。采用自下向上的方法，设计晶体管-仿真-建立版图-对逻辑门单元仿真建模</p>\n</blockquote>\n<img src=\"/2023/08/09/Physical-design/01.png\" class=\"\">\n<p><strong>硅虚拟原型设计</strong></p>\n<img src=\"/2023/08/09/Physical-design/02.png\" class=\"\">\n<p>与展平化的物理设计流程区别</p>\n<ul>\n<li>布图阶段，考虑将整个设计进行分割</li>\n<li>布线时用了快速近似的试验布线法</li>\n<li>在做RC提取时，可以用集总电容模型</li>\n</ul>\n<p><strong>层次化物理设计</strong></p>\n<blockquote>\n<p>芯片设计的最终检查标准之一为是否实现了时序收敛</p>\n</blockquote>\n<p>自上而下的层次化物理设计：将设计分为数个分割块，对每个分割块进行展品化处理（独立的布局布线），在顶层完成组装设计</p>\n<img src=\"/2023/08/09/Physical-design/03.png\" class=\"\">\n<p>优点：将很大的设计化成多个小设计，如果有时序问题可能存在于个别模块，再去重点解决，降低了复杂性。</p>\n<ul>\n<li><p>基于设计驱动时序图</p>\n<p>在顶层设计和模块设计之间建立一个连接的时序图桥梁，从而避免当模块设计完成后回到顶层无法收敛而造成大量的设计迭代。</p>\n<p>将模块级的实施分成多个阶段，如时钟树综合，详细布线阶段，布线优化阶段</p>\n</li>\n</ul>\n<h3 id=\"数字集成电路设计收敛\"><a href=\"#数字集成电路设计收敛\" class=\"headerlink\" title=\"数字集成电路设计收敛\"></a>数字集成电路设计收敛</h3><blockquote>\n<p>设计时序收敛任务通过三大部分工作来完成：数据系统，优化引擎，分析引擎</p>\n<p>数据系统：由读取、处理和存储</p>\n<p>优化引擎：基于算法去实现逻辑优化，布局优化，和布线优化</p>\n<p>分析引擎：由设计工程师借助EDA工具用于时序分析，功耗分析和噪声分析的EDA工具</p>\n</blockquote>\n<p><strong>时序收敛</strong></p>\n<p>静态时序分析最重要任务：寻找最长延时路径以及最坏情况下的延时</p>\n<p>总延时：由逻辑门延时和互连线延时组成</p>\n<p>静态时序路径：组合逻辑电路，时序逻辑电路形成的路径</p>\n<p><strong>功耗分析</strong></p>\n<ul>\n<li><p>静态功耗分析</p>\n<p>使用时序库提供的器件功耗可以计算</p>\n</li>\n<li><p>动态功耗分析</p>\n<p>需要提供设计仿真的数据</p>\n</li>\n</ul>\n<p>降低功耗的方式：多电源电压方法、门控电路方法、衬底电压偏执方法</p>\n<img src=\"/2023/08/09/Physical-design/04.png\" class=\"\">\n<h3 id=\"习题：\"><a href=\"#习题：\" class=\"headerlink\" title=\"习题：\"></a>习题：</h3><ul>\n<li><p>1、讨论什么是数字电路的物理设计和物理实施？</p>\n<p>集成电路的物理实施方法被概括为从RTL综合到最终完成GDSII数据的实现，RTL一种硬件描述语言，用于描述数字电路的逻辑功能和寄存器传输级别的行为。GDSII是一种电子设计自动化工具所使用的标准格式，用于描述芯片的物理布局和制造信息。</p>\n<p>将RTL转换为GDSII是一个多步骤的过程，通常包括以下几个主要阶段：</p>\n<ul>\n<li>1、逻辑综合：将RTL描述的电路转换为门级电路，生成门级网表。</li>\n<li>2、时序优化：对门级网表进行优化，以减少电路的面积、功耗或者时钟延迟等。</li>\n<li>3、布局：根据门级网表生成芯片的物理布局，包括各个组件的位置、尺寸和连线等。</li>\n<li>4、布线：根据布局信息进行连线，确保电路的信号可以正确传输。</li>\n<li>5、物理验证：对布局和布线结果进行物理验证，包括规则检查、电气特性分析等。<ul>\n<li>后面有一个提取阶段</li>\n</ul>\n</li>\n<li>6、转换为GDSII：将经过物理验证的布局和布线结果转化为GDSII格式，生成最终的物理设计数据</li>\n</ul>\n</li>\n<li><p>2、什么是硅虚拟原型SVP？为什么要提出硅虚拟模型设计方法？</p>\n<p>硅虚拟原型：是一种基于软件仿真和硬件加速的技术，用于验证和评估芯片设计的功能和新能。</p>\n<p>采用硅虚拟模型设计方法能够尽早预估该设计能否大致实现时序收敛，具有更快的设计迭代速度和更低的开发成本。</p>\n</li>\n<li><p>3、展平式物理设计与层次式物理设计的共同点和不同点是什么？</p>\n<p>基本流程都具备，但是步骤顺序可能存在偏差</p>\n<p>展平式设计是一种自下而上的模块化方法，从底层器件再到版图</p>\n<p>层次化设计是一种自上而下的物理设计方法，从版图再往下</p>\n</li>\n<li><p>4、设计收敛的实现与设计流程有关吗？</p>\n<p>有关，设计流程可以提供一种系统化的方法和框架，能够有效地引导和管理设计的各个阶段，以实现设计收敛，使得设计能够按照预期目标收敛。</p>\n</li>\n<li><p>5、当今EDA工具的设计所采用的主要的数据文件格式有哪些？数据库格式有哪些？常用的编程语言有哪些？</p>\n<p>RTL：硬件描述语言编写的RTL代码</p>\n<p>网表：描述芯片的逻辑电路结构和连接关系的文本文件</p>\n<p>GDSII：用于描述芯片的物理布局和制造信息的二进制格式</p>\n<p>LEF和DEF：用于描述芯片的物理布局和制造信息的二进制格式</p>\n<p>SDC：用于定义时序约束的文本文件，指定电路的时序要求和约束条件</p>\n</li>\n</ul>\n<h2 id=\"第二章、物理设计建库与验证\"><a href=\"#第二章、物理设计建库与验证\" class=\"headerlink\" title=\"第二章、物理设计建库与验证\"></a>第二章、物理设计建库与验证</h2><h3 id=\"集成电路工艺与版图\"><a href=\"#集成电路工艺与版图\" class=\"headerlink\" title=\"集成电路工艺与版图\"></a>集成电路工艺与版图</h3><p><strong>CMOS工艺流程</strong></p>\n<p>晶圆—形成制造晶体管所需的衬底和阱区—形成晶体管栅层图形—形成源漏、衬底和阱接触等其它有源区—通过接触孔将需要连接的地方与第一层金属互连—进行其它几层金属互连—添加钝化层与外界隔离开</p>\n<p><strong>工艺技术文件</strong></p>\n<blockquote>\n<p>晶体代工厂提供给设计者用于后端版图设计的技术文件，用于与EDA工具交互工艺信息，内容包括图形定义及显示信息，互连线工艺信息和通孔工艺信息</p>\n</blockquote>\n<h3 id=\"设计规则检查（DRC）\"><a href=\"#设计规则检查（DRC）\" class=\"headerlink\" title=\"设计规则检查（DRC）\"></a>设计规则检查（DRC）</h3><p>主要目的：检查版图中所有因违反设计规则而引起潜在断路，短路或不良效应的物理验证过程</p>\n<p><strong>版图设计规则</strong></p>\n<blockquote>\n<p>晶圆代工厂对不同工艺参数制定出满足芯片制造良率的同一工艺层以及不同工艺层之间几何尺寸的最小值，这些最小值规划的集合就是版图设计规则。</p>\n</blockquote>\n<ul>\n<li>逻辑运算<ul>\n<li>AND操作</li>\n<li>OR操作</li>\n<li>NOT操作，双目运算，A NOT B属于A，但不属于B的部分</li>\n</ul>\n</li>\n<li>拓扑运算<ul>\n<li>重叠</li>\n<li>包含</li>\n<li>相切</li>\n</ul>\n</li>\n<li>集合运算<ul>\n<li>面积</li>\n<li>周长</li>\n<li>间距</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"电路规则检查\"><a href=\"#电路规则检查\" class=\"headerlink\" title=\"电路规则检查\"></a>电路规则检查</h3><blockquote>\n<p>1、所有信号的电气连接关系是否一致</p>\n<p>2、器件类型尺寸是否一致</p>\n<p>LVS文件：期间提前规则、电路比较规则、器件捆绑规则</p>\n</blockquote>\n<p><strong>电路提取与比较</strong></p>\n<p>步骤：更具LVS提取规则，从版图中抽取出版图所需要的网表文件。将抽取出的网表文件与电路网表文件做对比。</p>\n<p><strong>器件类型和数目及尺寸检查</strong></p>\n<ul>\n<li>器件类型检查：电阻、电容、电感、双极晶体管、MOS管、二极管<ul>\n<li>通过从版图与原理图中寻找名称相一致的器件实现</li>\n</ul>\n</li>\n<li>器件数目与尺寸检查<ul>\n<li>检查版图中对应节点上期间的数量以及每个器件的尺寸是否与原理图中对应结点的期间数量与尺寸一致</li>\n</ul>\n</li>\n</ul>\n<p><strong>LVS在数字IC中的检查</strong></p>\n<p>常用的解决LVS错误的方法</p>\n<ul>\n<li>检查器件数目</li>\n<li>检查器件类型</li>\n<li>检查节点数量</li>\n<li>检查电源线和地线的连接</li>\n<li>从关键点找起</li>\n</ul>\n<h3 id=\"版图寄生参数提取与设计仿真\"><a href=\"#版图寄生参数提取与设计仿真\" class=\"headerlink\" title=\"版图寄生参数提取与设计仿真\"></a><strong>版图寄生参数提取与设计仿真</strong></h3><p><strong>版图寄生参数提取</strong></p>\n<p>版图设计的完整寄生参数应当包括R（电阻）、C（电容）、L（电感）、K（互感）</p>\n<p>LPE（版图寄生参数提取）/PRE（寄生电阻提取）提取的主要参数包括MOS管源漏的周长、面积、电阻，沟道的长与宽，双极晶体管和二极管的结面积、结周长，以及结点寄生电容、互连线电容电阻、接触孔电阻等。</p>\n<p><strong>版图设计仿真</strong></p>\n<p>使用牛顿迭代法，用泰勒级数的前几项来寻找方程f(x)=0的根</p>\n<h3 id=\"逻辑单元库的建立\"><a href=\"#逻辑单元库的建立\" class=\"headerlink\" title=\"逻辑单元库的建立\"></a>逻辑单元库的建立</h3><blockquote>\n<p>逻辑单元的建库流程归纳为以下5步</p>\n<p>1、方案设计与论证</p>\n<p>2、电路设计</p>\n<p>3、版图设计与物流库生成</p>\n<p>4、标准单元特性及库模型生成</p>\n<p>5、设计验证</p>\n</blockquote>\n<p><strong>逻辑单元类别</strong></p>\n<p>完整的单元库根据在芯片中的应用可以分为三类</p>\n<ul>\n<li><p>标准单元(standard cell)</p>\n<p>放置于芯片的核心区起逻辑功能粘接作用</p>\n</li>\n<li><p>模块宏单元(macro block)</p>\n<p>放置于芯片核心区，至少包括嵌入式存储器（RAM和ROM）、IP、COT模块</p>\n<p>其它重要的宏单元模块：始终PLL模块，DSP模块</p>\n</li>\n<li><p>输入输出单元(I/O pad cell)</p>\n<p>放置于核区的周围，用于芯片信号的输入、输出和电源供给</p>\n</li>\n</ul>\n<img src=\"/2023/08/09/Physical-design/05.png\" class=\"\">\n<p><strong>逻辑单元电路</strong></p>\n<p>组合逻辑电路简称为组合电路包括</p>\n<ul>\n<li>反向逻辑电路：反向器、与非门、或非门</li>\n<li>非反向逻辑电路：缓冲器、与门、或门</li>\n<li>其它常用逻辑电路：数据选择门（MUX）、异或门、数据传输门（TBUF）、复合门（AOI）</li>\n<li>特殊功能的逻辑电路：加法器、乘法器、除法器</li>\n</ul>\n<p>时序逻辑电路也称为时序电路</p>\n<blockquote>\n<p>输出信号不但同但钱的输入相关还和上一时间的输出有关，具有记忆功能</p>\n</blockquote>\n<p>包括：</p>\n<ul>\n<li>锁存器（Latch）：专指电平敏感的时序电路</li>\n<li>寄存器类（flip flop）：时钟边沿出发</li>\n</ul>\n<p><strong>模块单元（宏单元模块）</strong></p>\n<p>存储单元ROM：NOR ROM、NAND ROM、EPROM、EEPROM、FAMOS ROM</p>\n<p>存储单元RAM：静态随机存储器SRAM、动态随机存储器DRAM</p>\n<p>专用模块：客户自由工具COT，专用标准产品ASSP，信号处理器DSP</p>\n<p>黑盒子商业IP模块：电路设计不公开</p>\n<p>模拟电路模块：时钟锁相环PLL模块</p>\n<p><strong>输入输出单元</strong></p>\n<blockquote>\n<p>包括输入信号、输出信号、三态门、双向、电源和接地单元</p>\n</blockquote>\n<p>对于输入单元要考虑静电放电的防护</p>\n<p>形成电阻的方法：n型扩散层、p型扩散层和多晶硅</p>\n<p>形成电容的方法：Poly、Mos栅电容</p>\n<p><strong>物理单元库与数据文件，LEF文件</strong></p>\n<img src=\"/2023/08/09/Physical-design/01.png\" class=\"\">\n<p>标准单元建库的规则</p>\n<ul>\n<li>所有单元都等高的矩形，或者是基本高度的整数倍</li>\n<li>所有版图都用预先定义的模板进行设计</li>\n<li>所有单元的端口位置、大小、形状都尽量满足网格间距的要求</li>\n<li>电源线和地线一般位于单元的上下边界</li>\n</ul>\n<p>模块单元建库</p>\n<ul>\n<li>先建立RAM和ROM的基本单元</li>\n<li>根据比特和字长，自底向上堆砌生成版图</li>\n</ul>\n<p>I/O单元</p>\n<ul>\n<li>IO拐角单元在芯LEF文档的单元类型中被定义为Endcap，分布在拐角处</li>\n</ul>\n<p><strong>时序单元建库与数据文件</strong></p>\n<p>器件延时：表示信号通过一个逻辑门时所经历的时间，反映了门对输入信号变化响应的快慢。通过输入信号电压变化的50%到输出信号电压变化的50%所需要的时间来定义门延时的大小。</p>\n<img src=\"/2023/08/09/Physical-design/06.png\" class=\"\">\n<p>用于DSM设计的器件延时模型</p>\n<ul>\n<li>开关线性RC模型</li>\n<li>经验推导公式（K-Factor方程）</li>\n<li>非线性延时模型</li>\n<li>可伸缩多项式模型</li>\n</ul>\n<p>时序库文件</p>\n<img src=\"/2023/08/09/Physical-design/07.png\" class=\"\">\n<p>EDA工具通常采用两种模型计算天线比率，一种时部分检查模型，另一种是积累检查模型</p>\n<h3 id=\"习题：-1\"><a href=\"#习题：-1\" class=\"headerlink\" title=\"习题：\"></a>习题：</h3><ul>\n<li><p>1、什么是标准单元库？它主要包括哪几类单元？它们分别在电路中起什么作用？</p>\n<p>标准单元库是一种预先设计和验证的模块化的芯片单元集合，用于构建数字集成电路，包含了经过验证和优化的标准逻辑门和寄存器等基本单元，可以在芯片设计中重复使用，以节省设计时间和提高设计的可靠性。</p>\n<p>主要包括：逻辑门、寄存器、编码解码器、算术逻辑单元、存储器单元</p>\n<p>使用标准单元库可以提高设计的效率，降低设计风险，促进可重用性。</p>\n</li>\n<li><p>2、标准单元有几种不同抽象级别的描述？为什么要采用不同抽象层描述同一电路单元？</p>\n<p>逻辑级描述、电路级描述、物理级描述</p>\n<p>采用不同抽象层描述同一电路单元可以更好的管理设计的不同方面，优化设计的性能和可靠性，并在设计复杂性和效率之间进行权衡。</p>\n</li>\n<li><p>3、解释LEF库文件在物理实施布局布线中的作用和重要性，并说明它所定义的内容是如何知道EDA工具实现自动布局布线的。</p>\n<p>LEF库文件定义了标准单元的物理特性，包括尺寸大小方向以及引脚位置和功能等等</p>\n<p>EDA工具实现自动布局布线是通过读取和解析LEF库文件中的信息。工具可以根据LEF文件中定义的物理特性和约束，生成优化芯片的物理布局和连线。</p>\n</li>\n</ul>\n<h2 id=\"第三章、布图规划（芯片规划）和布局\"><a href=\"#第三章、布图规划（芯片规划）和布局\" class=\"headerlink\" title=\"第三章、布图规划（芯片规划）和布局\"></a>第三章、布图规划（芯片规划）和布局</h2><h3 id=\"布图规划\"><a href=\"#布图规划\" class=\"headerlink\" title=\"布图规划\"></a>布图规划</h3><p>布图规划开始时，首先要准备好各种基本设计数据和相应的物理库、时序库文件，并输入到不图规划的工具环境中来</p>\n<img src=\"/2023/08/09/Physical-design/08.png\" class=\"\">\n<p>布图规划主要内容包含对芯片大小的规划、芯片设计输入输出单元的规划、大量硬核或模块的规划</p>\n<p><strong>布图规划的主要目标</strong></p>\n<ul>\n<li>确定芯片的面积</li>\n<li>确保时序的收敛</li>\n<li>保证芯片的稳定</li>\n<li>满足布线的要求：保证布线通畅的同时，尽量缩短走线的长度</li>\n</ul>\n<p><strong>I/O接口单元的放置与供电</strong></p>\n<p>放置方式：1、pin点方式，2、pad条状方式，3、做成固定模块，将pad集成</p>\n<p>当芯片面积较大，芯片时序较为紧张时，I/O单元也可能均匀分布在芯片的内部</p>\n<p>I/O单元的供电：I/O单元分为信号接口和电源两种</p>\n<p>电源I/O单元分为3类：给模拟器件供电的I/O单元、给数字期间供电的、用于隔离数字供电和模拟供电</p>\n<p>数字I/O也分为两大组：一组是给I/O单元供电，一组是给核内的标准单元供电</p>\n<p>给I/O单元供电的供电单元数量由多种因素决定：I/O单元的消耗、输出I/O单元的驱动能力、同步开关噪声</p>\n<p><strong>布图规划方案与延迟预估</strong></p>\n<p>展平化设计</p>\n<p>因为还没有进入布线阶段，使用线负载模型预估当前布局的时序，展平式的方法会占用大量的内存，需要很长的运行时间。</p>\n<p>层次化设计</p>\n<blockquote>\n<p>思想是将大规模的顶层设计分解成多个子模块，每个子模块并行完成布局布线，最后在顶层组装。</p>\n<p>大致分为三个步骤：芯片顶层设计规划、子模块分割与实现、芯片顶层组装时序</p>\n</blockquote>\n<p>在层次化设计的过程中，需要在布图和布局规划中对时钟进行预估，流程图如下：</p>\n<blockquote>\n<p>根据子模块大小，和子模块中的元件数量以及复杂度来进行预估</p>\n</blockquote>\n<img src=\"/2023/08/09/Physical-design/09.png\" class=\"\">\n<p><strong>模块布放与布线通道</strong></p>\n<p>布线轨道：芯片内部专门用于布线的路径</p>\n<p>布线通道：每两条或多条布线轨道的空间，上面不可以摆放标准单元</p>\n<h3 id=\"电源规划\"><a href=\"#电源规划\" class=\"headerlink\" title=\"电源规划\"></a>电源规划</h3><blockquote>\n<p>给整个芯片的供电设计出一个均匀的网络，电源规划在芯片布图规划后或在布图规划过程中交叉完成。</p>\n<p>电源网络设置、数字模拟混合供电、单电源与多电源供电电压网络设置</p>\n</blockquote>\n<p>芯片供电是通过I/O单元来实现的，需要先完成电源预算，</p>\n<p><strong>电源网络设计</strong></p>\n<ul>\n<li>电源连接关系定义global net connect</li>\n<li>芯片核内部分的电源环设计power ring</li>\n<li>芯片内所包含的硬核（如 RAM、ROM以及IP、COT模块）的电源环设计</li>\n<li>芯片核内纵横交错的电源网络设计</li>\n<li>芯片的供电单元与电源环的连接</li>\n<li>芯片内部的电源网络与硬核电源环连接部分的设计</li>\n<li>将标准单元的供电网络和硬核电源环连接部分的设计</li>\n<li>I/O供电单元电源环的设计</li>\n</ul>\n<p>1、全局电源</p>\n<p>电源的定义主要包括：全局电源的定义以及连接关系的定义。</p>\n<ul>\n<li>电源和接地网络：通过wire定义</li>\n<li>接高电压和接低电压网络</li>\n<li>电压和接地端口</li>\n<li>填充单元网络</li>\n</ul>\n<p>2、电源环线</p>\n<p>为了能够均匀供电，包围在标准单元周围的环形供电金属，是连接供电I/O单元和标准单元的桥梁</p>\n<p>电源网格可以平均分布电流，缩短电流回路，在有效减少电压降的同时，避免由于电流分布不均时造成的热点现象以及电迁移问题。</p>\n<p>3、电源条线</p>\n<p>芯片内部纵横交错的电源网格和电源条线设计有专门的理论和算法。</p>\n<img src=\"/2023/08/09/Physical-design/10.png\" class=\"\">\n<p>纵向必须用偶数层走线，横向必须用奇数层走线。</p>\n<p><strong>数字与模拟混合供电</strong></p>\n<p>1、模拟模块的工作区域一般放置于芯片的某个角落</p>\n<p>2、模拟区域需要单独供电</p>\n<p>3、在模拟模块的周围布置保护隔离环，从而实现数字信号和模拟信号电源之间的隔离</p>\n<img src=\"/2023/08/09/Physical-design/11.png\" class=\"\">\n<p><strong>多电源供电</strong>（麻了，看不懂）</p>\n<h3 id=\"布局\"><a href=\"#布局\" class=\"headerlink\" title=\"布局\"></a>布局</h3><blockquote>\n<p>因为此时以及将芯片的各个部分规划好了，需要在具体规划的区域中填充详细的模块</p>\n</blockquote>\n<p><strong>展平式布局</strong></p>\n<p>模块的摆放与布局</p>\n<p>标准单元的摆放和优化</p>\n<p>简单来说：放置模块和标准单元·</p>\n<p><strong>层次化布局</strong></p>\n<blockquote>\n<p>先分配子模块、作子模块的布局、所有子模块完成后在顶层组装</p>\n</blockquote>\n<ul>\n<li><p>约束类型确定</p>\n<blockquote>\n<p>约束类型一般有三种：向导约束、区域约束和限制约束</p>\n</blockquote>\n</li>\n<li><p>子模块大小位置的制定</p>\n</li>\n</ul>\n<p><strong>布局目标预估</strong></p>\n<blockquote>\n<p>在标准单元布局优化完成后，需要对设计进行拥塞分析，静态时序分析，噪声分析，和电源分析以确定布局的好坏</p>\n</blockquote>\n<p>布局的目标</p>\n<ul>\n<li>各模块的位置相对确定</li>\n<li>满足设计规则的要求</li>\n<li>芯片的时序和供电较为良好</li>\n</ul>\n<p><strong>标准单元布局优化算法</strong></p>\n<blockquote>\n<p>布局优化的算法从步骤上可以分成三个阶段：结群布局、全局布局、详细布局</p>\n</blockquote>\n<p>1、布局优化的算法</p>\n<ul>\n<li><p>结群算法（clustering聚类算法）</p>\n<p>选择一个单元作为种子，以各个种子为原始群不断结合与其最紧密的单元。</p>\n</li>\n<li><p>模拟退火算法、KL算法、FM算法</p>\n</li>\n<li><p>全局布局：最小切割法、模拟退火算法、贪心算法、力向量算法、NRG算法、HALO算法</p>\n</li>\n<li><p>布局优化算法：纯标准单元布局算法、模块布局算法、混合单元布局算法</p>\n</li>\n</ul>\n<p>2、从优化目标上优化算法</p>\n<ul>\n<li>基于布线拥塞的布局优化算法</li>\n<li>基于时序的布局算法</li>\n<li>预防噪声的布局算法</li>\n</ul>\n<h3 id=\"扫描链重组\"><a href=\"#扫描链重组\" class=\"headerlink\" title=\"扫描链重组\"></a>扫描链重组</h3><blockquote>\n<p>扫描链是可测试性设计的重要内容，将芯片中所应用的普通寄存器替换成带扫描功能的多输入输出扫描寄存器，首位连接成串，从而实现附加的测试功能。</p>\n</blockquote>\n<p>将连接在扫描链上的在芯片内随机分布的扫描寄存器单元按照其物理位置，在不影响逻辑功能的前提下，重写进行连接，从而减少扫描链的走线长度。</p>\n<p>实现方法：</p>\n<ul>\n<li>本地化重组</li>\n<li>基于扫描DEF的扫描链重组方法</li>\n</ul>\n<h3 id=\"物理设计网表文件\"><a href=\"#物理设计网表文件\" class=\"headerlink\" title=\"物理设计网表文件\"></a>物理设计网表文件</h3><p>DEF(design exchange format)文件：设计交换给格式</p>\n<p>PDEF(physical DEF)：物理设计交换格式</p>\n<h2 id=\"第四章时钟树综合CTS\"><a href=\"#第四章时钟树综合CTS\" class=\"headerlink\" title=\"第四章时钟树综合CTS\"></a>第四章时钟树综合CTS</h2><h3 id=\"时钟信号\"><a href=\"#时钟信号\" class=\"headerlink\" title=\"时钟信号\"></a>时钟信号</h3><p><strong>时钟信号抖动</strong>：时钟抖动定义为信号时间与理想事件时间的偏差，抖动中含有确定抖动成分和随机抖动成分。</p>\n<ul>\n<li>确定抖动：串扰、电磁干扰、同时开关输出引起</li>\n<li>随即抖动：服从高斯分布，通常由半导体晶体结构的热振动和半导体掺杂密度不均匀中共价电子引起</li>\n</ul>\n<h3 id=\"时钟树综合的方法\"><a href=\"#时钟树综合的方法\" class=\"headerlink\" title=\"时钟树综合的方法\"></a>时钟树综合的方法</h3><blockquote>\n<p>芯片设计中的时钟分为两类：真实时钟（real clock）和虚拟时钟（virtual clock）</p>\n<p>真实时钟又有两种模式：时钟树综合前没有延时的理想时钟，时钟树综合后的传播时钟</p>\n</blockquote>\n<p><strong>时钟树综合与标准设计约束文件</strong>：SDC文件（时序约束文件）</p>\n<p>SDC文件三部分：时钟定义、输入延迟、输出延迟</p>\n<p>通过工艺文件来约束时钟信号的相关属性</p>\n<p>时钟的定义将通过时钟树综合来实现，时钟延迟和时钟抖动或不确定性将在静态时序分析时进行检查。</p>\n<p><strong>时钟树结构</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">时钟树：时钟信号在物理设计中的实现结果<br>根节点：时钟信号的起点<br>叶结点：时钟信号经过一系列分布结点最终到达寄存器时钟输入端或其它时钟终点<br>根单元、分布单元、叶单元：根节点、分布节点和叶结点都依附于的逻辑单元<br></code></pre></td></tr></table></figure>\n<p>时钟网络从根节点逐级插入驱动器，从而到达其叶结点，按照芯片始终网络的约束要求产生时钟树的过程叫做是中暑综合。</p>\n<img src=\"/2023/08/09/Physical-design/image-20230809095839094.png\" class=\"\" title=\"image-20230809095839094\">\n<p>时钟树根据其在芯片内的分布特征，可分为多种结构：H树、 X树、平衡树、疏状或脊椎状时钟网</p>\n<h3 id=\"时钟树设计策略\"><a href=\"#时钟树设计策略\" class=\"headerlink\" title=\"时钟树设计策略\"></a>时钟树设计策略</h3><p><strong>时钟树综合策略</strong></p>\n<ul>\n<li>自我交叉</li>\n<li>相互交叉时钟</li>\n<li>有用偏差</li>\n</ul>\n<img src=\"/2023/08/09/Physical-design/image-20230809102800761.png\" class=\"\" title=\"image-20230809102800761\">\n<ul>\n<li><p>OVC片上误差分析法与CPPR共同路径悲观去除的应用</p>\n</li>\n<li><p>与布局相结合的手动时钟树设计</p>\n</li>\n<li>对时钟插入多驱动的buffer</li>\n</ul>\n<p><strong>异步时钟树设计</strong></p>\n<p>实际的SoC设计中，是以异步时钟设计来实现的，从而降低功耗</p>\n<img src=\"/2023/08/09/Physical-design/image-20230809105341276.png\" class=\"\" title=\"image-20230809105341276\">\n<p><strong>门控时钟</strong></p>\n<p>门控时钟是降低功耗最常用的方法，使用一个控制信号控制时钟的开启。</p>\n<h3 id=\"时钟树分析\"><a href=\"#时钟树分析\" class=\"headerlink\" title=\"时钟树分析\"></a>时钟树分析</h3><p><strong>时钟树与功耗分析</strong></p>\n<blockquote>\n<p>时钟树上的功耗由静态功耗、短路功耗和跳变功耗三部分组成</p>\n</blockquote>\n<ul>\n<li>静态功耗：各个buffer上静态功耗和，减少静态功耗的方法就是减少buffer的加权数</li>\n<li>短路功耗：与转换时间成正比，与阈值电压的3次方成反比</li>\n<li>跳变功耗：占比50%以上，由门的加权数值以及互连线总的电容决定</li>\n</ul>\n<p>降低功耗的方案</p>\n<ul>\n<li>1、减小时钟信号转换时间，信号从10%转化到90%所需要的时间</li>\n<li>2、降低结点电容</li>\n</ul>\n<h2 id=\"第五章、布线\"><a href=\"#第五章、布线\" class=\"headerlink\" title=\"第五章、布线\"></a>第五章、布线</h2><blockquote>\n<p>将分布在芯片核内的模块、标准单元和输入输出接口单元按逻辑关系进行互联</p>\n<p>要求百分百地完成它们之间的所有逻辑信号的互联，并为满足各种约束条件进行优化</p>\n</blockquote>\n<h3 id=\"全局布线\"><a href=\"#全局布线\" class=\"headerlink\" title=\"全局布线\"></a>全局布线</h3><p><strong>全局布线目标</strong></p>\n<ul>\n<li>1、使总连线最短</li>\n<li>2、布线分散均匀不至于引起局部拥塞</li>\n<li>3、使关键路径延时最小，遵守时序规则</li>\n<li>4、理解信号完整性要求，避免串扰</li>\n<li>5、保持将BUS总线聚集相连等</li>\n</ul>\n<p><strong>全局布线规划</strong></p>\n<h3 id=\"详细布线\"><a href=\"#详细布线\" class=\"headerlink\" title=\"详细布线\"></a>详细布线</h3><p><strong>详细布线的目标</strong></p>\n<ul>\n<li>1、理解所有的设计规则</li>\n<li>2、自动切换并综合利用多层金属作连线</li>\n<li>3、遵守时序规则，优先使关键路径的延时满足要求</li>\n<li>4、对总连线长度进行优化</li>\n</ul>\n<p><strong>详细布线与设计规则</strong></p>\n<ul>\n<li>设计规则</li>\n<li>通孔和最小面积要求</li>\n<li>密度要求</li>\n<li>掩膜光刻过程中的工艺天线效应</li>\n<li>串扰在布线中的预防和修复</li>\n<li>纳米布线规则</li>\n<li>对焦布线规则</li>\n</ul>\n<p><strong>布线修正</strong></p>\n<ul>\n<li>自动修正</li>\n<li>渐进修正</li>\n<li>局部修正</li>\n</ul>\n<h2 id=\"第六章、静态时序分析\"><a href=\"#第六章、静态时序分析\" class=\"headerlink\" title=\"第六章、静态时序分析\"></a>第六章、静态时序分析</h2><blockquote>\n<p>做时序分析前，首先要对芯片的物理版图设计进行包括电阻、电感、电容参数的提取，在进行延时计算。</p>\n</blockquote>\n<h3 id=\"延迟计算与布线参数提取\"><a href=\"#延迟计算与布线参数提取\" class=\"headerlink\" title=\"延迟计算与布线参数提取\"></a>延迟计算与布线参数提取</h3><p><strong>延迟计算模型</strong></p>\n<blockquote>\n<p>可以在布局之后进行，也可以在时钟树综合后进行。使用WLM区估算</p>\n</blockquote>\n<p>各种参数提取、各种物理公式：电阻电容电感</p>\n<h3 id=\"寄生参数与延迟格式文件\"><a href=\"#寄生参数与延迟格式文件\" class=\"headerlink\" title=\"寄生参数与延迟格式文件\"></a>寄生参数与延迟格式文件</h3><p>1、标准寄生参数格式文件</p>\n<ul>\n<li>SPF-Standard Parasistic Format（File），标准寄生参数格式文件</li>\n<li>DSPF-Detailed SPF，详细标准寄生参数格式文件</li>\n<li>RSPF-Reduced SPF，简化标准寄生参数格式文件</li>\n<li>SPEF-Standard Parasitic Exchange Format（File），标准寄生参数交换格式文件</li>\n</ul>\n<h3 id=\"静态时序分析\"><a href=\"#静态时序分析\" class=\"headerlink\" title=\"静态时序分析\"></a>静态时序分析</h3><blockquote>\n<p>进行时序分析时，简单的说就是将某一段路径的时序与时序约束的要求进行比较。根本目的是为了检查在时钟的控制和要求的约束下，与其相关的数据能够符合时序要求被记录存储下来，这种时序检查就是一对常说的建立时间时序和保持时间时序。</p>\n</blockquote>\n<p>Setup定义：在时钟作用前沿到达前，同步输入信号D必须保持稳定的那段时间以使信号不至于丢失。</p>\n<p>Hold定义：在时钟作用前沿到达后，同步输入信号D必须保持稳定的那段时间以使得信号不至于丢失。</p>\n<p>1、建立时序（Setup）的违例</p>\n<p>要求同步输入数据D必须在时钟信号前的某个时段到达且不发射变化，这样数据才会被成功的锁存。</p>\n<p>2、保存时序违例</p>\n<p>增长数据的路径延迟</p>\n<p><strong>时序分析与时钟特性</strong></p>\n<ul>\n<li>定义输入输出环境参数<ul>\n<li>1、确定驱动</li>\n<li>2、确定驱动单元</li>\n<li>3、确定负载</li>\n<li>4、确定删除</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"时序优化\"><a href=\"#时序优化\" class=\"headerlink\" title=\"时序优化\"></a>时序优化</h3><p><strong>造成时序违例的因素</strong></p>\n<ul>\n<li>1、系统设计的复杂性和抽象性，存在不合理的约束</li>\n<li>2、逻辑综合时依据了不合理的WLM</li>\n<li>3、设计太大，互连线的相互牵制引起时序违例</li>\n<li>4、设计做了不合理的布局</li>\n</ul>\n<h3 id=\"习题\"><a href=\"#习题\" class=\"headerlink\" title=\"习题\"></a>习题</h3><p>1、什么是静态时序分析？描述它的分析步骤过程。</p>\n<ul>\n<li>静态时序分析是一种在设计和验证数字电路时用于评估电路时序特性的方法。主要用于分析电路中的时序路径，包括组合逻辑路径和时钟路径，以确保电路在给定的时钟频率下能够满足时序要求。是一种基于约束和路径分析的方法，用于评估电路的时序特性和性能。</li>\n</ul>\n<p>2、什么是建立时间和保持时间？什么是虚假路径、多周期路径？</p>\n<ul>\n<li>建立时间：在时钟上升沿到来之前，为了确保输入数据能够稳定的被采样，输入信号必须保持不变的最小时间。</li>\n<li>保持时间：在时钟上升沿到来之后，为了确保输入数据能够完整的写入，输入型号必须保持不变的最小时间。</li>\n<li>虚假路径：在时序分析中被认为不需要满足时序约束的路径。这些路径不会对电路的正常工作产生影响，因此可以被忽略。</li>\n<li>多周期路径：信号的传播时间可以超过一个周期。</li>\n</ul>\n<p>3、如何保证物理实施阶段的时序收敛？</p>\n<ul>\n<li>通过静态时序分析</li>\n</ul>\n<h2 id=\"第七章、功耗分析\"><a href=\"#第七章、功耗分析\" class=\"headerlink\" title=\"第七章、功耗分析\"></a>第七章、功耗分析</h2><blockquote>\n<p>动态分析：芯片工作过程中产生的功耗</p>\n<p>静态分析：芯片在待机状态时产生的平均功耗</p>\n</blockquote>\n<h3 id=\"静态功耗分析\"><a href=\"#静态功耗分析\" class=\"headerlink\" title=\"静态功耗分析\"></a>静态功耗分析</h3><blockquote>\n<p>反偏二极管泄漏电流</p>\n<p>门栅感应漏极泄漏电流</p>\n<p>亚阈值泄漏电流</p>\n<p>门栅泄漏电流</p>\n</blockquote>\n<h3 id=\"动态功耗分析\"><a href=\"#动态功耗分析\" class=\"headerlink\" title=\"动态功耗分析\"></a>动态功耗分析</h3><blockquote>\n<p>开关功耗+短路功耗</p>\n</blockquote>\n<h3 id=\"电压降分析与电迁移分析\"><a href=\"#电压降分析与电迁移分析\" class=\"headerlink\" title=\"电压降分析与电迁移分析\"></a><strong>电压降分析与电迁移分析</strong></h3><p>电迁移：在一定的制造工艺下，在它上面所能允许流过的最大电流是有一定限度的，否则过大的电流将会使金属连线断裂，导致芯片失效，这种由于电流引起的电路失效现象称为EM电迁移。</p>\n<p>电源网络的电迁移由平均电流密度、金属宽度以及孔的大小决定</p>\n<p>电迁移容限测量方法：漂移速度法、低频噪声法、电阻模型模拟、等，常用寿命测试法（测量一定数量的相同样品在规定条件下的失效时间）</p>\n<h3 id=\"功耗分析数据文件\"><a href=\"#功耗分析数据文件\" class=\"headerlink\" title=\"功耗分析数据文件\"></a>功耗分析数据文件</h3><blockquote>\n<p>功耗分析需要建立相应的数据库，并且借助于与功耗相关的文件来有效地控制和处理这些数据</p>\n</blockquote>\n<p>静态分析数据——TCF文件</p>\n<p>动态分析数据——输入多两个重要信息：电源凸点的位置分布信息和动态功耗仿真用的VCD文件+TWF文件</p>\n<p><strong>电源网格视图库</strong>——PGV(power grid view)</p>\n<blockquote>\n<p>用于分析芯片电压降效应的一种库文档格式</p>\n<p>使用PGV库计算功耗的精度不是很高</p>\n<p>根据供电网络分布，首先分别提取电源网络的电阻和电流节点处的平均结点阀门电流，再建立电源网络视图库</p>\n</blockquote>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"第一章、集成电路物理设计方法\"><a href=\"#第一章、集成电路物理设计方法\" class=\"headerlink\" title=\"第一章、集成电路物理设计方法\"></a>第一章、集成电路物理设计方法</h2><h3 id=\"数字集成电路设计流程\"><a href=\"#数字集成电路设计流程\" class=\"headerlink\" title=\"数字集成电路设计流程\"></a>数字集成电路设计流程</h3><p>三个I年代，发明，实施和整合</p>\n<p>Innovation：布局布线的基本算法、时序分析和逻辑综合的发明</p>\n<p>Implementation：开始于FPGA中门阵列的实现，ASIC设计中同等高度标准逻辑单元库的设计</p>\n<p>Integration：模块化</p>\n<p><strong>芯片的物理实施重点解决的问题</strong></p>\n<p>对于深亚微米芯片</p>\n<ul>\n<li><p>解决时序驱动设计</p>\n</li>\n<li><p>防止工艺天线效应</p>\n</li>\n<li>进行信号完整性分析</li>\n</ul>\n<p>对于纳米的设计，需要多考虑的问题</p>\n<ul>\n<li>功耗分析和低功耗设计，并要统一考虑它的功能验证，逻辑综合和形式验证</li>\n<li>实施纳米设计中的光学近似检查（OPC）和移相掩膜（PSM），增加设计产额和可制造性设计</li>\n<li>统计静态时序分析，多端角分析</li>\n</ul>\n<p><strong>展平式物理设计</strong></p>\n<blockquote>\n<p>标准逻辑门单元库的简历。采用自下向上的方法，设计晶体管-仿真-建立版图-对逻辑门单元仿真建模</p>\n</blockquote>\n<img src=\"/2023/08/09/Physical-design/01.png\" class=\"\">\n<p><strong>硅虚拟原型设计</strong></p>\n<img src=\"/2023/08/09/Physical-design/02.png\" class=\"\">\n<p>与展平化的物理设计流程区别</p>\n<ul>\n<li>布图阶段，考虑将整个设计进行分割</li>\n<li>布线时用了快速近似的试验布线法</li>\n<li>在做RC提取时，可以用集总电容模型</li>\n</ul>\n<p><strong>层次化物理设计</strong></p>\n<blockquote>\n<p>芯片设计的最终检查标准之一为是否实现了时序收敛</p>\n</blockquote>\n<p>自上而下的层次化物理设计：将设计分为数个分割块，对每个分割块进行展品化处理（独立的布局布线），在顶层完成组装设计</p>\n<img src=\"/2023/08/09/Physical-design/03.png\" class=\"\">\n<p>优点：将很大的设计化成多个小设计，如果有时序问题可能存在于个别模块，再去重点解决，降低了复杂性。</p>\n<ul>\n<li><p>基于设计驱动时序图</p>\n<p>在顶层设计和模块设计之间建立一个连接的时序图桥梁，从而避免当模块设计完成后回到顶层无法收敛而造成大量的设计迭代。</p>\n<p>将模块级的实施分成多个阶段，如时钟树综合，详细布线阶段，布线优化阶段</p>\n</li>\n</ul>\n<h3 id=\"数字集成电路设计收敛\"><a href=\"#数字集成电路设计收敛\" class=\"headerlink\" title=\"数字集成电路设计收敛\"></a>数字集成电路设计收敛</h3><blockquote>\n<p>设计时序收敛任务通过三大部分工作来完成：数据系统，优化引擎，分析引擎</p>\n<p>数据系统：由读取、处理和存储</p>\n<p>优化引擎：基于算法去实现逻辑优化，布局优化，和布线优化</p>\n<p>分析引擎：由设计工程师借助EDA工具用于时序分析，功耗分析和噪声分析的EDA工具</p>\n</blockquote>\n<p><strong>时序收敛</strong></p>\n<p>静态时序分析最重要任务：寻找最长延时路径以及最坏情况下的延时</p>\n<p>总延时：由逻辑门延时和互连线延时组成</p>\n<p>静态时序路径：组合逻辑电路，时序逻辑电路形成的路径</p>\n<p><strong>功耗分析</strong></p>\n<ul>\n<li><p>静态功耗分析</p>\n<p>使用时序库提供的器件功耗可以计算</p>\n</li>\n<li><p>动态功耗分析</p>\n<p>需要提供设计仿真的数据</p>\n</li>\n</ul>\n<p>降低功耗的方式：多电源电压方法、门控电路方法、衬底电压偏执方法</p>\n<img src=\"/2023/08/09/Physical-design/04.png\" class=\"\">\n<h3 id=\"习题：\"><a href=\"#习题：\" class=\"headerlink\" title=\"习题：\"></a>习题：</h3><ul>\n<li><p>1、讨论什么是数字电路的物理设计和物理实施？</p>\n<p>集成电路的物理实施方法被概括为从RTL综合到最终完成GDSII数据的实现，RTL一种硬件描述语言，用于描述数字电路的逻辑功能和寄存器传输级别的行为。GDSII是一种电子设计自动化工具所使用的标准格式，用于描述芯片的物理布局和制造信息。</p>\n<p>将RTL转换为GDSII是一个多步骤的过程，通常包括以下几个主要阶段：</p>\n<ul>\n<li>1、逻辑综合：将RTL描述的电路转换为门级电路，生成门级网表。</li>\n<li>2、时序优化：对门级网表进行优化，以减少电路的面积、功耗或者时钟延迟等。</li>\n<li>3、布局：根据门级网表生成芯片的物理布局，包括各个组件的位置、尺寸和连线等。</li>\n<li>4、布线：根据布局信息进行连线，确保电路的信号可以正确传输。</li>\n<li>5、物理验证：对布局和布线结果进行物理验证，包括规则检查、电气特性分析等。<ul>\n<li>后面有一个提取阶段</li>\n</ul>\n</li>\n<li>6、转换为GDSII：将经过物理验证的布局和布线结果转化为GDSII格式，生成最终的物理设计数据</li>\n</ul>\n</li>\n<li><p>2、什么是硅虚拟原型SVP？为什么要提出硅虚拟模型设计方法？</p>\n<p>硅虚拟原型：是一种基于软件仿真和硬件加速的技术，用于验证和评估芯片设计的功能和新能。</p>\n<p>采用硅虚拟模型设计方法能够尽早预估该设计能否大致实现时序收敛，具有更快的设计迭代速度和更低的开发成本。</p>\n</li>\n<li><p>3、展平式物理设计与层次式物理设计的共同点和不同点是什么？</p>\n<p>基本流程都具备，但是步骤顺序可能存在偏差</p>\n<p>展平式设计是一种自下而上的模块化方法，从底层器件再到版图</p>\n<p>层次化设计是一种自上而下的物理设计方法，从版图再往下</p>\n</li>\n<li><p>4、设计收敛的实现与设计流程有关吗？</p>\n<p>有关，设计流程可以提供一种系统化的方法和框架，能够有效地引导和管理设计的各个阶段，以实现设计收敛，使得设计能够按照预期目标收敛。</p>\n</li>\n<li><p>5、当今EDA工具的设计所采用的主要的数据文件格式有哪些？数据库格式有哪些？常用的编程语言有哪些？</p>\n<p>RTL：硬件描述语言编写的RTL代码</p>\n<p>网表：描述芯片的逻辑电路结构和连接关系的文本文件</p>\n<p>GDSII：用于描述芯片的物理布局和制造信息的二进制格式</p>\n<p>LEF和DEF：用于描述芯片的物理布局和制造信息的二进制格式</p>\n<p>SDC：用于定义时序约束的文本文件，指定电路的时序要求和约束条件</p>\n</li>\n</ul>\n<h2 id=\"第二章、物理设计建库与验证\"><a href=\"#第二章、物理设计建库与验证\" class=\"headerlink\" title=\"第二章、物理设计建库与验证\"></a>第二章、物理设计建库与验证</h2><h3 id=\"集成电路工艺与版图\"><a href=\"#集成电路工艺与版图\" class=\"headerlink\" title=\"集成电路工艺与版图\"></a>集成电路工艺与版图</h3><p><strong>CMOS工艺流程</strong></p>\n<p>晶圆—形成制造晶体管所需的衬底和阱区—形成晶体管栅层图形—形成源漏、衬底和阱接触等其它有源区—通过接触孔将需要连接的地方与第一层金属互连—进行其它几层金属互连—添加钝化层与外界隔离开</p>\n<p><strong>工艺技术文件</strong></p>\n<blockquote>\n<p>晶体代工厂提供给设计者用于后端版图设计的技术文件，用于与EDA工具交互工艺信息，内容包括图形定义及显示信息，互连线工艺信息和通孔工艺信息</p>\n</blockquote>\n<h3 id=\"设计规则检查（DRC）\"><a href=\"#设计规则检查（DRC）\" class=\"headerlink\" title=\"设计规则检查（DRC）\"></a>设计规则检查（DRC）</h3><p>主要目的：检查版图中所有因违反设计规则而引起潜在断路，短路或不良效应的物理验证过程</p>\n<p><strong>版图设计规则</strong></p>\n<blockquote>\n<p>晶圆代工厂对不同工艺参数制定出满足芯片制造良率的同一工艺层以及不同工艺层之间几何尺寸的最小值，这些最小值规划的集合就是版图设计规则。</p>\n</blockquote>\n<ul>\n<li>逻辑运算<ul>\n<li>AND操作</li>\n<li>OR操作</li>\n<li>NOT操作，双目运算，A NOT B属于A，但不属于B的部分</li>\n</ul>\n</li>\n<li>拓扑运算<ul>\n<li>重叠</li>\n<li>包含</li>\n<li>相切</li>\n</ul>\n</li>\n<li>集合运算<ul>\n<li>面积</li>\n<li>周长</li>\n<li>间距</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"电路规则检查\"><a href=\"#电路规则检查\" class=\"headerlink\" title=\"电路规则检查\"></a>电路规则检查</h3><blockquote>\n<p>1、所有信号的电气连接关系是否一致</p>\n<p>2、器件类型尺寸是否一致</p>\n<p>LVS文件：期间提前规则、电路比较规则、器件捆绑规则</p>\n</blockquote>\n<p><strong>电路提取与比较</strong></p>\n<p>步骤：更具LVS提取规则，从版图中抽取出版图所需要的网表文件。将抽取出的网表文件与电路网表文件做对比。</p>\n<p><strong>器件类型和数目及尺寸检查</strong></p>\n<ul>\n<li>器件类型检查：电阻、电容、电感、双极晶体管、MOS管、二极管<ul>\n<li>通过从版图与原理图中寻找名称相一致的器件实现</li>\n</ul>\n</li>\n<li>器件数目与尺寸检查<ul>\n<li>检查版图中对应节点上期间的数量以及每个器件的尺寸是否与原理图中对应结点的期间数量与尺寸一致</li>\n</ul>\n</li>\n</ul>\n<p><strong>LVS在数字IC中的检查</strong></p>\n<p>常用的解决LVS错误的方法</p>\n<ul>\n<li>检查器件数目</li>\n<li>检查器件类型</li>\n<li>检查节点数量</li>\n<li>检查电源线和地线的连接</li>\n<li>从关键点找起</li>\n</ul>\n<h3 id=\"版图寄生参数提取与设计仿真\"><a href=\"#版图寄生参数提取与设计仿真\" class=\"headerlink\" title=\"版图寄生参数提取与设计仿真\"></a><strong>版图寄生参数提取与设计仿真</strong></h3><p><strong>版图寄生参数提取</strong></p>\n<p>版图设计的完整寄生参数应当包括R（电阻）、C（电容）、L（电感）、K（互感）</p>\n<p>LPE（版图寄生参数提取）/PRE（寄生电阻提取）提取的主要参数包括MOS管源漏的周长、面积、电阻，沟道的长与宽，双极晶体管和二极管的结面积、结周长，以及结点寄生电容、互连线电容电阻、接触孔电阻等。</p>\n<p><strong>版图设计仿真</strong></p>\n<p>使用牛顿迭代法，用泰勒级数的前几项来寻找方程f(x)=0的根</p>\n<h3 id=\"逻辑单元库的建立\"><a href=\"#逻辑单元库的建立\" class=\"headerlink\" title=\"逻辑单元库的建立\"></a>逻辑单元库的建立</h3><blockquote>\n<p>逻辑单元的建库流程归纳为以下5步</p>\n<p>1、方案设计与论证</p>\n<p>2、电路设计</p>\n<p>3、版图设计与物流库生成</p>\n<p>4、标准单元特性及库模型生成</p>\n<p>5、设计验证</p>\n</blockquote>\n<p><strong>逻辑单元类别</strong></p>\n<p>完整的单元库根据在芯片中的应用可以分为三类</p>\n<ul>\n<li><p>标准单元(standard cell)</p>\n<p>放置于芯片的核心区起逻辑功能粘接作用</p>\n</li>\n<li><p>模块宏单元(macro block)</p>\n<p>放置于芯片核心区，至少包括嵌入式存储器（RAM和ROM）、IP、COT模块</p>\n<p>其它重要的宏单元模块：始终PLL模块，DSP模块</p>\n</li>\n<li><p>输入输出单元(I/O pad cell)</p>\n<p>放置于核区的周围，用于芯片信号的输入、输出和电源供给</p>\n</li>\n</ul>\n<img src=\"/2023/08/09/Physical-design/05.png\" class=\"\">\n<p><strong>逻辑单元电路</strong></p>\n<p>组合逻辑电路简称为组合电路包括</p>\n<ul>\n<li>反向逻辑电路：反向器、与非门、或非门</li>\n<li>非反向逻辑电路：缓冲器、与门、或门</li>\n<li>其它常用逻辑电路：数据选择门（MUX）、异或门、数据传输门（TBUF）、复合门（AOI）</li>\n<li>特殊功能的逻辑电路：加法器、乘法器、除法器</li>\n</ul>\n<p>时序逻辑电路也称为时序电路</p>\n<blockquote>\n<p>输出信号不但同但钱的输入相关还和上一时间的输出有关，具有记忆功能</p>\n</blockquote>\n<p>包括：</p>\n<ul>\n<li>锁存器（Latch）：专指电平敏感的时序电路</li>\n<li>寄存器类（flip flop）：时钟边沿出发</li>\n</ul>\n<p><strong>模块单元（宏单元模块）</strong></p>\n<p>存储单元ROM：NOR ROM、NAND ROM、EPROM、EEPROM、FAMOS ROM</p>\n<p>存储单元RAM：静态随机存储器SRAM、动态随机存储器DRAM</p>\n<p>专用模块：客户自由工具COT，专用标准产品ASSP，信号处理器DSP</p>\n<p>黑盒子商业IP模块：电路设计不公开</p>\n<p>模拟电路模块：时钟锁相环PLL模块</p>\n<p><strong>输入输出单元</strong></p>\n<blockquote>\n<p>包括输入信号、输出信号、三态门、双向、电源和接地单元</p>\n</blockquote>\n<p>对于输入单元要考虑静电放电的防护</p>\n<p>形成电阻的方法：n型扩散层、p型扩散层和多晶硅</p>\n<p>形成电容的方法：Poly、Mos栅电容</p>\n<p><strong>物理单元库与数据文件，LEF文件</strong></p>\n<img src=\"/2023/08/09/Physical-design/01.png\" class=\"\">\n<p>标准单元建库的规则</p>\n<ul>\n<li>所有单元都等高的矩形，或者是基本高度的整数倍</li>\n<li>所有版图都用预先定义的模板进行设计</li>\n<li>所有单元的端口位置、大小、形状都尽量满足网格间距的要求</li>\n<li>电源线和地线一般位于单元的上下边界</li>\n</ul>\n<p>模块单元建库</p>\n<ul>\n<li>先建立RAM和ROM的基本单元</li>\n<li>根据比特和字长，自底向上堆砌生成版图</li>\n</ul>\n<p>I/O单元</p>\n<ul>\n<li>IO拐角单元在芯LEF文档的单元类型中被定义为Endcap，分布在拐角处</li>\n</ul>\n<p><strong>时序单元建库与数据文件</strong></p>\n<p>器件延时：表示信号通过一个逻辑门时所经历的时间，反映了门对输入信号变化响应的快慢。通过输入信号电压变化的50%到输出信号电压变化的50%所需要的时间来定义门延时的大小。</p>\n<img src=\"/2023/08/09/Physical-design/06.png\" class=\"\">\n<p>用于DSM设计的器件延时模型</p>\n<ul>\n<li>开关线性RC模型</li>\n<li>经验推导公式（K-Factor方程）</li>\n<li>非线性延时模型</li>\n<li>可伸缩多项式模型</li>\n</ul>\n<p>时序库文件</p>\n<img src=\"/2023/08/09/Physical-design/07.png\" class=\"\">\n<p>EDA工具通常采用两种模型计算天线比率，一种时部分检查模型，另一种是积累检查模型</p>\n<h3 id=\"习题：-1\"><a href=\"#习题：-1\" class=\"headerlink\" title=\"习题：\"></a>习题：</h3><ul>\n<li><p>1、什么是标准单元库？它主要包括哪几类单元？它们分别在电路中起什么作用？</p>\n<p>标准单元库是一种预先设计和验证的模块化的芯片单元集合，用于构建数字集成电路，包含了经过验证和优化的标准逻辑门和寄存器等基本单元，可以在芯片设计中重复使用，以节省设计时间和提高设计的可靠性。</p>\n<p>主要包括：逻辑门、寄存器、编码解码器、算术逻辑单元、存储器单元</p>\n<p>使用标准单元库可以提高设计的效率，降低设计风险，促进可重用性。</p>\n</li>\n<li><p>2、标准单元有几种不同抽象级别的描述？为什么要采用不同抽象层描述同一电路单元？</p>\n<p>逻辑级描述、电路级描述、物理级描述</p>\n<p>采用不同抽象层描述同一电路单元可以更好的管理设计的不同方面，优化设计的性能和可靠性，并在设计复杂性和效率之间进行权衡。</p>\n</li>\n<li><p>3、解释LEF库文件在物理实施布局布线中的作用和重要性，并说明它所定义的内容是如何知道EDA工具实现自动布局布线的。</p>\n<p>LEF库文件定义了标准单元的物理特性，包括尺寸大小方向以及引脚位置和功能等等</p>\n<p>EDA工具实现自动布局布线是通过读取和解析LEF库文件中的信息。工具可以根据LEF文件中定义的物理特性和约束，生成优化芯片的物理布局和连线。</p>\n</li>\n</ul>\n<h2 id=\"第三章、布图规划（芯片规划）和布局\"><a href=\"#第三章、布图规划（芯片规划）和布局\" class=\"headerlink\" title=\"第三章、布图规划（芯片规划）和布局\"></a>第三章、布图规划（芯片规划）和布局</h2><h3 id=\"布图规划\"><a href=\"#布图规划\" class=\"headerlink\" title=\"布图规划\"></a>布图规划</h3><p>布图规划开始时，首先要准备好各种基本设计数据和相应的物理库、时序库文件，并输入到不图规划的工具环境中来</p>\n<img src=\"/2023/08/09/Physical-design/08.png\" class=\"\">\n<p>布图规划主要内容包含对芯片大小的规划、芯片设计输入输出单元的规划、大量硬核或模块的规划</p>\n<p><strong>布图规划的主要目标</strong></p>\n<ul>\n<li>确定芯片的面积</li>\n<li>确保时序的收敛</li>\n<li>保证芯片的稳定</li>\n<li>满足布线的要求：保证布线通畅的同时，尽量缩短走线的长度</li>\n</ul>\n<p><strong>I/O接口单元的放置与供电</strong></p>\n<p>放置方式：1、pin点方式，2、pad条状方式，3、做成固定模块，将pad集成</p>\n<p>当芯片面积较大，芯片时序较为紧张时，I/O单元也可能均匀分布在芯片的内部</p>\n<p>I/O单元的供电：I/O单元分为信号接口和电源两种</p>\n<p>电源I/O单元分为3类：给模拟器件供电的I/O单元、给数字期间供电的、用于隔离数字供电和模拟供电</p>\n<p>数字I/O也分为两大组：一组是给I/O单元供电，一组是给核内的标准单元供电</p>\n<p>给I/O单元供电的供电单元数量由多种因素决定：I/O单元的消耗、输出I/O单元的驱动能力、同步开关噪声</p>\n<p><strong>布图规划方案与延迟预估</strong></p>\n<p>展平化设计</p>\n<p>因为还没有进入布线阶段，使用线负载模型预估当前布局的时序，展平式的方法会占用大量的内存，需要很长的运行时间。</p>\n<p>层次化设计</p>\n<blockquote>\n<p>思想是将大规模的顶层设计分解成多个子模块，每个子模块并行完成布局布线，最后在顶层组装。</p>\n<p>大致分为三个步骤：芯片顶层设计规划、子模块分割与实现、芯片顶层组装时序</p>\n</blockquote>\n<p>在层次化设计的过程中，需要在布图和布局规划中对时钟进行预估，流程图如下：</p>\n<blockquote>\n<p>根据子模块大小，和子模块中的元件数量以及复杂度来进行预估</p>\n</blockquote>\n<img src=\"/2023/08/09/Physical-design/09.png\" class=\"\">\n<p><strong>模块布放与布线通道</strong></p>\n<p>布线轨道：芯片内部专门用于布线的路径</p>\n<p>布线通道：每两条或多条布线轨道的空间，上面不可以摆放标准单元</p>\n<h3 id=\"电源规划\"><a href=\"#电源规划\" class=\"headerlink\" title=\"电源规划\"></a>电源规划</h3><blockquote>\n<p>给整个芯片的供电设计出一个均匀的网络，电源规划在芯片布图规划后或在布图规划过程中交叉完成。</p>\n<p>电源网络设置、数字模拟混合供电、单电源与多电源供电电压网络设置</p>\n</blockquote>\n<p>芯片供电是通过I/O单元来实现的，需要先完成电源预算，</p>\n<p><strong>电源网络设计</strong></p>\n<ul>\n<li>电源连接关系定义global net connect</li>\n<li>芯片核内部分的电源环设计power ring</li>\n<li>芯片内所包含的硬核（如 RAM、ROM以及IP、COT模块）的电源环设计</li>\n<li>芯片核内纵横交错的电源网络设计</li>\n<li>芯片的供电单元与电源环的连接</li>\n<li>芯片内部的电源网络与硬核电源环连接部分的设计</li>\n<li>将标准单元的供电网络和硬核电源环连接部分的设计</li>\n<li>I/O供电单元电源环的设计</li>\n</ul>\n<p>1、全局电源</p>\n<p>电源的定义主要包括：全局电源的定义以及连接关系的定义。</p>\n<ul>\n<li>电源和接地网络：通过wire定义</li>\n<li>接高电压和接低电压网络</li>\n<li>电压和接地端口</li>\n<li>填充单元网络</li>\n</ul>\n<p>2、电源环线</p>\n<p>为了能够均匀供电，包围在标准单元周围的环形供电金属，是连接供电I/O单元和标准单元的桥梁</p>\n<p>电源网格可以平均分布电流，缩短电流回路，在有效减少电压降的同时，避免由于电流分布不均时造成的热点现象以及电迁移问题。</p>\n<p>3、电源条线</p>\n<p>芯片内部纵横交错的电源网格和电源条线设计有专门的理论和算法。</p>\n<img src=\"/2023/08/09/Physical-design/10.png\" class=\"\">\n<p>纵向必须用偶数层走线，横向必须用奇数层走线。</p>\n<p><strong>数字与模拟混合供电</strong></p>\n<p>1、模拟模块的工作区域一般放置于芯片的某个角落</p>\n<p>2、模拟区域需要单独供电</p>\n<p>3、在模拟模块的周围布置保护隔离环，从而实现数字信号和模拟信号电源之间的隔离</p>\n<img src=\"/2023/08/09/Physical-design/11.png\" class=\"\">\n<p><strong>多电源供电</strong>（麻了，看不懂）</p>\n<h3 id=\"布局\"><a href=\"#布局\" class=\"headerlink\" title=\"布局\"></a>布局</h3><blockquote>\n<p>因为此时以及将芯片的各个部分规划好了，需要在具体规划的区域中填充详细的模块</p>\n</blockquote>\n<p><strong>展平式布局</strong></p>\n<p>模块的摆放与布局</p>\n<p>标准单元的摆放和优化</p>\n<p>简单来说：放置模块和标准单元·</p>\n<p><strong>层次化布局</strong></p>\n<blockquote>\n<p>先分配子模块、作子模块的布局、所有子模块完成后在顶层组装</p>\n</blockquote>\n<ul>\n<li><p>约束类型确定</p>\n<blockquote>\n<p>约束类型一般有三种：向导约束、区域约束和限制约束</p>\n</blockquote>\n</li>\n<li><p>子模块大小位置的制定</p>\n</li>\n</ul>\n<p><strong>布局目标预估</strong></p>\n<blockquote>\n<p>在标准单元布局优化完成后，需要对设计进行拥塞分析，静态时序分析，噪声分析，和电源分析以确定布局的好坏</p>\n</blockquote>\n<p>布局的目标</p>\n<ul>\n<li>各模块的位置相对确定</li>\n<li>满足设计规则的要求</li>\n<li>芯片的时序和供电较为良好</li>\n</ul>\n<p><strong>标准单元布局优化算法</strong></p>\n<blockquote>\n<p>布局优化的算法从步骤上可以分成三个阶段：结群布局、全局布局、详细布局</p>\n</blockquote>\n<p>1、布局优化的算法</p>\n<ul>\n<li><p>结群算法（clustering聚类算法）</p>\n<p>选择一个单元作为种子，以各个种子为原始群不断结合与其最紧密的单元。</p>\n</li>\n<li><p>模拟退火算法、KL算法、FM算法</p>\n</li>\n<li><p>全局布局：最小切割法、模拟退火算法、贪心算法、力向量算法、NRG算法、HALO算法</p>\n</li>\n<li><p>布局优化算法：纯标准单元布局算法、模块布局算法、混合单元布局算法</p>\n</li>\n</ul>\n<p>2、从优化目标上优化算法</p>\n<ul>\n<li>基于布线拥塞的布局优化算法</li>\n<li>基于时序的布局算法</li>\n<li>预防噪声的布局算法</li>\n</ul>\n<h3 id=\"扫描链重组\"><a href=\"#扫描链重组\" class=\"headerlink\" title=\"扫描链重组\"></a>扫描链重组</h3><blockquote>\n<p>扫描链是可测试性设计的重要内容，将芯片中所应用的普通寄存器替换成带扫描功能的多输入输出扫描寄存器，首位连接成串，从而实现附加的测试功能。</p>\n</blockquote>\n<p>将连接在扫描链上的在芯片内随机分布的扫描寄存器单元按照其物理位置，在不影响逻辑功能的前提下，重写进行连接，从而减少扫描链的走线长度。</p>\n<p>实现方法：</p>\n<ul>\n<li>本地化重组</li>\n<li>基于扫描DEF的扫描链重组方法</li>\n</ul>\n<h3 id=\"物理设计网表文件\"><a href=\"#物理设计网表文件\" class=\"headerlink\" title=\"物理设计网表文件\"></a>物理设计网表文件</h3><p>DEF(design exchange format)文件：设计交换给格式</p>\n<p>PDEF(physical DEF)：物理设计交换格式</p>\n<h2 id=\"第四章时钟树综合CTS\"><a href=\"#第四章时钟树综合CTS\" class=\"headerlink\" title=\"第四章时钟树综合CTS\"></a>第四章时钟树综合CTS</h2><h3 id=\"时钟信号\"><a href=\"#时钟信号\" class=\"headerlink\" title=\"时钟信号\"></a>时钟信号</h3><p><strong>时钟信号抖动</strong>：时钟抖动定义为信号时间与理想事件时间的偏差，抖动中含有确定抖动成分和随机抖动成分。</p>\n<ul>\n<li>确定抖动：串扰、电磁干扰、同时开关输出引起</li>\n<li>随即抖动：服从高斯分布，通常由半导体晶体结构的热振动和半导体掺杂密度不均匀中共价电子引起</li>\n</ul>\n<h3 id=\"时钟树综合的方法\"><a href=\"#时钟树综合的方法\" class=\"headerlink\" title=\"时钟树综合的方法\"></a>时钟树综合的方法</h3><blockquote>\n<p>芯片设计中的时钟分为两类：真实时钟（real clock）和虚拟时钟（virtual clock）</p>\n<p>真实时钟又有两种模式：时钟树综合前没有延时的理想时钟，时钟树综合后的传播时钟</p>\n</blockquote>\n<p><strong>时钟树综合与标准设计约束文件</strong>：SDC文件（时序约束文件）</p>\n<p>SDC文件三部分：时钟定义、输入延迟、输出延迟</p>\n<p>通过工艺文件来约束时钟信号的相关属性</p>\n<p>时钟的定义将通过时钟树综合来实现，时钟延迟和时钟抖动或不确定性将在静态时序分析时进行检查。</p>\n<p><strong>时钟树结构</strong></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">时钟树：时钟信号在物理设计中的实现结果<br>根节点：时钟信号的起点<br>叶结点：时钟信号经过一系列分布结点最终到达寄存器时钟输入端或其它时钟终点<br>根单元、分布单元、叶单元：根节点、分布节点和叶结点都依附于的逻辑单元<br></code></pre></td></tr></table></figure>\n<p>时钟网络从根节点逐级插入驱动器，从而到达其叶结点，按照芯片始终网络的约束要求产生时钟树的过程叫做是中暑综合。</p>\n<img src=\"/2023/08/09/Physical-design/image-20230809095839094.png\" class=\"\" title=\"image-20230809095839094\">\n<p>时钟树根据其在芯片内的分布特征，可分为多种结构：H树、 X树、平衡树、疏状或脊椎状时钟网</p>\n<h3 id=\"时钟树设计策略\"><a href=\"#时钟树设计策略\" class=\"headerlink\" title=\"时钟树设计策略\"></a>时钟树设计策略</h3><p><strong>时钟树综合策略</strong></p>\n<ul>\n<li>自我交叉</li>\n<li>相互交叉时钟</li>\n<li>有用偏差</li>\n</ul>\n<img src=\"/2023/08/09/Physical-design/image-20230809102800761.png\" class=\"\" title=\"image-20230809102800761\">\n<ul>\n<li><p>OVC片上误差分析法与CPPR共同路径悲观去除的应用</p>\n</li>\n<li><p>与布局相结合的手动时钟树设计</p>\n</li>\n<li>对时钟插入多驱动的buffer</li>\n</ul>\n<p><strong>异步时钟树设计</strong></p>\n<p>实际的SoC设计中，是以异步时钟设计来实现的，从而降低功耗</p>\n<img src=\"/2023/08/09/Physical-design/image-20230809105341276.png\" class=\"\" title=\"image-20230809105341276\">\n<p><strong>门控时钟</strong></p>\n<p>门控时钟是降低功耗最常用的方法，使用一个控制信号控制时钟的开启。</p>\n<h3 id=\"时钟树分析\"><a href=\"#时钟树分析\" class=\"headerlink\" title=\"时钟树分析\"></a>时钟树分析</h3><p><strong>时钟树与功耗分析</strong></p>\n<blockquote>\n<p>时钟树上的功耗由静态功耗、短路功耗和跳变功耗三部分组成</p>\n</blockquote>\n<ul>\n<li>静态功耗：各个buffer上静态功耗和，减少静态功耗的方法就是减少buffer的加权数</li>\n<li>短路功耗：与转换时间成正比，与阈值电压的3次方成反比</li>\n<li>跳变功耗：占比50%以上，由门的加权数值以及互连线总的电容决定</li>\n</ul>\n<p>降低功耗的方案</p>\n<ul>\n<li>1、减小时钟信号转换时间，信号从10%转化到90%所需要的时间</li>\n<li>2、降低结点电容</li>\n</ul>\n<h2 id=\"第五章、布线\"><a href=\"#第五章、布线\" class=\"headerlink\" title=\"第五章、布线\"></a>第五章、布线</h2><blockquote>\n<p>将分布在芯片核内的模块、标准单元和输入输出接口单元按逻辑关系进行互联</p>\n<p>要求百分百地完成它们之间的所有逻辑信号的互联，并为满足各种约束条件进行优化</p>\n</blockquote>\n<h3 id=\"全局布线\"><a href=\"#全局布线\" class=\"headerlink\" title=\"全局布线\"></a>全局布线</h3><p><strong>全局布线目标</strong></p>\n<ul>\n<li>1、使总连线最短</li>\n<li>2、布线分散均匀不至于引起局部拥塞</li>\n<li>3、使关键路径延时最小，遵守时序规则</li>\n<li>4、理解信号完整性要求，避免串扰</li>\n<li>5、保持将BUS总线聚集相连等</li>\n</ul>\n<p><strong>全局布线规划</strong></p>\n<h3 id=\"详细布线\"><a href=\"#详细布线\" class=\"headerlink\" title=\"详细布线\"></a>详细布线</h3><p><strong>详细布线的目标</strong></p>\n<ul>\n<li>1、理解所有的设计规则</li>\n<li>2、自动切换并综合利用多层金属作连线</li>\n<li>3、遵守时序规则，优先使关键路径的延时满足要求</li>\n<li>4、对总连线长度进行优化</li>\n</ul>\n<p><strong>详细布线与设计规则</strong></p>\n<ul>\n<li>设计规则</li>\n<li>通孔和最小面积要求</li>\n<li>密度要求</li>\n<li>掩膜光刻过程中的工艺天线效应</li>\n<li>串扰在布线中的预防和修复</li>\n<li>纳米布线规则</li>\n<li>对焦布线规则</li>\n</ul>\n<p><strong>布线修正</strong></p>\n<ul>\n<li>自动修正</li>\n<li>渐进修正</li>\n<li>局部修正</li>\n</ul>\n<h2 id=\"第六章、静态时序分析\"><a href=\"#第六章、静态时序分析\" class=\"headerlink\" title=\"第六章、静态时序分析\"></a>第六章、静态时序分析</h2><blockquote>\n<p>做时序分析前，首先要对芯片的物理版图设计进行包括电阻、电感、电容参数的提取，在进行延时计算。</p>\n</blockquote>\n<h3 id=\"延迟计算与布线参数提取\"><a href=\"#延迟计算与布线参数提取\" class=\"headerlink\" title=\"延迟计算与布线参数提取\"></a>延迟计算与布线参数提取</h3><p><strong>延迟计算模型</strong></p>\n<blockquote>\n<p>可以在布局之后进行，也可以在时钟树综合后进行。使用WLM区估算</p>\n</blockquote>\n<p>各种参数提取、各种物理公式：电阻电容电感</p>\n<h3 id=\"寄生参数与延迟格式文件\"><a href=\"#寄生参数与延迟格式文件\" class=\"headerlink\" title=\"寄生参数与延迟格式文件\"></a>寄生参数与延迟格式文件</h3><p>1、标准寄生参数格式文件</p>\n<ul>\n<li>SPF-Standard Parasistic Format（File），标准寄生参数格式文件</li>\n<li>DSPF-Detailed SPF，详细标准寄生参数格式文件</li>\n<li>RSPF-Reduced SPF，简化标准寄生参数格式文件</li>\n<li>SPEF-Standard Parasitic Exchange Format（File），标准寄生参数交换格式文件</li>\n</ul>\n<h3 id=\"静态时序分析\"><a href=\"#静态时序分析\" class=\"headerlink\" title=\"静态时序分析\"></a>静态时序分析</h3><blockquote>\n<p>进行时序分析时，简单的说就是将某一段路径的时序与时序约束的要求进行比较。根本目的是为了检查在时钟的控制和要求的约束下，与其相关的数据能够符合时序要求被记录存储下来，这种时序检查就是一对常说的建立时间时序和保持时间时序。</p>\n</blockquote>\n<p>Setup定义：在时钟作用前沿到达前，同步输入信号D必须保持稳定的那段时间以使信号不至于丢失。</p>\n<p>Hold定义：在时钟作用前沿到达后，同步输入信号D必须保持稳定的那段时间以使得信号不至于丢失。</p>\n<p>1、建立时序（Setup）的违例</p>\n<p>要求同步输入数据D必须在时钟信号前的某个时段到达且不发射变化，这样数据才会被成功的锁存。</p>\n<p>2、保存时序违例</p>\n<p>增长数据的路径延迟</p>\n<p><strong>时序分析与时钟特性</strong></p>\n<ul>\n<li>定义输入输出环境参数<ul>\n<li>1、确定驱动</li>\n<li>2、确定驱动单元</li>\n<li>3、确定负载</li>\n<li>4、确定删除</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"时序优化\"><a href=\"#时序优化\" class=\"headerlink\" title=\"时序优化\"></a>时序优化</h3><p><strong>造成时序违例的因素</strong></p>\n<ul>\n<li>1、系统设计的复杂性和抽象性，存在不合理的约束</li>\n<li>2、逻辑综合时依据了不合理的WLM</li>\n<li>3、设计太大，互连线的相互牵制引起时序违例</li>\n<li>4、设计做了不合理的布局</li>\n</ul>\n<h3 id=\"习题\"><a href=\"#习题\" class=\"headerlink\" title=\"习题\"></a>习题</h3><p>1、什么是静态时序分析？描述它的分析步骤过程。</p>\n<ul>\n<li>静态时序分析是一种在设计和验证数字电路时用于评估电路时序特性的方法。主要用于分析电路中的时序路径，包括组合逻辑路径和时钟路径，以确保电路在给定的时钟频率下能够满足时序要求。是一种基于约束和路径分析的方法，用于评估电路的时序特性和性能。</li>\n</ul>\n<p>2、什么是建立时间和保持时间？什么是虚假路径、多周期路径？</p>\n<ul>\n<li>建立时间：在时钟上升沿到来之前，为了确保输入数据能够稳定的被采样，输入信号必须保持不变的最小时间。</li>\n<li>保持时间：在时钟上升沿到来之后，为了确保输入数据能够完整的写入，输入型号必须保持不变的最小时间。</li>\n<li>虚假路径：在时序分析中被认为不需要满足时序约束的路径。这些路径不会对电路的正常工作产生影响，因此可以被忽略。</li>\n<li>多周期路径：信号的传播时间可以超过一个周期。</li>\n</ul>\n<p>3、如何保证物理实施阶段的时序收敛？</p>\n<ul>\n<li>通过静态时序分析</li>\n</ul>\n<h2 id=\"第七章、功耗分析\"><a href=\"#第七章、功耗分析\" class=\"headerlink\" title=\"第七章、功耗分析\"></a>第七章、功耗分析</h2><blockquote>\n<p>动态分析：芯片工作过程中产生的功耗</p>\n<p>静态分析：芯片在待机状态时产生的平均功耗</p>\n</blockquote>\n<h3 id=\"静态功耗分析\"><a href=\"#静态功耗分析\" class=\"headerlink\" title=\"静态功耗分析\"></a>静态功耗分析</h3><blockquote>\n<p>反偏二极管泄漏电流</p>\n<p>门栅感应漏极泄漏电流</p>\n<p>亚阈值泄漏电流</p>\n<p>门栅泄漏电流</p>\n</blockquote>\n<h3 id=\"动态功耗分析\"><a href=\"#动态功耗分析\" class=\"headerlink\" title=\"动态功耗分析\"></a>动态功耗分析</h3><blockquote>\n<p>开关功耗+短路功耗</p>\n</blockquote>\n<h3 id=\"电压降分析与电迁移分析\"><a href=\"#电压降分析与电迁移分析\" class=\"headerlink\" title=\"电压降分析与电迁移分析\"></a><strong>电压降分析与电迁移分析</strong></h3><p>电迁移：在一定的制造工艺下，在它上面所能允许流过的最大电流是有一定限度的，否则过大的电流将会使金属连线断裂，导致芯片失效，这种由于电流引起的电路失效现象称为EM电迁移。</p>\n<p>电源网络的电迁移由平均电流密度、金属宽度以及孔的大小决定</p>\n<p>电迁移容限测量方法：漂移速度法、低频噪声法、电阻模型模拟、等，常用寿命测试法（测量一定数量的相同样品在规定条件下的失效时间）</p>\n<h3 id=\"功耗分析数据文件\"><a href=\"#功耗分析数据文件\" class=\"headerlink\" title=\"功耗分析数据文件\"></a>功耗分析数据文件</h3><blockquote>\n<p>功耗分析需要建立相应的数据库，并且借助于与功耗相关的文件来有效地控制和处理这些数据</p>\n</blockquote>\n<p>静态分析数据——TCF文件</p>\n<p>动态分析数据——输入多两个重要信息：电源凸点的位置分布信息和动态功耗仿真用的VCD文件+TWF文件</p>\n<p><strong>电源网格视图库</strong>——PGV(power grid view)</p>\n<blockquote>\n<p>用于分析芯片电压降效应的一种库文档格式</p>\n<p>使用PGV库计算功耗的精度不是很高</p>\n<p>根据供电网络分布，首先分别提取电源网络的电阻和电流节点处的平均结点阀门电流，再建立电源网络视图库</p>\n</blockquote>\n"},{"title":"VLSI超大规模集成电路物理设计","date":"2023-08-28T08:33:37.000Z","cover":"/img/default_cover03.jpg","top_img":null,"_content":"## 第一章 绪论\n\n### 电子设计自动化（EDA）\n\nEDA（Electronic Design Automation），全称电子设计自动化，是用来辅助超大规模集成电路设计生产的工业软件，涵盖电路芯片设计、制造、封装、测试整个流程。随着芯片设计的复杂程度不断提升，基于先进工艺节点的集成电路规模可达到数十亿个半导体器件，不借助EDA已经无法完成芯片设计。\n\nEDA工具是集成电路设计和制造流程的支撑，是集成电路设计方法学的载体，也是连接设计和制造两个环节的纽带和桥梁。\n\n采用软件来实现自动化\n\n> EDA将设计者的需求分为电子系统层次结构中的多个级别，包括集成电路、多芯片模块和印制电路板\n\nEDA工具总是面向整个设计过程的自动化，并将设计步骤链接成一个完整的设计流。\n\n### VLSI设计流程\n\n![image-20230817170808037](VLSI-Physical-Design/image-20230817170808037.png)\n\n系统规范—架构设计—功能和逻辑设计—电路设计—物理设计—物理验证和签收—制造—封装和测试—芯片\n\n物理设计关键步骤还可以细分\n\n划分—芯片规划—布局—时钟树综合—布线—时序收敛\n\n* 系统规范\n\n  定义系统的总体目标和高级需求：功能、性能、物理尺寸、生产技术\n\n* 架构设计\n\n  模拟和混合信号模块集成\n\n  存储管理——串行或者并行——寻址方案\n\n  计算核的类型核数量（处理器，数字信号处理单元，特别的DSP算法）\n\n  芯片内外的通信，对标准协议的支持\n\n  硬、软IP模块的使用\n\n  引脚分配、封装、管芯封装接口\n\n  电源需求\n\n  工艺技术核层堆栈的选择\n\n* 功能和逻辑设计\n\n  * 功能设计\n\n    每个模块的输入、输出和时序行为\n\n  * 逻辑设计（用硬件描述语言HDL，如Verilog和VHDL定义芯片的功能和时序行为）\n\n  * 逻辑综合工具自动使HDL转变为底层的电路单元。即映射为信号网列表或网表和特定的电路单元\n\n* 电路设计\n\n  一些关键的低端的单元必须在晶体管级来进行设计，这就是所谓的电路设计。\n\n  包括：静态RAM模块、I/O、模拟电路、高速函数（乘法器）以及静电放电保护电路\n\n* 物理设计\n\n  所有的设计组件（宏模块、单元、门）都实例化为几何表示\n\n  * 划分\n  * 布线规划\n  * 电源和地网布线\n  * 布局\n  * 时钟网综合\n  * 总体布线\n  * 详细布线\n  * 时序收敛\n\n* 物理验证\n\n* 制造：fabrication\n\n* 封装和测试\n\n\n\n### VLSI设计模式\n\n> 全定制和半定制\n\n* 半定制标准设计模式：\n\n  * 基于单元：通常采用标准单元和宏单元，包含许多预定义元件（从元件库复制而来）\n  * 基于阵列：采用门阵列或者FPGA，包含若干制备好的元件，通过预布线相连\n\n* 全制定设计\n\n  需要有版图编辑器\n\n* 标准单元设计，有固定的电源和接地端口\n\n  布局的自由度较少，复杂度大大降低\n\n* 宏单元\n\n  较大块逻辑，执行可重用的功能\n\n* 门阵列\n\n  具有标准逻辑功能的硅片，但是没有链接\n\n* 现场可编程门阵列（FPGA）\n\n  逻辑单元和互连都是预先制造好，但是用户可以通过开关来配置\n\n* 结构化ASIC（无通道门阵列）\n\n\n\n### 版图层和设计规则\n\n* 版图层\n\n  硅作为扩散层，多晶硅、铝和铜作为互连层；多晶硅作称为poly层，其余曾称为Metal1层、Metal2层等。\n\n  单元之间的布线是完全在金属层进行的。\n\n* 设计规则\n\n  大致分为三类\n\n  * 尺寸规则：任何组件（形状）的尺寸\n  * 间距规则：组件形状之间的间距\n  * 覆盖规则：组件形状之间的覆盖量\n\n\n\n### 物理设计优化\n\n物理设计的目标：最小芯片面积、最小线长和最少过孔\n\n最优化的目标：提升电路性能，可靠性\n\n* 版图优化\n\n  > 满足约束：工艺约束、电气约束、几何约束\n\n\n\n### EDA常用术语\n\n逻辑设计：将HDL描述映射到电路门和门在网表级的连接的过程。\n\n* 结果通常是单元或其他基本电路元件和连接的网表。\n\n物理设计：决定单元（或者其他电路元件）和它们的连接在集成电路版图中几何布置的过程。连接拓扑从网表中得到。\n\n* 物理设计的结果是几何和功能都正确的表示，用标准文件格式，例如GDSII流。\n\n版图验证包括：\n\n* 设计规则检验（DRC）——遵守所有的技术需求\n* 版图和原理图一致性检验（LVS）——是否和原始网表一致\n* 天线规则检验——没有天线效应\n* 电气规则检验——遵守所有的电气需求\n\n```\n组件：有基本功能的电路元件\n模块：一个电路划分或者一部分构件的集合\n块：具有形状的组件，有固定尺寸的电路划分\n单元：用不同构建建立的逻辑或者功能单位。如：INV，NAND，NOR，常用来指标准单元和宏单元\n标准单元：一种预先决定功能的单元，在标准单元里，逻辑设计是将标准单元排列在行里来实现的\n宏单元：一种没有预先定义尺寸的单元。可以指大型物理版图，如SRAM，CPU核\n引脚：一个电子终端，用于连接给定的构件到它的外部环境\n层：制造工艺等级，在这个等几种，设计构件在芯片上成型。\n接触层：硅核金属层之间的直接连接，接触层经常用在单元内\n过孔：金属层之间的连接，通常用来连接不同层的布线结构\n线网或信号：必须在相同电势下连接的引脚或终端的集合\n供电网：提供电流给单元的电源（VDD）和地网（GND）\n网表：设计中连接的所有信号网和构件的集合，或者是所有网和分段设计的连接引脚的列表。\n网表可以组成：1、面向引脚，每个设计构件都有一个相关线网的列表。2、面向线网，每一个线网都有一个相关构件的列表。网表在逻辑综合中创建，是物理设计的关键输入。\n线网权重（W）：用来表示线网的重要性或关键性\n\n网表的表示方法：连接图和连接矩阵\n```\n\n### 第一章总结\n\n* 什么是EDA？\n\n  EDA全称是Electrical Design Automation（电子设计自动化），是芯片设计中的辅助软件工具也是必不可少的一个工具，随着芯片中集成的半导体和电路规模越来越大，EDA工具也越来越重要。\n\n* 超大规模集成电路（VLSI）的设计流程？\n\n  系统规范—架构设计—逻辑功能设计—物理设计—物理验证—制造—封装—测试—芯片\n\n* 其中物理设计包括哪些部分？\n\n  物理设计包括：布图规划，布局规划，布线，时钟树综合，时序分析\n\n\n\n## 第二章 网表和系统划分\n\n一般采用分治的策略进行芯片设计，先将模块进行布局，然后将结果转换为几何划分。\n\n### 介绍\n\n> 降低现代集成电路设计复杂度的方法是将它们划分为更小的模块。\n\n划分的主要目标是将电路进行划分，使得子电路之间的连接数最小化，且符合设计约束。\n\n### 术语\n\n```\n元胞：构成组件的任何逻辑或功能单元\n划分或块是由元胞和组件构成的\n多元划分的问题是将电路划分为K个部分\n```\n\n### 优化目标\n\n在平衡划分大小时，将所有割边数或割边的权重数最小化，称为最小割划分算法\n\n### 划分算法\n\n> Kernighan-Lin算法（KL）、KL拓展算法、Fiduccia-Mattheyses（FM）算法\n>\n> **模拟退火法**、随机爬山算法\n\nKL算法：对于一个含有2*N个元胞且要划分的区域为N：N的，使用的是两个不同划分之间的元胞进行交换，通过计算能够是当前增益达到最大。\n\nFM算法：划分不平衡的算法，其中需要一个平衡因子来控制移动以后是否平衡。通过计算能够使得移动以后使得当前达到增益最大。可用于超图中。\n\n\n\n### 多级划分框架\n\n> 从粗粒度网表，到细粒度网表\n\n为了提高网表划分的可扩展性，FM算法被嵌入到了一个多级框架中去，包含几个不同的步骤。\n\n1、原始的展平的网表被进行层次结群。\n\n2、将FM算法应用到这个结群网表中。\n\n3、部分网表在非粗粒度阶段被解开结群。\n\n4、在细粒度阶段，FM算法增量式应用到部分被解开结群的网表中。\n\n5、第3和第4一直继续知道所有网表解开结群为止。\n\n\n\n* 结群\n\n  连接紧密的结点被结群，结群之外的连接保持原来网表的结构。通常结群的大小会受到限制，从而防止结群的退化。\n\n  合并结点后，结群的权重是它所包含的成员结点的权重综合\n\n* 多级划分\n\n  当结构过多的时候，FM算法会收到一定的限制，复杂度会很高，所以通过多级划分的方式可以减小复杂度\n\n* 基于多FPGA的系统划分\n\n## 第三章 芯片规划\n\n芯片规划处理大规模模块：高速缓存、嵌入式内存及面积已知、形状固定或可变或集成电路IP核等。\n\n**芯片规划主要包括了三个主要阶段：布图规划、引脚分配、电源规划**\n\n布局规划：根据模块的面积和长宽比来优化芯片的大小、降低互连线长度和改善时延，从而确定了这些模型的位置和大小。\n\n引脚分配：通过输出信号线连接到块引脚。I/O布局为芯片的输入和输出引脚确定焊盘的位置，通常在芯片的边缘。这一步最理想在布局规划前进行。\n\n电源规划：建立电源供电网，电源网和底线网。\n\n\n\n### 布图规划介绍\n\n布图描述了模块之间的关系\n\n布局规划阶段确保：1、每个芯片模块被分配了一个形状或位置，便于进行门布局。2、每个有外部连接的引脚被分配了一个位置，这样内部和外部的线网都可以进行布线了。\n\n\n\n### 布图规划的优化目标\n\n每个模块的位置和它的长宽比\n\n* 全局边界框的面积和形状：影响电路性能、成品率、制造代价\n* 总线长，最小生成树\n* 面积和总线长的组合\n* 信号时延\n\n### 术语\n\n```\n矩形划分：将芯片面积划分为一组块或非重叠矩形的几何\n布图规划二划分：通过不断对矩形进行划分得到的一个矩形划分，从整个芯片开始，反复用水平或垂直割线将其划分为两个小矩形。\n二划分树或者二划分布图规划树：有k个叶子和k-1个内部节点的二叉树，每个叶子代表一个块，每个内部节点代表一条水平或垂直割线。\n布图树：一棵表示层次化布图的树。每个叶子节点代表一个块，每个内部节点代表一个水平分割或垂直分割。\n约束图：对一个布图表示，包括两个有向图，垂直约束图和水平约束图，可以得到块之间的相对位置关系。\n垂直约束图：节点权重表示块的高度。最长路径，相当于布局所需的最小垂直高度。\n水平约束图：结点权重代表块的宽度。最长路径，相当于布局所需的最小水平宽度。\n序列对：块排列的一个有序对。用S+和S-表示，用于区分序列是左右关系还是上下关系。\n```\n\n### 布图的表示\n\n> 布图的表示方法：1、约束图，2、序列对\n\n布图、约束图（垂直约束图，水平约束图）、序列对\n\n问题：\n\n如何将一个布图转化为一个约束图对（垂直&水平）\n\n* 垂直约束图：从下到上，从左到右，先绘制所有的有向箭头，再删除不能直接相连的箭头\n\n如何将一个布图转化为一个序列对\n\n* 序列的规则，先考虑垂直方向，再考虑水平方向\n  * a在b的左边，s1<a,b> s2<a,b>\n  * a在b的上面，s1<a,b> s2<b,a>\n\n如何将一个序列对转化为一个布图\n\n> 已知布图的起始点，每个块的宽和高，布图的布局方向（一般是左下到右上）\n\n### 布图规划算法\n\n> 布图优化算法：给定一个块的几何，布图尺寸的选择决定了布图面积的最小值，以及每个块的方向和大小。\n>\n> **群生长，模拟退火法**：寻求1、在满足布图面积上限的条件下，最小化互连线总长度。2、同时优化总线长和面积。\n\n* 布局尺寸变化\n\n  寻找最小面积布图的尺寸和相应的每个块的尺寸。\n\n  * 构造所有块的形状函数\n  * 确定顶层布图的形状函数\n  * 找出布图和每个独立块的尺寸和位置\n\n群生长\n\n基于群生长的方法中，布图是由迭代的增加块，直到所有块都被分配完。\n\n* 线性排序\n\n  终端网：没有被其他没被安置的相关块\n\n  新网：在部分构造排序的任何块上都没有引脚\n\n  持续网：在部分构造排序上至少在块上有一个引脚，以及在无序块上至少有一个引脚\n\n  以终端网减去新网的值作为增益，排序后每次都进行迭代，得到最终线性排序的序列\n\n* 群生长\n\n  按照线性排序的顺序，依次将最优块放置在布图上\n\n\n模拟退火（SA）\n\n是一种迭代算法，从一个初始解开始，寻求目标函数解的不断改进。在每次迭代中，要考虑当前解的局部邻域解。\n\n### 引脚分配\n\n在引脚分配中，所有线网（信号）被分配到唯一的引脚位置，这样设计性能才是最优化的。优化目标包括块内外的最大化线网可布性和最小化电寄生参数。\n\n引脚分配可以用来连接功能或电等价的元胞引脚。\n\n优化目标：建立一个块和所有它与其他块的引脚的连接关系。\n\n### 电源和地线布线\n\n电源和地线网分布设计\n\n> 供电网VDD和GND，为每个元胞提供电源，每个元胞都必须与VDD和GND相连。\n>\n> 供电网是：大型的、跨越整个芯片的、再信号布线之前布线\n\n电源和地线网的物理设计有两种方法：平面法，主要用于模拟电路或者定制块设计中。网格法，主要用于数字集成电路设计中。\n\n* 芯片规划的步骤：布图规划、引脚分配、电源和地线分配\n* 布图用什么来表示？\n* 布图规划有哪些算法？\n\n## 第4章 全局和详细布局\n\n将电路划分成小模块和对版图进行布局规划，从而确定块的轮廓线和引脚位置后，要求解优化目标（最小化元件间的总线长），布局要确定每个块中的标准单元或逻辑元件的位置。\n\n全局布局：分配大概的位置，给可变动的器件\n\n* 忽视可布目标的特殊形状和大小，不会试图去排列它们的位置到有效的行和列中去。\n* 进行全局定位和全局分布密度\n\n详细布局：明确器件的位置使其成为合理的元胞位置并确保没有重叠\n\n* 通过局部操作（交换两个元件）或移动一个行中的几个元件来为其他元件提供位置空间，从而增量式的改进每个标准单元的位置。\n\n合法化：将可布元件布置到行列中去，并消除重叠。\n\n### 介绍\n\n布局的目标：为了确定所有电路元件在一个（平面）版图中的位置和方向，给出解的约束（如没有元胞的重叠）和优化目标（如总线长最小化）\n\n### 优化目标\n\n布局器通常优化目标是总线长。\n\n* 几种划线模型的选择\n\n  * 单链模型\n  * 星形模型\n  * 最小生成树模型（克鲁斯卡尔）（RMST）\n  * 直线最小树\n\n* 带线网权重的总线长\n\n  * 所有网络的线长与权重的乘积之和\n\n* 最大割数\n\n  最小化某一个布局总的割数\n\n* 布线拥挤度（可以使用密度来表示：即布线所需要的轨道数与可提供的轨道数的比值）\n\n  当所有穿过边的布线数小于最大的布线数时，则说明该布局是可布线的\n\n* 信号延时\n\n  对于给定的涉及，布局的总线长影响最大时钟频率，主要依赖于线网的时延和门时延。\n\n  电路时序通常使用静态时序分析法（STA）进行验证，对线网和门时延进行估算。常见的术语包括实际到达时间（AAT）和需求到达时间（RAT），可对电路中每个结点v进行估算。\n\n### 全局布局\n\n> 全局布局确定布局的大致位置，详细布局消除重叠的因素\n\n最小割划分、二次布局、力矢量布局、模拟退火\n\n* 最小割布局：利用划分算法将网表和版图区域划分为较小的子网表和子区域。子网表和子区域重复划分到更小的部分，直到每个子区域包含少量的元胞。当实现最小割布局时，网表被划分为每个子区域拥有它自己唯一的子网表。\n\n  版图划分的方向：割方向交替法（垂直割线和水平割线交替划分）、割方向重复法（先用单一方向划分，直到达到最小以后，在换方向）\n\n  在版图划分的过程中，通常会将版图划分的方向和最小割划分算法结合起来，这样才能够在版图上最终定位某一个模块的位置。\n\n  * 最小化割网的标准算法KL算法和FM算法\n\n  * 有外部链接的最小割布局\n\n    假设每个元胞分别被布置在它们各自的区域中心。如果相关的i拦截接近下一个划分割线，在做下一个割线时则不用考虑这些结点。\n\n* 解析布局（最小化目标函数）\n\n  * **二次线长布局**：分为两个阶段\n    * 第一阶段：依据元胞的中心对元胞进行布局，**从而对二次线长函数最小化**。\n    * 第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有的单元原来的重叠消除。**详细布局将所有元胞位置合法化并产生一个高质量的、无重叠的布局。**\n\n\n  第一阶段方法：迭代求解线性方程：共轭梯度法（CG）、逐次超松弛法（SOR）\n\n  第二阶段方法：详细布局：最小割布局、力矢量布局\n\n  * 二次线长布局具体算法：\n\n  ```\n  已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。求：所有的元胞的x坐标和y坐标。\n  \n  1、列出所有连接的元胞线网的X的总线长L(p)：所有的x距离的差的平方\n  2、分别对所有参数中的x求偏导，并令偏导为0\n  3、列出方程组，解出来的x阵列就是所需要求的解\n  对于Y方向也是同理\n  \n  该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题\n  ```\n\n  * **力矢量布局**\n\n    用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。\n\n    采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。**将目标转化为将所有的元胞放在一个力平衡的位置上。**——**称为零力目标**（ZFT）\n\n    * 对于每一个元胞，都有一个理想的最小ZFT位置。\n    * 通过迭代的移动每个单元或者交换元胞到这个位置或相邻近位置，逐步改善布局结果\n\n    > 个人认为：这个方法不能让每一个元胞都到达力的平衡状态，使用一次迭代或者交换，就会打乱原始平衡的元胞。\n\n  * 基本力矢量布局算法\n\n    > Loss为权重乘以坐标差的累计和\n\n  ```\n  1、任意初始布局\n  2、为每个布局中的元胞设定坐标，并标记为UNMOVED\n  3、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序\n  4、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成\n  5、若ZFT位置被占据，则移动到其他的位置\n  \n  第5步确定p的ZFT时，若ZFT被元胞q占据，则移动位置的确定\n  1、如果可能，将p移动到靠近q的位置\n  2、若交换p，q后，代价变小，则交换\n  3、链式移动，p移动到q，q移动到下一个，以此类推\n  4、波状移动，p移动到q，再重新计算q的ZFT\n  ```\n\n* 模拟退火算法\n\n  列出损失函数，使用带动量的梯度下降，最终计算出使得损失函数最小的最优解\n\n* 现代布局算法\n\n\n### 合法化和详细布局\n\n> 合法化：寻求合法的、没有重叠的布局，从而减少对线长、时序和其他设计目标的不利影响。\n\n目标：消除元胞中的重叠\n\n使用贪心算法\n\n* 按照x坐标进行排序，并进行贪心处理，贪心选择策略为移动到当前元胞最近的，可用的合法位置，但不能超出行的范围。\n\n* 缺点\n  * 没有对网表进行考虑\n  * 产生了大量的空白区域\n\n## 第五章  总体布线\n\n在总体布线中，具有相同点位的引脚用线路相连。\n\n### 介绍\n\n给定一个布局和一个网表：确定必要的连接数\n\n需要优化的布线目标：最小化总线长，最大时序松弛\n\n总体布线可分为：固定的裸片布线（芯片外形和所有布线资源都是固定的），可变的裸片布线（可以根据需要添加新布线轨道）\n\n常见的几种布线算法\n\n* 总体布线：粗粒分配布线到**布线区域**\n* 详细布线：细粒分配布线到**布线轨道**，包括线网排序，引脚排序。用于完善总体布线。\n* 时序驱动布线：线网拓扑优化和资源分配到关键线网\n* 大信号网布线：电源（VDD）和地线（GND）布线\n* 几何技术：非曼哈顿和时钟布线\n\n### 术语和定义\n\n```\n布线轨道（列）：一条可用的水平（垂直）接线通路。\n布线区域：包含了布线轨道的区域。\n规格一致的布线区域：由均匀分布的水平和垂直网格线形成，产生芯片区域上规格一致的网格。\n规格不一致的布线区域：由水平和垂直边界形成，与外部引脚连接或宏单元边界对齐。\n通道：一个矩形不限区域，在两个相对边上由引脚，而在另两边则没有引脚。\n水平通道：在顶端和低端边界上有引脚的通道。\n垂直通道：在左右边界上有引脚的通道。\n通道容量：代表了可用的布线轨道或者列的数量。\n开关盒：水平和垂直通道的交集。\n2D开关盒：四个边界都有端子的开关盒。\n3D开关盒：六个边界都有端子的开关盒，包括顶部和底部。\n```\n\n优化目标\n\n> 最小总线长度，减少线网上的信号时延\n\n1、确定一个给定布局是否可布线。2、在可用布线区域中确定所有线网的一个粗略布线。","source":"_posts/VLSI-Physical-Design.md","raw":"---\ntitle: VLSI超大规模集成电路物理设计\ncategories: 学习笔记\ndate: 2023-08-28 16:33:37\ntags: [EDA, 电子设计自动化, 物理设计, VLSI]\ncover:\ntop_img:\n---\n## 第一章 绪论\n\n### 电子设计自动化（EDA）\n\nEDA（Electronic Design Automation），全称电子设计自动化，是用来辅助超大规模集成电路设计生产的工业软件，涵盖电路芯片设计、制造、封装、测试整个流程。随着芯片设计的复杂程度不断提升，基于先进工艺节点的集成电路规模可达到数十亿个半导体器件，不借助EDA已经无法完成芯片设计。\n\nEDA工具是集成电路设计和制造流程的支撑，是集成电路设计方法学的载体，也是连接设计和制造两个环节的纽带和桥梁。\n\n采用软件来实现自动化\n\n> EDA将设计者的需求分为电子系统层次结构中的多个级别，包括集成电路、多芯片模块和印制电路板\n\nEDA工具总是面向整个设计过程的自动化，并将设计步骤链接成一个完整的设计流。\n\n### VLSI设计流程\n\n![image-20230817170808037](VLSI-Physical-Design/image-20230817170808037.png)\n\n系统规范—架构设计—功能和逻辑设计—电路设计—物理设计—物理验证和签收—制造—封装和测试—芯片\n\n物理设计关键步骤还可以细分\n\n划分—芯片规划—布局—时钟树综合—布线—时序收敛\n\n* 系统规范\n\n  定义系统的总体目标和高级需求：功能、性能、物理尺寸、生产技术\n\n* 架构设计\n\n  模拟和混合信号模块集成\n\n  存储管理——串行或者并行——寻址方案\n\n  计算核的类型核数量（处理器，数字信号处理单元，特别的DSP算法）\n\n  芯片内外的通信，对标准协议的支持\n\n  硬、软IP模块的使用\n\n  引脚分配、封装、管芯封装接口\n\n  电源需求\n\n  工艺技术核层堆栈的选择\n\n* 功能和逻辑设计\n\n  * 功能设计\n\n    每个模块的输入、输出和时序行为\n\n  * 逻辑设计（用硬件描述语言HDL，如Verilog和VHDL定义芯片的功能和时序行为）\n\n  * 逻辑综合工具自动使HDL转变为底层的电路单元。即映射为信号网列表或网表和特定的电路单元\n\n* 电路设计\n\n  一些关键的低端的单元必须在晶体管级来进行设计，这就是所谓的电路设计。\n\n  包括：静态RAM模块、I/O、模拟电路、高速函数（乘法器）以及静电放电保护电路\n\n* 物理设计\n\n  所有的设计组件（宏模块、单元、门）都实例化为几何表示\n\n  * 划分\n  * 布线规划\n  * 电源和地网布线\n  * 布局\n  * 时钟网综合\n  * 总体布线\n  * 详细布线\n  * 时序收敛\n\n* 物理验证\n\n* 制造：fabrication\n\n* 封装和测试\n\n\n\n### VLSI设计模式\n\n> 全定制和半定制\n\n* 半定制标准设计模式：\n\n  * 基于单元：通常采用标准单元和宏单元，包含许多预定义元件（从元件库复制而来）\n  * 基于阵列：采用门阵列或者FPGA，包含若干制备好的元件，通过预布线相连\n\n* 全制定设计\n\n  需要有版图编辑器\n\n* 标准单元设计，有固定的电源和接地端口\n\n  布局的自由度较少，复杂度大大降低\n\n* 宏单元\n\n  较大块逻辑，执行可重用的功能\n\n* 门阵列\n\n  具有标准逻辑功能的硅片，但是没有链接\n\n* 现场可编程门阵列（FPGA）\n\n  逻辑单元和互连都是预先制造好，但是用户可以通过开关来配置\n\n* 结构化ASIC（无通道门阵列）\n\n\n\n### 版图层和设计规则\n\n* 版图层\n\n  硅作为扩散层，多晶硅、铝和铜作为互连层；多晶硅作称为poly层，其余曾称为Metal1层、Metal2层等。\n\n  单元之间的布线是完全在金属层进行的。\n\n* 设计规则\n\n  大致分为三类\n\n  * 尺寸规则：任何组件（形状）的尺寸\n  * 间距规则：组件形状之间的间距\n  * 覆盖规则：组件形状之间的覆盖量\n\n\n\n### 物理设计优化\n\n物理设计的目标：最小芯片面积、最小线长和最少过孔\n\n最优化的目标：提升电路性能，可靠性\n\n* 版图优化\n\n  > 满足约束：工艺约束、电气约束、几何约束\n\n\n\n### EDA常用术语\n\n逻辑设计：将HDL描述映射到电路门和门在网表级的连接的过程。\n\n* 结果通常是单元或其他基本电路元件和连接的网表。\n\n物理设计：决定单元（或者其他电路元件）和它们的连接在集成电路版图中几何布置的过程。连接拓扑从网表中得到。\n\n* 物理设计的结果是几何和功能都正确的表示，用标准文件格式，例如GDSII流。\n\n版图验证包括：\n\n* 设计规则检验（DRC）——遵守所有的技术需求\n* 版图和原理图一致性检验（LVS）——是否和原始网表一致\n* 天线规则检验——没有天线效应\n* 电气规则检验——遵守所有的电气需求\n\n```\n组件：有基本功能的电路元件\n模块：一个电路划分或者一部分构件的集合\n块：具有形状的组件，有固定尺寸的电路划分\n单元：用不同构建建立的逻辑或者功能单位。如：INV，NAND，NOR，常用来指标准单元和宏单元\n标准单元：一种预先决定功能的单元，在标准单元里，逻辑设计是将标准单元排列在行里来实现的\n宏单元：一种没有预先定义尺寸的单元。可以指大型物理版图，如SRAM，CPU核\n引脚：一个电子终端，用于连接给定的构件到它的外部环境\n层：制造工艺等级，在这个等几种，设计构件在芯片上成型。\n接触层：硅核金属层之间的直接连接，接触层经常用在单元内\n过孔：金属层之间的连接，通常用来连接不同层的布线结构\n线网或信号：必须在相同电势下连接的引脚或终端的集合\n供电网：提供电流给单元的电源（VDD）和地网（GND）\n网表：设计中连接的所有信号网和构件的集合，或者是所有网和分段设计的连接引脚的列表。\n网表可以组成：1、面向引脚，每个设计构件都有一个相关线网的列表。2、面向线网，每一个线网都有一个相关构件的列表。网表在逻辑综合中创建，是物理设计的关键输入。\n线网权重（W）：用来表示线网的重要性或关键性\n\n网表的表示方法：连接图和连接矩阵\n```\n\n### 第一章总结\n\n* 什么是EDA？\n\n  EDA全称是Electrical Design Automation（电子设计自动化），是芯片设计中的辅助软件工具也是必不可少的一个工具，随着芯片中集成的半导体和电路规模越来越大，EDA工具也越来越重要。\n\n* 超大规模集成电路（VLSI）的设计流程？\n\n  系统规范—架构设计—逻辑功能设计—物理设计—物理验证—制造—封装—测试—芯片\n\n* 其中物理设计包括哪些部分？\n\n  物理设计包括：布图规划，布局规划，布线，时钟树综合，时序分析\n\n\n\n## 第二章 网表和系统划分\n\n一般采用分治的策略进行芯片设计，先将模块进行布局，然后将结果转换为几何划分。\n\n### 介绍\n\n> 降低现代集成电路设计复杂度的方法是将它们划分为更小的模块。\n\n划分的主要目标是将电路进行划分，使得子电路之间的连接数最小化，且符合设计约束。\n\n### 术语\n\n```\n元胞：构成组件的任何逻辑或功能单元\n划分或块是由元胞和组件构成的\n多元划分的问题是将电路划分为K个部分\n```\n\n### 优化目标\n\n在平衡划分大小时，将所有割边数或割边的权重数最小化，称为最小割划分算法\n\n### 划分算法\n\n> Kernighan-Lin算法（KL）、KL拓展算法、Fiduccia-Mattheyses（FM）算法\n>\n> **模拟退火法**、随机爬山算法\n\nKL算法：对于一个含有2*N个元胞且要划分的区域为N：N的，使用的是两个不同划分之间的元胞进行交换，通过计算能够是当前增益达到最大。\n\nFM算法：划分不平衡的算法，其中需要一个平衡因子来控制移动以后是否平衡。通过计算能够使得移动以后使得当前达到增益最大。可用于超图中。\n\n\n\n### 多级划分框架\n\n> 从粗粒度网表，到细粒度网表\n\n为了提高网表划分的可扩展性，FM算法被嵌入到了一个多级框架中去，包含几个不同的步骤。\n\n1、原始的展平的网表被进行层次结群。\n\n2、将FM算法应用到这个结群网表中。\n\n3、部分网表在非粗粒度阶段被解开结群。\n\n4、在细粒度阶段，FM算法增量式应用到部分被解开结群的网表中。\n\n5、第3和第4一直继续知道所有网表解开结群为止。\n\n\n\n* 结群\n\n  连接紧密的结点被结群，结群之外的连接保持原来网表的结构。通常结群的大小会受到限制，从而防止结群的退化。\n\n  合并结点后，结群的权重是它所包含的成员结点的权重综合\n\n* 多级划分\n\n  当结构过多的时候，FM算法会收到一定的限制，复杂度会很高，所以通过多级划分的方式可以减小复杂度\n\n* 基于多FPGA的系统划分\n\n## 第三章 芯片规划\n\n芯片规划处理大规模模块：高速缓存、嵌入式内存及面积已知、形状固定或可变或集成电路IP核等。\n\n**芯片规划主要包括了三个主要阶段：布图规划、引脚分配、电源规划**\n\n布局规划：根据模块的面积和长宽比来优化芯片的大小、降低互连线长度和改善时延，从而确定了这些模型的位置和大小。\n\n引脚分配：通过输出信号线连接到块引脚。I/O布局为芯片的输入和输出引脚确定焊盘的位置，通常在芯片的边缘。这一步最理想在布局规划前进行。\n\n电源规划：建立电源供电网，电源网和底线网。\n\n\n\n### 布图规划介绍\n\n布图描述了模块之间的关系\n\n布局规划阶段确保：1、每个芯片模块被分配了一个形状或位置，便于进行门布局。2、每个有外部连接的引脚被分配了一个位置，这样内部和外部的线网都可以进行布线了。\n\n\n\n### 布图规划的优化目标\n\n每个模块的位置和它的长宽比\n\n* 全局边界框的面积和形状：影响电路性能、成品率、制造代价\n* 总线长，最小生成树\n* 面积和总线长的组合\n* 信号时延\n\n### 术语\n\n```\n矩形划分：将芯片面积划分为一组块或非重叠矩形的几何\n布图规划二划分：通过不断对矩形进行划分得到的一个矩形划分，从整个芯片开始，反复用水平或垂直割线将其划分为两个小矩形。\n二划分树或者二划分布图规划树：有k个叶子和k-1个内部节点的二叉树，每个叶子代表一个块，每个内部节点代表一条水平或垂直割线。\n布图树：一棵表示层次化布图的树。每个叶子节点代表一个块，每个内部节点代表一个水平分割或垂直分割。\n约束图：对一个布图表示，包括两个有向图，垂直约束图和水平约束图，可以得到块之间的相对位置关系。\n垂直约束图：节点权重表示块的高度。最长路径，相当于布局所需的最小垂直高度。\n水平约束图：结点权重代表块的宽度。最长路径，相当于布局所需的最小水平宽度。\n序列对：块排列的一个有序对。用S+和S-表示，用于区分序列是左右关系还是上下关系。\n```\n\n### 布图的表示\n\n> 布图的表示方法：1、约束图，2、序列对\n\n布图、约束图（垂直约束图，水平约束图）、序列对\n\n问题：\n\n如何将一个布图转化为一个约束图对（垂直&水平）\n\n* 垂直约束图：从下到上，从左到右，先绘制所有的有向箭头，再删除不能直接相连的箭头\n\n如何将一个布图转化为一个序列对\n\n* 序列的规则，先考虑垂直方向，再考虑水平方向\n  * a在b的左边，s1<a,b> s2<a,b>\n  * a在b的上面，s1<a,b> s2<b,a>\n\n如何将一个序列对转化为一个布图\n\n> 已知布图的起始点，每个块的宽和高，布图的布局方向（一般是左下到右上）\n\n### 布图规划算法\n\n> 布图优化算法：给定一个块的几何，布图尺寸的选择决定了布图面积的最小值，以及每个块的方向和大小。\n>\n> **群生长，模拟退火法**：寻求1、在满足布图面积上限的条件下，最小化互连线总长度。2、同时优化总线长和面积。\n\n* 布局尺寸变化\n\n  寻找最小面积布图的尺寸和相应的每个块的尺寸。\n\n  * 构造所有块的形状函数\n  * 确定顶层布图的形状函数\n  * 找出布图和每个独立块的尺寸和位置\n\n群生长\n\n基于群生长的方法中，布图是由迭代的增加块，直到所有块都被分配完。\n\n* 线性排序\n\n  终端网：没有被其他没被安置的相关块\n\n  新网：在部分构造排序的任何块上都没有引脚\n\n  持续网：在部分构造排序上至少在块上有一个引脚，以及在无序块上至少有一个引脚\n\n  以终端网减去新网的值作为增益，排序后每次都进行迭代，得到最终线性排序的序列\n\n* 群生长\n\n  按照线性排序的顺序，依次将最优块放置在布图上\n\n\n模拟退火（SA）\n\n是一种迭代算法，从一个初始解开始，寻求目标函数解的不断改进。在每次迭代中，要考虑当前解的局部邻域解。\n\n### 引脚分配\n\n在引脚分配中，所有线网（信号）被分配到唯一的引脚位置，这样设计性能才是最优化的。优化目标包括块内外的最大化线网可布性和最小化电寄生参数。\n\n引脚分配可以用来连接功能或电等价的元胞引脚。\n\n优化目标：建立一个块和所有它与其他块的引脚的连接关系。\n\n### 电源和地线布线\n\n电源和地线网分布设计\n\n> 供电网VDD和GND，为每个元胞提供电源，每个元胞都必须与VDD和GND相连。\n>\n> 供电网是：大型的、跨越整个芯片的、再信号布线之前布线\n\n电源和地线网的物理设计有两种方法：平面法，主要用于模拟电路或者定制块设计中。网格法，主要用于数字集成电路设计中。\n\n* 芯片规划的步骤：布图规划、引脚分配、电源和地线分配\n* 布图用什么来表示？\n* 布图规划有哪些算法？\n\n## 第4章 全局和详细布局\n\n将电路划分成小模块和对版图进行布局规划，从而确定块的轮廓线和引脚位置后，要求解优化目标（最小化元件间的总线长），布局要确定每个块中的标准单元或逻辑元件的位置。\n\n全局布局：分配大概的位置，给可变动的器件\n\n* 忽视可布目标的特殊形状和大小，不会试图去排列它们的位置到有效的行和列中去。\n* 进行全局定位和全局分布密度\n\n详细布局：明确器件的位置使其成为合理的元胞位置并确保没有重叠\n\n* 通过局部操作（交换两个元件）或移动一个行中的几个元件来为其他元件提供位置空间，从而增量式的改进每个标准单元的位置。\n\n合法化：将可布元件布置到行列中去，并消除重叠。\n\n### 介绍\n\n布局的目标：为了确定所有电路元件在一个（平面）版图中的位置和方向，给出解的约束（如没有元胞的重叠）和优化目标（如总线长最小化）\n\n### 优化目标\n\n布局器通常优化目标是总线长。\n\n* 几种划线模型的选择\n\n  * 单链模型\n  * 星形模型\n  * 最小生成树模型（克鲁斯卡尔）（RMST）\n  * 直线最小树\n\n* 带线网权重的总线长\n\n  * 所有网络的线长与权重的乘积之和\n\n* 最大割数\n\n  最小化某一个布局总的割数\n\n* 布线拥挤度（可以使用密度来表示：即布线所需要的轨道数与可提供的轨道数的比值）\n\n  当所有穿过边的布线数小于最大的布线数时，则说明该布局是可布线的\n\n* 信号延时\n\n  对于给定的涉及，布局的总线长影响最大时钟频率，主要依赖于线网的时延和门时延。\n\n  电路时序通常使用静态时序分析法（STA）进行验证，对线网和门时延进行估算。常见的术语包括实际到达时间（AAT）和需求到达时间（RAT），可对电路中每个结点v进行估算。\n\n### 全局布局\n\n> 全局布局确定布局的大致位置，详细布局消除重叠的因素\n\n最小割划分、二次布局、力矢量布局、模拟退火\n\n* 最小割布局：利用划分算法将网表和版图区域划分为较小的子网表和子区域。子网表和子区域重复划分到更小的部分，直到每个子区域包含少量的元胞。当实现最小割布局时，网表被划分为每个子区域拥有它自己唯一的子网表。\n\n  版图划分的方向：割方向交替法（垂直割线和水平割线交替划分）、割方向重复法（先用单一方向划分，直到达到最小以后，在换方向）\n\n  在版图划分的过程中，通常会将版图划分的方向和最小割划分算法结合起来，这样才能够在版图上最终定位某一个模块的位置。\n\n  * 最小化割网的标准算法KL算法和FM算法\n\n  * 有外部链接的最小割布局\n\n    假设每个元胞分别被布置在它们各自的区域中心。如果相关的i拦截接近下一个划分割线，在做下一个割线时则不用考虑这些结点。\n\n* 解析布局（最小化目标函数）\n\n  * **二次线长布局**：分为两个阶段\n    * 第一阶段：依据元胞的中心对元胞进行布局，**从而对二次线长函数最小化**。\n    * 第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有的单元原来的重叠消除。**详细布局将所有元胞位置合法化并产生一个高质量的、无重叠的布局。**\n\n\n  第一阶段方法：迭代求解线性方程：共轭梯度法（CG）、逐次超松弛法（SOR）\n\n  第二阶段方法：详细布局：最小割布局、力矢量布局\n\n  * 二次线长布局具体算法：\n\n  ```\n  已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。求：所有的元胞的x坐标和y坐标。\n  \n  1、列出所有连接的元胞线网的X的总线长L(p)：所有的x距离的差的平方\n  2、分别对所有参数中的x求偏导，并令偏导为0\n  3、列出方程组，解出来的x阵列就是所需要求的解\n  对于Y方向也是同理\n  \n  该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题\n  ```\n\n  * **力矢量布局**\n\n    用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。\n\n    采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。**将目标转化为将所有的元胞放在一个力平衡的位置上。**——**称为零力目标**（ZFT）\n\n    * 对于每一个元胞，都有一个理想的最小ZFT位置。\n    * 通过迭代的移动每个单元或者交换元胞到这个位置或相邻近位置，逐步改善布局结果\n\n    > 个人认为：这个方法不能让每一个元胞都到达力的平衡状态，使用一次迭代或者交换，就会打乱原始平衡的元胞。\n\n  * 基本力矢量布局算法\n\n    > Loss为权重乘以坐标差的累计和\n\n  ```\n  1、任意初始布局\n  2、为每个布局中的元胞设定坐标，并标记为UNMOVED\n  3、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序\n  4、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成\n  5、若ZFT位置被占据，则移动到其他的位置\n  \n  第5步确定p的ZFT时，若ZFT被元胞q占据，则移动位置的确定\n  1、如果可能，将p移动到靠近q的位置\n  2、若交换p，q后，代价变小，则交换\n  3、链式移动，p移动到q，q移动到下一个，以此类推\n  4、波状移动，p移动到q，再重新计算q的ZFT\n  ```\n\n* 模拟退火算法\n\n  列出损失函数，使用带动量的梯度下降，最终计算出使得损失函数最小的最优解\n\n* 现代布局算法\n\n\n### 合法化和详细布局\n\n> 合法化：寻求合法的、没有重叠的布局，从而减少对线长、时序和其他设计目标的不利影响。\n\n目标：消除元胞中的重叠\n\n使用贪心算法\n\n* 按照x坐标进行排序，并进行贪心处理，贪心选择策略为移动到当前元胞最近的，可用的合法位置，但不能超出行的范围。\n\n* 缺点\n  * 没有对网表进行考虑\n  * 产生了大量的空白区域\n\n## 第五章  总体布线\n\n在总体布线中，具有相同点位的引脚用线路相连。\n\n### 介绍\n\n给定一个布局和一个网表：确定必要的连接数\n\n需要优化的布线目标：最小化总线长，最大时序松弛\n\n总体布线可分为：固定的裸片布线（芯片外形和所有布线资源都是固定的），可变的裸片布线（可以根据需要添加新布线轨道）\n\n常见的几种布线算法\n\n* 总体布线：粗粒分配布线到**布线区域**\n* 详细布线：细粒分配布线到**布线轨道**，包括线网排序，引脚排序。用于完善总体布线。\n* 时序驱动布线：线网拓扑优化和资源分配到关键线网\n* 大信号网布线：电源（VDD）和地线（GND）布线\n* 几何技术：非曼哈顿和时钟布线\n\n### 术语和定义\n\n```\n布线轨道（列）：一条可用的水平（垂直）接线通路。\n布线区域：包含了布线轨道的区域。\n规格一致的布线区域：由均匀分布的水平和垂直网格线形成，产生芯片区域上规格一致的网格。\n规格不一致的布线区域：由水平和垂直边界形成，与外部引脚连接或宏单元边界对齐。\n通道：一个矩形不限区域，在两个相对边上由引脚，而在另两边则没有引脚。\n水平通道：在顶端和低端边界上有引脚的通道。\n垂直通道：在左右边界上有引脚的通道。\n通道容量：代表了可用的布线轨道或者列的数量。\n开关盒：水平和垂直通道的交集。\n2D开关盒：四个边界都有端子的开关盒。\n3D开关盒：六个边界都有端子的开关盒，包括顶部和底部。\n```\n\n优化目标\n\n> 最小总线长度，减少线网上的信号时延\n\n1、确定一个给定布局是否可布线。2、在可用布线区域中确定所有线网的一个粗略布线。","slug":"VLSI-Physical-Design","published":1,"updated":"2024-06-05T09:03:03.624Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttn000s08jv2o5d8urh","content":"<h2 id=\"第一章-绪论\"><a href=\"#第一章-绪论\" class=\"headerlink\" title=\"第一章 绪论\"></a>第一章 绪论</h2><h3 id=\"电子设计自动化（EDA）\"><a href=\"#电子设计自动化（EDA）\" class=\"headerlink\" title=\"电子设计自动化（EDA）\"></a>电子设计自动化（EDA）</h3><p>EDA（Electronic Design Automation），全称电子设计自动化，是用来辅助超大规模集成电路设计生产的工业软件，涵盖电路芯片设计、制造、封装、测试整个流程。随着芯片设计的复杂程度不断提升，基于先进工艺节点的集成电路规模可达到数十亿个半导体器件，不借助EDA已经无法完成芯片设计。</p>\n<p>EDA工具是集成电路设计和制造流程的支撑，是集成电路设计方法学的载体，也是连接设计和制造两个环节的纽带和桥梁。</p>\n<p>采用软件来实现自动化</p>\n<blockquote>\n<p>EDA将设计者的需求分为电子系统层次结构中的多个级别，包括集成电路、多芯片模块和印制电路板</p>\n</blockquote>\n<p>EDA工具总是面向整个设计过程的自动化，并将设计步骤链接成一个完整的设计流。</p>\n<h3 id=\"VLSI设计流程\"><a href=\"#VLSI设计流程\" class=\"headerlink\" title=\"VLSI设计流程\"></a>VLSI设计流程</h3><img src=\"/2023/08/28/VLSI-Physical-Design/image-20230817170808037.png\" class=\"\" title=\"image-20230817170808037\">\n<p>系统规范—架构设计—功能和逻辑设计—电路设计—物理设计—物理验证和签收—制造—封装和测试—芯片</p>\n<p>物理设计关键步骤还可以细分</p>\n<p>划分—芯片规划—布局—时钟树综合—布线—时序收敛</p>\n<ul>\n<li><p>系统规范</p>\n<p>定义系统的总体目标和高级需求：功能、性能、物理尺寸、生产技术</p>\n</li>\n<li><p>架构设计</p>\n<p>模拟和混合信号模块集成</p>\n<p>存储管理——串行或者并行——寻址方案</p>\n<p>计算核的类型核数量（处理器，数字信号处理单元，特别的DSP算法）</p>\n<p>芯片内外的通信，对标准协议的支持</p>\n<p>硬、软IP模块的使用</p>\n<p>引脚分配、封装、管芯封装接口</p>\n<p>电源需求</p>\n<p>工艺技术核层堆栈的选择</p>\n</li>\n<li><p>功能和逻辑设计</p>\n<ul>\n<li><p>功能设计</p>\n<p>每个模块的输入、输出和时序行为</p>\n</li>\n<li><p>逻辑设计（用硬件描述语言HDL，如Verilog和VHDL定义芯片的功能和时序行为）</p>\n</li>\n<li><p>逻辑综合工具自动使HDL转变为底层的电路单元。即映射为信号网列表或网表和特定的电路单元</p>\n</li>\n</ul>\n</li>\n<li><p>电路设计</p>\n<p>一些关键的低端的单元必须在晶体管级来进行设计，这就是所谓的电路设计。</p>\n<p>包括：静态RAM模块、I/O、模拟电路、高速函数（乘法器）以及静电放电保护电路</p>\n</li>\n<li><p>物理设计</p>\n<p>所有的设计组件（宏模块、单元、门）都实例化为几何表示</p>\n<ul>\n<li>划分</li>\n<li>布线规划</li>\n<li>电源和地网布线</li>\n<li>布局</li>\n<li>时钟网综合</li>\n<li>总体布线</li>\n<li>详细布线</li>\n<li>时序收敛</li>\n</ul>\n</li>\n<li><p>物理验证</p>\n</li>\n<li><p>制造：fabrication</p>\n</li>\n<li><p>封装和测试</p>\n</li>\n</ul>\n<h3 id=\"VLSI设计模式\"><a href=\"#VLSI设计模式\" class=\"headerlink\" title=\"VLSI设计模式\"></a>VLSI设计模式</h3><blockquote>\n<p>全定制和半定制</p>\n</blockquote>\n<ul>\n<li><p>半定制标准设计模式：</p>\n<ul>\n<li>基于单元：通常采用标准单元和宏单元，包含许多预定义元件（从元件库复制而来）</li>\n<li>基于阵列：采用门阵列或者FPGA，包含若干制备好的元件，通过预布线相连</li>\n</ul>\n</li>\n<li><p>全制定设计</p>\n<p>需要有版图编辑器</p>\n</li>\n<li><p>标准单元设计，有固定的电源和接地端口</p>\n<p>布局的自由度较少，复杂度大大降低</p>\n</li>\n<li><p>宏单元</p>\n<p>较大块逻辑，执行可重用的功能</p>\n</li>\n<li><p>门阵列</p>\n<p>具有标准逻辑功能的硅片，但是没有链接</p>\n</li>\n<li><p>现场可编程门阵列（FPGA）</p>\n<p>逻辑单元和互连都是预先制造好，但是用户可以通过开关来配置</p>\n</li>\n<li><p>结构化ASIC（无通道门阵列）</p>\n</li>\n</ul>\n<h3 id=\"版图层和设计规则\"><a href=\"#版图层和设计规则\" class=\"headerlink\" title=\"版图层和设计规则\"></a>版图层和设计规则</h3><ul>\n<li><p>版图层</p>\n<p>硅作为扩散层，多晶硅、铝和铜作为互连层；多晶硅作称为poly层，其余曾称为Metal1层、Metal2层等。</p>\n<p>单元之间的布线是完全在金属层进行的。</p>\n</li>\n<li><p>设计规则</p>\n<p>大致分为三类</p>\n<ul>\n<li>尺寸规则：任何组件（形状）的尺寸</li>\n<li>间距规则：组件形状之间的间距</li>\n<li>覆盖规则：组件形状之间的覆盖量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"物理设计优化\"><a href=\"#物理设计优化\" class=\"headerlink\" title=\"物理设计优化\"></a>物理设计优化</h3><p>物理设计的目标：最小芯片面积、最小线长和最少过孔</p>\n<p>最优化的目标：提升电路性能，可靠性</p>\n<ul>\n<li><p>版图优化</p>\n<blockquote>\n<p>满足约束：工艺约束、电气约束、几何约束</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"EDA常用术语\"><a href=\"#EDA常用术语\" class=\"headerlink\" title=\"EDA常用术语\"></a>EDA常用术语</h3><p>逻辑设计：将HDL描述映射到电路门和门在网表级的连接的过程。</p>\n<ul>\n<li>结果通常是单元或其他基本电路元件和连接的网表。</li>\n</ul>\n<p>物理设计：决定单元（或者其他电路元件）和它们的连接在集成电路版图中几何布置的过程。连接拓扑从网表中得到。</p>\n<ul>\n<li>物理设计的结果是几何和功能都正确的表示，用标准文件格式，例如GDSII流。</li>\n</ul>\n<p>版图验证包括：</p>\n<ul>\n<li>设计规则检验（DRC）——遵守所有的技术需求</li>\n<li>版图和原理图一致性检验（LVS）——是否和原始网表一致</li>\n<li>天线规则检验——没有天线效应</li>\n<li>电气规则检验——遵守所有的电气需求</li>\n</ul>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">组件：有基本功能的电路元件<br>模块：一个电路划分或者一部分构件的集合<br>块：具有形状的组件，有固定尺寸的电路划分<br>单元：用不同构建建立的逻辑或者功能单位。如：INV，NAND，<span class=\"hljs-keyword\">NOR，常用来指标准单元和宏单元</span><br><span class=\"hljs-keyword\"></span>标准单元：一种预先决定功能的单元，在标准单元里，逻辑设计是将标准单元排列在行里来实现的<br>宏单元：一种没有预先定义尺寸的单元。可以指大型物理版图，如<span class=\"hljs-keyword\">SRAM，CPU核</span><br><span class=\"hljs-keyword\"></span>引脚：一个电子终端，用于连接给定的构件到它的外部环境<br>层：制造工艺等级，在这个等几种，设计构件在芯片上成型。<br>接触层：硅核金属层之间的直接连接，接触层经常用在单元内<br>过孔：金属层之间的连接，通常用来连接不同层的布线结构<br>线网或信号：必须在相同电势下连接的引脚或终端的集合<br>供电网：提供电流给单元的电源（VDD）和地网（GND）<br>网表：设计中连接的所有信号网和构件的集合，或者是所有网和分段设计的连接引脚的列表。<br>网表可以组成：<span class=\"hljs-number\">1</span>、面向引脚，每个设计构件都有一个相关线网的列表。<span class=\"hljs-number\">2</span>、面向线网，每一个线网都有一个相关构件的列表。网表在逻辑综合中创建，是物理设计的关键输入。<br>线网权重（W）：用来表示线网的重要性或关键性<br><br>网表的表示方法：连接图和连接矩阵<br></code></pre></td></tr></table></figure>\n<h3 id=\"第一章总结\"><a href=\"#第一章总结\" class=\"headerlink\" title=\"第一章总结\"></a>第一章总结</h3><ul>\n<li><p>什么是EDA？</p>\n<p>EDA全称是Electrical Design Automation（电子设计自动化），是芯片设计中的辅助软件工具也是必不可少的一个工具，随着芯片中集成的半导体和电路规模越来越大，EDA工具也越来越重要。</p>\n</li>\n<li><p>超大规模集成电路（VLSI）的设计流程？</p>\n<p>系统规范—架构设计—逻辑功能设计—物理设计—物理验证—制造—封装—测试—芯片</p>\n</li>\n<li><p>其中物理设计包括哪些部分？</p>\n<p>物理设计包括：布图规划，布局规划，布线，时钟树综合，时序分析</p>\n</li>\n</ul>\n<h2 id=\"第二章-网表和系统划分\"><a href=\"#第二章-网表和系统划分\" class=\"headerlink\" title=\"第二章 网表和系统划分\"></a>第二章 网表和系统划分</h2><p>一般采用分治的策略进行芯片设计，先将模块进行布局，然后将结果转换为几何划分。</p>\n<h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><blockquote>\n<p>降低现代集成电路设计复杂度的方法是将它们划分为更小的模块。</p>\n</blockquote>\n<p>划分的主要目标是将电路进行划分，使得子电路之间的连接数最小化，且符合设计约束。</p>\n<h3 id=\"术语\"><a href=\"#术语\" class=\"headerlink\" title=\"术语\"></a>术语</h3><figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">元胞：构成组件的任何逻辑或功能单元<br>划分或块是由元胞和组件构成的<br>多元划分的问题是将电路划分为<span class=\"hljs-built_in\">K</span>个部分<br></code></pre></td></tr></table></figure>\n<h3 id=\"优化目标\"><a href=\"#优化目标\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h3><p>在平衡划分大小时，将所有割边数或割边的权重数最小化，称为最小割划分算法</p>\n<h3 id=\"划分算法\"><a href=\"#划分算法\" class=\"headerlink\" title=\"划分算法\"></a>划分算法</h3><blockquote>\n<p>Kernighan-Lin算法（KL）、KL拓展算法、Fiduccia-Mattheyses（FM）算法</p>\n<p><strong>模拟退火法</strong>、随机爬山算法</p>\n</blockquote>\n<p>KL算法：对于一个含有2*N个元胞且要划分的区域为N：N的，使用的是两个不同划分之间的元胞进行交换，通过计算能够是当前增益达到最大。</p>\n<p>FM算法：划分不平衡的算法，其中需要一个平衡因子来控制移动以后是否平衡。通过计算能够使得移动以后使得当前达到增益最大。可用于超图中。</p>\n<h3 id=\"多级划分框架\"><a href=\"#多级划分框架\" class=\"headerlink\" title=\"多级划分框架\"></a>多级划分框架</h3><blockquote>\n<p>从粗粒度网表，到细粒度网表</p>\n</blockquote>\n<p>为了提高网表划分的可扩展性，FM算法被嵌入到了一个多级框架中去，包含几个不同的步骤。</p>\n<p>1、原始的展平的网表被进行层次结群。</p>\n<p>2、将FM算法应用到这个结群网表中。</p>\n<p>3、部分网表在非粗粒度阶段被解开结群。</p>\n<p>4、在细粒度阶段，FM算法增量式应用到部分被解开结群的网表中。</p>\n<p>5、第3和第4一直继续知道所有网表解开结群为止。</p>\n<ul>\n<li><p>结群</p>\n<p>连接紧密的结点被结群，结群之外的连接保持原来网表的结构。通常结群的大小会受到限制，从而防止结群的退化。</p>\n<p>合并结点后，结群的权重是它所包含的成员结点的权重综合</p>\n</li>\n<li><p>多级划分</p>\n<p>当结构过多的时候，FM算法会收到一定的限制，复杂度会很高，所以通过多级划分的方式可以减小复杂度</p>\n</li>\n<li><p>基于多FPGA的系统划分</p>\n</li>\n</ul>\n<h2 id=\"第三章-芯片规划\"><a href=\"#第三章-芯片规划\" class=\"headerlink\" title=\"第三章 芯片规划\"></a>第三章 芯片规划</h2><p>芯片规划处理大规模模块：高速缓存、嵌入式内存及面积已知、形状固定或可变或集成电路IP核等。</p>\n<p><strong>芯片规划主要包括了三个主要阶段：布图规划、引脚分配、电源规划</strong></p>\n<p>布局规划：根据模块的面积和长宽比来优化芯片的大小、降低互连线长度和改善时延，从而确定了这些模型的位置和大小。</p>\n<p>引脚分配：通过输出信号线连接到块引脚。I/O布局为芯片的输入和输出引脚确定焊盘的位置，通常在芯片的边缘。这一步最理想在布局规划前进行。</p>\n<p>电源规划：建立电源供电网，电源网和底线网。</p>\n<h3 id=\"布图规划介绍\"><a href=\"#布图规划介绍\" class=\"headerlink\" title=\"布图规划介绍\"></a>布图规划介绍</h3><p>布图描述了模块之间的关系</p>\n<p>布局规划阶段确保：1、每个芯片模块被分配了一个形状或位置，便于进行门布局。2、每个有外部连接的引脚被分配了一个位置，这样内部和外部的线网都可以进行布线了。</p>\n<h3 id=\"布图规划的优化目标\"><a href=\"#布图规划的优化目标\" class=\"headerlink\" title=\"布图规划的优化目标\"></a>布图规划的优化目标</h3><p>每个模块的位置和它的长宽比</p>\n<ul>\n<li>全局边界框的面积和形状：影响电路性能、成品率、制造代价</li>\n<li>总线长，最小生成树</li>\n<li>面积和总线长的组合</li>\n<li>信号时延</li>\n</ul>\n<h3 id=\"术语-1\"><a href=\"#术语-1\" class=\"headerlink\" title=\"术语\"></a>术语</h3><figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">矩形划分：将芯片面积划分为一组块或非重叠矩形的几何<br>布图规划二划分：通过不断对矩形进行划分得到的一个矩形划分，从整个芯片开始，反复用水平或垂直割线将其划分为两个小矩形。<br>二划分树或者二划分布图规划树：有k个叶子和k<span class=\"hljs-string\">-1</span>个内部节点的二叉树，每个叶子代表一个块，每个内部节点代表一条水平或垂直割线。<br>布图树：一棵表示层次化布图的树。每个叶子节点代表一个块，每个内部节点代表一个水平分割或垂直分割。<br>约束图：对一个布图表示，包括两个有向图，垂直约束图和水平约束图，可以得到块之间的相对位置关系。<br>垂直约束图：节点权重表示块的高度。最长路径，相当于布局所需的最小垂直高度。<br>水平约束图：结点权重代表块的宽度。最长路径，相当于布局所需的最小水平宽度。<br>序列对：块排列的一个有序对。用S+和S-表示，用于区分序列是左右关系还是上下关系。<br></code></pre></td></tr></table></figure>\n<h3 id=\"布图的表示\"><a href=\"#布图的表示\" class=\"headerlink\" title=\"布图的表示\"></a>布图的表示</h3><blockquote>\n<p>布图的表示方法：1、约束图，2、序列对</p>\n</blockquote>\n<p>布图、约束图（垂直约束图，水平约束图）、序列对</p>\n<p>问题：</p>\n<p>如何将一个布图转化为一个约束图对（垂直&amp;水平）</p>\n<ul>\n<li>垂直约束图：从下到上，从左到右，先绘制所有的有向箭头，再删除不能直接相连的箭头</li>\n</ul>\n<p>如何将一个布图转化为一个序列对</p>\n<ul>\n<li>序列的规则，先考虑垂直方向，再考虑水平方向<ul>\n<li>a在b的左边，s1<a,b> s2<a,b></li>\n<li>a在b的上面，s1<a,b> s2<b,a></li>\n</ul>\n</li>\n</ul>\n<p>如何将一个序列对转化为一个布图</p>\n<blockquote>\n<p>已知布图的起始点，每个块的宽和高，布图的布局方向（一般是左下到右上）</p>\n</blockquote>\n<h3 id=\"布图规划算法\"><a href=\"#布图规划算法\" class=\"headerlink\" title=\"布图规划算法\"></a>布图规划算法</h3><blockquote>\n<p>布图优化算法：给定一个块的几何，布图尺寸的选择决定了布图面积的最小值，以及每个块的方向和大小。</p>\n<p><strong>群生长，模拟退火法</strong>：寻求1、在满足布图面积上限的条件下，最小化互连线总长度。2、同时优化总线长和面积。</p>\n</blockquote>\n<ul>\n<li><p>布局尺寸变化</p>\n<p>寻找最小面积布图的尺寸和相应的每个块的尺寸。</p>\n<ul>\n<li>构造所有块的形状函数</li>\n<li>确定顶层布图的形状函数</li>\n<li>找出布图和每个独立块的尺寸和位置</li>\n</ul>\n</li>\n</ul>\n<p>群生长</p>\n<p>基于群生长的方法中，布图是由迭代的增加块，直到所有块都被分配完。</p>\n<ul>\n<li><p>线性排序</p>\n<p>终端网：没有被其他没被安置的相关块</p>\n<p>新网：在部分构造排序的任何块上都没有引脚</p>\n<p>持续网：在部分构造排序上至少在块上有一个引脚，以及在无序块上至少有一个引脚</p>\n<p>以终端网减去新网的值作为增益，排序后每次都进行迭代，得到最终线性排序的序列</p>\n</li>\n<li><p>群生长</p>\n<p>按照线性排序的顺序，依次将最优块放置在布图上</p>\n</li>\n</ul>\n<p>模拟退火（SA）</p>\n<p>是一种迭代算法，从一个初始解开始，寻求目标函数解的不断改进。在每次迭代中，要考虑当前解的局部邻域解。</p>\n<h3 id=\"引脚分配\"><a href=\"#引脚分配\" class=\"headerlink\" title=\"引脚分配\"></a>引脚分配</h3><p>在引脚分配中，所有线网（信号）被分配到唯一的引脚位置，这样设计性能才是最优化的。优化目标包括块内外的最大化线网可布性和最小化电寄生参数。</p>\n<p>引脚分配可以用来连接功能或电等价的元胞引脚。</p>\n<p>优化目标：建立一个块和所有它与其他块的引脚的连接关系。</p>\n<h3 id=\"电源和地线布线\"><a href=\"#电源和地线布线\" class=\"headerlink\" title=\"电源和地线布线\"></a>电源和地线布线</h3><p>电源和地线网分布设计</p>\n<blockquote>\n<p>供电网VDD和GND，为每个元胞提供电源，每个元胞都必须与VDD和GND相连。</p>\n<p>供电网是：大型的、跨越整个芯片的、再信号布线之前布线</p>\n</blockquote>\n<p>电源和地线网的物理设计有两种方法：平面法，主要用于模拟电路或者定制块设计中。网格法，主要用于数字集成电路设计中。</p>\n<ul>\n<li>芯片规划的步骤：布图规划、引脚分配、电源和地线分配</li>\n<li>布图用什么来表示？</li>\n<li>布图规划有哪些算法？</li>\n</ul>\n<h2 id=\"第4章-全局和详细布局\"><a href=\"#第4章-全局和详细布局\" class=\"headerlink\" title=\"第4章 全局和详细布局\"></a>第4章 全局和详细布局</h2><p>将电路划分成小模块和对版图进行布局规划，从而确定块的轮廓线和引脚位置后，要求解优化目标（最小化元件间的总线长），布局要确定每个块中的标准单元或逻辑元件的位置。</p>\n<p>全局布局：分配大概的位置，给可变动的器件</p>\n<ul>\n<li>忽视可布目标的特殊形状和大小，不会试图去排列它们的位置到有效的行和列中去。</li>\n<li>进行全局定位和全局分布密度</li>\n</ul>\n<p>详细布局：明确器件的位置使其成为合理的元胞位置并确保没有重叠</p>\n<ul>\n<li>通过局部操作（交换两个元件）或移动一个行中的几个元件来为其他元件提供位置空间，从而增量式的改进每个标准单元的位置。</li>\n</ul>\n<p>合法化：将可布元件布置到行列中去，并消除重叠。</p>\n<h3 id=\"介绍-1\"><a href=\"#介绍-1\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>布局的目标：为了确定所有电路元件在一个（平面）版图中的位置和方向，给出解的约束（如没有元胞的重叠）和优化目标（如总线长最小化）</p>\n<h3 id=\"优化目标-1\"><a href=\"#优化目标-1\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h3><p>布局器通常优化目标是总线长。</p>\n<ul>\n<li><p>几种划线模型的选择</p>\n<ul>\n<li>单链模型</li>\n<li>星形模型</li>\n<li>最小生成树模型（克鲁斯卡尔）（RMST）</li>\n<li>直线最小树</li>\n</ul>\n</li>\n<li><p>带线网权重的总线长</p>\n<ul>\n<li>所有网络的线长与权重的乘积之和</li>\n</ul>\n</li>\n<li><p>最大割数</p>\n<p>最小化某一个布局总的割数</p>\n</li>\n<li><p>布线拥挤度（可以使用密度来表示：即布线所需要的轨道数与可提供的轨道数的比值）</p>\n<p>当所有穿过边的布线数小于最大的布线数时，则说明该布局是可布线的</p>\n</li>\n<li><p>信号延时</p>\n<p>对于给定的涉及，布局的总线长影响最大时钟频率，主要依赖于线网的时延和门时延。</p>\n<p>电路时序通常使用静态时序分析法（STA）进行验证，对线网和门时延进行估算。常见的术语包括实际到达时间（AAT）和需求到达时间（RAT），可对电路中每个结点v进行估算。</p>\n</li>\n</ul>\n<h3 id=\"全局布局\"><a href=\"#全局布局\" class=\"headerlink\" title=\"全局布局\"></a>全局布局</h3><blockquote>\n<p>全局布局确定布局的大致位置，详细布局消除重叠的因素</p>\n</blockquote>\n<p>最小割划分、二次布局、力矢量布局、模拟退火</p>\n<ul>\n<li><p>最小割布局：利用划分算法将网表和版图区域划分为较小的子网表和子区域。子网表和子区域重复划分到更小的部分，直到每个子区域包含少量的元胞。当实现最小割布局时，网表被划分为每个子区域拥有它自己唯一的子网表。</p>\n<p>版图划分的方向：割方向交替法（垂直割线和水平割线交替划分）、割方向重复法（先用单一方向划分，直到达到最小以后，在换方向）</p>\n<p>在版图划分的过程中，通常会将版图划分的方向和最小割划分算法结合起来，这样才能够在版图上最终定位某一个模块的位置。</p>\n<ul>\n<li><p>最小化割网的标准算法KL算法和FM算法</p>\n</li>\n<li><p>有外部链接的最小割布局</p>\n<p>假设每个元胞分别被布置在它们各自的区域中心。如果相关的i拦截接近下一个划分割线，在做下一个割线时则不用考虑这些结点。</p>\n</li>\n</ul>\n</li>\n<li><p>解析布局（最小化目标函数）</p>\n<ul>\n<li><strong>二次线长布局</strong>：分为两个阶段<ul>\n<li>第一阶段：依据元胞的中心对元胞进行布局，<strong>从而对二次线长函数最小化</strong>。</li>\n<li>第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有的单元原来的重叠消除。<strong>详细布局将所有元胞位置合法化并产生一个高质量的、无重叠的布局。</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>  第一阶段方法：迭代求解线性方程：共轭梯度法（CG）、逐次超松弛法（SOR）</p>\n<p>  第二阶段方法：详细布局：最小割布局、力矢量布局</p>\n<ul>\n<li><p>二次线长布局具体算法：</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。求：所有的元胞的<span class=\"hljs-keyword\">x</span>坐标和y坐标。<br><br><span class=\"hljs-number\">1</span>、列出所有连接的元胞线网的X的总线长L(p)：所有的<span class=\"hljs-keyword\">x</span>距离的差的平方<br><span class=\"hljs-number\">2</span>、分别对所有参数中的<span class=\"hljs-keyword\">x</span>求偏导，并令偏导为<span class=\"hljs-number\">0</span><br><span class=\"hljs-number\">3</span>、列出方程组，解出来的<span class=\"hljs-keyword\">x</span>阵列就是所需要求的解<br>对于Y方向也是同理<br><br>该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>力矢量布局</strong></p>\n<p>用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。</p>\n<p>采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。<strong>将目标转化为将所有的元胞放在一个力平衡的位置上。</strong>——<strong>称为零力目标</strong>（ZFT）</p>\n<ul>\n<li>对于每一个元胞，都有一个理想的最小ZFT位置。</li>\n<li>通过迭代的移动每个单元或者交换元胞到这个位置或相邻近位置，逐步改善布局结果</li>\n</ul>\n<blockquote>\n<p>个人认为：这个方法不能让每一个元胞都到达力的平衡状态，使用一次迭代或者交换，就会打乱原始平衡的元胞。</p>\n</blockquote>\n</li>\n<li><p>基本力矢量布局算法</p>\n<blockquote>\n<p>Loss为权重乘以坐标差的累计和</p>\n</blockquote>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-number\">1</span>、任意初始布局<br><span class=\"hljs-number\">2</span>、为每个布局中的元胞设定坐标，并标记为UNMOVED<br><span class=\"hljs-number\">3</span>、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序<br><span class=\"hljs-number\">4</span>、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成<br><span class=\"hljs-number\">5</span>、若ZFT位置被占据，则移动到其他的位置<br><br>第<span class=\"hljs-number\">5</span>步确定<span class=\"hljs-selector-tag\">p</span>的ZFT时，若ZFT被元胞<span class=\"hljs-selector-tag\">q</span>占据，则移动位置的确定<br><span class=\"hljs-number\">1</span>、如果可能，将<span class=\"hljs-selector-tag\">p</span>移动到靠近<span class=\"hljs-selector-tag\">q</span>的位置<br><span class=\"hljs-number\">2</span>、若交换<span class=\"hljs-selector-tag\">p</span>，<span class=\"hljs-selector-tag\">q</span>后，代价变小，则交换<br><span class=\"hljs-number\">3</span>、链式移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，<span class=\"hljs-selector-tag\">q</span>移动到下一个，以此类推<br><span class=\"hljs-number\">4</span>、波状移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，再重新计算<span class=\"hljs-selector-tag\">q</span>的ZFT<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<ul>\n<li><p>模拟退火算法</p>\n<p>列出损失函数，使用带动量的梯度下降，最终计算出使得损失函数最小的最优解</p>\n</li>\n<li><p>现代布局算法</p>\n</li>\n</ul>\n<h3 id=\"合法化和详细布局\"><a href=\"#合法化和详细布局\" class=\"headerlink\" title=\"合法化和详细布局\"></a>合法化和详细布局</h3><blockquote>\n<p>合法化：寻求合法的、没有重叠的布局，从而减少对线长、时序和其他设计目标的不利影响。</p>\n</blockquote>\n<p>目标：消除元胞中的重叠</p>\n<p>使用贪心算法</p>\n<ul>\n<li><p>按照x坐标进行排序，并进行贪心处理，贪心选择策略为移动到当前元胞最近的，可用的合法位置，但不能超出行的范围。</p>\n</li>\n<li><p>缺点</p>\n<ul>\n<li>没有对网表进行考虑</li>\n<li>产生了大量的空白区域</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第五章-总体布线\"><a href=\"#第五章-总体布线\" class=\"headerlink\" title=\"第五章  总体布线\"></a>第五章  总体布线</h2><p>在总体布线中，具有相同点位的引脚用线路相连。</p>\n<h3 id=\"介绍-2\"><a href=\"#介绍-2\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>给定一个布局和一个网表：确定必要的连接数</p>\n<p>需要优化的布线目标：最小化总线长，最大时序松弛</p>\n<p>总体布线可分为：固定的裸片布线（芯片外形和所有布线资源都是固定的），可变的裸片布线（可以根据需要添加新布线轨道）</p>\n<p>常见的几种布线算法</p>\n<ul>\n<li>总体布线：粗粒分配布线到<strong>布线区域</strong></li>\n<li>详细布线：细粒分配布线到<strong>布线轨道</strong>，包括线网排序，引脚排序。用于完善总体布线。</li>\n<li>时序驱动布线：线网拓扑优化和资源分配到关键线网</li>\n<li>大信号网布线：电源（VDD）和地线（GND）布线</li>\n<li>几何技术：非曼哈顿和时钟布线</li>\n</ul>\n<h3 id=\"术语和定义\"><a href=\"#术语和定义\" class=\"headerlink\" title=\"术语和定义\"></a>术语和定义</h3><figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">布线轨道（列）：一条可用的水平（垂直）接线通路。<br>布线区域：包含了布线轨道的区域。<br>规格一致的布线区域：由均匀分布的水平和垂直网格线形成，产生芯片区域上规格一致的网格。<br>规格不一致的布线区域：由水平和垂直边界形成，与外部引脚连接或宏单元边界对齐。<br>通道：一个矩形不限区域，在两个相对边上由引脚，而在另两边则没有引脚。<br>水平通道：在顶端和低端边界上有引脚的通道。<br>垂直通道：在左右边界上有引脚的通道。<br>通道容量：代表了可用的布线轨道或者列的数量。<br>开关盒：水平和垂直通道的交集。<br><span class=\"hljs-number\">2</span><span class=\"hljs-built_in\">D</span>开关盒：四个边界都有端子的开关盒。<br><span class=\"hljs-number\">3</span><span class=\"hljs-built_in\">D</span>开关盒：六个边界都有端子的开关盒，包括顶部和底部。<br></code></pre></td></tr></table></figure>\n<p>优化目标</p>\n<blockquote>\n<p>最小总线长度，减少线网上的信号时延</p>\n</blockquote>\n<p>1、确定一个给定布局是否可布线。2、在可用布线区域中确定所有线网的一个粗略布线。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"第一章-绪论\"><a href=\"#第一章-绪论\" class=\"headerlink\" title=\"第一章 绪论\"></a>第一章 绪论</h2><h3 id=\"电子设计自动化（EDA）\"><a href=\"#电子设计自动化（EDA）\" class=\"headerlink\" title=\"电子设计自动化（EDA）\"></a>电子设计自动化（EDA）</h3><p>EDA（Electronic Design Automation），全称电子设计自动化，是用来辅助超大规模集成电路设计生产的工业软件，涵盖电路芯片设计、制造、封装、测试整个流程。随着芯片设计的复杂程度不断提升，基于先进工艺节点的集成电路规模可达到数十亿个半导体器件，不借助EDA已经无法完成芯片设计。</p>\n<p>EDA工具是集成电路设计和制造流程的支撑，是集成电路设计方法学的载体，也是连接设计和制造两个环节的纽带和桥梁。</p>\n<p>采用软件来实现自动化</p>\n<blockquote>\n<p>EDA将设计者的需求分为电子系统层次结构中的多个级别，包括集成电路、多芯片模块和印制电路板</p>\n</blockquote>\n<p>EDA工具总是面向整个设计过程的自动化，并将设计步骤链接成一个完整的设计流。</p>\n<h3 id=\"VLSI设计流程\"><a href=\"#VLSI设计流程\" class=\"headerlink\" title=\"VLSI设计流程\"></a>VLSI设计流程</h3><img src=\"/2023/08/28/VLSI-Physical-Design/image-20230817170808037.png\" class=\"\" title=\"image-20230817170808037\">\n<p>系统规范—架构设计—功能和逻辑设计—电路设计—物理设计—物理验证和签收—制造—封装和测试—芯片</p>\n<p>物理设计关键步骤还可以细分</p>\n<p>划分—芯片规划—布局—时钟树综合—布线—时序收敛</p>\n<ul>\n<li><p>系统规范</p>\n<p>定义系统的总体目标和高级需求：功能、性能、物理尺寸、生产技术</p>\n</li>\n<li><p>架构设计</p>\n<p>模拟和混合信号模块集成</p>\n<p>存储管理——串行或者并行——寻址方案</p>\n<p>计算核的类型核数量（处理器，数字信号处理单元，特别的DSP算法）</p>\n<p>芯片内外的通信，对标准协议的支持</p>\n<p>硬、软IP模块的使用</p>\n<p>引脚分配、封装、管芯封装接口</p>\n<p>电源需求</p>\n<p>工艺技术核层堆栈的选择</p>\n</li>\n<li><p>功能和逻辑设计</p>\n<ul>\n<li><p>功能设计</p>\n<p>每个模块的输入、输出和时序行为</p>\n</li>\n<li><p>逻辑设计（用硬件描述语言HDL，如Verilog和VHDL定义芯片的功能和时序行为）</p>\n</li>\n<li><p>逻辑综合工具自动使HDL转变为底层的电路单元。即映射为信号网列表或网表和特定的电路单元</p>\n</li>\n</ul>\n</li>\n<li><p>电路设计</p>\n<p>一些关键的低端的单元必须在晶体管级来进行设计，这就是所谓的电路设计。</p>\n<p>包括：静态RAM模块、I/O、模拟电路、高速函数（乘法器）以及静电放电保护电路</p>\n</li>\n<li><p>物理设计</p>\n<p>所有的设计组件（宏模块、单元、门）都实例化为几何表示</p>\n<ul>\n<li>划分</li>\n<li>布线规划</li>\n<li>电源和地网布线</li>\n<li>布局</li>\n<li>时钟网综合</li>\n<li>总体布线</li>\n<li>详细布线</li>\n<li>时序收敛</li>\n</ul>\n</li>\n<li><p>物理验证</p>\n</li>\n<li><p>制造：fabrication</p>\n</li>\n<li><p>封装和测试</p>\n</li>\n</ul>\n<h3 id=\"VLSI设计模式\"><a href=\"#VLSI设计模式\" class=\"headerlink\" title=\"VLSI设计模式\"></a>VLSI设计模式</h3><blockquote>\n<p>全定制和半定制</p>\n</blockquote>\n<ul>\n<li><p>半定制标准设计模式：</p>\n<ul>\n<li>基于单元：通常采用标准单元和宏单元，包含许多预定义元件（从元件库复制而来）</li>\n<li>基于阵列：采用门阵列或者FPGA，包含若干制备好的元件，通过预布线相连</li>\n</ul>\n</li>\n<li><p>全制定设计</p>\n<p>需要有版图编辑器</p>\n</li>\n<li><p>标准单元设计，有固定的电源和接地端口</p>\n<p>布局的自由度较少，复杂度大大降低</p>\n</li>\n<li><p>宏单元</p>\n<p>较大块逻辑，执行可重用的功能</p>\n</li>\n<li><p>门阵列</p>\n<p>具有标准逻辑功能的硅片，但是没有链接</p>\n</li>\n<li><p>现场可编程门阵列（FPGA）</p>\n<p>逻辑单元和互连都是预先制造好，但是用户可以通过开关来配置</p>\n</li>\n<li><p>结构化ASIC（无通道门阵列）</p>\n</li>\n</ul>\n<h3 id=\"版图层和设计规则\"><a href=\"#版图层和设计规则\" class=\"headerlink\" title=\"版图层和设计规则\"></a>版图层和设计规则</h3><ul>\n<li><p>版图层</p>\n<p>硅作为扩散层，多晶硅、铝和铜作为互连层；多晶硅作称为poly层，其余曾称为Metal1层、Metal2层等。</p>\n<p>单元之间的布线是完全在金属层进行的。</p>\n</li>\n<li><p>设计规则</p>\n<p>大致分为三类</p>\n<ul>\n<li>尺寸规则：任何组件（形状）的尺寸</li>\n<li>间距规则：组件形状之间的间距</li>\n<li>覆盖规则：组件形状之间的覆盖量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"物理设计优化\"><a href=\"#物理设计优化\" class=\"headerlink\" title=\"物理设计优化\"></a>物理设计优化</h3><p>物理设计的目标：最小芯片面积、最小线长和最少过孔</p>\n<p>最优化的目标：提升电路性能，可靠性</p>\n<ul>\n<li><p>版图优化</p>\n<blockquote>\n<p>满足约束：工艺约束、电气约束、几何约束</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"EDA常用术语\"><a href=\"#EDA常用术语\" class=\"headerlink\" title=\"EDA常用术语\"></a>EDA常用术语</h3><p>逻辑设计：将HDL描述映射到电路门和门在网表级的连接的过程。</p>\n<ul>\n<li>结果通常是单元或其他基本电路元件和连接的网表。</li>\n</ul>\n<p>物理设计：决定单元（或者其他电路元件）和它们的连接在集成电路版图中几何布置的过程。连接拓扑从网表中得到。</p>\n<ul>\n<li>物理设计的结果是几何和功能都正确的表示，用标准文件格式，例如GDSII流。</li>\n</ul>\n<p>版图验证包括：</p>\n<ul>\n<li>设计规则检验（DRC）——遵守所有的技术需求</li>\n<li>版图和原理图一致性检验（LVS）——是否和原始网表一致</li>\n<li>天线规则检验——没有天线效应</li>\n<li>电气规则检验——遵守所有的电气需求</li>\n</ul>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">组件：有基本功能的电路元件<br>模块：一个电路划分或者一部分构件的集合<br>块：具有形状的组件，有固定尺寸的电路划分<br>单元：用不同构建建立的逻辑或者功能单位。如：INV，NAND，<span class=\"hljs-keyword\">NOR，常用来指标准单元和宏单元</span><br><span class=\"hljs-keyword\"></span>标准单元：一种预先决定功能的单元，在标准单元里，逻辑设计是将标准单元排列在行里来实现的<br>宏单元：一种没有预先定义尺寸的单元。可以指大型物理版图，如<span class=\"hljs-keyword\">SRAM，CPU核</span><br><span class=\"hljs-keyword\"></span>引脚：一个电子终端，用于连接给定的构件到它的外部环境<br>层：制造工艺等级，在这个等几种，设计构件在芯片上成型。<br>接触层：硅核金属层之间的直接连接，接触层经常用在单元内<br>过孔：金属层之间的连接，通常用来连接不同层的布线结构<br>线网或信号：必须在相同电势下连接的引脚或终端的集合<br>供电网：提供电流给单元的电源（VDD）和地网（GND）<br>网表：设计中连接的所有信号网和构件的集合，或者是所有网和分段设计的连接引脚的列表。<br>网表可以组成：<span class=\"hljs-number\">1</span>、面向引脚，每个设计构件都有一个相关线网的列表。<span class=\"hljs-number\">2</span>、面向线网，每一个线网都有一个相关构件的列表。网表在逻辑综合中创建，是物理设计的关键输入。<br>线网权重（W）：用来表示线网的重要性或关键性<br><br>网表的表示方法：连接图和连接矩阵<br></code></pre></td></tr></table></figure>\n<h3 id=\"第一章总结\"><a href=\"#第一章总结\" class=\"headerlink\" title=\"第一章总结\"></a>第一章总结</h3><ul>\n<li><p>什么是EDA？</p>\n<p>EDA全称是Electrical Design Automation（电子设计自动化），是芯片设计中的辅助软件工具也是必不可少的一个工具，随着芯片中集成的半导体和电路规模越来越大，EDA工具也越来越重要。</p>\n</li>\n<li><p>超大规模集成电路（VLSI）的设计流程？</p>\n<p>系统规范—架构设计—逻辑功能设计—物理设计—物理验证—制造—封装—测试—芯片</p>\n</li>\n<li><p>其中物理设计包括哪些部分？</p>\n<p>物理设计包括：布图规划，布局规划，布线，时钟树综合，时序分析</p>\n</li>\n</ul>\n<h2 id=\"第二章-网表和系统划分\"><a href=\"#第二章-网表和系统划分\" class=\"headerlink\" title=\"第二章 网表和系统划分\"></a>第二章 网表和系统划分</h2><p>一般采用分治的策略进行芯片设计，先将模块进行布局，然后将结果转换为几何划分。</p>\n<h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><blockquote>\n<p>降低现代集成电路设计复杂度的方法是将它们划分为更小的模块。</p>\n</blockquote>\n<p>划分的主要目标是将电路进行划分，使得子电路之间的连接数最小化，且符合设计约束。</p>\n<h3 id=\"术语\"><a href=\"#术语\" class=\"headerlink\" title=\"术语\"></a>术语</h3><figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">元胞：构成组件的任何逻辑或功能单元<br>划分或块是由元胞和组件构成的<br>多元划分的问题是将电路划分为<span class=\"hljs-built_in\">K</span>个部分<br></code></pre></td></tr></table></figure>\n<h3 id=\"优化目标\"><a href=\"#优化目标\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h3><p>在平衡划分大小时，将所有割边数或割边的权重数最小化，称为最小割划分算法</p>\n<h3 id=\"划分算法\"><a href=\"#划分算法\" class=\"headerlink\" title=\"划分算法\"></a>划分算法</h3><blockquote>\n<p>Kernighan-Lin算法（KL）、KL拓展算法、Fiduccia-Mattheyses（FM）算法</p>\n<p><strong>模拟退火法</strong>、随机爬山算法</p>\n</blockquote>\n<p>KL算法：对于一个含有2*N个元胞且要划分的区域为N：N的，使用的是两个不同划分之间的元胞进行交换，通过计算能够是当前增益达到最大。</p>\n<p>FM算法：划分不平衡的算法，其中需要一个平衡因子来控制移动以后是否平衡。通过计算能够使得移动以后使得当前达到增益最大。可用于超图中。</p>\n<h3 id=\"多级划分框架\"><a href=\"#多级划分框架\" class=\"headerlink\" title=\"多级划分框架\"></a>多级划分框架</h3><blockquote>\n<p>从粗粒度网表，到细粒度网表</p>\n</blockquote>\n<p>为了提高网表划分的可扩展性，FM算法被嵌入到了一个多级框架中去，包含几个不同的步骤。</p>\n<p>1、原始的展平的网表被进行层次结群。</p>\n<p>2、将FM算法应用到这个结群网表中。</p>\n<p>3、部分网表在非粗粒度阶段被解开结群。</p>\n<p>4、在细粒度阶段，FM算法增量式应用到部分被解开结群的网表中。</p>\n<p>5、第3和第4一直继续知道所有网表解开结群为止。</p>\n<ul>\n<li><p>结群</p>\n<p>连接紧密的结点被结群，结群之外的连接保持原来网表的结构。通常结群的大小会受到限制，从而防止结群的退化。</p>\n<p>合并结点后，结群的权重是它所包含的成员结点的权重综合</p>\n</li>\n<li><p>多级划分</p>\n<p>当结构过多的时候，FM算法会收到一定的限制，复杂度会很高，所以通过多级划分的方式可以减小复杂度</p>\n</li>\n<li><p>基于多FPGA的系统划分</p>\n</li>\n</ul>\n<h2 id=\"第三章-芯片规划\"><a href=\"#第三章-芯片规划\" class=\"headerlink\" title=\"第三章 芯片规划\"></a>第三章 芯片规划</h2><p>芯片规划处理大规模模块：高速缓存、嵌入式内存及面积已知、形状固定或可变或集成电路IP核等。</p>\n<p><strong>芯片规划主要包括了三个主要阶段：布图规划、引脚分配、电源规划</strong></p>\n<p>布局规划：根据模块的面积和长宽比来优化芯片的大小、降低互连线长度和改善时延，从而确定了这些模型的位置和大小。</p>\n<p>引脚分配：通过输出信号线连接到块引脚。I/O布局为芯片的输入和输出引脚确定焊盘的位置，通常在芯片的边缘。这一步最理想在布局规划前进行。</p>\n<p>电源规划：建立电源供电网，电源网和底线网。</p>\n<h3 id=\"布图规划介绍\"><a href=\"#布图规划介绍\" class=\"headerlink\" title=\"布图规划介绍\"></a>布图规划介绍</h3><p>布图描述了模块之间的关系</p>\n<p>布局规划阶段确保：1、每个芯片模块被分配了一个形状或位置，便于进行门布局。2、每个有外部连接的引脚被分配了一个位置，这样内部和外部的线网都可以进行布线了。</p>\n<h3 id=\"布图规划的优化目标\"><a href=\"#布图规划的优化目标\" class=\"headerlink\" title=\"布图规划的优化目标\"></a>布图规划的优化目标</h3><p>每个模块的位置和它的长宽比</p>\n<ul>\n<li>全局边界框的面积和形状：影响电路性能、成品率、制造代价</li>\n<li>总线长，最小生成树</li>\n<li>面积和总线长的组合</li>\n<li>信号时延</li>\n</ul>\n<h3 id=\"术语-1\"><a href=\"#术语-1\" class=\"headerlink\" title=\"术语\"></a>术语</h3><figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\">矩形划分：将芯片面积划分为一组块或非重叠矩形的几何<br>布图规划二划分：通过不断对矩形进行划分得到的一个矩形划分，从整个芯片开始，反复用水平或垂直割线将其划分为两个小矩形。<br>二划分树或者二划分布图规划树：有k个叶子和k<span class=\"hljs-string\">-1</span>个内部节点的二叉树，每个叶子代表一个块，每个内部节点代表一条水平或垂直割线。<br>布图树：一棵表示层次化布图的树。每个叶子节点代表一个块，每个内部节点代表一个水平分割或垂直分割。<br>约束图：对一个布图表示，包括两个有向图，垂直约束图和水平约束图，可以得到块之间的相对位置关系。<br>垂直约束图：节点权重表示块的高度。最长路径，相当于布局所需的最小垂直高度。<br>水平约束图：结点权重代表块的宽度。最长路径，相当于布局所需的最小水平宽度。<br>序列对：块排列的一个有序对。用S+和S-表示，用于区分序列是左右关系还是上下关系。<br></code></pre></td></tr></table></figure>\n<h3 id=\"布图的表示\"><a href=\"#布图的表示\" class=\"headerlink\" title=\"布图的表示\"></a>布图的表示</h3><blockquote>\n<p>布图的表示方法：1、约束图，2、序列对</p>\n</blockquote>\n<p>布图、约束图（垂直约束图，水平约束图）、序列对</p>\n<p>问题：</p>\n<p>如何将一个布图转化为一个约束图对（垂直&amp;水平）</p>\n<ul>\n<li>垂直约束图：从下到上，从左到右，先绘制所有的有向箭头，再删除不能直接相连的箭头</li>\n</ul>\n<p>如何将一个布图转化为一个序列对</p>\n<ul>\n<li>序列的规则，先考虑垂直方向，再考虑水平方向<ul>\n<li>a在b的左边，s1<a,b> s2<a,b></li>\n<li>a在b的上面，s1<a,b> s2<b,a></li>\n</ul>\n</li>\n</ul>\n<p>如何将一个序列对转化为一个布图</p>\n<blockquote>\n<p>已知布图的起始点，每个块的宽和高，布图的布局方向（一般是左下到右上）</p>\n</blockquote>\n<h3 id=\"布图规划算法\"><a href=\"#布图规划算法\" class=\"headerlink\" title=\"布图规划算法\"></a>布图规划算法</h3><blockquote>\n<p>布图优化算法：给定一个块的几何，布图尺寸的选择决定了布图面积的最小值，以及每个块的方向和大小。</p>\n<p><strong>群生长，模拟退火法</strong>：寻求1、在满足布图面积上限的条件下，最小化互连线总长度。2、同时优化总线长和面积。</p>\n</blockquote>\n<ul>\n<li><p>布局尺寸变化</p>\n<p>寻找最小面积布图的尺寸和相应的每个块的尺寸。</p>\n<ul>\n<li>构造所有块的形状函数</li>\n<li>确定顶层布图的形状函数</li>\n<li>找出布图和每个独立块的尺寸和位置</li>\n</ul>\n</li>\n</ul>\n<p>群生长</p>\n<p>基于群生长的方法中，布图是由迭代的增加块，直到所有块都被分配完。</p>\n<ul>\n<li><p>线性排序</p>\n<p>终端网：没有被其他没被安置的相关块</p>\n<p>新网：在部分构造排序的任何块上都没有引脚</p>\n<p>持续网：在部分构造排序上至少在块上有一个引脚，以及在无序块上至少有一个引脚</p>\n<p>以终端网减去新网的值作为增益，排序后每次都进行迭代，得到最终线性排序的序列</p>\n</li>\n<li><p>群生长</p>\n<p>按照线性排序的顺序，依次将最优块放置在布图上</p>\n</li>\n</ul>\n<p>模拟退火（SA）</p>\n<p>是一种迭代算法，从一个初始解开始，寻求目标函数解的不断改进。在每次迭代中，要考虑当前解的局部邻域解。</p>\n<h3 id=\"引脚分配\"><a href=\"#引脚分配\" class=\"headerlink\" title=\"引脚分配\"></a>引脚分配</h3><p>在引脚分配中，所有线网（信号）被分配到唯一的引脚位置，这样设计性能才是最优化的。优化目标包括块内外的最大化线网可布性和最小化电寄生参数。</p>\n<p>引脚分配可以用来连接功能或电等价的元胞引脚。</p>\n<p>优化目标：建立一个块和所有它与其他块的引脚的连接关系。</p>\n<h3 id=\"电源和地线布线\"><a href=\"#电源和地线布线\" class=\"headerlink\" title=\"电源和地线布线\"></a>电源和地线布线</h3><p>电源和地线网分布设计</p>\n<blockquote>\n<p>供电网VDD和GND，为每个元胞提供电源，每个元胞都必须与VDD和GND相连。</p>\n<p>供电网是：大型的、跨越整个芯片的、再信号布线之前布线</p>\n</blockquote>\n<p>电源和地线网的物理设计有两种方法：平面法，主要用于模拟电路或者定制块设计中。网格法，主要用于数字集成电路设计中。</p>\n<ul>\n<li>芯片规划的步骤：布图规划、引脚分配、电源和地线分配</li>\n<li>布图用什么来表示？</li>\n<li>布图规划有哪些算法？</li>\n</ul>\n<h2 id=\"第4章-全局和详细布局\"><a href=\"#第4章-全局和详细布局\" class=\"headerlink\" title=\"第4章 全局和详细布局\"></a>第4章 全局和详细布局</h2><p>将电路划分成小模块和对版图进行布局规划，从而确定块的轮廓线和引脚位置后，要求解优化目标（最小化元件间的总线长），布局要确定每个块中的标准单元或逻辑元件的位置。</p>\n<p>全局布局：分配大概的位置，给可变动的器件</p>\n<ul>\n<li>忽视可布目标的特殊形状和大小，不会试图去排列它们的位置到有效的行和列中去。</li>\n<li>进行全局定位和全局分布密度</li>\n</ul>\n<p>详细布局：明确器件的位置使其成为合理的元胞位置并确保没有重叠</p>\n<ul>\n<li>通过局部操作（交换两个元件）或移动一个行中的几个元件来为其他元件提供位置空间，从而增量式的改进每个标准单元的位置。</li>\n</ul>\n<p>合法化：将可布元件布置到行列中去，并消除重叠。</p>\n<h3 id=\"介绍-1\"><a href=\"#介绍-1\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>布局的目标：为了确定所有电路元件在一个（平面）版图中的位置和方向，给出解的约束（如没有元胞的重叠）和优化目标（如总线长最小化）</p>\n<h3 id=\"优化目标-1\"><a href=\"#优化目标-1\" class=\"headerlink\" title=\"优化目标\"></a>优化目标</h3><p>布局器通常优化目标是总线长。</p>\n<ul>\n<li><p>几种划线模型的选择</p>\n<ul>\n<li>单链模型</li>\n<li>星形模型</li>\n<li>最小生成树模型（克鲁斯卡尔）（RMST）</li>\n<li>直线最小树</li>\n</ul>\n</li>\n<li><p>带线网权重的总线长</p>\n<ul>\n<li>所有网络的线长与权重的乘积之和</li>\n</ul>\n</li>\n<li><p>最大割数</p>\n<p>最小化某一个布局总的割数</p>\n</li>\n<li><p>布线拥挤度（可以使用密度来表示：即布线所需要的轨道数与可提供的轨道数的比值）</p>\n<p>当所有穿过边的布线数小于最大的布线数时，则说明该布局是可布线的</p>\n</li>\n<li><p>信号延时</p>\n<p>对于给定的涉及，布局的总线长影响最大时钟频率，主要依赖于线网的时延和门时延。</p>\n<p>电路时序通常使用静态时序分析法（STA）进行验证，对线网和门时延进行估算。常见的术语包括实际到达时间（AAT）和需求到达时间（RAT），可对电路中每个结点v进行估算。</p>\n</li>\n</ul>\n<h3 id=\"全局布局\"><a href=\"#全局布局\" class=\"headerlink\" title=\"全局布局\"></a>全局布局</h3><blockquote>\n<p>全局布局确定布局的大致位置，详细布局消除重叠的因素</p>\n</blockquote>\n<p>最小割划分、二次布局、力矢量布局、模拟退火</p>\n<ul>\n<li><p>最小割布局：利用划分算法将网表和版图区域划分为较小的子网表和子区域。子网表和子区域重复划分到更小的部分，直到每个子区域包含少量的元胞。当实现最小割布局时，网表被划分为每个子区域拥有它自己唯一的子网表。</p>\n<p>版图划分的方向：割方向交替法（垂直割线和水平割线交替划分）、割方向重复法（先用单一方向划分，直到达到最小以后，在换方向）</p>\n<p>在版图划分的过程中，通常会将版图划分的方向和最小割划分算法结合起来，这样才能够在版图上最终定位某一个模块的位置。</p>\n<ul>\n<li><p>最小化割网的标准算法KL算法和FM算法</p>\n</li>\n<li><p>有外部链接的最小割布局</p>\n<p>假设每个元胞分别被布置在它们各自的区域中心。如果相关的i拦截接近下一个划分割线，在做下一个割线时则不用考虑这些结点。</p>\n</li>\n</ul>\n</li>\n<li><p>解析布局（最小化目标函数）</p>\n<ul>\n<li><strong>二次线长布局</strong>：分为两个阶段<ul>\n<li>第一阶段：依据元胞的中心对元胞进行布局，<strong>从而对二次线长函数最小化</strong>。</li>\n<li>第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有的单元原来的重叠消除。<strong>详细布局将所有元胞位置合法化并产生一个高质量的、无重叠的布局。</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>  第一阶段方法：迭代求解线性方程：共轭梯度法（CG）、逐次超松弛法（SOR）</p>\n<p>  第二阶段方法：详细布局：最小割布局、力矢量布局</p>\n<ul>\n<li><p>二次线长布局具体算法：</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。求：所有的元胞的<span class=\"hljs-keyword\">x</span>坐标和y坐标。<br><br><span class=\"hljs-number\">1</span>、列出所有连接的元胞线网的X的总线长L(p)：所有的<span class=\"hljs-keyword\">x</span>距离的差的平方<br><span class=\"hljs-number\">2</span>、分别对所有参数中的<span class=\"hljs-keyword\">x</span>求偏导，并令偏导为<span class=\"hljs-number\">0</span><br><span class=\"hljs-number\">3</span>、列出方程组，解出来的<span class=\"hljs-keyword\">x</span>阵列就是所需要求的解<br>对于Y方向也是同理<br><br>该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>力矢量布局</strong></p>\n<p>用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。</p>\n<p>采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。<strong>将目标转化为将所有的元胞放在一个力平衡的位置上。</strong>——<strong>称为零力目标</strong>（ZFT）</p>\n<ul>\n<li>对于每一个元胞，都有一个理想的最小ZFT位置。</li>\n<li>通过迭代的移动每个单元或者交换元胞到这个位置或相邻近位置，逐步改善布局结果</li>\n</ul>\n<blockquote>\n<p>个人认为：这个方法不能让每一个元胞都到达力的平衡状态，使用一次迭代或者交换，就会打乱原始平衡的元胞。</p>\n</blockquote>\n</li>\n<li><p>基本力矢量布局算法</p>\n<blockquote>\n<p>Loss为权重乘以坐标差的累计和</p>\n</blockquote>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-number\">1</span>、任意初始布局<br><span class=\"hljs-number\">2</span>、为每个布局中的元胞设定坐标，并标记为UNMOVED<br><span class=\"hljs-number\">3</span>、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序<br><span class=\"hljs-number\">4</span>、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成<br><span class=\"hljs-number\">5</span>、若ZFT位置被占据，则移动到其他的位置<br><br>第<span class=\"hljs-number\">5</span>步确定<span class=\"hljs-selector-tag\">p</span>的ZFT时，若ZFT被元胞<span class=\"hljs-selector-tag\">q</span>占据，则移动位置的确定<br><span class=\"hljs-number\">1</span>、如果可能，将<span class=\"hljs-selector-tag\">p</span>移动到靠近<span class=\"hljs-selector-tag\">q</span>的位置<br><span class=\"hljs-number\">2</span>、若交换<span class=\"hljs-selector-tag\">p</span>，<span class=\"hljs-selector-tag\">q</span>后，代价变小，则交换<br><span class=\"hljs-number\">3</span>、链式移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，<span class=\"hljs-selector-tag\">q</span>移动到下一个，以此类推<br><span class=\"hljs-number\">4</span>、波状移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，再重新计算<span class=\"hljs-selector-tag\">q</span>的ZFT<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<ul>\n<li><p>模拟退火算法</p>\n<p>列出损失函数，使用带动量的梯度下降，最终计算出使得损失函数最小的最优解</p>\n</li>\n<li><p>现代布局算法</p>\n</li>\n</ul>\n<h3 id=\"合法化和详细布局\"><a href=\"#合法化和详细布局\" class=\"headerlink\" title=\"合法化和详细布局\"></a>合法化和详细布局</h3><blockquote>\n<p>合法化：寻求合法的、没有重叠的布局，从而减少对线长、时序和其他设计目标的不利影响。</p>\n</blockquote>\n<p>目标：消除元胞中的重叠</p>\n<p>使用贪心算法</p>\n<ul>\n<li><p>按照x坐标进行排序，并进行贪心处理，贪心选择策略为移动到当前元胞最近的，可用的合法位置，但不能超出行的范围。</p>\n</li>\n<li><p>缺点</p>\n<ul>\n<li>没有对网表进行考虑</li>\n<li>产生了大量的空白区域</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第五章-总体布线\"><a href=\"#第五章-总体布线\" class=\"headerlink\" title=\"第五章  总体布线\"></a>第五章  总体布线</h2><p>在总体布线中，具有相同点位的引脚用线路相连。</p>\n<h3 id=\"介绍-2\"><a href=\"#介绍-2\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><p>给定一个布局和一个网表：确定必要的连接数</p>\n<p>需要优化的布线目标：最小化总线长，最大时序松弛</p>\n<p>总体布线可分为：固定的裸片布线（芯片外形和所有布线资源都是固定的），可变的裸片布线（可以根据需要添加新布线轨道）</p>\n<p>常见的几种布线算法</p>\n<ul>\n<li>总体布线：粗粒分配布线到<strong>布线区域</strong></li>\n<li>详细布线：细粒分配布线到<strong>布线轨道</strong>，包括线网排序，引脚排序。用于完善总体布线。</li>\n<li>时序驱动布线：线网拓扑优化和资源分配到关键线网</li>\n<li>大信号网布线：电源（VDD）和地线（GND）布线</li>\n<li>几何技术：非曼哈顿和时钟布线</li>\n</ul>\n<h3 id=\"术语和定义\"><a href=\"#术语和定义\" class=\"headerlink\" title=\"术语和定义\"></a>术语和定义</h3><figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">布线轨道（列）：一条可用的水平（垂直）接线通路。<br>布线区域：包含了布线轨道的区域。<br>规格一致的布线区域：由均匀分布的水平和垂直网格线形成，产生芯片区域上规格一致的网格。<br>规格不一致的布线区域：由水平和垂直边界形成，与外部引脚连接或宏单元边界对齐。<br>通道：一个矩形不限区域，在两个相对边上由引脚，而在另两边则没有引脚。<br>水平通道：在顶端和低端边界上有引脚的通道。<br>垂直通道：在左右边界上有引脚的通道。<br>通道容量：代表了可用的布线轨道或者列的数量。<br>开关盒：水平和垂直通道的交集。<br><span class=\"hljs-number\">2</span><span class=\"hljs-built_in\">D</span>开关盒：四个边界都有端子的开关盒。<br><span class=\"hljs-number\">3</span><span class=\"hljs-built_in\">D</span>开关盒：六个边界都有端子的开关盒，包括顶部和底部。<br></code></pre></td></tr></table></figure>\n<p>优化目标</p>\n<blockquote>\n<p>最小总线长度，减少线网上的信号时延</p>\n</blockquote>\n<p>1、确定一个给定布局是否可布线。2、在可用布线区域中确定所有线网的一个粗略布线。</p>\n"},{"title":"A-Star算法模拟实现","date":"2023-07-28T11:04:33.000Z","cover":"/img/default_cover07.jpg","top_img":null,"_content":"## A star算法模拟实现\n\n### 内容：\n\n已知如下图地图，黑色表示障碍物无法通行，要求实现避障算法寻找从红色起点出发到达绿色终点的最优路径。\n\n![img](a-star-assignment/1.jpg)\n\n要求：\n\n（1） 对图中的地图进行建模，抽象成类，对数据进行封装；\n\n（2） 思考寻路算法的实现，对问题进行拆解，对算法实现也要求抽象接口类；\n\n（3） 使用给定的C++工程模板，按照模板编写CMakeLists.txt，以及Google Test单元测试，DoxyGen注释的使用。\n\n\n\n### 数据结构设计\n\n> 拿到题目最开始的想法就是想静态的实现对地图的绘制，然后对Astar算法进行复习，通过思考过后，觉得map形状，起始点，终点以及障碍，都是可以由用户通过交互的方式来完成的，进而选择将一些必要的数据聚合在类里面封装起来，本次实验一共设计了两个类，分别为Point（用于存储点的信息），Map（用于存储地图的相关信息，同时前端界面的拓展）\n\n#### 1、点的坐标抽象成一个结构体\n\nXy结构体存储的是点的位置坐标，x表示横坐标，y表示纵坐标，初始值都设置为0。\n\n```\nstruct Xy\n{\n    int x = 0;\n    int y = 0;\n};\n```\n\n\n\n#### 2、地图上的每一个点抽象成一个Point类\n\n* Point类中含有的私有成员\n\n|   成员名   |               具体含义                |\n| :--------: | :-----------------------------------: |\n|   Xy _xy   |    Xy结构体，存储当前Point的坐标信    |\n| int _value | 状态码，用于标记当前的坐标的Point状态 |\n\n* Point类中含有的公有成员\n\n|                  成员名                   |              具体含义              |\n| :---------------------------------------: | :--------------------------------: |\n|                  int _f                   |               总代价               |\n|                  int _g                   |           当前走过的代价           |\n|                  int _h                   |            到终点的代价            |\n|              Point* _parent;              | 存储上一个经过的Point保存路径信息  |\n|                 Point();                  |            默认构造函数            |\n|   Point(int m_x, int m_y, int m_value);   |            重载构造函数            |\n|                 ~Point();                 |              析构函数              |\n|             void insertAbs();             |       将当前Point设置为障碍        |\n|            void insertFirst();            |      将当前Point设置为起始点       |\n|            void insertFinal();            |       将当前Point设置为终点        |\n|            void insertNoAbs();            |      将当前Point设置成非障碍       |\n|          void insertPriority();           |    将当前Point设置为优先队列内     |\n|              int getValue();              |           获取当前状态码           |\n|              void updateF();              |              更新_f值              |\n|                Xy getXy();                |            得到坐标信息            |\n|         void setParent(Point& p);         |             设置父节点             |\n| bool operator<(const Point& point1)const; | 重载比较函数作为优先队列第三个参数 |\n\n* Point类的友元函数\n\n|                            成员名                            |          具体含义           |\n| :----------------------------------------------------------: | :-------------------------: |\n| friend std::ostream& operator<<(std::ostream& os, Point& m_point); | 重载输出运算符打印Point信息 |\n\n#### 3、将地图抽象程一个Map类\n\n* Map类中含有的私有成员\n\n|                   成员名                   |         具体含义          |\n| :----------------------------------------: | :-----------------------: |\n|                int _length;                |        地图的长度         |\n|                int _weight;                |        地图的宽度         |\n|                 Xy _first;                 |     起始点的坐标信息      |\n|                 Xy _final;                 |      终点的坐标信息       |\n| std::vector< std::vector< Point  > > _map; | 整个地图由二维的Point组成 |\n| std::priority_queue< Point > _point_open;  |  存放当前优先队列中的点   |\n|          std::vector< Xy > _path;          |  寻路完毕过后的路径信息   |\n|             bool _haveway = 1;             |  表示当前地图是否有通路   |\n\n* Map类中含有的公有成员\n\n|                   成员名                    |                  具体含义                  |\n| :-----------------------------------------: | :----------------------------------------: |\n|                   Map();                    |                默认构造函数                |\n|      Map(int m_length, int m_weight);       | 重载构造函数，通过地图的宽和高来初始化地图 |\n|        void insertAbs(int x, int y);        |             将当前点设置为障碍             |\n|       void insertFirst(int x, int y);       |            将当前点设置为起始点            |\n|       void insertFinal(int x, int y);       |             将当前点设置为终点             |\n|        void deleteAbs(int x, int y);        |               删除当前障碍点               |\n|           bool isOnBoard(Xy xy);            |             判断当前点是否越界             |\n| int twoPointDistance(Xy point1, Xy point2); |           计算两点之间的斜线距离           |\n|       int gAdd(Xy point1, Xy point2);       |            计算代价_g的增量距离            |\n|                void aStar();                |               实现AStar算法                |\n|               void getPath();               |          存储起点到终点的最短路径          |\n|               void reStart();               |           刷新状态码和初始化操作           |\n\n* Map类的友元函数\n\n|                            成员名                            |                           具体含义                           |\n| :----------------------------------------------------------: | :----------------------------------------------------------: |\n| friend std::ostream& operator<<(std::ostream& os, Map& m_map); | 重载输出运算符，用于整个地图的输出，输出的数据为各个坐标位置的状态码 |\n\n* 拓展，用于前端的成员\n\n|                            成员名                            |         具体含义          |\n| :----------------------------------------------------------: | :-----------------------: |\n|        void paintEvent(QPaintEvent* event) override;         |     重写绘图画笔事件      |\n|          void mousePressEvent(QMouseEvent* event);           |     重写鼠标监听事件      |\n|                      int start_x = 10;                       |          基坐标x          |\n|                      int start_y = 10;                       |          基坐标y          |\n|                       int gsize = 50;                        |         网格大小          |\n| bool start_button = 0;<br/>bool final_button = 0;<br/>bool abs_button = 0;<br/>bool a_star_button = 0;<br/>bool clear_button = 1;<br/>bool restart_button = 0; |    鼠标资源的控制符号     |\n|                       int last_x = 0;                        | 记录上一次鼠标点击的坐标x |\n|                       int last_y = 0;                        | 记录上一次鼠标点击的坐标y |\n\n\n\n### 算法思想\n\n> 核心算法用到的是A-Star算法，这是一个启发式算法，属于贪心算法和bfs的结合，使用的贪心选择策略为当前预计的最小代价，通过代价函数来确定其下一步应该走的路径，每一次都记录上一次路过的结点，最终到达终点以后即可获得走过的路径。\t\n\n```\n算法描述\n1、建一个优先队列，优先队列按照代价从低到高进行排序。\n2、计算起始点的代价，将起始点push到优先队列中。\n3、不断从优先队列中取出top的元素，并将其周围的点push到优先队列中，周围的点满足的条件，不是障碍，且不在当前的openlist中，若在其中则比较代价大小，代价小则更新。并将父节点的记录保存下来。\n4、如果已经到了终点，则按照父节点寻找路径。\n5、若优先队列为空以后，则说明起点到终点没有路径。\n```\n\n\n\n![image-20230803165730214](a-star-assignment/image-20230803165730214.png)\n\n\n\n### 输入描述\n\n* 地图的长和宽\n\n  用户手动输入地图的长和宽，得到长和宽以后，会自动初始化地图大小\n\n* 输入起始点\n\n  选择地图上的某一空白处作为起始点\n\n* 输入终点\n\n  选择地图上的某一空白处作为终点\n\n* 输入障碍\n\n  选择地图上的空白处可以设置为障碍\n\n* 清除障碍\n\n  点击clear_abs可以将障碍清除\n\n* 寻路\n\n  点击a-star进行从起点到终点的寻路\n\n#### 输入测试：\n\n> 在本次实验中，一共设置了6个可以提供选择的按钮，当按钮处于灰色状态时，代表按钮处于未被激活状态，即该按钮不可点击，当按钮处于蓝色则说明按钮可点击。\n>\n> ADD_FIRST\t\t设置起点\n>\n> ADD_FINAL\t\t设置终点\n>\n> A_STAR\t\t\t\t使用Astar开始寻路\n>\n> ADD_ABS\t\t\t设置障碍\n>\n> CLEAR_ABS\t\t\t清除障碍\n>\n> RESTART\t\t\t\t重新开始，将一些状态清除\n\n* 测试一、5行10列\n\n![image-20230803171605818](a-star-assignment/image-20230803171605818.png)\n\n* 测试二、3行5列\n\n![image-20230803171645811](a-star-assignment/image-20230803171645811.png)\n\n#### 结果测试\n\n> 结果说明：\n>\n> 绿色的网格代表设置的起点\n>\n> 红色的网格代表设置的终点\n>\n> 黑色的网格代表设置的障碍\n>\n> 白色的网格代表可以通路\n>\n> 灰色的网格代表寻路算法经过的搜索空间\n\n* 测试一、无障碍情况\n\n![image-20230803172210807](a-star-assignment/image-20230803172210807.png)\n\n![image-20230803173053255](a-star-assignment/image-20230803173053255.png)\n\n\n\n* 测试二、随机障碍情况\n\n![image-20230803173141837](a-star-assignment/image-20230803173141837.png)\n\n![image-20230803173212434](a-star-assignment/image-20230803173212434.png)\n\n![image-20230803173244879](a-star-assignment/image-20230803173244879.png)\n\n![image-20230803173329009](a-star-assignment/image-20230803173329009.png)\n\n* 测试三、无通路情况\n\n  > 没有通路，则不会寻路，状态码为5的表示搜索到了的位置，从打印出的状态码中可以看出，搜索在障碍的边界处便中断了。\n\n![image-20230803173754572](a-star-assignment/image-20230803173754572.png)\n\n![image-20230803173808529](a-star-assignment/image-20230803173808529.png)\n\n\n\n### 总结\n\n#### 遇到的一些问题\n\n* **优先队列中比较函数的使用**\n\n  最开始使用的是代价f值作为比较函数中的参数，这样会导致一种情况，如果有两个代价一样的结点插入优先队列的时候，在下一次弹出优先队列的过程中，代价一样的结点会按照进入队列的先后顺序来进行弹出，也就是说在代价相同的结点中是按照广度优先的方式来进行的。但是如果我们在f值相同的情况下，再对h值进行比较，每次优先选择h值最小即最接近终点的结点出队列，这样就会将解空间缩小很多，具体案例如下所示。\n\n  * 使用两个参数的比较函数\n\n  ```\n  bool Point::operator<(const Point& point1)const {\n      if (_f == point1._f) return _h > point1._h;\n      return _f > point1._f;\n  }\n  ```\n\n![image-20230803183655944](a-star-assignment/image-20230803183655944.png)\n\n* * 使用一个参数的比较函数\n\n  ```\n  bool Point::operator<(const Point& point1)const {\n      // if (_f == point1._f) return _h > point1._h;\n      return _f > point1._f;\n  }\n  ```\n\n  \n\n![image-20230803183939400](a-star-assignment/image-20230803183939400.png)\n\n* **关于插入优先队列以后是否需要更新f值的问题**\n\n  在起初的版本中，通过简单的分析认为不需要更新f值，因为最开始认为如果能够在之前就到达的位置，再后面再到达了，说明会绕一些弯路，所以这样的f值肯定会大于或等于最开始进入openlist的结点。但在运行过程中出现了下面的问题，问题就是因为没有更新f值造成的，因为在最优路径中第一次遍历的最优路径上的点，不一定是通过最优路径中的点遍历的，所以会存在有f更小的现象。\n\n![问题：插入优先队列以后没有更新f值](a-star-assignment/问题：插入优先队列以后没有更新f值.png)\n\n* **在优先队列中查找元素的问题**\n\n  优先队列是一个堆的结构，很适用于取出最大值或者最小值，但如果是想要从优先队列中找到某一个元素，就较为难办了，在实验中出现的场景便是，需要确认当前遍历的结点是否在优先队列中，如果在优先队列中，则需要进行比较，不在的话则插入。\n\n  采用的方式是在Point类中加入了一个value参数，用于表示当前结点的状态码，当value为0时表示属于通路，1表示障碍，2表示起点，3表示终点，5表示在优先队列中，通过这样的方式便可以极大便利的获取当前结点的状态值，并达到随机访问结点状态的现象，如果某一个结点在优先队列中，只需要查看该节点的状态码即可。设置状态码还有一个好处，如果需要重新开始的话，只需要将该节点的状态码改为0即可。\n\n* **一个超级无脑的小bug**\n\n  在调试过程中，发现无法进行多次寻路，找了将近一天，最后发现Point中使用指针存储的parent结点用于寻路，下意识的在析构函数中使用delete删除parent，因为没有给parent分配内存，是使用等号复制地址的。所以在使用界面交互进行多次寻路的过程中，出现内存被回收的问题，窗口强制退出。\n\n* **前端遇到的一些问题**\n\n  前端需要解决的最主要的问题并不是绘图，而是资源状态的获取问题，获取鼠标事件，以及如何控制不同的点击执行不同的操作，最后使用一些bool值来进行组合完成。\n","source":"_posts/a-star-assignment.md","raw":"---\ntitle: A-Star算法模拟实现\ncategories: 算法实践\ndate: 2023-07-28 19:04:33\ntags: [A*算法, C++]\ncover:\ntop_img:\n---\n## A star算法模拟实现\n\n### 内容：\n\n已知如下图地图，黑色表示障碍物无法通行，要求实现避障算法寻找从红色起点出发到达绿色终点的最优路径。\n\n![img](a-star-assignment/1.jpg)\n\n要求：\n\n（1） 对图中的地图进行建模，抽象成类，对数据进行封装；\n\n（2） 思考寻路算法的实现，对问题进行拆解，对算法实现也要求抽象接口类；\n\n（3） 使用给定的C++工程模板，按照模板编写CMakeLists.txt，以及Google Test单元测试，DoxyGen注释的使用。\n\n\n\n### 数据结构设计\n\n> 拿到题目最开始的想法就是想静态的实现对地图的绘制，然后对Astar算法进行复习，通过思考过后，觉得map形状，起始点，终点以及障碍，都是可以由用户通过交互的方式来完成的，进而选择将一些必要的数据聚合在类里面封装起来，本次实验一共设计了两个类，分别为Point（用于存储点的信息），Map（用于存储地图的相关信息，同时前端界面的拓展）\n\n#### 1、点的坐标抽象成一个结构体\n\nXy结构体存储的是点的位置坐标，x表示横坐标，y表示纵坐标，初始值都设置为0。\n\n```\nstruct Xy\n{\n    int x = 0;\n    int y = 0;\n};\n```\n\n\n\n#### 2、地图上的每一个点抽象成一个Point类\n\n* Point类中含有的私有成员\n\n|   成员名   |               具体含义                |\n| :--------: | :-----------------------------------: |\n|   Xy _xy   |    Xy结构体，存储当前Point的坐标信    |\n| int _value | 状态码，用于标记当前的坐标的Point状态 |\n\n* Point类中含有的公有成员\n\n|                  成员名                   |              具体含义              |\n| :---------------------------------------: | :--------------------------------: |\n|                  int _f                   |               总代价               |\n|                  int _g                   |           当前走过的代价           |\n|                  int _h                   |            到终点的代价            |\n|              Point* _parent;              | 存储上一个经过的Point保存路径信息  |\n|                 Point();                  |            默认构造函数            |\n|   Point(int m_x, int m_y, int m_value);   |            重载构造函数            |\n|                 ~Point();                 |              析构函数              |\n|             void insertAbs();             |       将当前Point设置为障碍        |\n|            void insertFirst();            |      将当前Point设置为起始点       |\n|            void insertFinal();            |       将当前Point设置为终点        |\n|            void insertNoAbs();            |      将当前Point设置成非障碍       |\n|          void insertPriority();           |    将当前Point设置为优先队列内     |\n|              int getValue();              |           获取当前状态码           |\n|              void updateF();              |              更新_f值              |\n|                Xy getXy();                |            得到坐标信息            |\n|         void setParent(Point& p);         |             设置父节点             |\n| bool operator<(const Point& point1)const; | 重载比较函数作为优先队列第三个参数 |\n\n* Point类的友元函数\n\n|                            成员名                            |          具体含义           |\n| :----------------------------------------------------------: | :-------------------------: |\n| friend std::ostream& operator<<(std::ostream& os, Point& m_point); | 重载输出运算符打印Point信息 |\n\n#### 3、将地图抽象程一个Map类\n\n* Map类中含有的私有成员\n\n|                   成员名                   |         具体含义          |\n| :----------------------------------------: | :-----------------------: |\n|                int _length;                |        地图的长度         |\n|                int _weight;                |        地图的宽度         |\n|                 Xy _first;                 |     起始点的坐标信息      |\n|                 Xy _final;                 |      终点的坐标信息       |\n| std::vector< std::vector< Point  > > _map; | 整个地图由二维的Point组成 |\n| std::priority_queue< Point > _point_open;  |  存放当前优先队列中的点   |\n|          std::vector< Xy > _path;          |  寻路完毕过后的路径信息   |\n|             bool _haveway = 1;             |  表示当前地图是否有通路   |\n\n* Map类中含有的公有成员\n\n|                   成员名                    |                  具体含义                  |\n| :-----------------------------------------: | :----------------------------------------: |\n|                   Map();                    |                默认构造函数                |\n|      Map(int m_length, int m_weight);       | 重载构造函数，通过地图的宽和高来初始化地图 |\n|        void insertAbs(int x, int y);        |             将当前点设置为障碍             |\n|       void insertFirst(int x, int y);       |            将当前点设置为起始点            |\n|       void insertFinal(int x, int y);       |             将当前点设置为终点             |\n|        void deleteAbs(int x, int y);        |               删除当前障碍点               |\n|           bool isOnBoard(Xy xy);            |             判断当前点是否越界             |\n| int twoPointDistance(Xy point1, Xy point2); |           计算两点之间的斜线距离           |\n|       int gAdd(Xy point1, Xy point2);       |            计算代价_g的增量距离            |\n|                void aStar();                |               实现AStar算法                |\n|               void getPath();               |          存储起点到终点的最短路径          |\n|               void reStart();               |           刷新状态码和初始化操作           |\n\n* Map类的友元函数\n\n|                            成员名                            |                           具体含义                           |\n| :----------------------------------------------------------: | :----------------------------------------------------------: |\n| friend std::ostream& operator<<(std::ostream& os, Map& m_map); | 重载输出运算符，用于整个地图的输出，输出的数据为各个坐标位置的状态码 |\n\n* 拓展，用于前端的成员\n\n|                            成员名                            |         具体含义          |\n| :----------------------------------------------------------: | :-----------------------: |\n|        void paintEvent(QPaintEvent* event) override;         |     重写绘图画笔事件      |\n|          void mousePressEvent(QMouseEvent* event);           |     重写鼠标监听事件      |\n|                      int start_x = 10;                       |          基坐标x          |\n|                      int start_y = 10;                       |          基坐标y          |\n|                       int gsize = 50;                        |         网格大小          |\n| bool start_button = 0;<br/>bool final_button = 0;<br/>bool abs_button = 0;<br/>bool a_star_button = 0;<br/>bool clear_button = 1;<br/>bool restart_button = 0; |    鼠标资源的控制符号     |\n|                       int last_x = 0;                        | 记录上一次鼠标点击的坐标x |\n|                       int last_y = 0;                        | 记录上一次鼠标点击的坐标y |\n\n\n\n### 算法思想\n\n> 核心算法用到的是A-Star算法，这是一个启发式算法，属于贪心算法和bfs的结合，使用的贪心选择策略为当前预计的最小代价，通过代价函数来确定其下一步应该走的路径，每一次都记录上一次路过的结点，最终到达终点以后即可获得走过的路径。\t\n\n```\n算法描述\n1、建一个优先队列，优先队列按照代价从低到高进行排序。\n2、计算起始点的代价，将起始点push到优先队列中。\n3、不断从优先队列中取出top的元素，并将其周围的点push到优先队列中，周围的点满足的条件，不是障碍，且不在当前的openlist中，若在其中则比较代价大小，代价小则更新。并将父节点的记录保存下来。\n4、如果已经到了终点，则按照父节点寻找路径。\n5、若优先队列为空以后，则说明起点到终点没有路径。\n```\n\n\n\n![image-20230803165730214](a-star-assignment/image-20230803165730214.png)\n\n\n\n### 输入描述\n\n* 地图的长和宽\n\n  用户手动输入地图的长和宽，得到长和宽以后，会自动初始化地图大小\n\n* 输入起始点\n\n  选择地图上的某一空白处作为起始点\n\n* 输入终点\n\n  选择地图上的某一空白处作为终点\n\n* 输入障碍\n\n  选择地图上的空白处可以设置为障碍\n\n* 清除障碍\n\n  点击clear_abs可以将障碍清除\n\n* 寻路\n\n  点击a-star进行从起点到终点的寻路\n\n#### 输入测试：\n\n> 在本次实验中，一共设置了6个可以提供选择的按钮，当按钮处于灰色状态时，代表按钮处于未被激活状态，即该按钮不可点击，当按钮处于蓝色则说明按钮可点击。\n>\n> ADD_FIRST\t\t设置起点\n>\n> ADD_FINAL\t\t设置终点\n>\n> A_STAR\t\t\t\t使用Astar开始寻路\n>\n> ADD_ABS\t\t\t设置障碍\n>\n> CLEAR_ABS\t\t\t清除障碍\n>\n> RESTART\t\t\t\t重新开始，将一些状态清除\n\n* 测试一、5行10列\n\n![image-20230803171605818](a-star-assignment/image-20230803171605818.png)\n\n* 测试二、3行5列\n\n![image-20230803171645811](a-star-assignment/image-20230803171645811.png)\n\n#### 结果测试\n\n> 结果说明：\n>\n> 绿色的网格代表设置的起点\n>\n> 红色的网格代表设置的终点\n>\n> 黑色的网格代表设置的障碍\n>\n> 白色的网格代表可以通路\n>\n> 灰色的网格代表寻路算法经过的搜索空间\n\n* 测试一、无障碍情况\n\n![image-20230803172210807](a-star-assignment/image-20230803172210807.png)\n\n![image-20230803173053255](a-star-assignment/image-20230803173053255.png)\n\n\n\n* 测试二、随机障碍情况\n\n![image-20230803173141837](a-star-assignment/image-20230803173141837.png)\n\n![image-20230803173212434](a-star-assignment/image-20230803173212434.png)\n\n![image-20230803173244879](a-star-assignment/image-20230803173244879.png)\n\n![image-20230803173329009](a-star-assignment/image-20230803173329009.png)\n\n* 测试三、无通路情况\n\n  > 没有通路，则不会寻路，状态码为5的表示搜索到了的位置，从打印出的状态码中可以看出，搜索在障碍的边界处便中断了。\n\n![image-20230803173754572](a-star-assignment/image-20230803173754572.png)\n\n![image-20230803173808529](a-star-assignment/image-20230803173808529.png)\n\n\n\n### 总结\n\n#### 遇到的一些问题\n\n* **优先队列中比较函数的使用**\n\n  最开始使用的是代价f值作为比较函数中的参数，这样会导致一种情况，如果有两个代价一样的结点插入优先队列的时候，在下一次弹出优先队列的过程中，代价一样的结点会按照进入队列的先后顺序来进行弹出，也就是说在代价相同的结点中是按照广度优先的方式来进行的。但是如果我们在f值相同的情况下，再对h值进行比较，每次优先选择h值最小即最接近终点的结点出队列，这样就会将解空间缩小很多，具体案例如下所示。\n\n  * 使用两个参数的比较函数\n\n  ```\n  bool Point::operator<(const Point& point1)const {\n      if (_f == point1._f) return _h > point1._h;\n      return _f > point1._f;\n  }\n  ```\n\n![image-20230803183655944](a-star-assignment/image-20230803183655944.png)\n\n* * 使用一个参数的比较函数\n\n  ```\n  bool Point::operator<(const Point& point1)const {\n      // if (_f == point1._f) return _h > point1._h;\n      return _f > point1._f;\n  }\n  ```\n\n  \n\n![image-20230803183939400](a-star-assignment/image-20230803183939400.png)\n\n* **关于插入优先队列以后是否需要更新f值的问题**\n\n  在起初的版本中，通过简单的分析认为不需要更新f值，因为最开始认为如果能够在之前就到达的位置，再后面再到达了，说明会绕一些弯路，所以这样的f值肯定会大于或等于最开始进入openlist的结点。但在运行过程中出现了下面的问题，问题就是因为没有更新f值造成的，因为在最优路径中第一次遍历的最优路径上的点，不一定是通过最优路径中的点遍历的，所以会存在有f更小的现象。\n\n![问题：插入优先队列以后没有更新f值](a-star-assignment/问题：插入优先队列以后没有更新f值.png)\n\n* **在优先队列中查找元素的问题**\n\n  优先队列是一个堆的结构，很适用于取出最大值或者最小值，但如果是想要从优先队列中找到某一个元素，就较为难办了，在实验中出现的场景便是，需要确认当前遍历的结点是否在优先队列中，如果在优先队列中，则需要进行比较，不在的话则插入。\n\n  采用的方式是在Point类中加入了一个value参数，用于表示当前结点的状态码，当value为0时表示属于通路，1表示障碍，2表示起点，3表示终点，5表示在优先队列中，通过这样的方式便可以极大便利的获取当前结点的状态值，并达到随机访问结点状态的现象，如果某一个结点在优先队列中，只需要查看该节点的状态码即可。设置状态码还有一个好处，如果需要重新开始的话，只需要将该节点的状态码改为0即可。\n\n* **一个超级无脑的小bug**\n\n  在调试过程中，发现无法进行多次寻路，找了将近一天，最后发现Point中使用指针存储的parent结点用于寻路，下意识的在析构函数中使用delete删除parent，因为没有给parent分配内存，是使用等号复制地址的。所以在使用界面交互进行多次寻路的过程中，出现内存被回收的问题，窗口强制退出。\n\n* **前端遇到的一些问题**\n\n  前端需要解决的最主要的问题并不是绘图，而是资源状态的获取问题，获取鼠标事件，以及如何控制不同的点击执行不同的操作，最后使用一些bool值来进行组合完成。\n","slug":"a-star-assignment","published":1,"updated":"2024-06-05T09:03:03.627Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttn000u08jv56vq9p5c","content":"<h2 id=\"A-star算法模拟实现\"><a href=\"#A-star算法模拟实现\" class=\"headerlink\" title=\"A star算法模拟实现\"></a>A star算法模拟实现</h2><h3 id=\"内容：\"><a href=\"#内容：\" class=\"headerlink\" title=\"内容：\"></a>内容：</h3><p>已知如下图地图，黑色表示障碍物无法通行，要求实现避障算法寻找从红色起点出发到达绿色终点的最优路径。</p>\n<img src=\"/2023/07/28/a-star-assignment/1.jpg\" class=\"\" title=\"img\">\n<p>要求：</p>\n<p>（1） 对图中的地图进行建模，抽象成类，对数据进行封装；</p>\n<p>（2） 思考寻路算法的实现，对问题进行拆解，对算法实现也要求抽象接口类；</p>\n<p>（3） 使用给定的C++工程模板，按照模板编写CMakeLists.txt，以及Google Test单元测试，DoxyGen注释的使用。</p>\n<h3 id=\"数据结构设计\"><a href=\"#数据结构设计\" class=\"headerlink\" title=\"数据结构设计\"></a>数据结构设计</h3><blockquote>\n<p>拿到题目最开始的想法就是想静态的实现对地图的绘制，然后对Astar算法进行复习，通过思考过后，觉得map形状，起始点，终点以及障碍，都是可以由用户通过交互的方式来完成的，进而选择将一些必要的数据聚合在类里面封装起来，本次实验一共设计了两个类，分别为Point（用于存储点的信息），Map（用于存储地图的相关信息，同时前端界面的拓展）</p>\n</blockquote>\n<h4 id=\"1、点的坐标抽象成一个结构体\"><a href=\"#1、点的坐标抽象成一个结构体\" class=\"headerlink\" title=\"1、点的坐标抽象成一个结构体\"></a>1、点的坐标抽象成一个结构体</h4><p>Xy结构体存储的是点的位置坐标，x表示横坐标，y表示纵坐标，初始值都设置为0。</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">struct Xy<br>&#123;<br>    int x <span class=\"hljs-operator\">=</span> <span class=\"hljs-number\">0</span><span class=\"hljs-comment\">;</span><br>    int y <span class=\"hljs-operator\">=</span> <span class=\"hljs-number\">0</span><span class=\"hljs-comment\">;</span><br>&#125;<span class=\"hljs-comment\">;</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"2、地图上的每一个点抽象成一个Point类\"><a href=\"#2、地图上的每一个点抽象成一个Point类\" class=\"headerlink\" title=\"2、地图上的每一个点抽象成一个Point类\"></a>2、地图上的每一个点抽象成一个Point类</h4><ul>\n<li>Point类中含有的私有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Xy _xy</td>\n<td style=\"text-align:center\">Xy结构体，存储当前Point的坐标信</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _value</td>\n<td style=\"text-align:center\">状态码，用于标记当前的坐标的Point状态</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Point类中含有的公有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">int _f</td>\n<td style=\"text-align:center\">总代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _g</td>\n<td style=\"text-align:center\">当前走过的代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _h</td>\n<td style=\"text-align:center\">到终点的代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point* _parent;</td>\n<td style=\"text-align:center\">存储上一个经过的Point保存路径信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point();</td>\n<td style=\"text-align:center\">默认构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point(int m_x, int m_y, int m_value);</td>\n<td style=\"text-align:center\">重载构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">~Point();</td>\n<td style=\"text-align:center\">析构函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertAbs();</td>\n<td style=\"text-align:center\">将当前Point设置为障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFirst();</td>\n<td style=\"text-align:center\">将当前Point设置为起始点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFinal();</td>\n<td style=\"text-align:center\">将当前Point设置为终点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertNoAbs();</td>\n<td style=\"text-align:center\">将当前Point设置成非障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertPriority();</td>\n<td style=\"text-align:center\">将当前Point设置为优先队列内</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int getValue();</td>\n<td style=\"text-align:center\">获取当前状态码</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void updateF();</td>\n<td style=\"text-align:center\">更新_f值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy getXy();</td>\n<td style=\"text-align:center\">得到坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void setParent(Point&amp; p);</td>\n<td style=\"text-align:center\">设置父节点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool operator&lt;(const Point&amp; point1)const;</td>\n<td style=\"text-align:center\">重载比较函数作为优先队列第三个参数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Point类的友元函数</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, Point&amp; m_point);</td>\n<td style=\"text-align:center\">重载输出运算符打印Point信息</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3、将地图抽象程一个Map类\"><a href=\"#3、将地图抽象程一个Map类\" class=\"headerlink\" title=\"3、将地图抽象程一个Map类\"></a>3、将地图抽象程一个Map类</h4><ul>\n<li>Map类中含有的私有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">int _length;</td>\n<td style=\"text-align:center\">地图的长度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _weight;</td>\n<td style=\"text-align:center\">地图的宽度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy _first;</td>\n<td style=\"text-align:center\">起始点的坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy _final;</td>\n<td style=\"text-align:center\">终点的坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::vector&lt; std::vector&lt; Point  &gt; &gt; _map;</td>\n<td style=\"text-align:center\">整个地图由二维的Point组成</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::priority_queue&lt; Point &gt; _point_open;</td>\n<td style=\"text-align:center\">存放当前优先队列中的点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::vector&lt; Xy &gt; _path;</td>\n<td style=\"text-align:center\">寻路完毕过后的路径信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool _haveway = 1;</td>\n<td style=\"text-align:center\">表示当前地图是否有通路</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Map类中含有的公有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Map();</td>\n<td style=\"text-align:center\">默认构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Map(int m_length, int m_weight);</td>\n<td style=\"text-align:center\">重载构造函数，通过地图的宽和高来初始化地图</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertAbs(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFirst(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为起始点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFinal(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为终点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void deleteAbs(int x, int y);</td>\n<td style=\"text-align:center\">删除当前障碍点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool isOnBoard(Xy xy);</td>\n<td style=\"text-align:center\">判断当前点是否越界</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int twoPointDistance(Xy point1, Xy point2);</td>\n<td style=\"text-align:center\">计算两点之间的斜线距离</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int gAdd(Xy point1, Xy point2);</td>\n<td style=\"text-align:center\">计算代价_g的增量距离</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void aStar();</td>\n<td style=\"text-align:center\">实现AStar算法</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void getPath();</td>\n<td style=\"text-align:center\">存储起点到终点的最短路径</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void reStart();</td>\n<td style=\"text-align:center\">刷新状态码和初始化操作</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Map类的友元函数</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, Map&amp; m_map);</td>\n<td style=\"text-align:center\">重载输出运算符，用于整个地图的输出，输出的数据为各个坐标位置的状态码</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>拓展，用于前端的成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">void paintEvent(QPaintEvent* event) override;</td>\n<td style=\"text-align:center\">重写绘图画笔事件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void mousePressEvent(QMouseEvent* event);</td>\n<td style=\"text-align:center\">重写鼠标监听事件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int start_x = 10;</td>\n<td style=\"text-align:center\">基坐标x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int start_y = 10;</td>\n<td style=\"text-align:center\">基坐标y</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int gsize = 50;</td>\n<td style=\"text-align:center\">网格大小</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool start_button = 0;<br/>bool final_button = 0;<br/>bool abs_button = 0;<br/>bool a_star_button = 0;<br/>bool clear_button = 1;<br/>bool restart_button = 0;</td>\n<td style=\"text-align:center\">鼠标资源的控制符号</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int last_x = 0;</td>\n<td style=\"text-align:center\">记录上一次鼠标点击的坐标x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int last_y = 0;</td>\n<td style=\"text-align:center\">记录上一次鼠标点击的坐标y</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"算法思想\"><a href=\"#算法思想\" class=\"headerlink\" title=\"算法思想\"></a>算法思想</h3><blockquote>\n<p>核心算法用到的是A-Star算法，这是一个启发式算法，属于贪心算法和bfs的结合，使用的贪心选择策略为当前预计的最小代价，通过代价函数来确定其下一步应该走的路径，每一次都记录上一次路过的结点，最终到达终点以后即可获得走过的路径。    </p>\n</blockquote>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\">算法描述<br><span class=\"hljs-number\">1</span>、建一个优先队列，优先队列按照代价从低到高进行排序。<br><span class=\"hljs-number\">2</span>、计算起始点的代价，将起始点<span class=\"hljs-keyword\">push</span>到优先队列中。<br><span class=\"hljs-number\">3</span>、不断从优先队列中取出<span class=\"hljs-literal\">top</span>的元素，并将其周围的点<span class=\"hljs-keyword\">push</span>到优先队列中，周围的点满足的条件，不是障碍，且不在当前的openlist中，若在其中则比较代价大小，代价小则更新。并将父节点的记录保存下来。<br><span class=\"hljs-number\">4</span>、如果已经到了终点，则按照父节点寻找路径。<br><span class=\"hljs-number\">5</span>、若优先队列为空以后，则说明起点到终点没有路径。<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803165730214.png\" class=\"\" title=\"image-20230803165730214\">\n<h3 id=\"输入描述\"><a href=\"#输入描述\" class=\"headerlink\" title=\"输入描述\"></a>输入描述</h3><ul>\n<li><p>地图的长和宽</p>\n<p>用户手动输入地图的长和宽，得到长和宽以后，会自动初始化地图大小</p>\n</li>\n<li><p>输入起始点</p>\n<p>选择地图上的某一空白处作为起始点</p>\n</li>\n<li><p>输入终点</p>\n<p>选择地图上的某一空白处作为终点</p>\n</li>\n<li><p>输入障碍</p>\n<p>选择地图上的空白处可以设置为障碍</p>\n</li>\n<li><p>清除障碍</p>\n<p>点击clear_abs可以将障碍清除</p>\n</li>\n<li><p>寻路</p>\n<p>点击a-star进行从起点到终点的寻路</p>\n</li>\n</ul>\n<h4 id=\"输入测试：\"><a href=\"#输入测试：\" class=\"headerlink\" title=\"输入测试：\"></a>输入测试：</h4><blockquote>\n<p>在本次实验中，一共设置了6个可以提供选择的按钮，当按钮处于灰色状态时，代表按钮处于未被激活状态，即该按钮不可点击，当按钮处于蓝色则说明按钮可点击。</p>\n<p>ADD_FIRST        设置起点</p>\n<p>ADD_FINAL        设置终点</p>\n<p>A_STAR                使用Astar开始寻路</p>\n<p>ADD_ABS            设置障碍</p>\n<p>CLEAR_ABS            清除障碍</p>\n<p>RESTART                重新开始，将一些状态清除</p>\n</blockquote>\n<ul>\n<li>测试一、5行10列</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803171605818.png\" class=\"\" title=\"image-20230803171605818\">\n<ul>\n<li>测试二、3行5列</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803171645811.png\" class=\"\" title=\"image-20230803171645811\">\n<h4 id=\"结果测试\"><a href=\"#结果测试\" class=\"headerlink\" title=\"结果测试\"></a>结果测试</h4><blockquote>\n<p>结果说明：</p>\n<p>绿色的网格代表设置的起点</p>\n<p>红色的网格代表设置的终点</p>\n<p>黑色的网格代表设置的障碍</p>\n<p>白色的网格代表可以通路</p>\n<p>灰色的网格代表寻路算法经过的搜索空间</p>\n</blockquote>\n<ul>\n<li>测试一、无障碍情况</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803172210807.png\" class=\"\" title=\"image-20230803172210807\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173053255.png\" class=\"\" title=\"image-20230803173053255\">\n<ul>\n<li>测试二、随机障碍情况</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173141837.png\" class=\"\" title=\"image-20230803173141837\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173212434.png\" class=\"\" title=\"image-20230803173212434\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173244879.png\" class=\"\" title=\"image-20230803173244879\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173329009.png\" class=\"\" title=\"image-20230803173329009\">\n<ul>\n<li><p>测试三、无通路情况</p>\n<blockquote>\n<p>没有通路，则不会寻路，状态码为5的表示搜索到了的位置，从打印出的状态码中可以看出，搜索在障碍的边界处便中断了。</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173754572.png\" class=\"\" title=\"image-20230803173754572\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173808529.png\" class=\"\" title=\"image-20230803173808529\">\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><h4 id=\"遇到的一些问题\"><a href=\"#遇到的一些问题\" class=\"headerlink\" title=\"遇到的一些问题\"></a>遇到的一些问题</h4><ul>\n<li><p><strong>优先队列中比较函数的使用</strong></p>\n<p>最开始使用的是代价f值作为比较函数中的参数，这样会导致一种情况，如果有两个代价一样的结点插入优先队列的时候，在下一次弹出优先队列的过程中，代价一样的结点会按照进入队列的先后顺序来进行弹出，也就是说在代价相同的结点中是按照广度优先的方式来进行的。但是如果我们在f值相同的情况下，再对h值进行比较，每次优先选择h值最小即最接近终点的结点出队列，这样就会将解空间缩小很多，具体案例如下所示。</p>\n<ul>\n<li>使用两个参数的比较函数</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">bool</span> Point::<span class=\"hljs-keyword\">operator</span>&lt;(<span class=\"hljs-type\">const</span> Point&amp; point1)<span class=\"hljs-type\">const</span> &#123;<br>    <span class=\"hljs-keyword\">if</span> (_f == point1._f) <span class=\"hljs-keyword\">return</span> _h &gt; point1._h;<br>    <span class=\"hljs-keyword\">return</span> _f &gt; point1._f;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803183655944.png\" class=\"\" title=\"image-20230803183655944\">\n<ul>\n<li><ul>\n<li>使用一个参数的比较函数</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">bool</span> Point::<span class=\"hljs-keyword\">operator</span>&lt;(<span class=\"hljs-type\">const</span> Point&amp; point1)<span class=\"hljs-type\">const</span> &#123;<br>    <span class=\"hljs-comment\">// if (_f == point1._f) return _h &gt; point1._h;</span><br>    <span class=\"hljs-keyword\">return</span> _f &gt; point1._f;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803183939400.png\" class=\"\" title=\"image-20230803183939400\">\n<ul>\n<li><p><strong>关于插入优先队列以后是否需要更新f值的问题</strong></p>\n<p>在起初的版本中，通过简单的分析认为不需要更新f值，因为最开始认为如果能够在之前就到达的位置，再后面再到达了，说明会绕一些弯路，所以这样的f值肯定会大于或等于最开始进入openlist的结点。但在运行过程中出现了下面的问题，问题就是因为没有更新f值造成的，因为在最优路径中第一次遍历的最优路径上的点，不一定是通过最优路径中的点遍历的，所以会存在有f更小的现象。</p>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/%E9%97%AE%E9%A2%98%EF%BC%9A%E6%8F%92%E5%85%A5%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E4%BB%A5%E5%90%8E%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0f%E5%80%BC.png\" class=\"\" title=\"问题：插入优先队列以后没有更新f值\">\n<ul>\n<li><p><strong>在优先队列中查找元素的问题</strong></p>\n<p>优先队列是一个堆的结构，很适用于取出最大值或者最小值，但如果是想要从优先队列中找到某一个元素，就较为难办了，在实验中出现的场景便是，需要确认当前遍历的结点是否在优先队列中，如果在优先队列中，则需要进行比较，不在的话则插入。</p>\n<p>采用的方式是在Point类中加入了一个value参数，用于表示当前结点的状态码，当value为0时表示属于通路，1表示障碍，2表示起点，3表示终点，5表示在优先队列中，通过这样的方式便可以极大便利的获取当前结点的状态值，并达到随机访问结点状态的现象，如果某一个结点在优先队列中，只需要查看该节点的状态码即可。设置状态码还有一个好处，如果需要重新开始的话，只需要将该节点的状态码改为0即可。</p>\n</li>\n<li><p><strong>一个超级无脑的小bug</strong></p>\n<p>在调试过程中，发现无法进行多次寻路，找了将近一天，最后发现Point中使用指针存储的parent结点用于寻路，下意识的在析构函数中使用delete删除parent，因为没有给parent分配内存，是使用等号复制地址的。所以在使用界面交互进行多次寻路的过程中，出现内存被回收的问题，窗口强制退出。</p>\n</li>\n<li><p><strong>前端遇到的一些问题</strong></p>\n<p>前端需要解决的最主要的问题并不是绘图，而是资源状态的获取问题，获取鼠标事件，以及如何控制不同的点击执行不同的操作，最后使用一些bool值来进行组合完成。</p>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"A-star算法模拟实现\"><a href=\"#A-star算法模拟实现\" class=\"headerlink\" title=\"A star算法模拟实现\"></a>A star算法模拟实现</h2><h3 id=\"内容：\"><a href=\"#内容：\" class=\"headerlink\" title=\"内容：\"></a>内容：</h3><p>已知如下图地图，黑色表示障碍物无法通行，要求实现避障算法寻找从红色起点出发到达绿色终点的最优路径。</p>\n<img src=\"/2023/07/28/a-star-assignment/1.jpg\" class=\"\" title=\"img\">\n<p>要求：</p>\n<p>（1） 对图中的地图进行建模，抽象成类，对数据进行封装；</p>\n<p>（2） 思考寻路算法的实现，对问题进行拆解，对算法实现也要求抽象接口类；</p>\n<p>（3） 使用给定的C++工程模板，按照模板编写CMakeLists.txt，以及Google Test单元测试，DoxyGen注释的使用。</p>\n<h3 id=\"数据结构设计\"><a href=\"#数据结构设计\" class=\"headerlink\" title=\"数据结构设计\"></a>数据结构设计</h3><blockquote>\n<p>拿到题目最开始的想法就是想静态的实现对地图的绘制，然后对Astar算法进行复习，通过思考过后，觉得map形状，起始点，终点以及障碍，都是可以由用户通过交互的方式来完成的，进而选择将一些必要的数据聚合在类里面封装起来，本次实验一共设计了两个类，分别为Point（用于存储点的信息），Map（用于存储地图的相关信息，同时前端界面的拓展）</p>\n</blockquote>\n<h4 id=\"1、点的坐标抽象成一个结构体\"><a href=\"#1、点的坐标抽象成一个结构体\" class=\"headerlink\" title=\"1、点的坐标抽象成一个结构体\"></a>1、点的坐标抽象成一个结构体</h4><p>Xy结构体存储的是点的位置坐标，x表示横坐标，y表示纵坐标，初始值都设置为0。</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">struct Xy<br>&#123;<br>    int x <span class=\"hljs-operator\">=</span> <span class=\"hljs-number\">0</span><span class=\"hljs-comment\">;</span><br>    int y <span class=\"hljs-operator\">=</span> <span class=\"hljs-number\">0</span><span class=\"hljs-comment\">;</span><br>&#125;<span class=\"hljs-comment\">;</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"2、地图上的每一个点抽象成一个Point类\"><a href=\"#2、地图上的每一个点抽象成一个Point类\" class=\"headerlink\" title=\"2、地图上的每一个点抽象成一个Point类\"></a>2、地图上的每一个点抽象成一个Point类</h4><ul>\n<li>Point类中含有的私有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Xy _xy</td>\n<td style=\"text-align:center\">Xy结构体，存储当前Point的坐标信</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _value</td>\n<td style=\"text-align:center\">状态码，用于标记当前的坐标的Point状态</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Point类中含有的公有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">int _f</td>\n<td style=\"text-align:center\">总代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _g</td>\n<td style=\"text-align:center\">当前走过的代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _h</td>\n<td style=\"text-align:center\">到终点的代价</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point* _parent;</td>\n<td style=\"text-align:center\">存储上一个经过的Point保存路径信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point();</td>\n<td style=\"text-align:center\">默认构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Point(int m_x, int m_y, int m_value);</td>\n<td style=\"text-align:center\">重载构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">~Point();</td>\n<td style=\"text-align:center\">析构函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertAbs();</td>\n<td style=\"text-align:center\">将当前Point设置为障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFirst();</td>\n<td style=\"text-align:center\">将当前Point设置为起始点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFinal();</td>\n<td style=\"text-align:center\">将当前Point设置为终点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertNoAbs();</td>\n<td style=\"text-align:center\">将当前Point设置成非障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertPriority();</td>\n<td style=\"text-align:center\">将当前Point设置为优先队列内</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int getValue();</td>\n<td style=\"text-align:center\">获取当前状态码</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void updateF();</td>\n<td style=\"text-align:center\">更新_f值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy getXy();</td>\n<td style=\"text-align:center\">得到坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void setParent(Point&amp; p);</td>\n<td style=\"text-align:center\">设置父节点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool operator&lt;(const Point&amp; point1)const;</td>\n<td style=\"text-align:center\">重载比较函数作为优先队列第三个参数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Point类的友元函数</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, Point&amp; m_point);</td>\n<td style=\"text-align:center\">重载输出运算符打印Point信息</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3、将地图抽象程一个Map类\"><a href=\"#3、将地图抽象程一个Map类\" class=\"headerlink\" title=\"3、将地图抽象程一个Map类\"></a>3、将地图抽象程一个Map类</h4><ul>\n<li>Map类中含有的私有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">int _length;</td>\n<td style=\"text-align:center\">地图的长度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int _weight;</td>\n<td style=\"text-align:center\">地图的宽度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy _first;</td>\n<td style=\"text-align:center\">起始点的坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Xy _final;</td>\n<td style=\"text-align:center\">终点的坐标信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::vector&lt; std::vector&lt; Point  &gt; &gt; _map;</td>\n<td style=\"text-align:center\">整个地图由二维的Point组成</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::priority_queue&lt; Point &gt; _point_open;</td>\n<td style=\"text-align:center\">存放当前优先队列中的点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">std::vector&lt; Xy &gt; _path;</td>\n<td style=\"text-align:center\">寻路完毕过后的路径信息</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool _haveway = 1;</td>\n<td style=\"text-align:center\">表示当前地图是否有通路</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Map类中含有的公有成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Map();</td>\n<td style=\"text-align:center\">默认构造函数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Map(int m_length, int m_weight);</td>\n<td style=\"text-align:center\">重载构造函数，通过地图的宽和高来初始化地图</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertAbs(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为障碍</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFirst(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为起始点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void insertFinal(int x, int y);</td>\n<td style=\"text-align:center\">将当前点设置为终点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void deleteAbs(int x, int y);</td>\n<td style=\"text-align:center\">删除当前障碍点</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool isOnBoard(Xy xy);</td>\n<td style=\"text-align:center\">判断当前点是否越界</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int twoPointDistance(Xy point1, Xy point2);</td>\n<td style=\"text-align:center\">计算两点之间的斜线距离</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int gAdd(Xy point1, Xy point2);</td>\n<td style=\"text-align:center\">计算代价_g的增量距离</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void aStar();</td>\n<td style=\"text-align:center\">实现AStar算法</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void getPath();</td>\n<td style=\"text-align:center\">存储起点到终点的最短路径</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void reStart();</td>\n<td style=\"text-align:center\">刷新状态码和初始化操作</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Map类的友元函数</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, Map&amp; m_map);</td>\n<td style=\"text-align:center\">重载输出运算符，用于整个地图的输出，输出的数据为各个坐标位置的状态码</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>拓展，用于前端的成员</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">成员名</th>\n<th style=\"text-align:center\">具体含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">void paintEvent(QPaintEvent* event) override;</td>\n<td style=\"text-align:center\">重写绘图画笔事件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void mousePressEvent(QMouseEvent* event);</td>\n<td style=\"text-align:center\">重写鼠标监听事件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int start_x = 10;</td>\n<td style=\"text-align:center\">基坐标x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int start_y = 10;</td>\n<td style=\"text-align:center\">基坐标y</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int gsize = 50;</td>\n<td style=\"text-align:center\">网格大小</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool start_button = 0;<br/>bool final_button = 0;<br/>bool abs_button = 0;<br/>bool a_star_button = 0;<br/>bool clear_button = 1;<br/>bool restart_button = 0;</td>\n<td style=\"text-align:center\">鼠标资源的控制符号</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int last_x = 0;</td>\n<td style=\"text-align:center\">记录上一次鼠标点击的坐标x</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">int last_y = 0;</td>\n<td style=\"text-align:center\">记录上一次鼠标点击的坐标y</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"算法思想\"><a href=\"#算法思想\" class=\"headerlink\" title=\"算法思想\"></a>算法思想</h3><blockquote>\n<p>核心算法用到的是A-Star算法，这是一个启发式算法，属于贪心算法和bfs的结合，使用的贪心选择策略为当前预计的最小代价，通过代价函数来确定其下一步应该走的路径，每一次都记录上一次路过的结点，最终到达终点以后即可获得走过的路径。    </p>\n</blockquote>\n<figure class=\"highlight nsis\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nsis\">算法描述<br><span class=\"hljs-number\">1</span>、建一个优先队列，优先队列按照代价从低到高进行排序。<br><span class=\"hljs-number\">2</span>、计算起始点的代价，将起始点<span class=\"hljs-keyword\">push</span>到优先队列中。<br><span class=\"hljs-number\">3</span>、不断从优先队列中取出<span class=\"hljs-literal\">top</span>的元素，并将其周围的点<span class=\"hljs-keyword\">push</span>到优先队列中，周围的点满足的条件，不是障碍，且不在当前的openlist中，若在其中则比较代价大小，代价小则更新。并将父节点的记录保存下来。<br><span class=\"hljs-number\">4</span>、如果已经到了终点，则按照父节点寻找路径。<br><span class=\"hljs-number\">5</span>、若优先队列为空以后，则说明起点到终点没有路径。<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803165730214.png\" class=\"\" title=\"image-20230803165730214\">\n<h3 id=\"输入描述\"><a href=\"#输入描述\" class=\"headerlink\" title=\"输入描述\"></a>输入描述</h3><ul>\n<li><p>地图的长和宽</p>\n<p>用户手动输入地图的长和宽，得到长和宽以后，会自动初始化地图大小</p>\n</li>\n<li><p>输入起始点</p>\n<p>选择地图上的某一空白处作为起始点</p>\n</li>\n<li><p>输入终点</p>\n<p>选择地图上的某一空白处作为终点</p>\n</li>\n<li><p>输入障碍</p>\n<p>选择地图上的空白处可以设置为障碍</p>\n</li>\n<li><p>清除障碍</p>\n<p>点击clear_abs可以将障碍清除</p>\n</li>\n<li><p>寻路</p>\n<p>点击a-star进行从起点到终点的寻路</p>\n</li>\n</ul>\n<h4 id=\"输入测试：\"><a href=\"#输入测试：\" class=\"headerlink\" title=\"输入测试：\"></a>输入测试：</h4><blockquote>\n<p>在本次实验中，一共设置了6个可以提供选择的按钮，当按钮处于灰色状态时，代表按钮处于未被激活状态，即该按钮不可点击，当按钮处于蓝色则说明按钮可点击。</p>\n<p>ADD_FIRST        设置起点</p>\n<p>ADD_FINAL        设置终点</p>\n<p>A_STAR                使用Astar开始寻路</p>\n<p>ADD_ABS            设置障碍</p>\n<p>CLEAR_ABS            清除障碍</p>\n<p>RESTART                重新开始，将一些状态清除</p>\n</blockquote>\n<ul>\n<li>测试一、5行10列</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803171605818.png\" class=\"\" title=\"image-20230803171605818\">\n<ul>\n<li>测试二、3行5列</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803171645811.png\" class=\"\" title=\"image-20230803171645811\">\n<h4 id=\"结果测试\"><a href=\"#结果测试\" class=\"headerlink\" title=\"结果测试\"></a>结果测试</h4><blockquote>\n<p>结果说明：</p>\n<p>绿色的网格代表设置的起点</p>\n<p>红色的网格代表设置的终点</p>\n<p>黑色的网格代表设置的障碍</p>\n<p>白色的网格代表可以通路</p>\n<p>灰色的网格代表寻路算法经过的搜索空间</p>\n</blockquote>\n<ul>\n<li>测试一、无障碍情况</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803172210807.png\" class=\"\" title=\"image-20230803172210807\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173053255.png\" class=\"\" title=\"image-20230803173053255\">\n<ul>\n<li>测试二、随机障碍情况</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173141837.png\" class=\"\" title=\"image-20230803173141837\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173212434.png\" class=\"\" title=\"image-20230803173212434\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173244879.png\" class=\"\" title=\"image-20230803173244879\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173329009.png\" class=\"\" title=\"image-20230803173329009\">\n<ul>\n<li><p>测试三、无通路情况</p>\n<blockquote>\n<p>没有通路，则不会寻路，状态码为5的表示搜索到了的位置，从打印出的状态码中可以看出，搜索在障碍的边界处便中断了。</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173754572.png\" class=\"\" title=\"image-20230803173754572\">\n<img src=\"/2023/07/28/a-star-assignment/image-20230803173808529.png\" class=\"\" title=\"image-20230803173808529\">\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><h4 id=\"遇到的一些问题\"><a href=\"#遇到的一些问题\" class=\"headerlink\" title=\"遇到的一些问题\"></a>遇到的一些问题</h4><ul>\n<li><p><strong>优先队列中比较函数的使用</strong></p>\n<p>最开始使用的是代价f值作为比较函数中的参数，这样会导致一种情况，如果有两个代价一样的结点插入优先队列的时候，在下一次弹出优先队列的过程中，代价一样的结点会按照进入队列的先后顺序来进行弹出，也就是说在代价相同的结点中是按照广度优先的方式来进行的。但是如果我们在f值相同的情况下，再对h值进行比较，每次优先选择h值最小即最接近终点的结点出队列，这样就会将解空间缩小很多，具体案例如下所示。</p>\n<ul>\n<li>使用两个参数的比较函数</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">bool</span> Point::<span class=\"hljs-keyword\">operator</span>&lt;(<span class=\"hljs-type\">const</span> Point&amp; point1)<span class=\"hljs-type\">const</span> &#123;<br>    <span class=\"hljs-keyword\">if</span> (_f == point1._f) <span class=\"hljs-keyword\">return</span> _h &gt; point1._h;<br>    <span class=\"hljs-keyword\">return</span> _f &gt; point1._f;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803183655944.png\" class=\"\" title=\"image-20230803183655944\">\n<ul>\n<li><ul>\n<li>使用一个参数的比较函数</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">bool</span> Point::<span class=\"hljs-keyword\">operator</span>&lt;(<span class=\"hljs-type\">const</span> Point&amp; point1)<span class=\"hljs-type\">const</span> &#123;<br>    <span class=\"hljs-comment\">// if (_f == point1._f) return _h &gt; point1._h;</span><br>    <span class=\"hljs-keyword\">return</span> _f &gt; point1._f;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/image-20230803183939400.png\" class=\"\" title=\"image-20230803183939400\">\n<ul>\n<li><p><strong>关于插入优先队列以后是否需要更新f值的问题</strong></p>\n<p>在起初的版本中，通过简单的分析认为不需要更新f值，因为最开始认为如果能够在之前就到达的位置，再后面再到达了，说明会绕一些弯路，所以这样的f值肯定会大于或等于最开始进入openlist的结点。但在运行过程中出现了下面的问题，问题就是因为没有更新f值造成的，因为在最优路径中第一次遍历的最优路径上的点，不一定是通过最优路径中的点遍历的，所以会存在有f更小的现象。</p>\n</li>\n</ul>\n<img src=\"/2023/07/28/a-star-assignment/%E9%97%AE%E9%A2%98%EF%BC%9A%E6%8F%92%E5%85%A5%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E4%BB%A5%E5%90%8E%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0f%E5%80%BC.png\" class=\"\" title=\"问题：插入优先队列以后没有更新f值\">\n<ul>\n<li><p><strong>在优先队列中查找元素的问题</strong></p>\n<p>优先队列是一个堆的结构，很适用于取出最大值或者最小值，但如果是想要从优先队列中找到某一个元素，就较为难办了，在实验中出现的场景便是，需要确认当前遍历的结点是否在优先队列中，如果在优先队列中，则需要进行比较，不在的话则插入。</p>\n<p>采用的方式是在Point类中加入了一个value参数，用于表示当前结点的状态码，当value为0时表示属于通路，1表示障碍，2表示起点，3表示终点，5表示在优先队列中，通过这样的方式便可以极大便利的获取当前结点的状态值，并达到随机访问结点状态的现象，如果某一个结点在优先队列中，只需要查看该节点的状态码即可。设置状态码还有一个好处，如果需要重新开始的话，只需要将该节点的状态码改为0即可。</p>\n</li>\n<li><p><strong>一个超级无脑的小bug</strong></p>\n<p>在调试过程中，发现无法进行多次寻路，找了将近一天，最后发现Point中使用指针存储的parent结点用于寻路，下意识的在析构函数中使用delete删除parent，因为没有给parent分配内存，是使用等号复制地址的。所以在使用界面交互进行多次寻路的过程中，出现内存被回收的问题，窗口强制退出。</p>\n</li>\n<li><p><strong>前端遇到的一些问题</strong></p>\n<p>前端需要解决的最主要的问题并不是绘图，而是资源状态的获取问题，获取鼠标事件，以及如何控制不同的点击执行不同的操作，最后使用一些bool值来进行组合完成。</p>\n</li>\n</ul>\n"},{"title":"高性能键值存储系统实现","date":"2024-02-27T03:29:57.000Z","cover":"/img/default_cover04.jpg","top_img":null,"_content":"### \n\n# 简易Redis的实现\n\n这个项目实现了一个简易的redis，使用hashmap来管理键值对数据，使用hashmap+AVL数来管理Zset数据，并实现了hashmap的渐进式扩容，减少因为扩容重新哈希化带来rehash的代价。使用poll技术来实现IO多路复用，完成一个服务端与多个客户端建立连接的过程，使用双向链表来管理连接，通过最小堆来控制val的生存时间，并通过将两者结合的方式，控制poll的最大超时时间，用来确保每一次poll的陷入内核和退出内核在主进程中都有处理的任务。\n\n1、最小堆的维护，当为某一个key设置好ttl时，会将key当中需要维护的ttl放入到最小堆当中，每一次轮询结束以后，会统一进行处理，已经失效的key\n\n2、双向链表的维护，poll当中，会把第一个fd设置成为用于处理连接事件的fd，当有连接事件发生的时候，会处理连接，接受一个新的连接，并将其放入到双向链表的头部，会有一个conn的结构体，里面实现了读写缓存，以及接受当前连接的空闲队列节点，以及建立连接的时间，然后会把这个连接放入到空闲队列当中的头部。\n\n3、过期时间的处理，会在每一次poll以及对应的事件处理结束以后，对当前的key进行ttl的检查，包括conn的过期时间和key的过期时间，会对空闲队列中的一些长期占用时间的连接进行清除，以及最小堆当中过期的key进行清理（不断地pop掉最小堆当中的数据，直到没有那些超时数据）。\n\n4、线程池的作用，当缓存数据过多时，实现异步清除。\n\n## 一、实现的命令\n\n```txt\n// hashtable\nset key value\t向哈希表中插入键值对\nget key\t\t\t从哈希表中查找键对应的值\ndel key\t\t\t从哈希表中删除键\nkeys\t\t\t打印出哈希表中所有的keys\n\n// zset\nzadd key score name\t\t向键为key中，插入name，score\nzscore key name\t\t\t按照key和name查找score\nzrem key name\t\t\t删除键为key中的name元素\nzscore key name\t\t\t查找键为key的name的score\nzquery\n\n```\n\n\n\n## 二、Socket编程相关语法\n\n### 服务端\n\n* 创建句柄\n\n函数原型：`int socket(int domain, int type, int protocol);`\n\ndomin：指定通信域，ipv4或ipv6，AF_INET表示ipv4地址\n\ntype：指定套接字类型\n\nprotocol：0表示为TCP协议\n\n* 设置socket可选项\n* Bind，绑定ip和端口号\n* Listen\n\n```c++\nvoid Server::run_server() {\n    \n    // init coding...\n\n    if (fd < 0) {\n        die(\"socket()\");\n    }\n\n    int val = 1;\n    setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &val, sizeof(val));\n\n    // bind\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(0);\n    int rv = bind(fd, (const sockaddr *)&addr, sizeof(addr));\n    if (rv) {\n        die(\"bind()\");\n    }\n\n    // listen\n    rv = listen(fd, SOMAXCONN);\n    if (rv) {\n        die(\"listen()\");\n    }\n\n    // coding...\n}\n\nint main() {\n    int fd = socket(AF_INET, SOCK_STREAM, 0);\n    // bind\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(0);    // wildcard address 0.0.0.0\n    Server server(addr, fd);\n    \n    server.run_server();\n    return 0;\n}\n\n```\n\n### 客户端\n\n* 创建句柄\n* 设置IP地址和端口号\n* Connect\n\n```C++\nvoid Client::run_client(int argc, char **argv) {\n    if (fd < 0) {\n        die(\"socket()\");\n    }\n\n    int rv = connect(fd, (const struct sockaddr *)&addr, sizeof(addr));\n    if (rv) {\n        die(\"connect\");\n    }\n\n    // coding...\n\n    close(fd);\n}\n\nint main(int argc, char **argv) {\n    int fd = socket(AF_INET, SOCK_STREAM, 0);\n\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(INADDR_LOOPBACK);  // 127.0.0.1\n    \n    Client client(addr, fd);\n    client.run_client(argc, argv);\n\n    return 0;\n}\n```\n\n**使用的协议**\n\nlen+msg的结合\n\nlen表示后面的字长，msg表示要获取的数据\n\n\n\n## 三、事件循环和非阻塞型IO\n\n> 在服务器端网络编程中，处理并发连接有三种方法：forking、多线程（multi-threading）和事件循环（event loops）。forking会为每个客户端连接创建新的进程以实现并发。多线程使用线程而不是进程。事件循环使用轮询和非阻塞 I/O，通常在单个线程上运行。由于进程和线程的开销，大多数现代生产级软件使用事件循环来进行网络编程。\n\n在项目中用到了IO多路复用中的poll技术来实现，在服务端使用单个进程和多个客户端建立连接，在客户端看来，像是每一个客户端都和一个独立的服务端建立了连接并进行数据通信，而在服务端看来，它所完成的则是在不同的时间段服务不同的客户，但由于时间片比较小，就会让客户端感觉好像实现了多个进程通信的过程。\n\n\n## 四、哈希表数据结构\n\n### 数据结构\n\n* 哈希节点\n\n  哈希表节点是以链表的形式存储，包含一个next节点和一个hcode（哈希化以后的映射值）\n\n```c++\n// 哈希表节点\nstruct HNode {\n    HNode *next = NULL;\n    uint64_t hcode = 0;\n};\n```\n\n* 哈希表\n\n  哈希表主要载体是一个HNode的二维指针，第一个指针代表的是哈希值，第二个指针存储的是链表，链表是用来解决哈希冲突的方式。size表示的是当前哈希表中的总结点数目，mask表示掩码，为哈希表第一个维度大小减1。\n\n  在哈希表中实现了，insert，lookup，detach，init接口，分别表示节点的插入，节点的查找，节点的删除。\n\n  需要使用有参的构造函数初始化，传入的参数为整型，整型必须为2的幂，便于构建mask。\n\n  * 节点的插入过程\n\n    1、先计算当前节点中hcode应该属于的pos（即链表位置），计算方式是与`&`上mask\n\n    2、使用头插法，将节点插入到对应的位置，修改size大小\n\n  * 节点的查找过程\n\n    1、查找哈希化后的链表位置。\n\n    2、在链表中查找当前节点。\n\n  * 节点的删除过程`HNode *detach(HNode **from)`\n\n    1、解除引用，获取链表位置\n\n    2、绕过当前节点，指向下一节点\n\n    3、具体使用需要先找到节点位置，再调用detach\n\n```C++\n// 哈希表\n// 接口: insert, lookup, detach\nclass HTab {\nprivate:\n    HNode **tab = NULL;\n    size_t size = 0;\n    size_t mask = 0;\n\npublic:\n    HTab() = default;\n    // 传入的n必须为2的幂\n    HTab(size_t n): size(0), mask(n-1){\n        assert((n & (n-1)) == 0);\n        tab = new HNode*[n];\n    };\n    ~HTab() { delete[] tab; }\n\n    void insert(HNode *node);\n    HNode *lookup(HNode *key, bool (*eq)(HNode *, HNode *));\n    HNode *detach(HNode **from);\n\n    // setter\n    void set_tab(HNode **t) { tab = t; }\n    void set_mask(size_t m) { mask = m; }\n    void set_size(size_t s) { size = s; }\n\n    // getter\n    HNode **get_tab() { return tab; }\n    size_t get_mask() { return mask; }\n    size_t get_size() { return size; }\n};\n```\n\n* 哈希map\n\n  哈希表中含有两个HTab，用于完成渐进式的rehash。第一张表存储新的键值，第二张表存储旧的键值，当在第一张表中查找不到元素时，会再在第二张表查找。\n\n  固定值的设置，k_max_load_factor表示负载因子，设置为8，即表示当前的总的HMap的节点数大于Mask的8倍的时候，就会对哈希表进行扩容。k_resizing_work的大小表示将哈希扩容分配到各个语句当中的单次转移的节点数量。resizing_pos记录resizing的位置。\n\n  哈希Map实现了，insert，lookup，pop，size，destroy的接口，分别表示**插入，查找，删除，返回哈希map节点数，以及销毁**。同时会在负载过大时，重新申请更大的内存，执行resize操作，并分发到其他语句当中。\n\n  start_resizing：检查ht2节点数是否大于零，若大于零，说明正在进行rehash中，将指定数量的节点rehash\n\n  start_resizing：分配一个更大的表给ht1，要提前将ht2指向ht1\n\n  * 插入的实现\n\n    1、将节点插入到ht1当中，如果ht1为空，则新建ht1\n\n    2、检查ht2是否为空，如果为空，则检查表1的负载因子，大于特定值，则开始resizing，如果ht2不为空，则说明正在resize，执行help_resizing。\n\n  * 查找的实现\n\n    1、执行start_resizing\n\n    2、分别在ht1和ht2中查找\n\n  * 删除的实现\n\n    1、执行start_resizing\n\n    2、执行查找，用返回节点执行节点删除\n\n```c++\n\n// 哈希map\n// 使用两张哈希表用于渐进式rehash\n// 接口: insert, lookup, pop, size, destroy\n// private: start_resizing, help_resizing\nclass HMap {\npublic:\n    HTab ht1;   // newer\n    HTab ht2;   // older\nprivate:\n    size_t resizing_pos = 0;    \n    const size_t k_resizing_work = 128; // constant work\n    const size_t k_max_load_factor = 8; // constant load factor\n    void help_resizing();\n    void start_resizing();\n\npublic:\n    HMap() : ht1(1), ht2(1), resizing_pos(0) {};\n    HMap(size_t n): ht1(n), ht2(1), resizing_pos(0) {};\n    ~HMap() { ht1.~HTab(); ht2.~HTab(); }\n\n    // 插入、查找、删除、大小、销毁\n    void insert(HNode *node);\n    HNode *lookup(HNode *key, bool (*eq)(HNode *, HNode *));\n    HNode *pop(HNode *key, bool (*eq)(HNode *, HNode *));\n    size_t size();\n    void destroy();\n};\n```\n\n实际应用过程中还会有一个结构体\n\n将哈希表节点和键值对进行绑定\n\n```c++\nstruct Entry {\n    struct HNode node;\n    std::string key;\n    std::string val;\n};\n```\n\n### 渐进式rehash过程\n\n在哈希表的构建时，使用的是用二维指针来存储哈希表，解决哈希冲突的方式是常用的拉链法（使用链表存储映射值相等的哈希元素），第一个维度作为哈希映射的key值来定位到具体的映射链表，第二个维度则是用来解决哈希冲突的，考虑到哈希表定义本身的属性，我们是希望哈希表的哈希冲突尽可能少，也就是我们的链表的长度尽可能短，随着我们插入的数据不断增加，我们产生的哈希冲突也是会增加的。\n\n在这里我们定义了一个负载因子`k_max_load_factor`，在实际插入的过程中，当当前用于查找的哈希表中的负载（元素个数/掩码）大于负载因子，会启动rehash的过程，我们会申请一张比原来哈希表大两倍的哈希表，将当前哈希表中的数据重新映射到这一张新的哈希表中。这样我们原来短，高的哈希表，就会变成长，矮的哈希表。\n\n我们知道，当哈希表中的元素过多的时候，需要对所有元素都一起进行rehash是一个非常耗时的过程，如果我们只有一张哈希表，我们在进行rehash的过程中，还不能够允许其他插入、删除以及查询操作，为了解决这样一个问题，我们采用将rehash分散在各个其他语句的步骤，在我们负载因子达到一定程度的时候，我们会启动渐进式rehash，当我们有其他插入或者查询语句到来的时候，我们会先进行部分node的rehsah，再进行查询语句。我们可以看下面例子。\n\n```C++\nHNode *HMap::lookup(HNode *key, bool (*eq)(HNode *, HNode *)) {\n    help_resizing();\n    HNode **from = ht1.lookup(key, eq);\n    from = from ? from : ht2.lookup(key, eq);\n    return from ? *from : NULL;\n}\n\n// class HMap\nvoid HMap::help_resizing() {\n    size_t nwork = 0;\n    while (nwork < k_resizing_work && ht2.get_size() > 0) {\n        // scan for nodes from ht2 and move them to ht1\n        HNode **from = &ht2.get_tab()[resizing_pos];\n        if (!*from) {\n            resizing_pos++;\n            continue;\n        }\n\n        ht1.insert(ht2.detach(from));\n        nwork++;\n    }\n\n    if (ht2.get_size() == 0 && ht2.get_tab()) {\n        // done\n        delete[] ht2.get_tab();\n        ht2 = HTab{};\n    }\n}\n```\n\n\n\n## 五、平衡二叉树\n\n平衡二叉树是一种特殊的二叉搜索树，对平衡二叉树来说，它的中序遍历是有序的，并且左右子树的高度差会处于一个平衡的状态，这样可以保证每次查找都能够在比较快的时间内完成。\n\n### 数据结构\n\n> 平衡二叉树本身就是由节点构成的\n\ndepth：以当前节点为根节点所在树的高度\n\ncnt：以当前节点为根节点的总节点数，便于进行区间统计\n\nleft：左节点，right：右节点，parent：父节点\n\n提供的辅助函数\n\n* rot_left：对当前节点进行左旋操作\n\n```\n// 对b节点进行左旋，返回d节点\n  b         d\n / \\       /\na   d ==> b\n   /     / \\\n  c     a   c\n```\n\n* rot_right：镜像操作\n\n* avl_fix_left\n\n  1、左子树的右子树太深需要先左旋后右旋\n\n  2、左子树的左子树太深，直接右旋\n\n```\n   root\n   /            左旋(root->left)\n  A\n / \\\nB   C\n   / \\\n  D   E\n  \n   root\n   /              右旋(root)\n  C\n / \\\nA   E\n/ \\\nB   D\n\n    C\n   / \\\n  A   root\n / \\    \\\nB   D    E\n```\n\n* avl_fix_right也类似\n\n* avl_fix：对平衡二叉树的修复，当执行删除和插入节点时，调用这个函数保持节点的平衡\n\n* avl_del：删除节点\n\n  1、当当前要删除的节点不存在右节点时，如果有左子树，将左子树向上提，如果没有左子树，说明删除的是root，最终都是返回左子树，返回左子树\n\n  2、如果存在右节点，递归的找到右节点当中的最小元素，修改树的结构\n\n* avl_offset：从当前节点出发，按照偏移来进行查找节点\n\n  1、初始化pos为0，表示当前节点相对于起始节点的位置\n\n  2、如果pos等于偏移量，则返回\n\n  3、如果小于偏移量，并且加上右节点的节点数大于offset，则说明在右子树\n\n  4、如果大于偏移量，并且减去左节点的节点数小于offset，说明在左子树\n\n  5、否则在父节点\n\n```C++\n// 平衡二叉树\nclass AVLNode\n{\nprivate:\n    uint32_t depth = 0;\n    uint32_t cnt = 0;\n    AVLNode *left = NULL;\n    AVLNode *right = NULL;\n    AVLNode *parent = NULL;\n\npublic:\n    AVLNode(AVLNode *node);\n    AVLNode();\n    ~AVLNode();\n    AVLNode *avl_fix(AVLNode *node);\n    AVLNode *avl_del(AVLNode *node);\n    AVLNode *avl_offset(AVLNode *node, int64_t offset);\n\n    // get \n    uint32_t avl_depth(AVLNode *node);\n    uint32_t avl_cnt(AVLNode *node);\n    uint32_t max(uint32_t lhs, uint32_t rhs);\n    void avl_update(AVLNode *node);\n    \n    AVLNode *rot_left(AVLNode *node);\n    AVLNode *rot_right(AVLNode *node);\n    AVLNode *avl_fix_left(AVLNode *root);\n    AVLNode *avl_fix_right(AVLNode *root);\n\nprivate:\n};\n```\n\n\n\n## 六、zset数据结构\n\nzset在Redis中是使用跳表+哈希表来实现的\n\n这里使用AVL树+哈希表来实现\n\n* ZNode\n\n  ZNode中需要存储AVL树节点以及哈希节点，同时存储score是用于排序的键，ZNode中携带的数据可以提供快速查找，也支持有序访问，node同时属于AVL树和哈希表。\n\n```C++\nclass ZNode {\npublic:\n    AVLNode tree; // AVL树节点\n    HNode hmap;   // 哈希表节点\n    double score; // 分数\n    size_t len;   // 名称长度\n    char name[0];\n\n    ZNode(const char* name, size_t len, double score);\n    ~ZNode() = default;\n};\n```\n\n* ZSet\n\n  在ZSet中包含一个tree指向平衡二叉树的根节点，平衡二叉树关联着ZNode中的tree，同时维护一张HMap哈希表，用于对数据的快速查找\n\n|                             接口                             |                    功能                     |\n| :----------------------------------------------------------: | :-----------------------------------------: |\n|      ZNode *zset_lookup(const char *name, size_t len);       |  根据传入的name来进行查找，从哈希表中查找   |\n|  bool zset_add(const char *name, size_t len, double score);  |          向ZSet中添加一个节点元素           |\n|        ZNode *zset_pop(const char *name, size_t len);        |    从ZSet中弹出一个元素，按照name来弹出     |\n| ZNode *zset_query(double score, const char *name, size_t len); |     查找ZSet中分数以及name都相等的ZNode     |\n|      ZNode *znode_offset(ZNode *node, int64_t offset);       |     根据分数的偏移从AVLtree中查找ZNode      |\n|                     void zset_dispose();                     | 清空当前的ZSet，包括AVL树的清空和hmap的清空 |\n\n```C++\nclass ZSet\n{\nprivate:\n    AVLNode *tree = nullptr;\n    HMap hmap;\n\npublic:\n    ZSet() = default;\n    ~ZSet() { zset_dispose(); }\n\n    // helper\n    ZNode *znode_new(const char *name, size_t len, double score);\n    uint32_t min(size_t lhs, size_t rhs);\n    bool zless(AVLNode *lhs, double score, const char *name, size_t len);\n    bool zless(AVLNode *lhs, AVLNode *rhs);\n    void zset_update(ZNode *node, double score);\n    void tree_add(ZNode *node);\n    \n    // interface\n    bool zset_add(const char *name, size_t len, double score);\n    // 根据键值来查找哈希表\n    ZNode *zset_lookup(const char *name, size_t len);\n    ZNode *zset_pop(const char *name, size_t len);\n    ZNode *zset_query(double score, const char *name, size_t len);\n    ZNode *znode_offset(ZNode *node, int64_t offset);\n    void znode_del(ZNode *node);\n    void tree_dispose(AVLNode *node);\n    void zset_dispose();\n};\n```\n\nzset_lookup\n\n按照name在ZSet中查找节点\n\n* 直接通过hmap查找\n\n```C++\nZNode *ZSet::zset_lookup(const char *name, size_t len) {\n    if(!tree) {\n        return nullptr;\n    }\n    HKey key;\n    key.node.hcode = str_hash((uint8_t*)name, len);\n    key.name = name;\n    key.len = len;\n    HNode *found = hmap.lookup(&key.node, &hcmp);\n    return found ? container_of(found, ZNode, hmap) : nullptr;\n}\n```\n\nzset_add\n\n* 先查找set中是否存在有对应的节点，如果有则更新value的值\n* 如果没有，则生成一个新的znode并插入到zset中\n\n```C++\nbool ZSet::zset_add(const char *name, size_t len, double score) {\n    ZNode *node = zset_lookup(name, len);\n    if (node) {\n        zset_update(node, score);\n        return false;\n    } else {\n        node = znode_new(name, len, score);\n        hmap.insert(&node->hmap);\n        tree_add(node);\n        return true;\n    }\n}\n```\n\nzset_pop\n\n> 通过name在zset数据结构中弹出对应的节点\n\n* 先从哈希表中查找对应的哈希节点\n* 通过找到的节点找到节点的Znode\n* 在AVL书中删除对应的Znode，并返回当前节点\n\n```C++\nZNode *ZSet::zset_pop(const char *name, size_t len) {\n    if(!tree) {\n        return nullptr;\n    }\n\n    HKey key;\n    key.node.hcode = str_hash((uint8_t*)name, len);\n    key.name = name;\n    key.len = len;\n    HNode *found = hmap.lookup(&key.node, &hcmp);\n    if(!found) {\n        return nullptr;\n    }\n\n    ZNode *node = found->owner;\n    tree = tree->avl_del(&node->tree);\n    return node;\n}\n```\n\nzset_query\n\n> 通过分数以及name查找的znode\n\n* 先通过分数在AVL树上进行查找，是一个二分查找的过程\n* 再通过比较查找得到的节点的name是否相等来对比返回结果\n\n```C++\nZNode *ZSet::zset_query(double score, const char *name, size_t len) {\n    AVLNode *found = nullptr;\n    AVLNode *cur = tree;\n    while(cur) {\n        if(zless(cur, score, name, len)) {\n            cur = cur->right;\n        } else {\n            found = cur;\n            cur = cur->left;\n        }\n    }\n    return found ? found->owner : nullptr;\n}\n\nbool ZSet::zless(AVLNode *lhs, double score, const char *name, size_t len) {\n    // 根据指针偏移找到ZNode\n    auto zl = lhs->owner;\n    if (zl->score != score) {\n        return zl->score < score;\n    }\n    int rv = memcmp(zl->name, name, min(zl->len, len));\n    if (rv != 0) {\n        return rv < 0;\n    }\n    return zl->len < len;\n}\n```\n\nznode_offset\n\n> 根据score的偏移在AVL树中查找Znode。在我们的代码中AVL节点的定义，参考上面的avl_offset文字算法伪代码\n\n```C++\nZNode *ZSet::znode_offset(ZNode *node, int64_t offset) {\n    AVLNode *tnode = node ? tree->avl_offset(&node->tree, offset) : nullptr;\n    return tnode ? tnode->owner : nullptr;\n}\n```\n\n\n## 七、测试效果\n\n\n","source":"_posts/build-sample-redis.md","raw":"---\ntitle: 高性能键值存储系统实现\ntags:\n  - 数据库\n  - Redis\n  - 数据库缓存\n  - C++\ncategories: 算法实践\ndate: 2024-02-27 11:29:57\ncover:\ntop_img:\n---\n### \n\n# 简易Redis的实现\n\n这个项目实现了一个简易的redis，使用hashmap来管理键值对数据，使用hashmap+AVL数来管理Zset数据，并实现了hashmap的渐进式扩容，减少因为扩容重新哈希化带来rehash的代价。使用poll技术来实现IO多路复用，完成一个服务端与多个客户端建立连接的过程，使用双向链表来管理连接，通过最小堆来控制val的生存时间，并通过将两者结合的方式，控制poll的最大超时时间，用来确保每一次poll的陷入内核和退出内核在主进程中都有处理的任务。\n\n1、最小堆的维护，当为某一个key设置好ttl时，会将key当中需要维护的ttl放入到最小堆当中，每一次轮询结束以后，会统一进行处理，已经失效的key\n\n2、双向链表的维护，poll当中，会把第一个fd设置成为用于处理连接事件的fd，当有连接事件发生的时候，会处理连接，接受一个新的连接，并将其放入到双向链表的头部，会有一个conn的结构体，里面实现了读写缓存，以及接受当前连接的空闲队列节点，以及建立连接的时间，然后会把这个连接放入到空闲队列当中的头部。\n\n3、过期时间的处理，会在每一次poll以及对应的事件处理结束以后，对当前的key进行ttl的检查，包括conn的过期时间和key的过期时间，会对空闲队列中的一些长期占用时间的连接进行清除，以及最小堆当中过期的key进行清理（不断地pop掉最小堆当中的数据，直到没有那些超时数据）。\n\n4、线程池的作用，当缓存数据过多时，实现异步清除。\n\n## 一、实现的命令\n\n```txt\n// hashtable\nset key value\t向哈希表中插入键值对\nget key\t\t\t从哈希表中查找键对应的值\ndel key\t\t\t从哈希表中删除键\nkeys\t\t\t打印出哈希表中所有的keys\n\n// zset\nzadd key score name\t\t向键为key中，插入name，score\nzscore key name\t\t\t按照key和name查找score\nzrem key name\t\t\t删除键为key中的name元素\nzscore key name\t\t\t查找键为key的name的score\nzquery\n\n```\n\n\n\n## 二、Socket编程相关语法\n\n### 服务端\n\n* 创建句柄\n\n函数原型：`int socket(int domain, int type, int protocol);`\n\ndomin：指定通信域，ipv4或ipv6，AF_INET表示ipv4地址\n\ntype：指定套接字类型\n\nprotocol：0表示为TCP协议\n\n* 设置socket可选项\n* Bind，绑定ip和端口号\n* Listen\n\n```c++\nvoid Server::run_server() {\n    \n    // init coding...\n\n    if (fd < 0) {\n        die(\"socket()\");\n    }\n\n    int val = 1;\n    setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &val, sizeof(val));\n\n    // bind\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(0);\n    int rv = bind(fd, (const sockaddr *)&addr, sizeof(addr));\n    if (rv) {\n        die(\"bind()\");\n    }\n\n    // listen\n    rv = listen(fd, SOMAXCONN);\n    if (rv) {\n        die(\"listen()\");\n    }\n\n    // coding...\n}\n\nint main() {\n    int fd = socket(AF_INET, SOCK_STREAM, 0);\n    // bind\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(0);    // wildcard address 0.0.0.0\n    Server server(addr, fd);\n    \n    server.run_server();\n    return 0;\n}\n\n```\n\n### 客户端\n\n* 创建句柄\n* 设置IP地址和端口号\n* Connect\n\n```C++\nvoid Client::run_client(int argc, char **argv) {\n    if (fd < 0) {\n        die(\"socket()\");\n    }\n\n    int rv = connect(fd, (const struct sockaddr *)&addr, sizeof(addr));\n    if (rv) {\n        die(\"connect\");\n    }\n\n    // coding...\n\n    close(fd);\n}\n\nint main(int argc, char **argv) {\n    int fd = socket(AF_INET, SOCK_STREAM, 0);\n\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(INADDR_LOOPBACK);  // 127.0.0.1\n    \n    Client client(addr, fd);\n    client.run_client(argc, argv);\n\n    return 0;\n}\n```\n\n**使用的协议**\n\nlen+msg的结合\n\nlen表示后面的字长，msg表示要获取的数据\n\n\n\n## 三、事件循环和非阻塞型IO\n\n> 在服务器端网络编程中，处理并发连接有三种方法：forking、多线程（multi-threading）和事件循环（event loops）。forking会为每个客户端连接创建新的进程以实现并发。多线程使用线程而不是进程。事件循环使用轮询和非阻塞 I/O，通常在单个线程上运行。由于进程和线程的开销，大多数现代生产级软件使用事件循环来进行网络编程。\n\n在项目中用到了IO多路复用中的poll技术来实现，在服务端使用单个进程和多个客户端建立连接，在客户端看来，像是每一个客户端都和一个独立的服务端建立了连接并进行数据通信，而在服务端看来，它所完成的则是在不同的时间段服务不同的客户，但由于时间片比较小，就会让客户端感觉好像实现了多个进程通信的过程。\n\n\n## 四、哈希表数据结构\n\n### 数据结构\n\n* 哈希节点\n\n  哈希表节点是以链表的形式存储，包含一个next节点和一个hcode（哈希化以后的映射值）\n\n```c++\n// 哈希表节点\nstruct HNode {\n    HNode *next = NULL;\n    uint64_t hcode = 0;\n};\n```\n\n* 哈希表\n\n  哈希表主要载体是一个HNode的二维指针，第一个指针代表的是哈希值，第二个指针存储的是链表，链表是用来解决哈希冲突的方式。size表示的是当前哈希表中的总结点数目，mask表示掩码，为哈希表第一个维度大小减1。\n\n  在哈希表中实现了，insert，lookup，detach，init接口，分别表示节点的插入，节点的查找，节点的删除。\n\n  需要使用有参的构造函数初始化，传入的参数为整型，整型必须为2的幂，便于构建mask。\n\n  * 节点的插入过程\n\n    1、先计算当前节点中hcode应该属于的pos（即链表位置），计算方式是与`&`上mask\n\n    2、使用头插法，将节点插入到对应的位置，修改size大小\n\n  * 节点的查找过程\n\n    1、查找哈希化后的链表位置。\n\n    2、在链表中查找当前节点。\n\n  * 节点的删除过程`HNode *detach(HNode **from)`\n\n    1、解除引用，获取链表位置\n\n    2、绕过当前节点，指向下一节点\n\n    3、具体使用需要先找到节点位置，再调用detach\n\n```C++\n// 哈希表\n// 接口: insert, lookup, detach\nclass HTab {\nprivate:\n    HNode **tab = NULL;\n    size_t size = 0;\n    size_t mask = 0;\n\npublic:\n    HTab() = default;\n    // 传入的n必须为2的幂\n    HTab(size_t n): size(0), mask(n-1){\n        assert((n & (n-1)) == 0);\n        tab = new HNode*[n];\n    };\n    ~HTab() { delete[] tab; }\n\n    void insert(HNode *node);\n    HNode *lookup(HNode *key, bool (*eq)(HNode *, HNode *));\n    HNode *detach(HNode **from);\n\n    // setter\n    void set_tab(HNode **t) { tab = t; }\n    void set_mask(size_t m) { mask = m; }\n    void set_size(size_t s) { size = s; }\n\n    // getter\n    HNode **get_tab() { return tab; }\n    size_t get_mask() { return mask; }\n    size_t get_size() { return size; }\n};\n```\n\n* 哈希map\n\n  哈希表中含有两个HTab，用于完成渐进式的rehash。第一张表存储新的键值，第二张表存储旧的键值，当在第一张表中查找不到元素时，会再在第二张表查找。\n\n  固定值的设置，k_max_load_factor表示负载因子，设置为8，即表示当前的总的HMap的节点数大于Mask的8倍的时候，就会对哈希表进行扩容。k_resizing_work的大小表示将哈希扩容分配到各个语句当中的单次转移的节点数量。resizing_pos记录resizing的位置。\n\n  哈希Map实现了，insert，lookup，pop，size，destroy的接口，分别表示**插入，查找，删除，返回哈希map节点数，以及销毁**。同时会在负载过大时，重新申请更大的内存，执行resize操作，并分发到其他语句当中。\n\n  start_resizing：检查ht2节点数是否大于零，若大于零，说明正在进行rehash中，将指定数量的节点rehash\n\n  start_resizing：分配一个更大的表给ht1，要提前将ht2指向ht1\n\n  * 插入的实现\n\n    1、将节点插入到ht1当中，如果ht1为空，则新建ht1\n\n    2、检查ht2是否为空，如果为空，则检查表1的负载因子，大于特定值，则开始resizing，如果ht2不为空，则说明正在resize，执行help_resizing。\n\n  * 查找的实现\n\n    1、执行start_resizing\n\n    2、分别在ht1和ht2中查找\n\n  * 删除的实现\n\n    1、执行start_resizing\n\n    2、执行查找，用返回节点执行节点删除\n\n```c++\n\n// 哈希map\n// 使用两张哈希表用于渐进式rehash\n// 接口: insert, lookup, pop, size, destroy\n// private: start_resizing, help_resizing\nclass HMap {\npublic:\n    HTab ht1;   // newer\n    HTab ht2;   // older\nprivate:\n    size_t resizing_pos = 0;    \n    const size_t k_resizing_work = 128; // constant work\n    const size_t k_max_load_factor = 8; // constant load factor\n    void help_resizing();\n    void start_resizing();\n\npublic:\n    HMap() : ht1(1), ht2(1), resizing_pos(0) {};\n    HMap(size_t n): ht1(n), ht2(1), resizing_pos(0) {};\n    ~HMap() { ht1.~HTab(); ht2.~HTab(); }\n\n    // 插入、查找、删除、大小、销毁\n    void insert(HNode *node);\n    HNode *lookup(HNode *key, bool (*eq)(HNode *, HNode *));\n    HNode *pop(HNode *key, bool (*eq)(HNode *, HNode *));\n    size_t size();\n    void destroy();\n};\n```\n\n实际应用过程中还会有一个结构体\n\n将哈希表节点和键值对进行绑定\n\n```c++\nstruct Entry {\n    struct HNode node;\n    std::string key;\n    std::string val;\n};\n```\n\n### 渐进式rehash过程\n\n在哈希表的构建时，使用的是用二维指针来存储哈希表，解决哈希冲突的方式是常用的拉链法（使用链表存储映射值相等的哈希元素），第一个维度作为哈希映射的key值来定位到具体的映射链表，第二个维度则是用来解决哈希冲突的，考虑到哈希表定义本身的属性，我们是希望哈希表的哈希冲突尽可能少，也就是我们的链表的长度尽可能短，随着我们插入的数据不断增加，我们产生的哈希冲突也是会增加的。\n\n在这里我们定义了一个负载因子`k_max_load_factor`，在实际插入的过程中，当当前用于查找的哈希表中的负载（元素个数/掩码）大于负载因子，会启动rehash的过程，我们会申请一张比原来哈希表大两倍的哈希表，将当前哈希表中的数据重新映射到这一张新的哈希表中。这样我们原来短，高的哈希表，就会变成长，矮的哈希表。\n\n我们知道，当哈希表中的元素过多的时候，需要对所有元素都一起进行rehash是一个非常耗时的过程，如果我们只有一张哈希表，我们在进行rehash的过程中，还不能够允许其他插入、删除以及查询操作，为了解决这样一个问题，我们采用将rehash分散在各个其他语句的步骤，在我们负载因子达到一定程度的时候，我们会启动渐进式rehash，当我们有其他插入或者查询语句到来的时候，我们会先进行部分node的rehsah，再进行查询语句。我们可以看下面例子。\n\n```C++\nHNode *HMap::lookup(HNode *key, bool (*eq)(HNode *, HNode *)) {\n    help_resizing();\n    HNode **from = ht1.lookup(key, eq);\n    from = from ? from : ht2.lookup(key, eq);\n    return from ? *from : NULL;\n}\n\n// class HMap\nvoid HMap::help_resizing() {\n    size_t nwork = 0;\n    while (nwork < k_resizing_work && ht2.get_size() > 0) {\n        // scan for nodes from ht2 and move them to ht1\n        HNode **from = &ht2.get_tab()[resizing_pos];\n        if (!*from) {\n            resizing_pos++;\n            continue;\n        }\n\n        ht1.insert(ht2.detach(from));\n        nwork++;\n    }\n\n    if (ht2.get_size() == 0 && ht2.get_tab()) {\n        // done\n        delete[] ht2.get_tab();\n        ht2 = HTab{};\n    }\n}\n```\n\n\n\n## 五、平衡二叉树\n\n平衡二叉树是一种特殊的二叉搜索树，对平衡二叉树来说，它的中序遍历是有序的，并且左右子树的高度差会处于一个平衡的状态，这样可以保证每次查找都能够在比较快的时间内完成。\n\n### 数据结构\n\n> 平衡二叉树本身就是由节点构成的\n\ndepth：以当前节点为根节点所在树的高度\n\ncnt：以当前节点为根节点的总节点数，便于进行区间统计\n\nleft：左节点，right：右节点，parent：父节点\n\n提供的辅助函数\n\n* rot_left：对当前节点进行左旋操作\n\n```\n// 对b节点进行左旋，返回d节点\n  b         d\n / \\       /\na   d ==> b\n   /     / \\\n  c     a   c\n```\n\n* rot_right：镜像操作\n\n* avl_fix_left\n\n  1、左子树的右子树太深需要先左旋后右旋\n\n  2、左子树的左子树太深，直接右旋\n\n```\n   root\n   /            左旋(root->left)\n  A\n / \\\nB   C\n   / \\\n  D   E\n  \n   root\n   /              右旋(root)\n  C\n / \\\nA   E\n/ \\\nB   D\n\n    C\n   / \\\n  A   root\n / \\    \\\nB   D    E\n```\n\n* avl_fix_right也类似\n\n* avl_fix：对平衡二叉树的修复，当执行删除和插入节点时，调用这个函数保持节点的平衡\n\n* avl_del：删除节点\n\n  1、当当前要删除的节点不存在右节点时，如果有左子树，将左子树向上提，如果没有左子树，说明删除的是root，最终都是返回左子树，返回左子树\n\n  2、如果存在右节点，递归的找到右节点当中的最小元素，修改树的结构\n\n* avl_offset：从当前节点出发，按照偏移来进行查找节点\n\n  1、初始化pos为0，表示当前节点相对于起始节点的位置\n\n  2、如果pos等于偏移量，则返回\n\n  3、如果小于偏移量，并且加上右节点的节点数大于offset，则说明在右子树\n\n  4、如果大于偏移量，并且减去左节点的节点数小于offset，说明在左子树\n\n  5、否则在父节点\n\n```C++\n// 平衡二叉树\nclass AVLNode\n{\nprivate:\n    uint32_t depth = 0;\n    uint32_t cnt = 0;\n    AVLNode *left = NULL;\n    AVLNode *right = NULL;\n    AVLNode *parent = NULL;\n\npublic:\n    AVLNode(AVLNode *node);\n    AVLNode();\n    ~AVLNode();\n    AVLNode *avl_fix(AVLNode *node);\n    AVLNode *avl_del(AVLNode *node);\n    AVLNode *avl_offset(AVLNode *node, int64_t offset);\n\n    // get \n    uint32_t avl_depth(AVLNode *node);\n    uint32_t avl_cnt(AVLNode *node);\n    uint32_t max(uint32_t lhs, uint32_t rhs);\n    void avl_update(AVLNode *node);\n    \n    AVLNode *rot_left(AVLNode *node);\n    AVLNode *rot_right(AVLNode *node);\n    AVLNode *avl_fix_left(AVLNode *root);\n    AVLNode *avl_fix_right(AVLNode *root);\n\nprivate:\n};\n```\n\n\n\n## 六、zset数据结构\n\nzset在Redis中是使用跳表+哈希表来实现的\n\n这里使用AVL树+哈希表来实现\n\n* ZNode\n\n  ZNode中需要存储AVL树节点以及哈希节点，同时存储score是用于排序的键，ZNode中携带的数据可以提供快速查找，也支持有序访问，node同时属于AVL树和哈希表。\n\n```C++\nclass ZNode {\npublic:\n    AVLNode tree; // AVL树节点\n    HNode hmap;   // 哈希表节点\n    double score; // 分数\n    size_t len;   // 名称长度\n    char name[0];\n\n    ZNode(const char* name, size_t len, double score);\n    ~ZNode() = default;\n};\n```\n\n* ZSet\n\n  在ZSet中包含一个tree指向平衡二叉树的根节点，平衡二叉树关联着ZNode中的tree，同时维护一张HMap哈希表，用于对数据的快速查找\n\n|                             接口                             |                    功能                     |\n| :----------------------------------------------------------: | :-----------------------------------------: |\n|      ZNode *zset_lookup(const char *name, size_t len);       |  根据传入的name来进行查找，从哈希表中查找   |\n|  bool zset_add(const char *name, size_t len, double score);  |          向ZSet中添加一个节点元素           |\n|        ZNode *zset_pop(const char *name, size_t len);        |    从ZSet中弹出一个元素，按照name来弹出     |\n| ZNode *zset_query(double score, const char *name, size_t len); |     查找ZSet中分数以及name都相等的ZNode     |\n|      ZNode *znode_offset(ZNode *node, int64_t offset);       |     根据分数的偏移从AVLtree中查找ZNode      |\n|                     void zset_dispose();                     | 清空当前的ZSet，包括AVL树的清空和hmap的清空 |\n\n```C++\nclass ZSet\n{\nprivate:\n    AVLNode *tree = nullptr;\n    HMap hmap;\n\npublic:\n    ZSet() = default;\n    ~ZSet() { zset_dispose(); }\n\n    // helper\n    ZNode *znode_new(const char *name, size_t len, double score);\n    uint32_t min(size_t lhs, size_t rhs);\n    bool zless(AVLNode *lhs, double score, const char *name, size_t len);\n    bool zless(AVLNode *lhs, AVLNode *rhs);\n    void zset_update(ZNode *node, double score);\n    void tree_add(ZNode *node);\n    \n    // interface\n    bool zset_add(const char *name, size_t len, double score);\n    // 根据键值来查找哈希表\n    ZNode *zset_lookup(const char *name, size_t len);\n    ZNode *zset_pop(const char *name, size_t len);\n    ZNode *zset_query(double score, const char *name, size_t len);\n    ZNode *znode_offset(ZNode *node, int64_t offset);\n    void znode_del(ZNode *node);\n    void tree_dispose(AVLNode *node);\n    void zset_dispose();\n};\n```\n\nzset_lookup\n\n按照name在ZSet中查找节点\n\n* 直接通过hmap查找\n\n```C++\nZNode *ZSet::zset_lookup(const char *name, size_t len) {\n    if(!tree) {\n        return nullptr;\n    }\n    HKey key;\n    key.node.hcode = str_hash((uint8_t*)name, len);\n    key.name = name;\n    key.len = len;\n    HNode *found = hmap.lookup(&key.node, &hcmp);\n    return found ? container_of(found, ZNode, hmap) : nullptr;\n}\n```\n\nzset_add\n\n* 先查找set中是否存在有对应的节点，如果有则更新value的值\n* 如果没有，则生成一个新的znode并插入到zset中\n\n```C++\nbool ZSet::zset_add(const char *name, size_t len, double score) {\n    ZNode *node = zset_lookup(name, len);\n    if (node) {\n        zset_update(node, score);\n        return false;\n    } else {\n        node = znode_new(name, len, score);\n        hmap.insert(&node->hmap);\n        tree_add(node);\n        return true;\n    }\n}\n```\n\nzset_pop\n\n> 通过name在zset数据结构中弹出对应的节点\n\n* 先从哈希表中查找对应的哈希节点\n* 通过找到的节点找到节点的Znode\n* 在AVL书中删除对应的Znode，并返回当前节点\n\n```C++\nZNode *ZSet::zset_pop(const char *name, size_t len) {\n    if(!tree) {\n        return nullptr;\n    }\n\n    HKey key;\n    key.node.hcode = str_hash((uint8_t*)name, len);\n    key.name = name;\n    key.len = len;\n    HNode *found = hmap.lookup(&key.node, &hcmp);\n    if(!found) {\n        return nullptr;\n    }\n\n    ZNode *node = found->owner;\n    tree = tree->avl_del(&node->tree);\n    return node;\n}\n```\n\nzset_query\n\n> 通过分数以及name查找的znode\n\n* 先通过分数在AVL树上进行查找，是一个二分查找的过程\n* 再通过比较查找得到的节点的name是否相等来对比返回结果\n\n```C++\nZNode *ZSet::zset_query(double score, const char *name, size_t len) {\n    AVLNode *found = nullptr;\n    AVLNode *cur = tree;\n    while(cur) {\n        if(zless(cur, score, name, len)) {\n            cur = cur->right;\n        } else {\n            found = cur;\n            cur = cur->left;\n        }\n    }\n    return found ? found->owner : nullptr;\n}\n\nbool ZSet::zless(AVLNode *lhs, double score, const char *name, size_t len) {\n    // 根据指针偏移找到ZNode\n    auto zl = lhs->owner;\n    if (zl->score != score) {\n        return zl->score < score;\n    }\n    int rv = memcmp(zl->name, name, min(zl->len, len));\n    if (rv != 0) {\n        return rv < 0;\n    }\n    return zl->len < len;\n}\n```\n\nznode_offset\n\n> 根据score的偏移在AVL树中查找Znode。在我们的代码中AVL节点的定义，参考上面的avl_offset文字算法伪代码\n\n```C++\nZNode *ZSet::znode_offset(ZNode *node, int64_t offset) {\n    AVLNode *tnode = node ? tree->avl_offset(&node->tree, offset) : nullptr;\n    return tnode ? tnode->owner : nullptr;\n}\n```\n\n\n## 七、测试效果\n\n\n","slug":"build-sample-redis","published":1,"updated":"2024-06-25T09:45:44.904Z","comments":1,"layout":"post","photos":[],"_id":"clyfintto000y08jv1z4c2f09","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"简易Redis的实现\"><a href=\"#简易Redis的实现\" class=\"headerlink\" title=\"简易Redis的实现\"></a>简易Redis的实现</h1><p>这个项目实现了一个简易的redis，使用hashmap来管理键值对数据，使用hashmap+AVL数来管理Zset数据，并实现了hashmap的渐进式扩容，减少因为扩容重新哈希化带来rehash的代价。使用poll技术来实现IO多路复用，完成一个服务端与多个客户端建立连接的过程，使用双向链表来管理连接，通过最小堆来控制val的生存时间，并通过将两者结合的方式，控制poll的最大超时时间，用来确保每一次poll的陷入内核和退出内核在主进程中都有处理的任务。</p>\n<p>1、最小堆的维护，当为某一个key设置好ttl时，会将key当中需要维护的ttl放入到最小堆当中，每一次轮询结束以后，会统一进行处理，已经失效的key</p>\n<p>2、双向链表的维护，poll当中，会把第一个fd设置成为用于处理连接事件的fd，当有连接事件发生的时候，会处理连接，接受一个新的连接，并将其放入到双向链表的头部，会有一个conn的结构体，里面实现了读写缓存，以及接受当前连接的空闲队列节点，以及建立连接的时间，然后会把这个连接放入到空闲队列当中的头部。</p>\n<p>3、过期时间的处理，会在每一次poll以及对应的事件处理结束以后，对当前的key进行ttl的检查，包括conn的过期时间和key的过期时间，会对空闲队列中的一些长期占用时间的连接进行清除，以及最小堆当中过期的key进行清理（不断地pop掉最小堆当中的数据，直到没有那些超时数据）。</p>\n<p>4、线程池的作用，当缓存数据过多时，实现异步清除。</p>\n<h2 id=\"一、实现的命令\"><a href=\"#一、实现的命令\" class=\"headerlink\" title=\"一、实现的命令\"></a>一、实现的命令</h2><figure class=\"highlight txt\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs txt\">// hashtable<br>set key value\t向哈希表中插入键值对<br>get key\t\t\t从哈希表中查找键对应的值<br>del key\t\t\t从哈希表中删除键<br>keys\t\t\t打印出哈希表中所有的keys<br><br>// zset<br>zadd key score name\t\t向键为key中，插入name，score<br>zscore key name\t\t\t按照key和name查找score<br>zrem key name\t\t\t删除键为key中的name元素<br>zscore key name\t\t\t查找键为key的name的score<br>zquery<br><br></code></pre></td></tr></table></figure>\n<h2 id=\"二、Socket编程相关语法\"><a href=\"#二、Socket编程相关语法\" class=\"headerlink\" title=\"二、Socket编程相关语法\"></a>二、Socket编程相关语法</h2><h3 id=\"服务端\"><a href=\"#服务端\" class=\"headerlink\" title=\"服务端\"></a>服务端</h3><ul>\n<li>创建句柄</li>\n</ul>\n<p>函数原型：<code>int socket(int domain, int type, int protocol);</code></p>\n<p>domin：指定通信域，ipv4或ipv6，AF_INET表示ipv4地址</p>\n<p>type：指定套接字类型</p>\n<p>protocol：0表示为TCP协议</p>\n<ul>\n<li>设置socket可选项</li>\n<li>Bind，绑定ip和端口号</li>\n<li>Listen</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Server::run_server</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <br>    <span class=\"hljs-comment\">// init coding...</span><br><br>    <span class=\"hljs-keyword\">if</span> (fd &lt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;socket()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-type\">int</span> val = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-built_in\">setsockopt</span>(fd, SOL_SOCKET, SO_REUSEADDR, &amp;val, <span class=\"hljs-built_in\">sizeof</span>(val));<br><br>    <span class=\"hljs-comment\">// bind</span><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(<span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">bind</span>(fd, (<span class=\"hljs-type\">const</span> sockaddr *)&amp;addr, <span class=\"hljs-built_in\">sizeof</span>(addr));<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;bind()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// listen</span><br>    rv = <span class=\"hljs-built_in\">listen</span>(fd, SOMAXCONN);<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;listen()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// coding...</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> fd = <span class=\"hljs-built_in\">socket</span>(AF_INET, SOCK_STREAM, <span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-comment\">// bind</span><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(<span class=\"hljs-number\">0</span>);    <span class=\"hljs-comment\">// wildcard address 0.0.0.0</span><br>    <span class=\"hljs-function\">Server <span class=\"hljs-title\">server</span><span class=\"hljs-params\">(addr, fd)</span></span>;<br>    <br>    server.<span class=\"hljs-built_in\">run_server</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><ul>\n<li>创建句柄</li>\n<li>设置IP地址和端口号</li>\n<li>Connect</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Client::run_client</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> argc, <span class=\"hljs-type\">char</span> **argv)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (fd &lt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;socket()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">connect</span>(fd, (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">struct</span> sockaddr *)&amp;addr, <span class=\"hljs-built_in\">sizeof</span>(addr));<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;connect&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// coding...</span><br><br>    <span class=\"hljs-built_in\">close</span>(fd);<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> argc, <span class=\"hljs-type\">char</span> **argv)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> fd = <span class=\"hljs-built_in\">socket</span>(AF_INET, SOCK_STREAM, <span class=\"hljs-number\">0</span>);<br><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(INADDR_LOOPBACK);  <span class=\"hljs-comment\">// 127.0.0.1</span><br>    <br>    <span class=\"hljs-function\">Client <span class=\"hljs-title\">client</span><span class=\"hljs-params\">(addr, fd)</span></span>;<br>    client.<span class=\"hljs-built_in\">run_client</span>(argc, argv);<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>使用的协议</strong></p>\n<p>len+msg的结合</p>\n<p>len表示后面的字长，msg表示要获取的数据</p>\n<h2 id=\"三、事件循环和非阻塞型IO\"><a href=\"#三、事件循环和非阻塞型IO\" class=\"headerlink\" title=\"三、事件循环和非阻塞型IO\"></a>三、事件循环和非阻塞型IO</h2><blockquote>\n<p>在服务器端网络编程中，处理并发连接有三种方法：forking、多线程（multi-threading）和事件循环（event loops）。forking会为每个客户端连接创建新的进程以实现并发。多线程使用线程而不是进程。事件循环使用轮询和非阻塞 I/O，通常在单个线程上运行。由于进程和线程的开销，大多数现代生产级软件使用事件循环来进行网络编程。</p>\n</blockquote>\n<p>在项目中用到了IO多路复用中的poll技术来实现，在服务端使用单个进程和多个客户端建立连接，在客户端看来，像是每一个客户端都和一个独立的服务端建立了连接并进行数据通信，而在服务端看来，它所完成的则是在不同的时间段服务不同的客户，但由于时间片比较小，就会让客户端感觉好像实现了多个进程通信的过程。</p>\n<h2 id=\"四、哈希表数据结构\"><a href=\"#四、哈希表数据结构\" class=\"headerlink\" title=\"四、哈希表数据结构\"></a>四、哈希表数据结构</h2><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><ul>\n<li><p>哈希节点</p>\n<p>哈希表节点是以链表的形式存储，包含一个next节点和一个hcode（哈希化以后的映射值）</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 哈希表节点</span><br><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">HNode</span> &#123;<br>    HNode *next = <span class=\"hljs-literal\">NULL</span>;<br>    <span class=\"hljs-type\">uint64_t</span> hcode = <span class=\"hljs-number\">0</span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>哈希表</p>\n<p>哈希表主要载体是一个HNode的二维指针，第一个指针代表的是哈希值，第二个指针存储的是链表，链表是用来解决哈希冲突的方式。size表示的是当前哈希表中的总结点数目，mask表示掩码，为哈希表第一个维度大小减1。</p>\n<p>在哈希表中实现了，insert，lookup，detach，init接口，分别表示节点的插入，节点的查找，节点的删除。</p>\n<p>需要使用有参的构造函数初始化，传入的参数为整型，整型必须为2的幂，便于构建mask。</p>\n<ul>\n<li><p>节点的插入过程</p>\n<p>1、先计算当前节点中hcode应该属于的pos（即链表位置），计算方式是与<code>&amp;</code>上mask</p>\n<p>2、使用头插法，将节点插入到对应的位置，修改size大小</p>\n</li>\n<li><p>节点的查找过程</p>\n<p>1、查找哈希化后的链表位置。</p>\n<p>2、在链表中查找当前节点。</p>\n</li>\n<li><p>节点的删除过程<code>HNode *detach(HNode **from)</code></p>\n<p>1、解除引用，获取链表位置</p>\n<p>2、绕过当前节点，指向下一节点</p>\n<p>3、具体使用需要先找到节点位置，再调用detach</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 哈希表</span><br><span class=\"hljs-comment\">// 接口: insert, lookup, detach</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">HTab</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    HNode **tab = <span class=\"hljs-literal\">NULL</span>;<br>    <span class=\"hljs-type\">size_t</span> size = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-type\">size_t</span> mask = <span class=\"hljs-number\">0</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">HTab</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-comment\">// 传入的n必须为2的幂</span><br>    <span class=\"hljs-built_in\">HTab</span>(<span class=\"hljs-type\">size_t</span> n): <span class=\"hljs-built_in\">size</span>(<span class=\"hljs-number\">0</span>), <span class=\"hljs-built_in\">mask</span>(n<span class=\"hljs-number\">-1</span>)&#123;<br>        <span class=\"hljs-built_in\">assert</span>((n &amp; (n<span class=\"hljs-number\">-1</span>)) == <span class=\"hljs-number\">0</span>);<br>        tab = <span class=\"hljs-keyword\">new</span> HNode*[n];<br>    &#125;;<br>    ~<span class=\"hljs-built_in\">HTab</span>() &#123; <span class=\"hljs-keyword\">delete</span>[] tab; &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">insert</span><span class=\"hljs-params\">(HNode *node)</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">detach</span><span class=\"hljs-params\">(HNode **from)</span></span>;<br><br>    <span class=\"hljs-comment\">// setter</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_tab</span><span class=\"hljs-params\">(HNode **t)</span> </span>&#123; tab = t; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_mask</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> m)</span> </span>&#123; mask = m; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_size</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> s)</span> </span>&#123; size = s; &#125;<br><br>    <span class=\"hljs-comment\">// getter</span><br>    <span class=\"hljs-function\">HNode **<span class=\"hljs-title\">get_tab</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> tab; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">get_mask</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> mask; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">get_size</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> size; &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>哈希map</p>\n<p>哈希表中含有两个HTab，用于完成渐进式的rehash。第一张表存储新的键值，第二张表存储旧的键值，当在第一张表中查找不到元素时，会再在第二张表查找。</p>\n<p>固定值的设置，k_max_load_factor表示负载因子，设置为8，即表示当前的总的HMap的节点数大于Mask的8倍的时候，就会对哈希表进行扩容。k_resizing_work的大小表示将哈希扩容分配到各个语句当中的单次转移的节点数量。resizing_pos记录resizing的位置。</p>\n<p>哈希Map实现了，insert，lookup，pop，size，destroy的接口，分别表示<strong>插入，查找，删除，返回哈希map节点数，以及销毁</strong>。同时会在负载过大时，重新申请更大的内存，执行resize操作，并分发到其他语句当中。</p>\n<p>start_resizing：检查ht2节点数是否大于零，若大于零，说明正在进行rehash中，将指定数量的节点rehash</p>\n<p>start_resizing：分配一个更大的表给ht1，要提前将ht2指向ht1</p>\n<ul>\n<li><p>插入的实现</p>\n<p>1、将节点插入到ht1当中，如果ht1为空，则新建ht1</p>\n<p>2、检查ht2是否为空，如果为空，则检查表1的负载因子，大于特定值，则开始resizing，如果ht2不为空，则说明正在resize，执行help_resizing。</p>\n</li>\n<li><p>查找的实现</p>\n<p>1、执行start_resizing</p>\n<p>2、分别在ht1和ht2中查找</p>\n</li>\n<li><p>删除的实现</p>\n<p>1、执行start_resizing</p>\n<p>2、执行查找，用返回节点执行节点删除</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><br><span class=\"hljs-comment\">// 哈希map</span><br><span class=\"hljs-comment\">// 使用两张哈希表用于渐进式rehash</span><br><span class=\"hljs-comment\">// 接口: insert, lookup, pop, size, destroy</span><br><span class=\"hljs-comment\">// private: start_resizing, help_resizing</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">HMap</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    HTab ht1;   <span class=\"hljs-comment\">// newer</span><br>    HTab ht2;   <span class=\"hljs-comment\">// older</span><br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">size_t</span> resizing_pos = <span class=\"hljs-number\">0</span>;    <br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> k_resizing_work = <span class=\"hljs-number\">128</span>; <span class=\"hljs-comment\">// constant work</span><br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> k_max_load_factor = <span class=\"hljs-number\">8</span>; <span class=\"hljs-comment\">// constant load factor</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">help_resizing</span><span class=\"hljs-params\">()</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">start_resizing</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">HMap</span>() : <span class=\"hljs-built_in\">ht1</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">ht2</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">resizing_pos</span>(<span class=\"hljs-number\">0</span>) &#123;&#125;;<br>    <span class=\"hljs-built_in\">HMap</span>(<span class=\"hljs-type\">size_t</span> n): <span class=\"hljs-built_in\">ht1</span>(n), <span class=\"hljs-built_in\">ht2</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">resizing_pos</span>(<span class=\"hljs-number\">0</span>) &#123;&#125;;<br>    ~<span class=\"hljs-built_in\">HMap</span>() &#123; ht1.~<span class=\"hljs-built_in\">HTab</span>(); ht2.~<span class=\"hljs-built_in\">HTab</span>(); &#125;<br><br>    <span class=\"hljs-comment\">// 插入、查找、删除、大小、销毁</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">insert</span><span class=\"hljs-params\">(HNode *node)</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">pop</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">size</span><span class=\"hljs-params\">()</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">destroy</span><span class=\"hljs-params\">()</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<p>实际应用过程中还会有一个结构体</p>\n<p>将哈希表节点和键值对进行绑定</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">Entry</span> &#123;<br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">HNode</span> node;<br>    std::string key;<br>    std::string val;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"渐进式rehash过程\"><a href=\"#渐进式rehash过程\" class=\"headerlink\" title=\"渐进式rehash过程\"></a>渐进式rehash过程</h3><p>在哈希表的构建时，使用的是用二维指针来存储哈希表，解决哈希冲突的方式是常用的拉链法（使用链表存储映射值相等的哈希元素），第一个维度作为哈希映射的key值来定位到具体的映射链表，第二个维度则是用来解决哈希冲突的，考虑到哈希表定义本身的属性，我们是希望哈希表的哈希冲突尽可能少，也就是我们的链表的长度尽可能短，随着我们插入的数据不断增加，我们产生的哈希冲突也是会增加的。</p>\n<p>在这里我们定义了一个负载因子<code>k_max_load_factor</code>，在实际插入的过程中，当当前用于查找的哈希表中的负载（元素个数/掩码）大于负载因子，会启动rehash的过程，我们会申请一张比原来哈希表大两倍的哈希表，将当前哈希表中的数据重新映射到这一张新的哈希表中。这样我们原来短，高的哈希表，就会变成长，矮的哈希表。</p>\n<p>我们知道，当哈希表中的元素过多的时候，需要对所有元素都一起进行rehash是一个非常耗时的过程，如果我们只有一张哈希表，我们在进行rehash的过程中，还不能够允许其他插入、删除以及查询操作，为了解决这样一个问题，我们采用将rehash分散在各个其他语句的步骤，在我们负载因子达到一定程度的时候，我们会启动渐进式rehash，当我们有其他插入或者查询语句到来的时候，我们会先进行部分node的rehsah，再进行查询语句。我们可以看下面例子。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">HNode *<span class=\"hljs-title\">HMap::lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span> </span>&#123;<br>    <span class=\"hljs-built_in\">help_resizing</span>();<br>    HNode **from = ht1.<span class=\"hljs-built_in\">lookup</span>(key, eq);<br>    from = from ? from : ht2.<span class=\"hljs-built_in\">lookup</span>(key, eq);<br>    <span class=\"hljs-keyword\">return</span> from ? *from : <span class=\"hljs-literal\">NULL</span>;<br>&#125;<br><br><span class=\"hljs-comment\">// class HMap</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HMap::help_resizing</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">size_t</span> nwork = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">while</span> (nwork &lt; k_resizing_work &amp;&amp; ht2.<span class=\"hljs-built_in\">get_size</span>() &gt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-comment\">// scan for nodes from ht2 and move them to ht1</span><br>        HNode **from = &amp;ht2.<span class=\"hljs-built_in\">get_tab</span>()[resizing_pos];<br>        <span class=\"hljs-keyword\">if</span> (!*from) &#123;<br>            resizing_pos++;<br>            <span class=\"hljs-keyword\">continue</span>;<br>        &#125;<br><br>        ht1.<span class=\"hljs-built_in\">insert</span>(ht2.<span class=\"hljs-built_in\">detach</span>(from));<br>        nwork++;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">if</span> (ht2.<span class=\"hljs-built_in\">get_size</span>() == <span class=\"hljs-number\">0</span> &amp;&amp; ht2.<span class=\"hljs-built_in\">get_tab</span>()) &#123;<br>        <span class=\"hljs-comment\">// done</span><br>        <span class=\"hljs-keyword\">delete</span>[] ht2.<span class=\"hljs-built_in\">get_tab</span>();<br>        ht2 = HTab&#123;&#125;;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"五、平衡二叉树\"><a href=\"#五、平衡二叉树\" class=\"headerlink\" title=\"五、平衡二叉树\"></a>五、平衡二叉树</h2><p>平衡二叉树是一种特殊的二叉搜索树，对平衡二叉树来说，它的中序遍历是有序的，并且左右子树的高度差会处于一个平衡的状态，这样可以保证每次查找都能够在比较快的时间内完成。</p>\n<h3 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><blockquote>\n<p>平衡二叉树本身就是由节点构成的</p>\n</blockquote>\n<p>depth：以当前节点为根节点所在树的高度</p>\n<p>cnt：以当前节点为根节点的总节点数，便于进行区间统计</p>\n<p>left：左节点，right：右节点，parent：父节点</p>\n<p>提供的辅助函数</p>\n<ul>\n<li>rot_left：对当前节点进行左旋操作</li>\n</ul>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\"><span class=\"hljs-comment\">// 对b节点进行左旋，返回d节点</span><br>  <span class=\"hljs-selector-tag\">b</span>         d<br> / \\       /<br><span class=\"hljs-selector-tag\">a</span>   d ==&gt; <span class=\"hljs-selector-tag\">b</span><br>   /     / \\<br>  c     <span class=\"hljs-selector-tag\">a</span>   c<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>rot_right：镜像操作</p>\n</li>\n<li><p>avl_fix_left</p>\n<p>1、左子树的右子树太深需要先左旋后右旋</p>\n<p>2、左子树的左子树太深，直接右旋</p>\n</li>\n</ul>\n<figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">   <span class=\"hljs-variable\">root</span><br>   <span class=\"hljs-operator\">/</span>            左旋<span class=\"hljs-punctuation\">(</span><span class=\"hljs-variable\">root</span><span class=\"hljs-operator\">-&gt;</span><span class=\"hljs-variable\">left</span><span class=\"hljs-punctuation\">)</span><br>  <span class=\"hljs-variable\">A</span><br> <span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">C</span><br>   <span class=\"hljs-operator\">/</span> \\<br>  <span class=\"hljs-built_in\">D</span>   <span class=\"hljs-built_in\">E</span><br>  <br>   <span class=\"hljs-variable\">root</span><br>   <span class=\"hljs-operator\">/</span>              右旋<span class=\"hljs-punctuation\">(</span><span class=\"hljs-variable\">root</span><span class=\"hljs-punctuation\">)</span><br>  <span class=\"hljs-built_in\">C</span><br> <span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">A</span>   <span class=\"hljs-built_in\">E</span><br><span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">D</span><br><br>    <span class=\"hljs-built_in\">C</span><br>   <span class=\"hljs-operator\">/</span> \\<br>  <span class=\"hljs-variable\">A</span>   <span class=\"hljs-variable\">root</span><br> <span class=\"hljs-operator\">/</span> \\    \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">D</span>    <span class=\"hljs-built_in\">E</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>avl_fix_right也类似</p>\n</li>\n<li><p>avl_fix：对平衡二叉树的修复，当执行删除和插入节点时，调用这个函数保持节点的平衡</p>\n</li>\n<li><p>avl_del：删除节点</p>\n<p>1、当当前要删除的节点不存在右节点时，如果有左子树，将左子树向上提，如果没有左子树，说明删除的是root，最终都是返回左子树，返回左子树</p>\n<p>2、如果存在右节点，递归的找到右节点当中的最小元素，修改树的结构</p>\n</li>\n<li><p>avl_offset：从当前节点出发，按照偏移来进行查找节点</p>\n<p>1、初始化pos为0，表示当前节点相对于起始节点的位置</p>\n<p>2、如果pos等于偏移量，则返回</p>\n<p>3、如果小于偏移量，并且加上右节点的节点数大于offset，则说明在右子树</p>\n<p>4、如果大于偏移量，并且减去左节点的节点数小于offset，说明在左子树</p>\n<p>5、否则在父节点</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 平衡二叉树</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AVLNode</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">uint32_t</span> depth = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-type\">uint32_t</span> cnt = <span class=\"hljs-number\">0</span>;<br>    AVLNode *left = <span class=\"hljs-literal\">NULL</span>;<br>    AVLNode *right = <span class=\"hljs-literal\">NULL</span>;<br>    AVLNode *parent = <span class=\"hljs-literal\">NULL</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">AVLNode</span>(AVLNode *node);<br>    <span class=\"hljs-built_in\">AVLNode</span>();<br>    ~<span class=\"hljs-built_in\">AVLNode</span>();<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_del</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_offset</span><span class=\"hljs-params\">(AVLNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span></span>;<br><br>    <span class=\"hljs-comment\">// get </span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">avl_depth</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">avl_cnt</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">max</span><span class=\"hljs-params\">(<span class=\"hljs-type\">uint32_t</span> lhs, <span class=\"hljs-type\">uint32_t</span> rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">avl_update</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">rot_left</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">rot_right</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix_left</span><span class=\"hljs-params\">(AVLNode *root)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix_right</span><span class=\"hljs-params\">(AVLNode *root)</span></span>;<br><br><span class=\"hljs-keyword\">private</span>:<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、zset数据结构\"><a href=\"#六、zset数据结构\" class=\"headerlink\" title=\"六、zset数据结构\"></a>六、zset数据结构</h2><p>zset在Redis中是使用跳表+哈希表来实现的</p>\n<p>这里使用AVL树+哈希表来实现</p>\n<ul>\n<li><p>ZNode</p>\n<p>ZNode中需要存储AVL树节点以及哈希节点，同时存储score是用于排序的键，ZNode中携带的数据可以提供快速查找，也支持有序访问，node同时属于AVL树和哈希表。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ZNode</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    AVLNode tree; <span class=\"hljs-comment\">// AVL树节点</span><br>    HNode hmap;   <span class=\"hljs-comment\">// 哈希表节点</span><br>    <span class=\"hljs-type\">double</span> score; <span class=\"hljs-comment\">// 分数</span><br>    <span class=\"hljs-type\">size_t</span> len;   <span class=\"hljs-comment\">// 名称长度</span><br>    <span class=\"hljs-type\">char</span> name[<span class=\"hljs-number\">0</span>];<br><br>    <span class=\"hljs-built_in\">ZNode</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>* name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score);<br>    ~<span class=\"hljs-built_in\">ZNode</span>() = <span class=\"hljs-keyword\">default</span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>ZSet</p>\n<p>在ZSet中包含一个tree指向平衡二叉树的根节点，平衡二叉树关联着ZNode中的tree，同时维护一张HMap哈希表，用于对数据的快速查找</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">接口</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_lookup(const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">根据传入的name来进行查找，从哈希表中查找</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool zset_add(const char *name, size_t len, double score);</td>\n<td style=\"text-align:center\">向ZSet中添加一个节点元素</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_pop(const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">从ZSet中弹出一个元素，按照name来弹出</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_query(double score, const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">查找ZSet中分数以及name都相等的ZNode</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>znode_offset(ZNode </em>node, int64_t offset);</td>\n<td style=\"text-align:center\">根据分数的偏移从AVLtree中查找ZNode</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void zset_dispose();</td>\n<td style=\"text-align:center\">清空当前的ZSet，包括AVL树的清空和hmap的清空</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ZSet</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    AVLNode *tree = <span class=\"hljs-literal\">nullptr</span>;<br>    HMap hmap;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ZSet</span>() = <span class=\"hljs-keyword\">default</span>;<br>    ~<span class=\"hljs-built_in\">ZSet</span>() &#123; <span class=\"hljs-built_in\">zset_dispose</span>(); &#125;<br><br>    <span class=\"hljs-comment\">// helper</span><br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">znode_new</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">min</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> lhs, <span class=\"hljs-type\">size_t</span> rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zless</span><span class=\"hljs-params\">(AVLNode *lhs, <span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zless</span><span class=\"hljs-params\">(AVLNode *lhs, AVLNode *rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zset_update</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">tree_add</span><span class=\"hljs-params\">(ZNode *node)</span></span>;<br>    <br>    <span class=\"hljs-comment\">// interface</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zset_add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-comment\">// 根据键值来查找哈希表</span><br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_lookup</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_pop</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_query</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">znode_offset</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">znode_del</span><span class=\"hljs-params\">(ZNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">tree_dispose</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zset_dispose</span><span class=\"hljs-params\">()</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<p>zset_lookup</p>\n<p>按照name在ZSet中查找节点</p>\n<ul>\n<li>直接通过hmap查找</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_lookup</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(!tree) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br>    HKey key;<br>    key.node.hcode = <span class=\"hljs-built_in\">str_hash</span>((<span class=\"hljs-type\">uint8_t</span>*)name, len);<br>    key.name = name;<br>    key.len = len;<br>    HNode *found = hmap.<span class=\"hljs-built_in\">lookup</span>(&amp;key.node, &amp;hcmp);<br>    <span class=\"hljs-keyword\">return</span> found ? <span class=\"hljs-built_in\">container_of</span>(found, ZNode, hmap) : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_add</p>\n<ul>\n<li>先查找set中是否存在有对应的节点，如果有则更新value的值</li>\n<li>如果没有，则生成一个新的znode并插入到zset中</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">ZSet::zset_add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span> </span>&#123;<br>    ZNode *node = <span class=\"hljs-built_in\">zset_lookup</span>(name, len);<br>    <span class=\"hljs-keyword\">if</span> (node) &#123;<br>        <span class=\"hljs-built_in\">zset_update</span>(node, score);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>        node = <span class=\"hljs-built_in\">znode_new</span>(name, len, score);<br>        hmap.<span class=\"hljs-built_in\">insert</span>(&amp;node-&gt;hmap);<br>        <span class=\"hljs-built_in\">tree_add</span>(node);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_pop</p>\n<blockquote>\n<p>通过name在zset数据结构中弹出对应的节点</p>\n</blockquote>\n<ul>\n<li>先从哈希表中查找对应的哈希节点</li>\n<li>通过找到的节点找到节点的Znode</li>\n<li>在AVL书中删除对应的Znode，并返回当前节点</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_pop</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(!tree) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br><br>    HKey key;<br>    key.node.hcode = <span class=\"hljs-built_in\">str_hash</span>((<span class=\"hljs-type\">uint8_t</span>*)name, len);<br>    key.name = name;<br>    key.len = len;<br>    HNode *found = hmap.<span class=\"hljs-built_in\">lookup</span>(&amp;key.node, &amp;hcmp);<br>    <span class=\"hljs-keyword\">if</span>(!found) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br><br>    ZNode *node = found-&gt;owner;<br>    tree = tree-&gt;<span class=\"hljs-built_in\">avl_del</span>(&amp;node-&gt;tree);<br>    <span class=\"hljs-keyword\">return</span> node;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_query</p>\n<blockquote>\n<p>通过分数以及name查找的znode</p>\n</blockquote>\n<ul>\n<li>先通过分数在AVL树上进行查找，是一个二分查找的过程</li>\n<li>再通过比较查找得到的节点的name是否相等来对比返回结果</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_query</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    AVLNode *found = <span class=\"hljs-literal\">nullptr</span>;<br>    AVLNode *cur = tree;<br>    <span class=\"hljs-keyword\">while</span>(cur) &#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">zless</span>(cur, score, name, len)) &#123;<br>            cur = cur-&gt;right;<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>            found = cur;<br>            cur = cur-&gt;left;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> found ? found-&gt;owner : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">ZSet::zless</span><span class=\"hljs-params\">(AVLNode *lhs, <span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 根据指针偏移找到ZNode</span><br>    <span class=\"hljs-keyword\">auto</span> zl = lhs-&gt;owner;<br>    <span class=\"hljs-keyword\">if</span> (zl-&gt;score != score) &#123;<br>        <span class=\"hljs-keyword\">return</span> zl-&gt;score &lt; score;<br>    &#125;<br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">memcmp</span>(zl-&gt;name, name, <span class=\"hljs-built_in\">min</span>(zl-&gt;len, len));<br>    <span class=\"hljs-keyword\">if</span> (rv != <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-keyword\">return</span> rv &lt; <span class=\"hljs-number\">0</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> zl-&gt;len &lt; len;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>znode_offset</p>\n<blockquote>\n<p>根据score的偏移在AVL树中查找Znode。在我们的代码中AVL节点的定义，参考上面的avl_offset文字算法伪代码</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::znode_offset</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span> </span>&#123;<br>    AVLNode *tnode = node ? tree-&gt;<span class=\"hljs-built_in\">avl_offset</span>(&amp;node-&gt;tree, offset) : <span class=\"hljs-literal\">nullptr</span>;<br>    <span class=\"hljs-keyword\">return</span> tnode ? tnode-&gt;owner : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、测试效果\"><a href=\"#七、测试效果\" class=\"headerlink\" title=\"七、测试效果\"></a>七、测试效果</h2>","cover_type":"img","excerpt":"","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"简易Redis的实现\"><a href=\"#简易Redis的实现\" class=\"headerlink\" title=\"简易Redis的实现\"></a>简易Redis的实现</h1><p>这个项目实现了一个简易的redis，使用hashmap来管理键值对数据，使用hashmap+AVL数来管理Zset数据，并实现了hashmap的渐进式扩容，减少因为扩容重新哈希化带来rehash的代价。使用poll技术来实现IO多路复用，完成一个服务端与多个客户端建立连接的过程，使用双向链表来管理连接，通过最小堆来控制val的生存时间，并通过将两者结合的方式，控制poll的最大超时时间，用来确保每一次poll的陷入内核和退出内核在主进程中都有处理的任务。</p>\n<p>1、最小堆的维护，当为某一个key设置好ttl时，会将key当中需要维护的ttl放入到最小堆当中，每一次轮询结束以后，会统一进行处理，已经失效的key</p>\n<p>2、双向链表的维护，poll当中，会把第一个fd设置成为用于处理连接事件的fd，当有连接事件发生的时候，会处理连接，接受一个新的连接，并将其放入到双向链表的头部，会有一个conn的结构体，里面实现了读写缓存，以及接受当前连接的空闲队列节点，以及建立连接的时间，然后会把这个连接放入到空闲队列当中的头部。</p>\n<p>3、过期时间的处理，会在每一次poll以及对应的事件处理结束以后，对当前的key进行ttl的检查，包括conn的过期时间和key的过期时间，会对空闲队列中的一些长期占用时间的连接进行清除，以及最小堆当中过期的key进行清理（不断地pop掉最小堆当中的数据，直到没有那些超时数据）。</p>\n<p>4、线程池的作用，当缓存数据过多时，实现异步清除。</p>\n<h2 id=\"一、实现的命令\"><a href=\"#一、实现的命令\" class=\"headerlink\" title=\"一、实现的命令\"></a>一、实现的命令</h2><figure class=\"highlight txt\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs txt\">// hashtable<br>set key value\t向哈希表中插入键值对<br>get key\t\t\t从哈希表中查找键对应的值<br>del key\t\t\t从哈希表中删除键<br>keys\t\t\t打印出哈希表中所有的keys<br><br>// zset<br>zadd key score name\t\t向键为key中，插入name，score<br>zscore key name\t\t\t按照key和name查找score<br>zrem key name\t\t\t删除键为key中的name元素<br>zscore key name\t\t\t查找键为key的name的score<br>zquery<br><br></code></pre></td></tr></table></figure>\n<h2 id=\"二、Socket编程相关语法\"><a href=\"#二、Socket编程相关语法\" class=\"headerlink\" title=\"二、Socket编程相关语法\"></a>二、Socket编程相关语法</h2><h3 id=\"服务端\"><a href=\"#服务端\" class=\"headerlink\" title=\"服务端\"></a>服务端</h3><ul>\n<li>创建句柄</li>\n</ul>\n<p>函数原型：<code>int socket(int domain, int type, int protocol);</code></p>\n<p>domin：指定通信域，ipv4或ipv6，AF_INET表示ipv4地址</p>\n<p>type：指定套接字类型</p>\n<p>protocol：0表示为TCP协议</p>\n<ul>\n<li>设置socket可选项</li>\n<li>Bind，绑定ip和端口号</li>\n<li>Listen</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Server::run_server</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <br>    <span class=\"hljs-comment\">// init coding...</span><br><br>    <span class=\"hljs-keyword\">if</span> (fd &lt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;socket()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-type\">int</span> val = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-built_in\">setsockopt</span>(fd, SOL_SOCKET, SO_REUSEADDR, &amp;val, <span class=\"hljs-built_in\">sizeof</span>(val));<br><br>    <span class=\"hljs-comment\">// bind</span><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(<span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">bind</span>(fd, (<span class=\"hljs-type\">const</span> sockaddr *)&amp;addr, <span class=\"hljs-built_in\">sizeof</span>(addr));<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;bind()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// listen</span><br>    rv = <span class=\"hljs-built_in\">listen</span>(fd, SOMAXCONN);<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;listen()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// coding...</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> fd = <span class=\"hljs-built_in\">socket</span>(AF_INET, SOCK_STREAM, <span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-comment\">// bind</span><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(<span class=\"hljs-number\">0</span>);    <span class=\"hljs-comment\">// wildcard address 0.0.0.0</span><br>    <span class=\"hljs-function\">Server <span class=\"hljs-title\">server</span><span class=\"hljs-params\">(addr, fd)</span></span>;<br>    <br>    server.<span class=\"hljs-built_in\">run_server</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><ul>\n<li>创建句柄</li>\n<li>设置IP地址和端口号</li>\n<li>Connect</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Client::run_client</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> argc, <span class=\"hljs-type\">char</span> **argv)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (fd &lt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;socket()&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">connect</span>(fd, (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">struct</span> sockaddr *)&amp;addr, <span class=\"hljs-built_in\">sizeof</span>(addr));<br>    <span class=\"hljs-keyword\">if</span> (rv) &#123;<br>        <span class=\"hljs-built_in\">die</span>(<span class=\"hljs-string\">&quot;connect&quot;</span>);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// coding...</span><br><br>    <span class=\"hljs-built_in\">close</span>(fd);<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> argc, <span class=\"hljs-type\">char</span> **argv)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> fd = <span class=\"hljs-built_in\">socket</span>(AF_INET, SOCK_STREAM, <span class=\"hljs-number\">0</span>);<br><br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">sockaddr_in</span> addr = &#123;&#125;;<br>    addr.sin_family = AF_INET;<br>    addr.sin_port = <span class=\"hljs-built_in\">ntohs</span>(<span class=\"hljs-number\">1234</span>);<br>    addr.sin_addr.s_addr = <span class=\"hljs-built_in\">ntohl</span>(INADDR_LOOPBACK);  <span class=\"hljs-comment\">// 127.0.0.1</span><br>    <br>    <span class=\"hljs-function\">Client <span class=\"hljs-title\">client</span><span class=\"hljs-params\">(addr, fd)</span></span>;<br>    client.<span class=\"hljs-built_in\">run_client</span>(argc, argv);<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>使用的协议</strong></p>\n<p>len+msg的结合</p>\n<p>len表示后面的字长，msg表示要获取的数据</p>\n<h2 id=\"三、事件循环和非阻塞型IO\"><a href=\"#三、事件循环和非阻塞型IO\" class=\"headerlink\" title=\"三、事件循环和非阻塞型IO\"></a>三、事件循环和非阻塞型IO</h2><blockquote>\n<p>在服务器端网络编程中，处理并发连接有三种方法：forking、多线程（multi-threading）和事件循环（event loops）。forking会为每个客户端连接创建新的进程以实现并发。多线程使用线程而不是进程。事件循环使用轮询和非阻塞 I/O，通常在单个线程上运行。由于进程和线程的开销，大多数现代生产级软件使用事件循环来进行网络编程。</p>\n</blockquote>\n<p>在项目中用到了IO多路复用中的poll技术来实现，在服务端使用单个进程和多个客户端建立连接，在客户端看来，像是每一个客户端都和一个独立的服务端建立了连接并进行数据通信，而在服务端看来，它所完成的则是在不同的时间段服务不同的客户，但由于时间片比较小，就会让客户端感觉好像实现了多个进程通信的过程。</p>\n<h2 id=\"四、哈希表数据结构\"><a href=\"#四、哈希表数据结构\" class=\"headerlink\" title=\"四、哈希表数据结构\"></a>四、哈希表数据结构</h2><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><ul>\n<li><p>哈希节点</p>\n<p>哈希表节点是以链表的形式存储，包含一个next节点和一个hcode（哈希化以后的映射值）</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 哈希表节点</span><br><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">HNode</span> &#123;<br>    HNode *next = <span class=\"hljs-literal\">NULL</span>;<br>    <span class=\"hljs-type\">uint64_t</span> hcode = <span class=\"hljs-number\">0</span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>哈希表</p>\n<p>哈希表主要载体是一个HNode的二维指针，第一个指针代表的是哈希值，第二个指针存储的是链表，链表是用来解决哈希冲突的方式。size表示的是当前哈希表中的总结点数目，mask表示掩码，为哈希表第一个维度大小减1。</p>\n<p>在哈希表中实现了，insert，lookup，detach，init接口，分别表示节点的插入，节点的查找，节点的删除。</p>\n<p>需要使用有参的构造函数初始化，传入的参数为整型，整型必须为2的幂，便于构建mask。</p>\n<ul>\n<li><p>节点的插入过程</p>\n<p>1、先计算当前节点中hcode应该属于的pos（即链表位置），计算方式是与<code>&amp;</code>上mask</p>\n<p>2、使用头插法，将节点插入到对应的位置，修改size大小</p>\n</li>\n<li><p>节点的查找过程</p>\n<p>1、查找哈希化后的链表位置。</p>\n<p>2、在链表中查找当前节点。</p>\n</li>\n<li><p>节点的删除过程<code>HNode *detach(HNode **from)</code></p>\n<p>1、解除引用，获取链表位置</p>\n<p>2、绕过当前节点，指向下一节点</p>\n<p>3、具体使用需要先找到节点位置，再调用detach</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 哈希表</span><br><span class=\"hljs-comment\">// 接口: insert, lookup, detach</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">HTab</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    HNode **tab = <span class=\"hljs-literal\">NULL</span>;<br>    <span class=\"hljs-type\">size_t</span> size = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-type\">size_t</span> mask = <span class=\"hljs-number\">0</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">HTab</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-comment\">// 传入的n必须为2的幂</span><br>    <span class=\"hljs-built_in\">HTab</span>(<span class=\"hljs-type\">size_t</span> n): <span class=\"hljs-built_in\">size</span>(<span class=\"hljs-number\">0</span>), <span class=\"hljs-built_in\">mask</span>(n<span class=\"hljs-number\">-1</span>)&#123;<br>        <span class=\"hljs-built_in\">assert</span>((n &amp; (n<span class=\"hljs-number\">-1</span>)) == <span class=\"hljs-number\">0</span>);<br>        tab = <span class=\"hljs-keyword\">new</span> HNode*[n];<br>    &#125;;<br>    ~<span class=\"hljs-built_in\">HTab</span>() &#123; <span class=\"hljs-keyword\">delete</span>[] tab; &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">insert</span><span class=\"hljs-params\">(HNode *node)</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">detach</span><span class=\"hljs-params\">(HNode **from)</span></span>;<br><br>    <span class=\"hljs-comment\">// setter</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_tab</span><span class=\"hljs-params\">(HNode **t)</span> </span>&#123; tab = t; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_mask</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> m)</span> </span>&#123; mask = m; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_size</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> s)</span> </span>&#123; size = s; &#125;<br><br>    <span class=\"hljs-comment\">// getter</span><br>    <span class=\"hljs-function\">HNode **<span class=\"hljs-title\">get_tab</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> tab; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">get_mask</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> mask; &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">get_size</span><span class=\"hljs-params\">()</span> </span>&#123; <span class=\"hljs-keyword\">return</span> size; &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>哈希map</p>\n<p>哈希表中含有两个HTab，用于完成渐进式的rehash。第一张表存储新的键值，第二张表存储旧的键值，当在第一张表中查找不到元素时，会再在第二张表查找。</p>\n<p>固定值的设置，k_max_load_factor表示负载因子，设置为8，即表示当前的总的HMap的节点数大于Mask的8倍的时候，就会对哈希表进行扩容。k_resizing_work的大小表示将哈希扩容分配到各个语句当中的单次转移的节点数量。resizing_pos记录resizing的位置。</p>\n<p>哈希Map实现了，insert，lookup，pop，size，destroy的接口，分别表示<strong>插入，查找，删除，返回哈希map节点数，以及销毁</strong>。同时会在负载过大时，重新申请更大的内存，执行resize操作，并分发到其他语句当中。</p>\n<p>start_resizing：检查ht2节点数是否大于零，若大于零，说明正在进行rehash中，将指定数量的节点rehash</p>\n<p>start_resizing：分配一个更大的表给ht1，要提前将ht2指向ht1</p>\n<ul>\n<li><p>插入的实现</p>\n<p>1、将节点插入到ht1当中，如果ht1为空，则新建ht1</p>\n<p>2、检查ht2是否为空，如果为空，则检查表1的负载因子，大于特定值，则开始resizing，如果ht2不为空，则说明正在resize，执行help_resizing。</p>\n</li>\n<li><p>查找的实现</p>\n<p>1、执行start_resizing</p>\n<p>2、分别在ht1和ht2中查找</p>\n</li>\n<li><p>删除的实现</p>\n<p>1、执行start_resizing</p>\n<p>2、执行查找，用返回节点执行节点删除</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><br><span class=\"hljs-comment\">// 哈希map</span><br><span class=\"hljs-comment\">// 使用两张哈希表用于渐进式rehash</span><br><span class=\"hljs-comment\">// 接口: insert, lookup, pop, size, destroy</span><br><span class=\"hljs-comment\">// private: start_resizing, help_resizing</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">HMap</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    HTab ht1;   <span class=\"hljs-comment\">// newer</span><br>    HTab ht2;   <span class=\"hljs-comment\">// older</span><br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">size_t</span> resizing_pos = <span class=\"hljs-number\">0</span>;    <br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> k_resizing_work = <span class=\"hljs-number\">128</span>; <span class=\"hljs-comment\">// constant work</span><br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> k_max_load_factor = <span class=\"hljs-number\">8</span>; <span class=\"hljs-comment\">// constant load factor</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">help_resizing</span><span class=\"hljs-params\">()</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">start_resizing</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">HMap</span>() : <span class=\"hljs-built_in\">ht1</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">ht2</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">resizing_pos</span>(<span class=\"hljs-number\">0</span>) &#123;&#125;;<br>    <span class=\"hljs-built_in\">HMap</span>(<span class=\"hljs-type\">size_t</span> n): <span class=\"hljs-built_in\">ht1</span>(n), <span class=\"hljs-built_in\">ht2</span>(<span class=\"hljs-number\">1</span>), <span class=\"hljs-built_in\">resizing_pos</span>(<span class=\"hljs-number\">0</span>) &#123;&#125;;<br>    ~<span class=\"hljs-built_in\">HMap</span>() &#123; ht1.~<span class=\"hljs-built_in\">HTab</span>(); ht2.~<span class=\"hljs-built_in\">HTab</span>(); &#125;<br><br>    <span class=\"hljs-comment\">// 插入、查找、删除、大小、销毁</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">insert</span><span class=\"hljs-params\">(HNode *node)</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\">HNode *<span class=\"hljs-title\">pop</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">size_t</span> <span class=\"hljs-title\">size</span><span class=\"hljs-params\">()</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">destroy</span><span class=\"hljs-params\">()</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<p>实际应用过程中还会有一个结构体</p>\n<p>将哈希表节点和键值对进行绑定</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">Entry</span> &#123;<br>    <span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">HNode</span> node;<br>    std::string key;<br>    std::string val;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"渐进式rehash过程\"><a href=\"#渐进式rehash过程\" class=\"headerlink\" title=\"渐进式rehash过程\"></a>渐进式rehash过程</h3><p>在哈希表的构建时，使用的是用二维指针来存储哈希表，解决哈希冲突的方式是常用的拉链法（使用链表存储映射值相等的哈希元素），第一个维度作为哈希映射的key值来定位到具体的映射链表，第二个维度则是用来解决哈希冲突的，考虑到哈希表定义本身的属性，我们是希望哈希表的哈希冲突尽可能少，也就是我们的链表的长度尽可能短，随着我们插入的数据不断增加，我们产生的哈希冲突也是会增加的。</p>\n<p>在这里我们定义了一个负载因子<code>k_max_load_factor</code>，在实际插入的过程中，当当前用于查找的哈希表中的负载（元素个数/掩码）大于负载因子，会启动rehash的过程，我们会申请一张比原来哈希表大两倍的哈希表，将当前哈希表中的数据重新映射到这一张新的哈希表中。这样我们原来短，高的哈希表，就会变成长，矮的哈希表。</p>\n<p>我们知道，当哈希表中的元素过多的时候，需要对所有元素都一起进行rehash是一个非常耗时的过程，如果我们只有一张哈希表，我们在进行rehash的过程中，还不能够允许其他插入、删除以及查询操作，为了解决这样一个问题，我们采用将rehash分散在各个其他语句的步骤，在我们负载因子达到一定程度的时候，我们会启动渐进式rehash，当我们有其他插入或者查询语句到来的时候，我们会先进行部分node的rehsah，再进行查询语句。我们可以看下面例子。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">HNode *<span class=\"hljs-title\">HMap::lookup</span><span class=\"hljs-params\">(HNode *key, <span class=\"hljs-type\">bool</span> (*eq)(HNode *, HNode *))</span> </span>&#123;<br>    <span class=\"hljs-built_in\">help_resizing</span>();<br>    HNode **from = ht1.<span class=\"hljs-built_in\">lookup</span>(key, eq);<br>    from = from ? from : ht2.<span class=\"hljs-built_in\">lookup</span>(key, eq);<br>    <span class=\"hljs-keyword\">return</span> from ? *from : <span class=\"hljs-literal\">NULL</span>;<br>&#125;<br><br><span class=\"hljs-comment\">// class HMap</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HMap::help_resizing</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">size_t</span> nwork = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">while</span> (nwork &lt; k_resizing_work &amp;&amp; ht2.<span class=\"hljs-built_in\">get_size</span>() &gt; <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-comment\">// scan for nodes from ht2 and move them to ht1</span><br>        HNode **from = &amp;ht2.<span class=\"hljs-built_in\">get_tab</span>()[resizing_pos];<br>        <span class=\"hljs-keyword\">if</span> (!*from) &#123;<br>            resizing_pos++;<br>            <span class=\"hljs-keyword\">continue</span>;<br>        &#125;<br><br>        ht1.<span class=\"hljs-built_in\">insert</span>(ht2.<span class=\"hljs-built_in\">detach</span>(from));<br>        nwork++;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">if</span> (ht2.<span class=\"hljs-built_in\">get_size</span>() == <span class=\"hljs-number\">0</span> &amp;&amp; ht2.<span class=\"hljs-built_in\">get_tab</span>()) &#123;<br>        <span class=\"hljs-comment\">// done</span><br>        <span class=\"hljs-keyword\">delete</span>[] ht2.<span class=\"hljs-built_in\">get_tab</span>();<br>        ht2 = HTab&#123;&#125;;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"五、平衡二叉树\"><a href=\"#五、平衡二叉树\" class=\"headerlink\" title=\"五、平衡二叉树\"></a>五、平衡二叉树</h2><p>平衡二叉树是一种特殊的二叉搜索树，对平衡二叉树来说，它的中序遍历是有序的，并且左右子树的高度差会处于一个平衡的状态，这样可以保证每次查找都能够在比较快的时间内完成。</p>\n<h3 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><blockquote>\n<p>平衡二叉树本身就是由节点构成的</p>\n</blockquote>\n<p>depth：以当前节点为根节点所在树的高度</p>\n<p>cnt：以当前节点为根节点的总节点数，便于进行区间统计</p>\n<p>left：左节点，right：右节点，parent：父节点</p>\n<p>提供的辅助函数</p>\n<ul>\n<li>rot_left：对当前节点进行左旋操作</li>\n</ul>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\"><span class=\"hljs-comment\">// 对b节点进行左旋，返回d节点</span><br>  <span class=\"hljs-selector-tag\">b</span>         d<br> / \\       /<br><span class=\"hljs-selector-tag\">a</span>   d ==&gt; <span class=\"hljs-selector-tag\">b</span><br>   /     / \\<br>  c     <span class=\"hljs-selector-tag\">a</span>   c<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>rot_right：镜像操作</p>\n</li>\n<li><p>avl_fix_left</p>\n<p>1、左子树的右子树太深需要先左旋后右旋</p>\n<p>2、左子树的左子树太深，直接右旋</p>\n</li>\n</ul>\n<figure class=\"highlight mathematica\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mathematica\">   <span class=\"hljs-variable\">root</span><br>   <span class=\"hljs-operator\">/</span>            左旋<span class=\"hljs-punctuation\">(</span><span class=\"hljs-variable\">root</span><span class=\"hljs-operator\">-&gt;</span><span class=\"hljs-variable\">left</span><span class=\"hljs-punctuation\">)</span><br>  <span class=\"hljs-variable\">A</span><br> <span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">C</span><br>   <span class=\"hljs-operator\">/</span> \\<br>  <span class=\"hljs-built_in\">D</span>   <span class=\"hljs-built_in\">E</span><br>  <br>   <span class=\"hljs-variable\">root</span><br>   <span class=\"hljs-operator\">/</span>              右旋<span class=\"hljs-punctuation\">(</span><span class=\"hljs-variable\">root</span><span class=\"hljs-punctuation\">)</span><br>  <span class=\"hljs-built_in\">C</span><br> <span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">A</span>   <span class=\"hljs-built_in\">E</span><br><span class=\"hljs-operator\">/</span> \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">D</span><br><br>    <span class=\"hljs-built_in\">C</span><br>   <span class=\"hljs-operator\">/</span> \\<br>  <span class=\"hljs-variable\">A</span>   <span class=\"hljs-variable\">root</span><br> <span class=\"hljs-operator\">/</span> \\    \\<br><span class=\"hljs-variable\">B</span>   <span class=\"hljs-built_in\">D</span>    <span class=\"hljs-built_in\">E</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>avl_fix_right也类似</p>\n</li>\n<li><p>avl_fix：对平衡二叉树的修复，当执行删除和插入节点时，调用这个函数保持节点的平衡</p>\n</li>\n<li><p>avl_del：删除节点</p>\n<p>1、当当前要删除的节点不存在右节点时，如果有左子树，将左子树向上提，如果没有左子树，说明删除的是root，最终都是返回左子树，返回左子树</p>\n<p>2、如果存在右节点，递归的找到右节点当中的最小元素，修改树的结构</p>\n</li>\n<li><p>avl_offset：从当前节点出发，按照偏移来进行查找节点</p>\n<p>1、初始化pos为0，表示当前节点相对于起始节点的位置</p>\n<p>2、如果pos等于偏移量，则返回</p>\n<p>3、如果小于偏移量，并且加上右节点的节点数大于offset，则说明在右子树</p>\n<p>4、如果大于偏移量，并且减去左节点的节点数小于offset，说明在左子树</p>\n<p>5、否则在父节点</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 平衡二叉树</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AVLNode</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">uint32_t</span> depth = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-type\">uint32_t</span> cnt = <span class=\"hljs-number\">0</span>;<br>    AVLNode *left = <span class=\"hljs-literal\">NULL</span>;<br>    AVLNode *right = <span class=\"hljs-literal\">NULL</span>;<br>    AVLNode *parent = <span class=\"hljs-literal\">NULL</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">AVLNode</span>(AVLNode *node);<br>    <span class=\"hljs-built_in\">AVLNode</span>();<br>    ~<span class=\"hljs-built_in\">AVLNode</span>();<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_del</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_offset</span><span class=\"hljs-params\">(AVLNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span></span>;<br><br>    <span class=\"hljs-comment\">// get </span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">avl_depth</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">avl_cnt</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">max</span><span class=\"hljs-params\">(<span class=\"hljs-type\">uint32_t</span> lhs, <span class=\"hljs-type\">uint32_t</span> rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">avl_update</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">rot_left</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">rot_right</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix_left</span><span class=\"hljs-params\">(AVLNode *root)</span></span>;<br>    <span class=\"hljs-function\">AVLNode *<span class=\"hljs-title\">avl_fix_right</span><span class=\"hljs-params\">(AVLNode *root)</span></span>;<br><br><span class=\"hljs-keyword\">private</span>:<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、zset数据结构\"><a href=\"#六、zset数据结构\" class=\"headerlink\" title=\"六、zset数据结构\"></a>六、zset数据结构</h2><p>zset在Redis中是使用跳表+哈希表来实现的</p>\n<p>这里使用AVL树+哈希表来实现</p>\n<ul>\n<li><p>ZNode</p>\n<p>ZNode中需要存储AVL树节点以及哈希节点，同时存储score是用于排序的键，ZNode中携带的数据可以提供快速查找，也支持有序访问，node同时属于AVL树和哈希表。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ZNode</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    AVLNode tree; <span class=\"hljs-comment\">// AVL树节点</span><br>    HNode hmap;   <span class=\"hljs-comment\">// 哈希表节点</span><br>    <span class=\"hljs-type\">double</span> score; <span class=\"hljs-comment\">// 分数</span><br>    <span class=\"hljs-type\">size_t</span> len;   <span class=\"hljs-comment\">// 名称长度</span><br>    <span class=\"hljs-type\">char</span> name[<span class=\"hljs-number\">0</span>];<br><br>    <span class=\"hljs-built_in\">ZNode</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span>* name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score);<br>    ~<span class=\"hljs-built_in\">ZNode</span>() = <span class=\"hljs-keyword\">default</span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>ZSet</p>\n<p>在ZSet中包含一个tree指向平衡二叉树的根节点，平衡二叉树关联着ZNode中的tree，同时维护一张HMap哈希表，用于对数据的快速查找</p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">接口</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_lookup(const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">根据传入的name来进行查找，从哈希表中查找</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">bool zset_add(const char *name, size_t len, double score);</td>\n<td style=\"text-align:center\">向ZSet中添加一个节点元素</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_pop(const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">从ZSet中弹出一个元素，按照name来弹出</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>zset_query(double score, const char </em>name, size_t len);</td>\n<td style=\"text-align:center\">查找ZSet中分数以及name都相等的ZNode</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ZNode <em>znode_offset(ZNode </em>node, int64_t offset);</td>\n<td style=\"text-align:center\">根据分数的偏移从AVLtree中查找ZNode</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">void zset_dispose();</td>\n<td style=\"text-align:center\">清空当前的ZSet，包括AVL树的清空和hmap的清空</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ZSet</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    AVLNode *tree = <span class=\"hljs-literal\">nullptr</span>;<br>    HMap hmap;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ZSet</span>() = <span class=\"hljs-keyword\">default</span>;<br>    ~<span class=\"hljs-built_in\">ZSet</span>() &#123; <span class=\"hljs-built_in\">zset_dispose</span>(); &#125;<br><br>    <span class=\"hljs-comment\">// helper</span><br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">znode_new</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">uint32_t</span> <span class=\"hljs-title\">min</span><span class=\"hljs-params\">(<span class=\"hljs-type\">size_t</span> lhs, <span class=\"hljs-type\">size_t</span> rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zless</span><span class=\"hljs-params\">(AVLNode *lhs, <span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zless</span><span class=\"hljs-params\">(AVLNode *lhs, AVLNode *rhs)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zset_update</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">tree_add</span><span class=\"hljs-params\">(ZNode *node)</span></span>;<br>    <br>    <span class=\"hljs-comment\">// interface</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">zset_add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span></span>;<br>    <span class=\"hljs-comment\">// 根据键值来查找哈希表</span><br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_lookup</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_pop</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">zset_query</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span></span>;<br>    <span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">znode_offset</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">znode_del</span><span class=\"hljs-params\">(ZNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">tree_dispose</span><span class=\"hljs-params\">(AVLNode *node)</span></span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zset_dispose</span><span class=\"hljs-params\">()</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<p>zset_lookup</p>\n<p>按照name在ZSet中查找节点</p>\n<ul>\n<li>直接通过hmap查找</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_lookup</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(!tree) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br>    HKey key;<br>    key.node.hcode = <span class=\"hljs-built_in\">str_hash</span>((<span class=\"hljs-type\">uint8_t</span>*)name, len);<br>    key.name = name;<br>    key.len = len;<br>    HNode *found = hmap.<span class=\"hljs-built_in\">lookup</span>(&amp;key.node, &amp;hcmp);<br>    <span class=\"hljs-keyword\">return</span> found ? <span class=\"hljs-built_in\">container_of</span>(found, ZNode, hmap) : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_add</p>\n<ul>\n<li>先查找set中是否存在有对应的节点，如果有则更新value的值</li>\n<li>如果没有，则生成一个新的znode并插入到zset中</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">ZSet::zset_add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len, <span class=\"hljs-type\">double</span> score)</span> </span>&#123;<br>    ZNode *node = <span class=\"hljs-built_in\">zset_lookup</span>(name, len);<br>    <span class=\"hljs-keyword\">if</span> (node) &#123;<br>        <span class=\"hljs-built_in\">zset_update</span>(node, score);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>        node = <span class=\"hljs-built_in\">znode_new</span>(name, len, score);<br>        hmap.<span class=\"hljs-built_in\">insert</span>(&amp;node-&gt;hmap);<br>        <span class=\"hljs-built_in\">tree_add</span>(node);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_pop</p>\n<blockquote>\n<p>通过name在zset数据结构中弹出对应的节点</p>\n</blockquote>\n<ul>\n<li>先从哈希表中查找对应的哈希节点</li>\n<li>通过找到的节点找到节点的Znode</li>\n<li>在AVL书中删除对应的Znode，并返回当前节点</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_pop</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(!tree) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br><br>    HKey key;<br>    key.node.hcode = <span class=\"hljs-built_in\">str_hash</span>((<span class=\"hljs-type\">uint8_t</span>*)name, len);<br>    key.name = name;<br>    key.len = len;<br>    HNode *found = hmap.<span class=\"hljs-built_in\">lookup</span>(&amp;key.node, &amp;hcmp);<br>    <span class=\"hljs-keyword\">if</span>(!found) &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nullptr</span>;<br>    &#125;<br><br>    ZNode *node = found-&gt;owner;<br>    tree = tree-&gt;<span class=\"hljs-built_in\">avl_del</span>(&amp;node-&gt;tree);<br>    <span class=\"hljs-keyword\">return</span> node;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>zset_query</p>\n<blockquote>\n<p>通过分数以及name查找的znode</p>\n</blockquote>\n<ul>\n<li>先通过分数在AVL树上进行查找，是一个二分查找的过程</li>\n<li>再通过比较查找得到的节点的name是否相等来对比返回结果</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::zset_query</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    AVLNode *found = <span class=\"hljs-literal\">nullptr</span>;<br>    AVLNode *cur = tree;<br>    <span class=\"hljs-keyword\">while</span>(cur) &#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">zless</span>(cur, score, name, len)) &#123;<br>            cur = cur-&gt;right;<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>            found = cur;<br>            cur = cur-&gt;left;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> found ? found-&gt;owner : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">ZSet::zless</span><span class=\"hljs-params\">(AVLNode *lhs, <span class=\"hljs-type\">double</span> score, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> *name, <span class=\"hljs-type\">size_t</span> len)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 根据指针偏移找到ZNode</span><br>    <span class=\"hljs-keyword\">auto</span> zl = lhs-&gt;owner;<br>    <span class=\"hljs-keyword\">if</span> (zl-&gt;score != score) &#123;<br>        <span class=\"hljs-keyword\">return</span> zl-&gt;score &lt; score;<br>    &#125;<br>    <span class=\"hljs-type\">int</span> rv = <span class=\"hljs-built_in\">memcmp</span>(zl-&gt;name, name, <span class=\"hljs-built_in\">min</span>(zl-&gt;len, len));<br>    <span class=\"hljs-keyword\">if</span> (rv != <span class=\"hljs-number\">0</span>) &#123;<br>        <span class=\"hljs-keyword\">return</span> rv &lt; <span class=\"hljs-number\">0</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> zl-&gt;len &lt; len;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>znode_offset</p>\n<blockquote>\n<p>根据score的偏移在AVL树中查找Znode。在我们的代码中AVL节点的定义，参考上面的avl_offset文字算法伪代码</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">ZNode *<span class=\"hljs-title\">ZSet::znode_offset</span><span class=\"hljs-params\">(ZNode *node, <span class=\"hljs-type\">int64_t</span> offset)</span> </span>&#123;<br>    AVLNode *tnode = node ? tree-&gt;<span class=\"hljs-built_in\">avl_offset</span>(&amp;node-&gt;tree, offset) : <span class=\"hljs-literal\">nullptr</span>;<br>    <span class=\"hljs-keyword\">return</span> tnode ? tnode-&gt;owner : <span class=\"hljs-literal\">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、测试效果\"><a href=\"#七、测试效果\" class=\"headerlink\" title=\"七、测试效果\"></a>七、测试效果</h2>"},{"title":"C++ Primer Plus学习笔记7-13章","date":"2023-07-21T07:58:51.000Z","cover":"/img/default_cover10.jpg","top_img":null,"_content":"### 第七章 函数-C++的编程模块\n\n函数的基本概念和应用：\n\n```\n具体应用\n按值传递，按地址传递\n函数在数组中的应用\n函数在结构体中的应用\n函数在string中的应用\n```\n\n\n\n#### 1、使用C++函数三部曲\n\n提供函数定义：根据返回值来定义函数，在函数中用return返回（函数通过将返回值复制到指定的CPU寄存器或内存单元中将其返回）。\n\n提供函数原型：函数原型描述了函数到编译器的接口，将函数的返回值的类型以及参数的类型和数量告诉编译器。\n\n调用函数：传入实参调用函数。\n\n\n\n#### 2、在函数中声明的变量\n\n在函数中声明的变量包括参数都是该函数私有的，在函数调用时，计算机为这些变量分配内存，函数结束时，计算机将释放这些变量使用的内存。\n\n\n\n#### 3、函数与数组\n\n在将数组作为函数参数传递的时候，既可以用int arr[]，也可以用int * arr。\n\n\n\n#### 4、指针和const\n\n常量指针和指针常量\n\n方法1：让指针指向一个常量对象，防止该指针来修改所指向的值\n\n```\n// 防止pt修改指向的值，但不能防止修改pt指针\n// 可以使用age来修改自身的值\nint age = 18;\nconst int * pt = &age;\n```\n\n* const 变量的地址可以赋给指向const的指针，但是不能赋值给常规指针。\n\n方法2：将指针本身声明为常量\n\n\n\n#### 5、使用const的好处\n\n避免由于无意间修改数据而导致的编程错误。\n\n使得函数能够处理const和非const实参，否则将只能接受非const数据。\n\n例：在使用函数来对某一个数组进行显示时，可以在形参使用const修饰数组，以防止函数对原始数组的修改。\n\n\n\n### 第八章 函数探幽\n\n函数更深的应用\n\n```\n内联函数\n```\n\n#### 内联函数\n\n常规函数和内联函数之间的区别在于C++编译器是如何将他们组合到程序中。对于常规函数的调用，会使用堆栈记录原始指令地址，随后跳转到目的函数中，执行结束后再返回原指令。对于内联函数的帝国用，编译器将使用相应的函数代码代替函数调用，在此过程并没有函数跳转调用的过程。\n\n相比之下，内联函数少去了函数跳转的时间，使用空间换时间。\n\n宏是通过文本替换来实现的。\n\n#### 引用变量\n\n引用时已定义变量的一个别名。引用必须在声明的时候将其初始化。\n\n引用作为参数传递可以使得被调用的函数访问调用函数中的变量。在传入参数中使用引用，就是为调用函数的变量新建了一个别名。\n\n什么情况下会生产临时变量：\n\n1、实参的类型正确，但不是左值\n\n```\n左值：可以取地址的，有名字的，非临时的变量就是左值\n右值：无法直接取到地址，没有名字的，临时变量就是右值\n\n新增右值引用的目的\n实现移动语义\n```\n\n2、实参类型不正确，但是可以转化为正确的类型\n\n\n\n使用引用变量的场景\n\n1、程序员能够修改调用函数中的数据对象\n\n2、通过传递引用而不是整个数据对象，可以提高程序的运行速度\n\n#### 函数重载\n\n原来仅仅是返回类型不一样是不能用作函数重载的。重载必须满足的是特征标不同，即传入的参数不一致。\n\n名称修饰：占位符\n\n#### 函数模板：使用泛型来定义函数（通用编程）\n\n> template <typename/class T>：定义模板以后使用模板定义数据\n\n当使用模板时，在调用模板函数的过程中，编译器会自动生成使用的模板类型的函数版本，但这一个过程对于程序员来说是透明的。\n\n#### 显示具体化\n\n在模板和具体化函数调用匹配产生冲突的时候，将优先使用具体化的函数进行匹配。\n\n显式实例化：通过<type>在函数调用的时候显示的给出需要用到的模板类型，这样编译器在进行编译期间就不需要自己分析模板类型。\n\n#### 编译器选择函数版本过程\n\n1、创建候选函数列表\n\n2、使用候选函数列表创建可行函数列表\n\n3、确定是否有最佳可行函数\n\n\n\ndecltype：类型推导\n\n> decltype(x+y) xpy = x + y\n>\n> 自动推导x+y的数据类型，并将其类型用于定义xpy，适合和模板进行共同使用。\n\nC++11后置返回类型：使用->将返回类型后置\n\nsizeof和strlen之间的区别，指针变量是无法用sizeof统计出字符串长度的。\n\n\n\n### 第九章  内存模块与名称空间\n\n#### 单独编译\n\n```\n头文件包含内容\n1、函数原型\n2、使用#define 或 const定义的符号常量\n3、结构声明\n4、类声明\n5、模板声明\n6、内联函数\n```\n\n#### 存储持续性、作用域和链接性\n\n数据存储方案\n\n* 自动存储持续性：函数参数，函数调用期间存在，函数执行结束释放\n* 静态存储持续性：整个程序运行过程中都存在，static变量\n* 线程存储持续性：生命周期和所属线程一样长\n* 动态存储持续性：new存在，delete释放，用户管理。\n\n作用域：名称在文件中的可见范围\n\n连接性：名称如何在不同单元中进行共享\n\nC++中的auto：自动类型推导\n\n变量只能定义一次，但可以多次应用，可以使用extern关键字对外部变量进行引用。\n\n* 说明符和限定符\n  * auto：自动类型推导\n  * register：指示寄存器存储\n  * static：用在作用域在整个文件的声明中时，表示内部链接性\n  * extern：表明是引用声明，声明引用在其它地方的变量\n  * thread_local：与线程的关系类似于静态变量于整个程序\n  * mutable：可修改的const\n* cv-限定符\n  * const\n  * volatile：告诉编译器不要进行编译器优化，比如一个for循环计数\n* mutable限定符\n  * 即使为const也可以修改\n\n内部链接性意味着每个文件都有自己的一组常量，而不是所有文件共享一组常量。\n\nnew定位运算符：能够指定要使用的位置，需要包含头文件new，\n\n#### 名称空间\n\n声明区域：参数在其在进行中所在的区域。\n\n潜在作用域：潜在作用域小于声明的区域。\n\n\n\n名称空间可以是全局的，也可以位于另一个名称空间中，但不能够位于代码块中。默认情况下，在名称空间中声明的名称的链接性为外部的。\n\n```\nnamespace Jack{\n\t//名称空间用到的变量和函数，类似于封装\n}\n```\n\nusing 和 using namespace：using可以使得某一个名称空间里面的函数或变量可用，using namespace 使得整个名称空间内的变量和函数都可用。\n\n如果全局中含有某名称空间的同名的变量，引用该名称空间时将自动隐藏名称空间的该变量，而使用全局变量。\n\n\n\n### 第十章 对象和类\n\n面向对象的特性：抽象、封装和数据隐藏、多态、继承、代码的可重用性\n\n#### 抽象和类\n\n接口：接口是一个共享框架，供两个系统交互时使用。\n\n访问控制字：public、private、protected，公有、私有、保护\n\n结构体默认访问类型为public，类的默认访问类型为private\n\n#### 类的构造函数和析构函数\n\n> 构造函数和析构函数都没有返回值类型\n\n构造函数\n\n显示调用和隐式调用，每一个对象在创建的时候会自动调用构造函数，构造函数可以由用户给出，也可以使用默认的构造函数（不做任何操作）。\n\n构造函数可以存在多个，能使用函数重载的方式来使用不同的构造函数。\n\n析构函数\n\n析构函数是在对象释放的时候自动调用的函数，用于释放新建的对象资源。\n\n* C++11列表初始化方式\n\n```\nBozo(const char * fname, const char * lname);\n\nBozo bozette = {\"Bozetta\", \"Biggens\"};\nBozo fufu{\"Fufu\", \"O'Dweeb\"};\nBozo *pc = new Bozo{\"Popo\", \"Le Peu\"};\n```\n\n#### this 指针\n\nthis指针指向的是自身的地址，如果需要返回自身对象，需要使用*this，访问自身的成员也可以使用this->成员变量来进行访问。\n\n\n\n### 第十一章 使用类\n\n#### 运算符重载\n\n* 不能重载的运算符\n\n  > sizeof、.（成员运算符）、.*(成员指针运算符)、::（作用域运算符）、?:（条件运算符）、typeid、const_cast、dynamic_cast、reinterpret_cast、static_cast\n\n运算符重载是面向对象多态的一种表现，使用运算符重载能够使得编程更加灵活，例如实现两个对象相加，可以使用+运算符重载。\n\n> operator运算符（）\n\n```\nclass Time{\n\tint a;\n\tint b;\npublic:\n\tTime(int m_a, int m_b){\n\t\ta = m_a;\n\t\tb = m_b;\n\t}\n\t\n\t// 对 + 运算符进行重载\n\tTime operator+(Time& t2){\n\t\tTime time;\n\t\ttime.a = a + t2.a;\n\t\ttime.b = b + t2.b;\n\t\treturn time;\n\t}\n}\n```\n\n#### 友元函数\n\n友元的三种类型：友元函数、友元类、友元成员函数。\n\n将函数、类、成员函数设置为类的友元，可以赋予该函数与类的成员函数相同的访问权限。\n\n* 创建友元函数\n\n  将函数原型前面加上friend放在类声明中。\n\n  如果要为类重载运算符，并将非类的项作为其第一个操作数，则可以使用友元函数来反转操作数的顺序。若不用友元函数访问，只能将一个参数传入到类的对象函数原型中，无法控制需要操作对象之间的顺序。\n\n> “<<” 运算符的重载\n\n```\n#include<iostream>\nusing namespace std;\n\n// 对<<运算符进行重载\nclass Time {\n\tfriend ostream& operator<<(ostream& os, const Time& t);\n\tint hour;\n\tint second;\n\npublic:\n\tTime(int m_hour, int m_second) {\n\t\thour = m_hour;\n\t\tsecond = m_second;\n\t}\n};\n// 返回流对象，便于传递操作\nostream& operator<<(ostream& os, const Time& t) {\n\tos << t.hour << \"   \" << t.second;\n\treturn os;\n}\n\nint main() {\n\tTime time(2, 40);\n\tcout << time << endl;\n\tsystem(\"PAUSE\");\n\treturn 0;\n}\n```\n\n当重载的函数和目标对象不在一个作用域内时，需要使用域名控制符号来对其进行访问。\n\n运算符重载，还可以更具特征标的数量不同再次进行重载。\n\n#### 类型转换\n\n构造函数可以使用隐式转换：隐式构造函数必须不能存在二义性\n\n> 在下面程序中，使用Stonewt st = 12;将默认隐式调用了构造函数Stonewt(double lbs)，对Stonewt的成员进行初始化。\n\n```\n#include<iostream>\nusing namespace std;\n\nclass Stonewt {\n\tint stone;\n\tdouble pds;\n\tdouble pounds;\n\npublic:\n\tStonewt(double lbs) {\n\t\tstone = int(lbs);\n\t\tpds = int(lbs) % 14 + lbs;\n\t\tpounds = lbs;\n\t}\n\tStonewt() {\n\t\tstone = pds = pounds = 0;\n\t}\n\tvoid show() {\n\t\tcout << stone << endl;\n\t\tcout << pds << endl;\n\t\tcout << pounds << endl;\n\t}\n};\n\nint main() {\n\tStonewt st = 12;\n\tst.show();\n\n\tsystem(\"PAUSE\");\n\treturn 0;\n}\n```\n\n如果关闭隐式构造函数则使用：explicit Stonewt(double lbs);\n\n#### 转换函数\n\n> 格式：operator typename();\n>\n> exp：operator double();\n\n如果在类里面定义了转化函数，可以将类强制转化成其它的数据类型。转化函数中返回需要进行转化的数据。\n\n\n\n### 第十二章  类的动态内存分配\n\n#### 动态内存和类\n\n再动态分配内存中，对象的析构函数是必不可少的，有的时候必须要重载赋值运算符。\n\n在类里面定义静态成员，意味着该类的所有对象能够共同享用这同一个静态成员变量。\n\n将对象作为函数参数来传递而不是使用引用来传递，容易造成函数结束以后对象自动释放并调用析构函数的现象。\n\n当使用一个对象初始化另一个对象的时候会调用拷贝构造函数。\n\n* C++为一个对象自动提供的成员函数：\n\n  * 默认构造函数：在对象创建时进行调用\n  * 默认析构函数：在对象销毁时调用\n  * 复制构造函数：用于将一个对象复制到新创建的对象中，默认复制构造函数用到的是浅拷贝。\n\n  * 赋值运算符重载：通常将一个对象使用等号赋值给另一个对象会用到，默认用的时浅拷贝\n  * 地址运算符重载\n  * 移动构造函数\n  * 移动赋值函数\n\n* 浅拷贝和深拷贝\n\n  在使用复制构造函数的过程中，默认进行的是浅拷贝，将一个对象的地址赋值给另一个需要初始化的对象。通过显性的修改复制构造函数的拷贝过程，可以实现深拷贝，即重新申请一块内存空间，将一个对象的数据放进去，让两个对象使用不同的两个地址空间。\n\n* C++11中引用nullptr表示空指针\n\n* 可以将成员函数声明为静态的，声明过后\n\n  * 不能通过对象调用静态成员函数，静态成员函数不能使用this指针\n  * 静态成员函数只能够使用静态数据成员\n\n#### 使用new注意事项\n\n* 使用new后应该同样用delete进行释放\n* new和delete必须相互兼容，new对应于delete，new[]对应与delete[]\n* 如果有多个构造函数，必须以相同的方式使用new\n* 应定义一个复制构造函数，深拷贝一个对象初始化为另一个对象\n* 应定义一个等号=运算符重载，通过深拷贝将一个对象赋值给另一个对象\n\n#### 有关返回对象的说明\n\n* 返回对象的引用、返回指向对象的const引用和返回const对象的区别\n\n  * 1、返回对象将调用赋值构造函数，返回引用不会\n  * 2、引用指向的对象应该在调用函数执行时存在\n\n* 返回指向非const对象引用\n\n  > 非const则说明可以对对象进行修改，具有传递性的操作必须返回非const对象引用\n\n* 当返回对象是被调用函数当中的局部变量，则不应该以引用来返回，而应该使用对象来返回，调用拷贝构造函数创建一个新的对象，比如算数运算符。\n\n若方法要返回局部对象，则应返回对象\n\n若方法或函数要返回一个没有共有复制构造函数的类的对象，必须返回一个指向这种对象的引用\n\n\n\n### 第十三章  类继承\n\n通过继承可以完成的一些工作：\n\n1、可以在已有类的基础上添加功能\n\n2、可以给类添加数据\n\n3、可以修改类的方法\n\n总结，对于父类的一些功能的拓展。一般情况下会遵守开闭原则。\n\n\n\n派生的类型：公有派生、私有派生、保护派生\n\n公有派生：基类的公有成员称为派生类的公有成员。基类的私有部分称为派生类的一部分，但是只能够通过基类的公有和保护方法来进行访问。\n\n\n\n父类指针指向子类对象， 通过这样的方式可以实现多态\n\n基类指针可以在不进行显示类型转换的情况下指向派生类对象；\n\n基类引用可以在不进行显示类型转化的情况下引用派生类对象；\n\n#### 多态公有继承\n\n方法1、在派生类中重新定义基类的方法，通过在父类对象和子类对象中定义同样的方法，分别使用父类和子类对象的实例来调用来实现不同对象对同一对象接口调用达到多态。\n\n方法2、使用虚方法，使用父类指针指向子类对象，在父类对象中使用虚函数，在子类对象中实现，通过一个父类指针指向子类对象来调用子类中的函数。\n\n* 虚析构函数的作用\n  * 使用虚析构函数可以确保正确的析构函数序列被调用。\n\n#### 动态联编和静态联编\n\n将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编。\n\n在编译过程中进行的联编称为静态联编。\n\n在程序运行时进行的联编称为动态联编，有虚函数的代码需要在函数运行过程中才能够确认虚函数中具体要执行和完成的任务。\n\n#### 虚函数的工作原理\n\n编译器处理虚函数的方法是，为每个对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表（vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。\n\n基类对象中包含一个指针，指向基类中所有虚函数表的地址表。派生类对象将包含一个指向对立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址，如果派生类没有定义虚函数，该虚函数表将保存函数原始版本的地址。\n\n#### 访问控制：protected\n\n派生类的成员可以直接访问基类的保护成员，但不能访问基类的私有成员，对于外部世界来说，保护成员的行为与私有成员相似，对于派生类来说，保护车关于的行为与公有成员相似。\n\n#### 抽象类\n\nC++可以通过纯虚函数提供未实现的函数，纯虚函数声明的结尾处为=0。\n\n当类声明中包含纯虚函数时，则不能够创建该类的对象。因为需要通过继承的方式来实现纯虚函数中未定义的方法实现。\n\n#### 继承和动态内存分配\n\n1、如果在派生类中没有用到动态内存分配，则无需进行操作，析构函数也不需要修改。\n\n2、如果派生类中有定义的指针需要动态分配内存的成员变量，则必须为派生类定义**显式析构函数、复制（拷贝）构造函数和赋值（=重载）构造函数**，在派生类的赋值构造函数和赋值构造函数中还必须显示的调用基类的构造函数。\n\n在派生类中重定义基类的方法不是重载，将直接覆盖基类的原始方法。\n\n","source":"_posts/c-primer-plus.md","raw":"---\ntitle: C++ Primer Plus学习笔记7-13章\ncategories: 学习笔记\ndate: 2023-07-21 15:58:51\ntags: [C++进阶, C++]\ncover:\ntop_img:\n---\n### 第七章 函数-C++的编程模块\n\n函数的基本概念和应用：\n\n```\n具体应用\n按值传递，按地址传递\n函数在数组中的应用\n函数在结构体中的应用\n函数在string中的应用\n```\n\n\n\n#### 1、使用C++函数三部曲\n\n提供函数定义：根据返回值来定义函数，在函数中用return返回（函数通过将返回值复制到指定的CPU寄存器或内存单元中将其返回）。\n\n提供函数原型：函数原型描述了函数到编译器的接口，将函数的返回值的类型以及参数的类型和数量告诉编译器。\n\n调用函数：传入实参调用函数。\n\n\n\n#### 2、在函数中声明的变量\n\n在函数中声明的变量包括参数都是该函数私有的，在函数调用时，计算机为这些变量分配内存，函数结束时，计算机将释放这些变量使用的内存。\n\n\n\n#### 3、函数与数组\n\n在将数组作为函数参数传递的时候，既可以用int arr[]，也可以用int * arr。\n\n\n\n#### 4、指针和const\n\n常量指针和指针常量\n\n方法1：让指针指向一个常量对象，防止该指针来修改所指向的值\n\n```\n// 防止pt修改指向的值，但不能防止修改pt指针\n// 可以使用age来修改自身的值\nint age = 18;\nconst int * pt = &age;\n```\n\n* const 变量的地址可以赋给指向const的指针，但是不能赋值给常规指针。\n\n方法2：将指针本身声明为常量\n\n\n\n#### 5、使用const的好处\n\n避免由于无意间修改数据而导致的编程错误。\n\n使得函数能够处理const和非const实参，否则将只能接受非const数据。\n\n例：在使用函数来对某一个数组进行显示时，可以在形参使用const修饰数组，以防止函数对原始数组的修改。\n\n\n\n### 第八章 函数探幽\n\n函数更深的应用\n\n```\n内联函数\n```\n\n#### 内联函数\n\n常规函数和内联函数之间的区别在于C++编译器是如何将他们组合到程序中。对于常规函数的调用，会使用堆栈记录原始指令地址，随后跳转到目的函数中，执行结束后再返回原指令。对于内联函数的帝国用，编译器将使用相应的函数代码代替函数调用，在此过程并没有函数跳转调用的过程。\n\n相比之下，内联函数少去了函数跳转的时间，使用空间换时间。\n\n宏是通过文本替换来实现的。\n\n#### 引用变量\n\n引用时已定义变量的一个别名。引用必须在声明的时候将其初始化。\n\n引用作为参数传递可以使得被调用的函数访问调用函数中的变量。在传入参数中使用引用，就是为调用函数的变量新建了一个别名。\n\n什么情况下会生产临时变量：\n\n1、实参的类型正确，但不是左值\n\n```\n左值：可以取地址的，有名字的，非临时的变量就是左值\n右值：无法直接取到地址，没有名字的，临时变量就是右值\n\n新增右值引用的目的\n实现移动语义\n```\n\n2、实参类型不正确，但是可以转化为正确的类型\n\n\n\n使用引用变量的场景\n\n1、程序员能够修改调用函数中的数据对象\n\n2、通过传递引用而不是整个数据对象，可以提高程序的运行速度\n\n#### 函数重载\n\n原来仅仅是返回类型不一样是不能用作函数重载的。重载必须满足的是特征标不同，即传入的参数不一致。\n\n名称修饰：占位符\n\n#### 函数模板：使用泛型来定义函数（通用编程）\n\n> template <typename/class T>：定义模板以后使用模板定义数据\n\n当使用模板时，在调用模板函数的过程中，编译器会自动生成使用的模板类型的函数版本，但这一个过程对于程序员来说是透明的。\n\n#### 显示具体化\n\n在模板和具体化函数调用匹配产生冲突的时候，将优先使用具体化的函数进行匹配。\n\n显式实例化：通过<type>在函数调用的时候显示的给出需要用到的模板类型，这样编译器在进行编译期间就不需要自己分析模板类型。\n\n#### 编译器选择函数版本过程\n\n1、创建候选函数列表\n\n2、使用候选函数列表创建可行函数列表\n\n3、确定是否有最佳可行函数\n\n\n\ndecltype：类型推导\n\n> decltype(x+y) xpy = x + y\n>\n> 自动推导x+y的数据类型，并将其类型用于定义xpy，适合和模板进行共同使用。\n\nC++11后置返回类型：使用->将返回类型后置\n\nsizeof和strlen之间的区别，指针变量是无法用sizeof统计出字符串长度的。\n\n\n\n### 第九章  内存模块与名称空间\n\n#### 单独编译\n\n```\n头文件包含内容\n1、函数原型\n2、使用#define 或 const定义的符号常量\n3、结构声明\n4、类声明\n5、模板声明\n6、内联函数\n```\n\n#### 存储持续性、作用域和链接性\n\n数据存储方案\n\n* 自动存储持续性：函数参数，函数调用期间存在，函数执行结束释放\n* 静态存储持续性：整个程序运行过程中都存在，static变量\n* 线程存储持续性：生命周期和所属线程一样长\n* 动态存储持续性：new存在，delete释放，用户管理。\n\n作用域：名称在文件中的可见范围\n\n连接性：名称如何在不同单元中进行共享\n\nC++中的auto：自动类型推导\n\n变量只能定义一次，但可以多次应用，可以使用extern关键字对外部变量进行引用。\n\n* 说明符和限定符\n  * auto：自动类型推导\n  * register：指示寄存器存储\n  * static：用在作用域在整个文件的声明中时，表示内部链接性\n  * extern：表明是引用声明，声明引用在其它地方的变量\n  * thread_local：与线程的关系类似于静态变量于整个程序\n  * mutable：可修改的const\n* cv-限定符\n  * const\n  * volatile：告诉编译器不要进行编译器优化，比如一个for循环计数\n* mutable限定符\n  * 即使为const也可以修改\n\n内部链接性意味着每个文件都有自己的一组常量，而不是所有文件共享一组常量。\n\nnew定位运算符：能够指定要使用的位置，需要包含头文件new，\n\n#### 名称空间\n\n声明区域：参数在其在进行中所在的区域。\n\n潜在作用域：潜在作用域小于声明的区域。\n\n\n\n名称空间可以是全局的，也可以位于另一个名称空间中，但不能够位于代码块中。默认情况下，在名称空间中声明的名称的链接性为外部的。\n\n```\nnamespace Jack{\n\t//名称空间用到的变量和函数，类似于封装\n}\n```\n\nusing 和 using namespace：using可以使得某一个名称空间里面的函数或变量可用，using namespace 使得整个名称空间内的变量和函数都可用。\n\n如果全局中含有某名称空间的同名的变量，引用该名称空间时将自动隐藏名称空间的该变量，而使用全局变量。\n\n\n\n### 第十章 对象和类\n\n面向对象的特性：抽象、封装和数据隐藏、多态、继承、代码的可重用性\n\n#### 抽象和类\n\n接口：接口是一个共享框架，供两个系统交互时使用。\n\n访问控制字：public、private、protected，公有、私有、保护\n\n结构体默认访问类型为public，类的默认访问类型为private\n\n#### 类的构造函数和析构函数\n\n> 构造函数和析构函数都没有返回值类型\n\n构造函数\n\n显示调用和隐式调用，每一个对象在创建的时候会自动调用构造函数，构造函数可以由用户给出，也可以使用默认的构造函数（不做任何操作）。\n\n构造函数可以存在多个，能使用函数重载的方式来使用不同的构造函数。\n\n析构函数\n\n析构函数是在对象释放的时候自动调用的函数，用于释放新建的对象资源。\n\n* C++11列表初始化方式\n\n```\nBozo(const char * fname, const char * lname);\n\nBozo bozette = {\"Bozetta\", \"Biggens\"};\nBozo fufu{\"Fufu\", \"O'Dweeb\"};\nBozo *pc = new Bozo{\"Popo\", \"Le Peu\"};\n```\n\n#### this 指针\n\nthis指针指向的是自身的地址，如果需要返回自身对象，需要使用*this，访问自身的成员也可以使用this->成员变量来进行访问。\n\n\n\n### 第十一章 使用类\n\n#### 运算符重载\n\n* 不能重载的运算符\n\n  > sizeof、.（成员运算符）、.*(成员指针运算符)、::（作用域运算符）、?:（条件运算符）、typeid、const_cast、dynamic_cast、reinterpret_cast、static_cast\n\n运算符重载是面向对象多态的一种表现，使用运算符重载能够使得编程更加灵活，例如实现两个对象相加，可以使用+运算符重载。\n\n> operator运算符（）\n\n```\nclass Time{\n\tint a;\n\tint b;\npublic:\n\tTime(int m_a, int m_b){\n\t\ta = m_a;\n\t\tb = m_b;\n\t}\n\t\n\t// 对 + 运算符进行重载\n\tTime operator+(Time& t2){\n\t\tTime time;\n\t\ttime.a = a + t2.a;\n\t\ttime.b = b + t2.b;\n\t\treturn time;\n\t}\n}\n```\n\n#### 友元函数\n\n友元的三种类型：友元函数、友元类、友元成员函数。\n\n将函数、类、成员函数设置为类的友元，可以赋予该函数与类的成员函数相同的访问权限。\n\n* 创建友元函数\n\n  将函数原型前面加上friend放在类声明中。\n\n  如果要为类重载运算符，并将非类的项作为其第一个操作数，则可以使用友元函数来反转操作数的顺序。若不用友元函数访问，只能将一个参数传入到类的对象函数原型中，无法控制需要操作对象之间的顺序。\n\n> “<<” 运算符的重载\n\n```\n#include<iostream>\nusing namespace std;\n\n// 对<<运算符进行重载\nclass Time {\n\tfriend ostream& operator<<(ostream& os, const Time& t);\n\tint hour;\n\tint second;\n\npublic:\n\tTime(int m_hour, int m_second) {\n\t\thour = m_hour;\n\t\tsecond = m_second;\n\t}\n};\n// 返回流对象，便于传递操作\nostream& operator<<(ostream& os, const Time& t) {\n\tos << t.hour << \"   \" << t.second;\n\treturn os;\n}\n\nint main() {\n\tTime time(2, 40);\n\tcout << time << endl;\n\tsystem(\"PAUSE\");\n\treturn 0;\n}\n```\n\n当重载的函数和目标对象不在一个作用域内时，需要使用域名控制符号来对其进行访问。\n\n运算符重载，还可以更具特征标的数量不同再次进行重载。\n\n#### 类型转换\n\n构造函数可以使用隐式转换：隐式构造函数必须不能存在二义性\n\n> 在下面程序中，使用Stonewt st = 12;将默认隐式调用了构造函数Stonewt(double lbs)，对Stonewt的成员进行初始化。\n\n```\n#include<iostream>\nusing namespace std;\n\nclass Stonewt {\n\tint stone;\n\tdouble pds;\n\tdouble pounds;\n\npublic:\n\tStonewt(double lbs) {\n\t\tstone = int(lbs);\n\t\tpds = int(lbs) % 14 + lbs;\n\t\tpounds = lbs;\n\t}\n\tStonewt() {\n\t\tstone = pds = pounds = 0;\n\t}\n\tvoid show() {\n\t\tcout << stone << endl;\n\t\tcout << pds << endl;\n\t\tcout << pounds << endl;\n\t}\n};\n\nint main() {\n\tStonewt st = 12;\n\tst.show();\n\n\tsystem(\"PAUSE\");\n\treturn 0;\n}\n```\n\n如果关闭隐式构造函数则使用：explicit Stonewt(double lbs);\n\n#### 转换函数\n\n> 格式：operator typename();\n>\n> exp：operator double();\n\n如果在类里面定义了转化函数，可以将类强制转化成其它的数据类型。转化函数中返回需要进行转化的数据。\n\n\n\n### 第十二章  类的动态内存分配\n\n#### 动态内存和类\n\n再动态分配内存中，对象的析构函数是必不可少的，有的时候必须要重载赋值运算符。\n\n在类里面定义静态成员，意味着该类的所有对象能够共同享用这同一个静态成员变量。\n\n将对象作为函数参数来传递而不是使用引用来传递，容易造成函数结束以后对象自动释放并调用析构函数的现象。\n\n当使用一个对象初始化另一个对象的时候会调用拷贝构造函数。\n\n* C++为一个对象自动提供的成员函数：\n\n  * 默认构造函数：在对象创建时进行调用\n  * 默认析构函数：在对象销毁时调用\n  * 复制构造函数：用于将一个对象复制到新创建的对象中，默认复制构造函数用到的是浅拷贝。\n\n  * 赋值运算符重载：通常将一个对象使用等号赋值给另一个对象会用到，默认用的时浅拷贝\n  * 地址运算符重载\n  * 移动构造函数\n  * 移动赋值函数\n\n* 浅拷贝和深拷贝\n\n  在使用复制构造函数的过程中，默认进行的是浅拷贝，将一个对象的地址赋值给另一个需要初始化的对象。通过显性的修改复制构造函数的拷贝过程，可以实现深拷贝，即重新申请一块内存空间，将一个对象的数据放进去，让两个对象使用不同的两个地址空间。\n\n* C++11中引用nullptr表示空指针\n\n* 可以将成员函数声明为静态的，声明过后\n\n  * 不能通过对象调用静态成员函数，静态成员函数不能使用this指针\n  * 静态成员函数只能够使用静态数据成员\n\n#### 使用new注意事项\n\n* 使用new后应该同样用delete进行释放\n* new和delete必须相互兼容，new对应于delete，new[]对应与delete[]\n* 如果有多个构造函数，必须以相同的方式使用new\n* 应定义一个复制构造函数，深拷贝一个对象初始化为另一个对象\n* 应定义一个等号=运算符重载，通过深拷贝将一个对象赋值给另一个对象\n\n#### 有关返回对象的说明\n\n* 返回对象的引用、返回指向对象的const引用和返回const对象的区别\n\n  * 1、返回对象将调用赋值构造函数，返回引用不会\n  * 2、引用指向的对象应该在调用函数执行时存在\n\n* 返回指向非const对象引用\n\n  > 非const则说明可以对对象进行修改，具有传递性的操作必须返回非const对象引用\n\n* 当返回对象是被调用函数当中的局部变量，则不应该以引用来返回，而应该使用对象来返回，调用拷贝构造函数创建一个新的对象，比如算数运算符。\n\n若方法要返回局部对象，则应返回对象\n\n若方法或函数要返回一个没有共有复制构造函数的类的对象，必须返回一个指向这种对象的引用\n\n\n\n### 第十三章  类继承\n\n通过继承可以完成的一些工作：\n\n1、可以在已有类的基础上添加功能\n\n2、可以给类添加数据\n\n3、可以修改类的方法\n\n总结，对于父类的一些功能的拓展。一般情况下会遵守开闭原则。\n\n\n\n派生的类型：公有派生、私有派生、保护派生\n\n公有派生：基类的公有成员称为派生类的公有成员。基类的私有部分称为派生类的一部分，但是只能够通过基类的公有和保护方法来进行访问。\n\n\n\n父类指针指向子类对象， 通过这样的方式可以实现多态\n\n基类指针可以在不进行显示类型转换的情况下指向派生类对象；\n\n基类引用可以在不进行显示类型转化的情况下引用派生类对象；\n\n#### 多态公有继承\n\n方法1、在派生类中重新定义基类的方法，通过在父类对象和子类对象中定义同样的方法，分别使用父类和子类对象的实例来调用来实现不同对象对同一对象接口调用达到多态。\n\n方法2、使用虚方法，使用父类指针指向子类对象，在父类对象中使用虚函数，在子类对象中实现，通过一个父类指针指向子类对象来调用子类中的函数。\n\n* 虚析构函数的作用\n  * 使用虚析构函数可以确保正确的析构函数序列被调用。\n\n#### 动态联编和静态联编\n\n将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编。\n\n在编译过程中进行的联编称为静态联编。\n\n在程序运行时进行的联编称为动态联编，有虚函数的代码需要在函数运行过程中才能够确认虚函数中具体要执行和完成的任务。\n\n#### 虚函数的工作原理\n\n编译器处理虚函数的方法是，为每个对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表（vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。\n\n基类对象中包含一个指针，指向基类中所有虚函数表的地址表。派生类对象将包含一个指向对立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址，如果派生类没有定义虚函数，该虚函数表将保存函数原始版本的地址。\n\n#### 访问控制：protected\n\n派生类的成员可以直接访问基类的保护成员，但不能访问基类的私有成员，对于外部世界来说，保护成员的行为与私有成员相似，对于派生类来说，保护车关于的行为与公有成员相似。\n\n#### 抽象类\n\nC++可以通过纯虚函数提供未实现的函数，纯虚函数声明的结尾处为=0。\n\n当类声明中包含纯虚函数时，则不能够创建该类的对象。因为需要通过继承的方式来实现纯虚函数中未定义的方法实现。\n\n#### 继承和动态内存分配\n\n1、如果在派生类中没有用到动态内存分配，则无需进行操作，析构函数也不需要修改。\n\n2、如果派生类中有定义的指针需要动态分配内存的成员变量，则必须为派生类定义**显式析构函数、复制（拷贝）构造函数和赋值（=重载）构造函数**，在派生类的赋值构造函数和赋值构造函数中还必须显示的调用基类的构造函数。\n\n在派生类中重定义基类的方法不是重载，将直接覆盖基类的原始方法。\n\n","slug":"c-primer-plus","published":1,"updated":"2024-06-05T09:03:03.633Z","comments":1,"layout":"post","photos":[],"_id":"clyfintto001108jvcpmfe2lj","content":"<h3 id=\"第七章-函数-C-的编程模块\"><a href=\"#第七章-函数-C-的编程模块\" class=\"headerlink\" title=\"第七章 函数-C++的编程模块\"></a>第七章 函数-C++的编程模块</h3><p>函数的基本概念和应用：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\">具体应用<br>按值传递，按地址传递<br>函数在数组中的应用<br>函数在结构体中的应用<br>函数在<span class=\"hljs-built_in\">string</span>中的应用<br></code></pre></td></tr></table></figure>\n<h4 id=\"1、使用C-函数三部曲\"><a href=\"#1、使用C-函数三部曲\" class=\"headerlink\" title=\"1、使用C++函数三部曲\"></a>1、使用C++函数三部曲</h4><p>提供函数定义：根据返回值来定义函数，在函数中用return返回（函数通过将返回值复制到指定的CPU寄存器或内存单元中将其返回）。</p>\n<p>提供函数原型：函数原型描述了函数到编译器的接口，将函数的返回值的类型以及参数的类型和数量告诉编译器。</p>\n<p>调用函数：传入实参调用函数。</p>\n<h4 id=\"2、在函数中声明的变量\"><a href=\"#2、在函数中声明的变量\" class=\"headerlink\" title=\"2、在函数中声明的变量\"></a>2、在函数中声明的变量</h4><p>在函数中声明的变量包括参数都是该函数私有的，在函数调用时，计算机为这些变量分配内存，函数结束时，计算机将释放这些变量使用的内存。</p>\n<h4 id=\"3、函数与数组\"><a href=\"#3、函数与数组\" class=\"headerlink\" title=\"3、函数与数组\"></a>3、函数与数组</h4><p>在将数组作为函数参数传递的时候，既可以用int arr[]，也可以用int * arr。</p>\n<h4 id=\"4、指针和const\"><a href=\"#4、指针和const\" class=\"headerlink\" title=\"4、指针和const\"></a>4、指针和const</h4><p>常量指针和指针常量</p>\n<p>方法1：让指针指向一个常量对象，防止该指针来修改所指向的值</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-comment\">// 防止pt修改指向的值，但不能防止修改pt指针</span><br><span class=\"hljs-comment\">// 可以使用age来修改自身的值</span><br><span class=\"hljs-built_in\">int</span> age = <span class=\"hljs-number\">18</span>;<br><span class=\"hljs-keyword\">const</span> <span class=\"hljs-built_in\">int</span> * pt = &amp;age;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>const 变量的地址可以赋给指向const的指针，但是不能赋值给常规指针。</li>\n</ul>\n<p>方法2：将指针本身声明为常量</p>\n<h4 id=\"5、使用const的好处\"><a href=\"#5、使用const的好处\" class=\"headerlink\" title=\"5、使用const的好处\"></a>5、使用const的好处</h4><p>避免由于无意间修改数据而导致的编程错误。</p>\n<p>使得函数能够处理const和非const实参，否则将只能接受非const数据。</p>\n<p>例：在使用函数来对某一个数组进行显示时，可以在形参使用const修饰数组，以防止函数对原始数组的修改。</p>\n<h3 id=\"第八章-函数探幽\"><a href=\"#第八章-函数探幽\" class=\"headerlink\" title=\"第八章 函数探幽\"></a>第八章 函数探幽</h3><p>函数更深的应用</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">内联函数<br></code></pre></td></tr></table></figure>\n<h4 id=\"内联函数\"><a href=\"#内联函数\" class=\"headerlink\" title=\"内联函数\"></a>内联函数</h4><p>常规函数和内联函数之间的区别在于C++编译器是如何将他们组合到程序中。对于常规函数的调用，会使用堆栈记录原始指令地址，随后跳转到目的函数中，执行结束后再返回原指令。对于内联函数的帝国用，编译器将使用相应的函数代码代替函数调用，在此过程并没有函数跳转调用的过程。</p>\n<p>相比之下，内联函数少去了函数跳转的时间，使用空间换时间。</p>\n<p>宏是通过文本替换来实现的。</p>\n<h4 id=\"引用变量\"><a href=\"#引用变量\" class=\"headerlink\" title=\"引用变量\"></a>引用变量</h4><p>引用时已定义变量的一个别名。引用必须在声明的时候将其初始化。</p>\n<p>引用作为参数传递可以使得被调用的函数访问调用函数中的变量。在传入参数中使用引用，就是为调用函数的变量新建了一个别名。</p>\n<p>什么情况下会生产临时变量：</p>\n<p>1、实参的类型正确，但不是左值</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">左值：可以取地址的，有名字的，非临时的变量就是左值<br>右值：无法直接取到地址，没有名字的，临时变量就是右值<br><br>新增右值引用的目的<br>实现移动语义<br></code></pre></td></tr></table></figure>\n<p>2、实参类型不正确，但是可以转化为正确的类型</p>\n<p>使用引用变量的场景</p>\n<p>1、程序员能够修改调用函数中的数据对象</p>\n<p>2、通过传递引用而不是整个数据对象，可以提高程序的运行速度</p>\n<h4 id=\"函数重载\"><a href=\"#函数重载\" class=\"headerlink\" title=\"函数重载\"></a>函数重载</h4><p>原来仅仅是返回类型不一样是不能用作函数重载的。重载必须满足的是特征标不同，即传入的参数不一致。</p>\n<p>名称修饰：占位符</p>\n<h4 id=\"函数模板：使用泛型来定义函数（通用编程）\"><a href=\"#函数模板：使用泛型来定义函数（通用编程）\" class=\"headerlink\" title=\"函数模板：使用泛型来定义函数（通用编程）\"></a>函数模板：使用泛型来定义函数（通用编程）</h4><blockquote>\n<p>template <typename/class T>：定义模板以后使用模板定义数据</p>\n</blockquote>\n<p>当使用模板时，在调用模板函数的过程中，编译器会自动生成使用的模板类型的函数版本，但这一个过程对于程序员来说是透明的。</p>\n<h4 id=\"显示具体化\"><a href=\"#显示具体化\" class=\"headerlink\" title=\"显示具体化\"></a>显示具体化</h4><p>在模板和具体化函数调用匹配产生冲突的时候，将优先使用具体化的函数进行匹配。</p>\n<p>显式实例化：通过<type>在函数调用的时候显示的给出需要用到的模板类型，这样编译器在进行编译期间就不需要自己分析模板类型。</p>\n<h4 id=\"编译器选择函数版本过程\"><a href=\"#编译器选择函数版本过程\" class=\"headerlink\" title=\"编译器选择函数版本过程\"></a>编译器选择函数版本过程</h4><p>1、创建候选函数列表</p>\n<p>2、使用候选函数列表创建可行函数列表</p>\n<p>3、确定是否有最佳可行函数</p>\n<p>decltype：类型推导</p>\n<blockquote>\n<p>decltype(x+y) xpy = x + y</p>\n<p>自动推导x+y的数据类型，并将其类型用于定义xpy，适合和模板进行共同使用。</p>\n</blockquote>\n<p>C++11后置返回类型：使用-&gt;将返回类型后置</p>\n<p>sizeof和strlen之间的区别，指针变量是无法用sizeof统计出字符串长度的。</p>\n<h3 id=\"第九章-内存模块与名称空间\"><a href=\"#第九章-内存模块与名称空间\" class=\"headerlink\" title=\"第九章  内存模块与名称空间\"></a>第九章  内存模块与名称空间</h3><h4 id=\"单独编译\"><a href=\"#单独编译\" class=\"headerlink\" title=\"单独编译\"></a>单独编译</h4><figure class=\"highlight hsp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs hsp\">头文件包含内容<br><span class=\"hljs-number\">1</span>、函数原型<br><span class=\"hljs-number\">2</span>、使用<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> 或 <span class=\"hljs-keyword\">const</span>定义的符号常量</span><br><span class=\"hljs-number\">3</span>、结构声明<br><span class=\"hljs-number\">4</span>、类声明<br><span class=\"hljs-number\">5</span>、模板声明<br><span class=\"hljs-number\">6</span>、内联函数<br></code></pre></td></tr></table></figure>\n<h4 id=\"存储持续性、作用域和链接性\"><a href=\"#存储持续性、作用域和链接性\" class=\"headerlink\" title=\"存储持续性、作用域和链接性\"></a>存储持续性、作用域和链接性</h4><p>数据存储方案</p>\n<ul>\n<li>自动存储持续性：函数参数，函数调用期间存在，函数执行结束释放</li>\n<li>静态存储持续性：整个程序运行过程中都存在，static变量</li>\n<li>线程存储持续性：生命周期和所属线程一样长</li>\n<li>动态存储持续性：new存在，delete释放，用户管理。</li>\n</ul>\n<p>作用域：名称在文件中的可见范围</p>\n<p>连接性：名称如何在不同单元中进行共享</p>\n<p>C++中的auto：自动类型推导</p>\n<p>变量只能定义一次，但可以多次应用，可以使用extern关键字对外部变量进行引用。</p>\n<ul>\n<li>说明符和限定符<ul>\n<li>auto：自动类型推导</li>\n<li>register：指示寄存器存储</li>\n<li>static：用在作用域在整个文件的声明中时，表示内部链接性</li>\n<li>extern：表明是引用声明，声明引用在其它地方的变量</li>\n<li>thread_local：与线程的关系类似于静态变量于整个程序</li>\n<li>mutable：可修改的const</li>\n</ul>\n</li>\n<li>cv-限定符<ul>\n<li>const</li>\n<li>volatile：告诉编译器不要进行编译器优化，比如一个for循环计数</li>\n</ul>\n</li>\n<li>mutable限定符<ul>\n<li>即使为const也可以修改</li>\n</ul>\n</li>\n</ul>\n<p>内部链接性意味着每个文件都有自己的一组常量，而不是所有文件共享一组常量。</p>\n<p>new定位运算符：能够指定要使用的位置，需要包含头文件new，</p>\n<h4 id=\"名称空间\"><a href=\"#名称空间\" class=\"headerlink\" title=\"名称空间\"></a>名称空间</h4><p>声明区域：参数在其在进行中所在的区域。</p>\n<p>潜在作用域：潜在作用域小于声明的区域。</p>\n<p>名称空间可以是全局的，也可以位于另一个名称空间中，但不能够位于代码块中。默认情况下，在名称空间中声明的名称的链接性为外部的。</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-symbol\">Jack</span>&#123;<br>\t<span class=\"hljs-comment\">//名称空间用到的变量和函数，类似于封装</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>using 和 using namespace：using可以使得某一个名称空间里面的函数或变量可用，using namespace 使得整个名称空间内的变量和函数都可用。</p>\n<p>如果全局中含有某名称空间的同名的变量，引用该名称空间时将自动隐藏名称空间的该变量，而使用全局变量。</p>\n<h3 id=\"第十章-对象和类\"><a href=\"#第十章-对象和类\" class=\"headerlink\" title=\"第十章 对象和类\"></a>第十章 对象和类</h3><p>面向对象的特性：抽象、封装和数据隐藏、多态、继承、代码的可重用性</p>\n<h4 id=\"抽象和类\"><a href=\"#抽象和类\" class=\"headerlink\" title=\"抽象和类\"></a>抽象和类</h4><p>接口：接口是一个共享框架，供两个系统交互时使用。</p>\n<p>访问控制字：public、private、protected，公有、私有、保护</p>\n<p>结构体默认访问类型为public，类的默认访问类型为private</p>\n<h4 id=\"类的构造函数和析构函数\"><a href=\"#类的构造函数和析构函数\" class=\"headerlink\" title=\"类的构造函数和析构函数\"></a>类的构造函数和析构函数</h4><blockquote>\n<p>构造函数和析构函数都没有返回值类型</p>\n</blockquote>\n<p>构造函数</p>\n<p>显示调用和隐式调用，每一个对象在创建的时候会自动调用构造函数，构造函数可以由用户给出，也可以使用默认的构造函数（不做任何操作）。</p>\n<p>构造函数可以存在多个，能使用函数重载的方式来使用不同的构造函数。</p>\n<p>析构函数</p>\n<p>析构函数是在对象释放的时候自动调用的函数，用于释放新建的对象资源。</p>\n<ul>\n<li>C++11列表初始化方式</li>\n</ul>\n<figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-built_in\">Bozo</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> * fname, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> * lname);<br><br>Bozo bozette = &#123;<span class=\"hljs-string\">&quot;Bozetta&quot;</span>, <span class=\"hljs-string\">&quot;Biggens&quot;</span>&#125;;<br>Bozo fufu&#123;<span class=\"hljs-string\">&quot;Fufu&quot;</span>, <span class=\"hljs-string\">&quot;O&#x27;Dweeb&quot;</span>&#125;;<br>Bozo *pc = <span class=\"hljs-keyword\">new</span> Bozo&#123;<span class=\"hljs-string\">&quot;Popo&quot;</span>, <span class=\"hljs-string\">&quot;Le Peu&quot;</span>&#125;;<br></code></pre></td></tr></table></figure>\n<h4 id=\"this-指针\"><a href=\"#this-指针\" class=\"headerlink\" title=\"this 指针\"></a>this 指针</h4><p>this指针指向的是自身的地址，如果需要返回自身对象，需要使用*this，访问自身的成员也可以使用this-&gt;成员变量来进行访问。</p>\n<h3 id=\"第十一章-使用类\"><a href=\"#第十一章-使用类\" class=\"headerlink\" title=\"第十一章 使用类\"></a>第十一章 使用类</h3><h4 id=\"运算符重载\"><a href=\"#运算符重载\" class=\"headerlink\" title=\"运算符重载\"></a>运算符重载</h4><ul>\n<li><p>不能重载的运算符</p>\n<blockquote>\n<p>sizeof、.（成员运算符）、.*(成员指针运算符)、::（作用域运算符）、?:（条件运算符）、typeid、const_cast、dynamic_cast、reinterpret_cast、static_cast</p>\n</blockquote>\n</li>\n</ul>\n<p>运算符重载是面向对象多态的一种表现，使用运算符重载能够使得编程更加灵活，例如实现两个对象相加，可以使用+运算符重载。</p>\n<blockquote>\n<p>operator运算符（）</p>\n</blockquote>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">class <span class=\"hljs-built_in\">Time</span>&#123;<br>\t<span class=\"hljs-built_in\">int</span> a;<br>\t<span class=\"hljs-built_in\">int</span> b;<br>publ<span class=\"hljs-symbol\">ic:</span><br>\t<span class=\"hljs-built_in\">Time</span>(<span class=\"hljs-built_in\">int</span> m_a, <span class=\"hljs-built_in\">int</span> m_b)&#123;<br>\t\ta = m_a;<br>\t\tb = m_b;<br>\t&#125;<br>\t<br>\t// 对 + 运算符进行重载<br>\t<span class=\"hljs-built_in\">Time</span> operator+(<span class=\"hljs-built_in\">Time</span>&amp; <span class=\"hljs-symbol\">t2</span>)&#123;<br>\t\t<span class=\"hljs-built_in\">Time</span> <span class=\"hljs-built_in\">time</span>;<br>\t\ttime.a = a + <span class=\"hljs-symbol\">t2</span>.a;<br>\t\ttime.b = b + <span class=\"hljs-symbol\">t2</span>.b;<br>\t\treturn <span class=\"hljs-built_in\">time</span>;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h4 id=\"友元函数\"><a href=\"#友元函数\" class=\"headerlink\" title=\"友元函数\"></a>友元函数</h4><p>友元的三种类型：友元函数、友元类、友元成员函数。</p>\n<p>将函数、类、成员函数设置为类的友元，可以赋予该函数与类的成员函数相同的访问权限。</p>\n<ul>\n<li><p>创建友元函数</p>\n<p>将函数原型前面加上friend放在类声明中。</p>\n<p>如果要为类重载运算符，并将非类的项作为其第一个操作数，则可以使用友元函数来反转操作数的顺序。若不用友元函数访问，只能将一个参数传入到类的对象函数原型中，无法控制需要操作对象之间的顺序。</p>\n</li>\n</ul>\n<blockquote>\n<p>“&lt;&lt;” 运算符的重载</p>\n</blockquote>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span><span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> std;<br><br><span class=\"hljs-comment\">// 对&lt;&lt;运算符进行重载</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Time</span> &#123;<br>\t<span class=\"hljs-keyword\">friend</span> ostream&amp; <span class=\"hljs-keyword\">operator</span>&lt;&lt;(ostream&amp; os, <span class=\"hljs-type\">const</span> Time&amp; t);<br>\t<span class=\"hljs-type\">int</span> hour;<br>\t<span class=\"hljs-type\">int</span> second;<br><br><span class=\"hljs-keyword\">public</span>:<br>\t<span class=\"hljs-built_in\">Time</span>(<span class=\"hljs-type\">int</span> m_hour, <span class=\"hljs-type\">int</span> m_second) &#123;<br>\t\thour = m_hour;<br>\t\tsecond = m_second;<br>\t&#125;<br>&#125;;<br><span class=\"hljs-comment\">// 返回流对象，便于传递操作</span><br>ostream&amp; <span class=\"hljs-keyword\">operator</span>&lt;&lt;(ostream&amp; os, <span class=\"hljs-type\">const</span> Time&amp; t) &#123;<br>\tos &lt;&lt; t.hour &lt;&lt; <span class=\"hljs-string\">&quot;   &quot;</span> &lt;&lt; t.second;<br>\t<span class=\"hljs-keyword\">return</span> os;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-function\">Time <span class=\"hljs-title\">time</span><span class=\"hljs-params\">(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">40</span>)</span></span>;<br>\tcout &lt;&lt; time &lt;&lt; endl;<br>\t<span class=\"hljs-built_in\">system</span>(<span class=\"hljs-string\">&quot;PAUSE&quot;</span>);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>当重载的函数和目标对象不在一个作用域内时，需要使用域名控制符号来对其进行访问。</p>\n<p>运算符重载，还可以更具特征标的数量不同再次进行重载。</p>\n<h4 id=\"类型转换\"><a href=\"#类型转换\" class=\"headerlink\" title=\"类型转换\"></a>类型转换</h4><p>构造函数可以使用隐式转换：隐式构造函数必须不能存在二义性</p>\n<blockquote>\n<p>在下面程序中，使用Stonewt st = 12;将默认隐式调用了构造函数Stonewt(double lbs)，对Stonewt的成员进行初始化。</p>\n</blockquote>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\"><span class=\"hljs-meta\">#include&lt;iostream&gt;</span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-title\">std</span>;<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Stonewt</span> &#123;<br>\t<span class=\"hljs-built_in\">int</span> stone;<br>\t<span class=\"hljs-built_in\">double</span> pds;<br>\t<span class=\"hljs-built_in\">double</span> pounds;<br><br><span class=\"hljs-keyword\">public</span>:<br>\tStonewt(<span class=\"hljs-built_in\">double</span> lbs) &#123;<br>\t\tstone = <span class=\"hljs-built_in\">int</span>(lbs);<br>\t\tpds = <span class=\"hljs-built_in\">int</span>(lbs) % <span class=\"hljs-number\">14</span> + lbs;<br>\t\tpounds = lbs;<br>\t&#125;<br>\tStonewt() &#123;<br>\t\tstone = pds = pounds = <span class=\"hljs-number\">0</span>;<br>\t&#125;<br>\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">show</span>()</span> &#123;<br>\t\tcout &lt;&lt; stone &lt;&lt; endl;<br>\t\tcout &lt;&lt; pds &lt;&lt; endl;<br>\t\tcout &lt;&lt; pounds &lt;&lt; endl;<br>\t&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-built_in\">int</span> <span class=\"hljs-title\">main</span>()</span> &#123;<br>\tStonewt st = <span class=\"hljs-number\">12</span>;<br>\tst.show();<br><br>\tsystem(<span class=\"hljs-string\">&quot;PAUSE&quot;</span>);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>如果关闭隐式构造函数则使用：explicit Stonewt(double lbs);</p>\n<h4 id=\"转换函数\"><a href=\"#转换函数\" class=\"headerlink\" title=\"转换函数\"></a>转换函数</h4><blockquote>\n<p>格式：operator typename();</p>\n<p>exp：operator double();</p>\n</blockquote>\n<p>如果在类里面定义了转化函数，可以将类强制转化成其它的数据类型。转化函数中返回需要进行转化的数据。</p>\n<h3 id=\"第十二章-类的动态内存分配\"><a href=\"#第十二章-类的动态内存分配\" class=\"headerlink\" title=\"第十二章  类的动态内存分配\"></a>第十二章  类的动态内存分配</h3><h4 id=\"动态内存和类\"><a href=\"#动态内存和类\" class=\"headerlink\" title=\"动态内存和类\"></a>动态内存和类</h4><p>再动态分配内存中，对象的析构函数是必不可少的，有的时候必须要重载赋值运算符。</p>\n<p>在类里面定义静态成员，意味着该类的所有对象能够共同享用这同一个静态成员变量。</p>\n<p>将对象作为函数参数来传递而不是使用引用来传递，容易造成函数结束以后对象自动释放并调用析构函数的现象。</p>\n<p>当使用一个对象初始化另一个对象的时候会调用拷贝构造函数。</p>\n<ul>\n<li><p>C++为一个对象自动提供的成员函数：</p>\n<ul>\n<li>默认构造函数：在对象创建时进行调用</li>\n<li>默认析构函数：在对象销毁时调用</li>\n<li><p>复制构造函数：用于将一个对象复制到新创建的对象中，默认复制构造函数用到的是浅拷贝。</p>\n</li>\n<li><p>赋值运算符重载：通常将一个对象使用等号赋值给另一个对象会用到，默认用的时浅拷贝</p>\n</li>\n<li>地址运算符重载</li>\n<li>移动构造函数</li>\n<li>移动赋值函数</li>\n</ul>\n</li>\n<li><p>浅拷贝和深拷贝</p>\n<p>在使用复制构造函数的过程中，默认进行的是浅拷贝，将一个对象的地址赋值给另一个需要初始化的对象。通过显性的修改复制构造函数的拷贝过程，可以实现深拷贝，即重新申请一块内存空间，将一个对象的数据放进去，让两个对象使用不同的两个地址空间。</p>\n</li>\n<li><p>C++11中引用nullptr表示空指针</p>\n</li>\n<li><p>可以将成员函数声明为静态的，声明过后</p>\n<ul>\n<li>不能通过对象调用静态成员函数，静态成员函数不能使用this指针</li>\n<li>静态成员函数只能够使用静态数据成员</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"使用new注意事项\"><a href=\"#使用new注意事项\" class=\"headerlink\" title=\"使用new注意事项\"></a>使用new注意事项</h4><ul>\n<li>使用new后应该同样用delete进行释放</li>\n<li>new和delete必须相互兼容，new对应于delete，new[]对应与delete[]</li>\n<li>如果有多个构造函数，必须以相同的方式使用new</li>\n<li>应定义一个复制构造函数，深拷贝一个对象初始化为另一个对象</li>\n<li>应定义一个等号=运算符重载，通过深拷贝将一个对象赋值给另一个对象</li>\n</ul>\n<h4 id=\"有关返回对象的说明\"><a href=\"#有关返回对象的说明\" class=\"headerlink\" title=\"有关返回对象的说明\"></a>有关返回对象的说明</h4><ul>\n<li><p>返回对象的引用、返回指向对象的const引用和返回const对象的区别</p>\n<ul>\n<li>1、返回对象将调用赋值构造函数，返回引用不会</li>\n<li>2、引用指向的对象应该在调用函数执行时存在</li>\n</ul>\n</li>\n<li><p>返回指向非const对象引用</p>\n<blockquote>\n<p>非const则说明可以对对象进行修改，具有传递性的操作必须返回非const对象引用</p>\n</blockquote>\n</li>\n<li><p>当返回对象是被调用函数当中的局部变量，则不应该以引用来返回，而应该使用对象来返回，调用拷贝构造函数创建一个新的对象，比如算数运算符。</p>\n</li>\n</ul>\n<p>若方法要返回局部对象，则应返回对象</p>\n<p>若方法或函数要返回一个没有共有复制构造函数的类的对象，必须返回一个指向这种对象的引用</p>\n<h3 id=\"第十三章-类继承\"><a href=\"#第十三章-类继承\" class=\"headerlink\" title=\"第十三章  类继承\"></a>第十三章  类继承</h3><p>通过继承可以完成的一些工作：</p>\n<p>1、可以在已有类的基础上添加功能</p>\n<p>2、可以给类添加数据</p>\n<p>3、可以修改类的方法</p>\n<p>总结，对于父类的一些功能的拓展。一般情况下会遵守开闭原则。</p>\n<p>派生的类型：公有派生、私有派生、保护派生</p>\n<p>公有派生：基类的公有成员称为派生类的公有成员。基类的私有部分称为派生类的一部分，但是只能够通过基类的公有和保护方法来进行访问。</p>\n<p>父类指针指向子类对象， 通过这样的方式可以实现多态</p>\n<p>基类指针可以在不进行显示类型转换的情况下指向派生类对象；</p>\n<p>基类引用可以在不进行显示类型转化的情况下引用派生类对象；</p>\n<h4 id=\"多态公有继承\"><a href=\"#多态公有继承\" class=\"headerlink\" title=\"多态公有继承\"></a>多态公有继承</h4><p>方法1、在派生类中重新定义基类的方法，通过在父类对象和子类对象中定义同样的方法，分别使用父类和子类对象的实例来调用来实现不同对象对同一对象接口调用达到多态。</p>\n<p>方法2、使用虚方法，使用父类指针指向子类对象，在父类对象中使用虚函数，在子类对象中实现，通过一个父类指针指向子类对象来调用子类中的函数。</p>\n<ul>\n<li>虚析构函数的作用<ul>\n<li>使用虚析构函数可以确保正确的析构函数序列被调用。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"动态联编和静态联编\"><a href=\"#动态联编和静态联编\" class=\"headerlink\" title=\"动态联编和静态联编\"></a>动态联编和静态联编</h4><p>将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编。</p>\n<p>在编译过程中进行的联编称为静态联编。</p>\n<p>在程序运行时进行的联编称为动态联编，有虚函数的代码需要在函数运行过程中才能够确认虚函数中具体要执行和完成的任务。</p>\n<h4 id=\"虚函数的工作原理\"><a href=\"#虚函数的工作原理\" class=\"headerlink\" title=\"虚函数的工作原理\"></a>虚函数的工作原理</h4><p>编译器处理虚函数的方法是，为每个对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表（vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。</p>\n<p>基类对象中包含一个指针，指向基类中所有虚函数表的地址表。派生类对象将包含一个指向对立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址，如果派生类没有定义虚函数，该虚函数表将保存函数原始版本的地址。</p>\n<h4 id=\"访问控制：protected\"><a href=\"#访问控制：protected\" class=\"headerlink\" title=\"访问控制：protected\"></a>访问控制：protected</h4><p>派生类的成员可以直接访问基类的保护成员，但不能访问基类的私有成员，对于外部世界来说，保护成员的行为与私有成员相似，对于派生类来说，保护车关于的行为与公有成员相似。</p>\n<h4 id=\"抽象类\"><a href=\"#抽象类\" class=\"headerlink\" title=\"抽象类\"></a>抽象类</h4><p>C++可以通过纯虚函数提供未实现的函数，纯虚函数声明的结尾处为=0。</p>\n<p>当类声明中包含纯虚函数时，则不能够创建该类的对象。因为需要通过继承的方式来实现纯虚函数中未定义的方法实现。</p>\n<h4 id=\"继承和动态内存分配\"><a href=\"#继承和动态内存分配\" class=\"headerlink\" title=\"继承和动态内存分配\"></a>继承和动态内存分配</h4><p>1、如果在派生类中没有用到动态内存分配，则无需进行操作，析构函数也不需要修改。</p>\n<p>2、如果派生类中有定义的指针需要动态分配内存的成员变量，则必须为派生类定义<strong>显式析构函数、复制（拷贝）构造函数和赋值（=重载）构造函数</strong>，在派生类的赋值构造函数和赋值构造函数中还必须显示的调用基类的构造函数。</p>\n<p>在派生类中重定义基类的方法不是重载，将直接覆盖基类的原始方法。</p>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"第七章-函数-C-的编程模块\"><a href=\"#第七章-函数-C-的编程模块\" class=\"headerlink\" title=\"第七章 函数-C++的编程模块\"></a>第七章 函数-C++的编程模块</h3><p>函数的基本概念和应用：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\">具体应用<br>按值传递，按地址传递<br>函数在数组中的应用<br>函数在结构体中的应用<br>函数在<span class=\"hljs-built_in\">string</span>中的应用<br></code></pre></td></tr></table></figure>\n<h4 id=\"1、使用C-函数三部曲\"><a href=\"#1、使用C-函数三部曲\" class=\"headerlink\" title=\"1、使用C++函数三部曲\"></a>1、使用C++函数三部曲</h4><p>提供函数定义：根据返回值来定义函数，在函数中用return返回（函数通过将返回值复制到指定的CPU寄存器或内存单元中将其返回）。</p>\n<p>提供函数原型：函数原型描述了函数到编译器的接口，将函数的返回值的类型以及参数的类型和数量告诉编译器。</p>\n<p>调用函数：传入实参调用函数。</p>\n<h4 id=\"2、在函数中声明的变量\"><a href=\"#2、在函数中声明的变量\" class=\"headerlink\" title=\"2、在函数中声明的变量\"></a>2、在函数中声明的变量</h4><p>在函数中声明的变量包括参数都是该函数私有的，在函数调用时，计算机为这些变量分配内存，函数结束时，计算机将释放这些变量使用的内存。</p>\n<h4 id=\"3、函数与数组\"><a href=\"#3、函数与数组\" class=\"headerlink\" title=\"3、函数与数组\"></a>3、函数与数组</h4><p>在将数组作为函数参数传递的时候，既可以用int arr[]，也可以用int * arr。</p>\n<h4 id=\"4、指针和const\"><a href=\"#4、指针和const\" class=\"headerlink\" title=\"4、指针和const\"></a>4、指针和const</h4><p>常量指针和指针常量</p>\n<p>方法1：让指针指向一个常量对象，防止该指针来修改所指向的值</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-comment\">// 防止pt修改指向的值，但不能防止修改pt指针</span><br><span class=\"hljs-comment\">// 可以使用age来修改自身的值</span><br><span class=\"hljs-built_in\">int</span> age = <span class=\"hljs-number\">18</span>;<br><span class=\"hljs-keyword\">const</span> <span class=\"hljs-built_in\">int</span> * pt = &amp;age;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>const 变量的地址可以赋给指向const的指针，但是不能赋值给常规指针。</li>\n</ul>\n<p>方法2：将指针本身声明为常量</p>\n<h4 id=\"5、使用const的好处\"><a href=\"#5、使用const的好处\" class=\"headerlink\" title=\"5、使用const的好处\"></a>5、使用const的好处</h4><p>避免由于无意间修改数据而导致的编程错误。</p>\n<p>使得函数能够处理const和非const实参，否则将只能接受非const数据。</p>\n<p>例：在使用函数来对某一个数组进行显示时，可以在形参使用const修饰数组，以防止函数对原始数组的修改。</p>\n<h3 id=\"第八章-函数探幽\"><a href=\"#第八章-函数探幽\" class=\"headerlink\" title=\"第八章 函数探幽\"></a>第八章 函数探幽</h3><p>函数更深的应用</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">内联函数<br></code></pre></td></tr></table></figure>\n<h4 id=\"内联函数\"><a href=\"#内联函数\" class=\"headerlink\" title=\"内联函数\"></a>内联函数</h4><p>常规函数和内联函数之间的区别在于C++编译器是如何将他们组合到程序中。对于常规函数的调用，会使用堆栈记录原始指令地址，随后跳转到目的函数中，执行结束后再返回原指令。对于内联函数的帝国用，编译器将使用相应的函数代码代替函数调用，在此过程并没有函数跳转调用的过程。</p>\n<p>相比之下，内联函数少去了函数跳转的时间，使用空间换时间。</p>\n<p>宏是通过文本替换来实现的。</p>\n<h4 id=\"引用变量\"><a href=\"#引用变量\" class=\"headerlink\" title=\"引用变量\"></a>引用变量</h4><p>引用时已定义变量的一个别名。引用必须在声明的时候将其初始化。</p>\n<p>引用作为参数传递可以使得被调用的函数访问调用函数中的变量。在传入参数中使用引用，就是为调用函数的变量新建了一个别名。</p>\n<p>什么情况下会生产临时变量：</p>\n<p>1、实参的类型正确，但不是左值</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">左值：可以取地址的，有名字的，非临时的变量就是左值<br>右值：无法直接取到地址，没有名字的，临时变量就是右值<br><br>新增右值引用的目的<br>实现移动语义<br></code></pre></td></tr></table></figure>\n<p>2、实参类型不正确，但是可以转化为正确的类型</p>\n<p>使用引用变量的场景</p>\n<p>1、程序员能够修改调用函数中的数据对象</p>\n<p>2、通过传递引用而不是整个数据对象，可以提高程序的运行速度</p>\n<h4 id=\"函数重载\"><a href=\"#函数重载\" class=\"headerlink\" title=\"函数重载\"></a>函数重载</h4><p>原来仅仅是返回类型不一样是不能用作函数重载的。重载必须满足的是特征标不同，即传入的参数不一致。</p>\n<p>名称修饰：占位符</p>\n<h4 id=\"函数模板：使用泛型来定义函数（通用编程）\"><a href=\"#函数模板：使用泛型来定义函数（通用编程）\" class=\"headerlink\" title=\"函数模板：使用泛型来定义函数（通用编程）\"></a>函数模板：使用泛型来定义函数（通用编程）</h4><blockquote>\n<p>template <typename/class T>：定义模板以后使用模板定义数据</p>\n</blockquote>\n<p>当使用模板时，在调用模板函数的过程中，编译器会自动生成使用的模板类型的函数版本，但这一个过程对于程序员来说是透明的。</p>\n<h4 id=\"显示具体化\"><a href=\"#显示具体化\" class=\"headerlink\" title=\"显示具体化\"></a>显示具体化</h4><p>在模板和具体化函数调用匹配产生冲突的时候，将优先使用具体化的函数进行匹配。</p>\n<p>显式实例化：通过<type>在函数调用的时候显示的给出需要用到的模板类型，这样编译器在进行编译期间就不需要自己分析模板类型。</p>\n<h4 id=\"编译器选择函数版本过程\"><a href=\"#编译器选择函数版本过程\" class=\"headerlink\" title=\"编译器选择函数版本过程\"></a>编译器选择函数版本过程</h4><p>1、创建候选函数列表</p>\n<p>2、使用候选函数列表创建可行函数列表</p>\n<p>3、确定是否有最佳可行函数</p>\n<p>decltype：类型推导</p>\n<blockquote>\n<p>decltype(x+y) xpy = x + y</p>\n<p>自动推导x+y的数据类型，并将其类型用于定义xpy，适合和模板进行共同使用。</p>\n</blockquote>\n<p>C++11后置返回类型：使用-&gt;将返回类型后置</p>\n<p>sizeof和strlen之间的区别，指针变量是无法用sizeof统计出字符串长度的。</p>\n<h3 id=\"第九章-内存模块与名称空间\"><a href=\"#第九章-内存模块与名称空间\" class=\"headerlink\" title=\"第九章  内存模块与名称空间\"></a>第九章  内存模块与名称空间</h3><h4 id=\"单独编译\"><a href=\"#单独编译\" class=\"headerlink\" title=\"单独编译\"></a>单独编译</h4><figure class=\"highlight hsp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs hsp\">头文件包含内容<br><span class=\"hljs-number\">1</span>、函数原型<br><span class=\"hljs-number\">2</span>、使用<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> 或 <span class=\"hljs-keyword\">const</span>定义的符号常量</span><br><span class=\"hljs-number\">3</span>、结构声明<br><span class=\"hljs-number\">4</span>、类声明<br><span class=\"hljs-number\">5</span>、模板声明<br><span class=\"hljs-number\">6</span>、内联函数<br></code></pre></td></tr></table></figure>\n<h4 id=\"存储持续性、作用域和链接性\"><a href=\"#存储持续性、作用域和链接性\" class=\"headerlink\" title=\"存储持续性、作用域和链接性\"></a>存储持续性、作用域和链接性</h4><p>数据存储方案</p>\n<ul>\n<li>自动存储持续性：函数参数，函数调用期间存在，函数执行结束释放</li>\n<li>静态存储持续性：整个程序运行过程中都存在，static变量</li>\n<li>线程存储持续性：生命周期和所属线程一样长</li>\n<li>动态存储持续性：new存在，delete释放，用户管理。</li>\n</ul>\n<p>作用域：名称在文件中的可见范围</p>\n<p>连接性：名称如何在不同单元中进行共享</p>\n<p>C++中的auto：自动类型推导</p>\n<p>变量只能定义一次，但可以多次应用，可以使用extern关键字对外部变量进行引用。</p>\n<ul>\n<li>说明符和限定符<ul>\n<li>auto：自动类型推导</li>\n<li>register：指示寄存器存储</li>\n<li>static：用在作用域在整个文件的声明中时，表示内部链接性</li>\n<li>extern：表明是引用声明，声明引用在其它地方的变量</li>\n<li>thread_local：与线程的关系类似于静态变量于整个程序</li>\n<li>mutable：可修改的const</li>\n</ul>\n</li>\n<li>cv-限定符<ul>\n<li>const</li>\n<li>volatile：告诉编译器不要进行编译器优化，比如一个for循环计数</li>\n</ul>\n</li>\n<li>mutable限定符<ul>\n<li>即使为const也可以修改</li>\n</ul>\n</li>\n</ul>\n<p>内部链接性意味着每个文件都有自己的一组常量，而不是所有文件共享一组常量。</p>\n<p>new定位运算符：能够指定要使用的位置，需要包含头文件new，</p>\n<h4 id=\"名称空间\"><a href=\"#名称空间\" class=\"headerlink\" title=\"名称空间\"></a>名称空间</h4><p>声明区域：参数在其在进行中所在的区域。</p>\n<p>潜在作用域：潜在作用域小于声明的区域。</p>\n<p>名称空间可以是全局的，也可以位于另一个名称空间中，但不能够位于代码块中。默认情况下，在名称空间中声明的名称的链接性为外部的。</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs angelscript\"><span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-symbol\">Jack</span>&#123;<br>\t<span class=\"hljs-comment\">//名称空间用到的变量和函数，类似于封装</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>using 和 using namespace：using可以使得某一个名称空间里面的函数或变量可用，using namespace 使得整个名称空间内的变量和函数都可用。</p>\n<p>如果全局中含有某名称空间的同名的变量，引用该名称空间时将自动隐藏名称空间的该变量，而使用全局变量。</p>\n<h3 id=\"第十章-对象和类\"><a href=\"#第十章-对象和类\" class=\"headerlink\" title=\"第十章 对象和类\"></a>第十章 对象和类</h3><p>面向对象的特性：抽象、封装和数据隐藏、多态、继承、代码的可重用性</p>\n<h4 id=\"抽象和类\"><a href=\"#抽象和类\" class=\"headerlink\" title=\"抽象和类\"></a>抽象和类</h4><p>接口：接口是一个共享框架，供两个系统交互时使用。</p>\n<p>访问控制字：public、private、protected，公有、私有、保护</p>\n<p>结构体默认访问类型为public，类的默认访问类型为private</p>\n<h4 id=\"类的构造函数和析构函数\"><a href=\"#类的构造函数和析构函数\" class=\"headerlink\" title=\"类的构造函数和析构函数\"></a>类的构造函数和析构函数</h4><blockquote>\n<p>构造函数和析构函数都没有返回值类型</p>\n</blockquote>\n<p>构造函数</p>\n<p>显示调用和隐式调用，每一个对象在创建的时候会自动调用构造函数，构造函数可以由用户给出，也可以使用默认的构造函数（不做任何操作）。</p>\n<p>构造函数可以存在多个，能使用函数重载的方式来使用不同的构造函数。</p>\n<p>析构函数</p>\n<p>析构函数是在对象释放的时候自动调用的函数，用于释放新建的对象资源。</p>\n<ul>\n<li>C++11列表初始化方式</li>\n</ul>\n<figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\"><span class=\"hljs-built_in\">Bozo</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> * fname, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">char</span> * lname);<br><br>Bozo bozette = &#123;<span class=\"hljs-string\">&quot;Bozetta&quot;</span>, <span class=\"hljs-string\">&quot;Biggens&quot;</span>&#125;;<br>Bozo fufu&#123;<span class=\"hljs-string\">&quot;Fufu&quot;</span>, <span class=\"hljs-string\">&quot;O&#x27;Dweeb&quot;</span>&#125;;<br>Bozo *pc = <span class=\"hljs-keyword\">new</span> Bozo&#123;<span class=\"hljs-string\">&quot;Popo&quot;</span>, <span class=\"hljs-string\">&quot;Le Peu&quot;</span>&#125;;<br></code></pre></td></tr></table></figure>\n<h4 id=\"this-指针\"><a href=\"#this-指针\" class=\"headerlink\" title=\"this 指针\"></a>this 指针</h4><p>this指针指向的是自身的地址，如果需要返回自身对象，需要使用*this，访问自身的成员也可以使用this-&gt;成员变量来进行访问。</p>\n<h3 id=\"第十一章-使用类\"><a href=\"#第十一章-使用类\" class=\"headerlink\" title=\"第十一章 使用类\"></a>第十一章 使用类</h3><h4 id=\"运算符重载\"><a href=\"#运算符重载\" class=\"headerlink\" title=\"运算符重载\"></a>运算符重载</h4><ul>\n<li><p>不能重载的运算符</p>\n<blockquote>\n<p>sizeof、.（成员运算符）、.*(成员指针运算符)、::（作用域运算符）、?:（条件运算符）、typeid、const_cast、dynamic_cast、reinterpret_cast、static_cast</p>\n</blockquote>\n</li>\n</ul>\n<p>运算符重载是面向对象多态的一种表现，使用运算符重载能够使得编程更加灵活，例如实现两个对象相加，可以使用+运算符重载。</p>\n<blockquote>\n<p>operator运算符（）</p>\n</blockquote>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">class <span class=\"hljs-built_in\">Time</span>&#123;<br>\t<span class=\"hljs-built_in\">int</span> a;<br>\t<span class=\"hljs-built_in\">int</span> b;<br>publ<span class=\"hljs-symbol\">ic:</span><br>\t<span class=\"hljs-built_in\">Time</span>(<span class=\"hljs-built_in\">int</span> m_a, <span class=\"hljs-built_in\">int</span> m_b)&#123;<br>\t\ta = m_a;<br>\t\tb = m_b;<br>\t&#125;<br>\t<br>\t// 对 + 运算符进行重载<br>\t<span class=\"hljs-built_in\">Time</span> operator+(<span class=\"hljs-built_in\">Time</span>&amp; <span class=\"hljs-symbol\">t2</span>)&#123;<br>\t\t<span class=\"hljs-built_in\">Time</span> <span class=\"hljs-built_in\">time</span>;<br>\t\ttime.a = a + <span class=\"hljs-symbol\">t2</span>.a;<br>\t\ttime.b = b + <span class=\"hljs-symbol\">t2</span>.b;<br>\t\treturn <span class=\"hljs-built_in\">time</span>;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h4 id=\"友元函数\"><a href=\"#友元函数\" class=\"headerlink\" title=\"友元函数\"></a>友元函数</h4><p>友元的三种类型：友元函数、友元类、友元成员函数。</p>\n<p>将函数、类、成员函数设置为类的友元，可以赋予该函数与类的成员函数相同的访问权限。</p>\n<ul>\n<li><p>创建友元函数</p>\n<p>将函数原型前面加上friend放在类声明中。</p>\n<p>如果要为类重载运算符，并将非类的项作为其第一个操作数，则可以使用友元函数来反转操作数的顺序。若不用友元函数访问，只能将一个参数传入到类的对象函数原型中，无法控制需要操作对象之间的顺序。</p>\n</li>\n</ul>\n<blockquote>\n<p>“&lt;&lt;” 运算符的重载</p>\n</blockquote>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span><span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> std;<br><br><span class=\"hljs-comment\">// 对&lt;&lt;运算符进行重载</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Time</span> &#123;<br>\t<span class=\"hljs-keyword\">friend</span> ostream&amp; <span class=\"hljs-keyword\">operator</span>&lt;&lt;(ostream&amp; os, <span class=\"hljs-type\">const</span> Time&amp; t);<br>\t<span class=\"hljs-type\">int</span> hour;<br>\t<span class=\"hljs-type\">int</span> second;<br><br><span class=\"hljs-keyword\">public</span>:<br>\t<span class=\"hljs-built_in\">Time</span>(<span class=\"hljs-type\">int</span> m_hour, <span class=\"hljs-type\">int</span> m_second) &#123;<br>\t\thour = m_hour;<br>\t\tsecond = m_second;<br>\t&#125;<br>&#125;;<br><span class=\"hljs-comment\">// 返回流对象，便于传递操作</span><br>ostream&amp; <span class=\"hljs-keyword\">operator</span>&lt;&lt;(ostream&amp; os, <span class=\"hljs-type\">const</span> Time&amp; t) &#123;<br>\tos &lt;&lt; t.hour &lt;&lt; <span class=\"hljs-string\">&quot;   &quot;</span> &lt;&lt; t.second;<br>\t<span class=\"hljs-keyword\">return</span> os;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-function\">Time <span class=\"hljs-title\">time</span><span class=\"hljs-params\">(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">40</span>)</span></span>;<br>\tcout &lt;&lt; time &lt;&lt; endl;<br>\t<span class=\"hljs-built_in\">system</span>(<span class=\"hljs-string\">&quot;PAUSE&quot;</span>);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>当重载的函数和目标对象不在一个作用域内时，需要使用域名控制符号来对其进行访问。</p>\n<p>运算符重载，还可以更具特征标的数量不同再次进行重载。</p>\n<h4 id=\"类型转换\"><a href=\"#类型转换\" class=\"headerlink\" title=\"类型转换\"></a>类型转换</h4><p>构造函数可以使用隐式转换：隐式构造函数必须不能存在二义性</p>\n<blockquote>\n<p>在下面程序中，使用Stonewt st = 12;将默认隐式调用了构造函数Stonewt(double lbs)，对Stonewt的成员进行初始化。</p>\n</blockquote>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\"><span class=\"hljs-meta\">#include&lt;iostream&gt;</span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-title\">std</span>;<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Stonewt</span> &#123;<br>\t<span class=\"hljs-built_in\">int</span> stone;<br>\t<span class=\"hljs-built_in\">double</span> pds;<br>\t<span class=\"hljs-built_in\">double</span> pounds;<br><br><span class=\"hljs-keyword\">public</span>:<br>\tStonewt(<span class=\"hljs-built_in\">double</span> lbs) &#123;<br>\t\tstone = <span class=\"hljs-built_in\">int</span>(lbs);<br>\t\tpds = <span class=\"hljs-built_in\">int</span>(lbs) % <span class=\"hljs-number\">14</span> + lbs;<br>\t\tpounds = lbs;<br>\t&#125;<br>\tStonewt() &#123;<br>\t\tstone = pds = pounds = <span class=\"hljs-number\">0</span>;<br>\t&#125;<br>\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">show</span>()</span> &#123;<br>\t\tcout &lt;&lt; stone &lt;&lt; endl;<br>\t\tcout &lt;&lt; pds &lt;&lt; endl;<br>\t\tcout &lt;&lt; pounds &lt;&lt; endl;<br>\t&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-built_in\">int</span> <span class=\"hljs-title\">main</span>()</span> &#123;<br>\tStonewt st = <span class=\"hljs-number\">12</span>;<br>\tst.show();<br><br>\tsystem(<span class=\"hljs-string\">&quot;PAUSE&quot;</span>);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>如果关闭隐式构造函数则使用：explicit Stonewt(double lbs);</p>\n<h4 id=\"转换函数\"><a href=\"#转换函数\" class=\"headerlink\" title=\"转换函数\"></a>转换函数</h4><blockquote>\n<p>格式：operator typename();</p>\n<p>exp：operator double();</p>\n</blockquote>\n<p>如果在类里面定义了转化函数，可以将类强制转化成其它的数据类型。转化函数中返回需要进行转化的数据。</p>\n<h3 id=\"第十二章-类的动态内存分配\"><a href=\"#第十二章-类的动态内存分配\" class=\"headerlink\" title=\"第十二章  类的动态内存分配\"></a>第十二章  类的动态内存分配</h3><h4 id=\"动态内存和类\"><a href=\"#动态内存和类\" class=\"headerlink\" title=\"动态内存和类\"></a>动态内存和类</h4><p>再动态分配内存中，对象的析构函数是必不可少的，有的时候必须要重载赋值运算符。</p>\n<p>在类里面定义静态成员，意味着该类的所有对象能够共同享用这同一个静态成员变量。</p>\n<p>将对象作为函数参数来传递而不是使用引用来传递，容易造成函数结束以后对象自动释放并调用析构函数的现象。</p>\n<p>当使用一个对象初始化另一个对象的时候会调用拷贝构造函数。</p>\n<ul>\n<li><p>C++为一个对象自动提供的成员函数：</p>\n<ul>\n<li>默认构造函数：在对象创建时进行调用</li>\n<li>默认析构函数：在对象销毁时调用</li>\n<li><p>复制构造函数：用于将一个对象复制到新创建的对象中，默认复制构造函数用到的是浅拷贝。</p>\n</li>\n<li><p>赋值运算符重载：通常将一个对象使用等号赋值给另一个对象会用到，默认用的时浅拷贝</p>\n</li>\n<li>地址运算符重载</li>\n<li>移动构造函数</li>\n<li>移动赋值函数</li>\n</ul>\n</li>\n<li><p>浅拷贝和深拷贝</p>\n<p>在使用复制构造函数的过程中，默认进行的是浅拷贝，将一个对象的地址赋值给另一个需要初始化的对象。通过显性的修改复制构造函数的拷贝过程，可以实现深拷贝，即重新申请一块内存空间，将一个对象的数据放进去，让两个对象使用不同的两个地址空间。</p>\n</li>\n<li><p>C++11中引用nullptr表示空指针</p>\n</li>\n<li><p>可以将成员函数声明为静态的，声明过后</p>\n<ul>\n<li>不能通过对象调用静态成员函数，静态成员函数不能使用this指针</li>\n<li>静态成员函数只能够使用静态数据成员</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"使用new注意事项\"><a href=\"#使用new注意事项\" class=\"headerlink\" title=\"使用new注意事项\"></a>使用new注意事项</h4><ul>\n<li>使用new后应该同样用delete进行释放</li>\n<li>new和delete必须相互兼容，new对应于delete，new[]对应与delete[]</li>\n<li>如果有多个构造函数，必须以相同的方式使用new</li>\n<li>应定义一个复制构造函数，深拷贝一个对象初始化为另一个对象</li>\n<li>应定义一个等号=运算符重载，通过深拷贝将一个对象赋值给另一个对象</li>\n</ul>\n<h4 id=\"有关返回对象的说明\"><a href=\"#有关返回对象的说明\" class=\"headerlink\" title=\"有关返回对象的说明\"></a>有关返回对象的说明</h4><ul>\n<li><p>返回对象的引用、返回指向对象的const引用和返回const对象的区别</p>\n<ul>\n<li>1、返回对象将调用赋值构造函数，返回引用不会</li>\n<li>2、引用指向的对象应该在调用函数执行时存在</li>\n</ul>\n</li>\n<li><p>返回指向非const对象引用</p>\n<blockquote>\n<p>非const则说明可以对对象进行修改，具有传递性的操作必须返回非const对象引用</p>\n</blockquote>\n</li>\n<li><p>当返回对象是被调用函数当中的局部变量，则不应该以引用来返回，而应该使用对象来返回，调用拷贝构造函数创建一个新的对象，比如算数运算符。</p>\n</li>\n</ul>\n<p>若方法要返回局部对象，则应返回对象</p>\n<p>若方法或函数要返回一个没有共有复制构造函数的类的对象，必须返回一个指向这种对象的引用</p>\n<h3 id=\"第十三章-类继承\"><a href=\"#第十三章-类继承\" class=\"headerlink\" title=\"第十三章  类继承\"></a>第十三章  类继承</h3><p>通过继承可以完成的一些工作：</p>\n<p>1、可以在已有类的基础上添加功能</p>\n<p>2、可以给类添加数据</p>\n<p>3、可以修改类的方法</p>\n<p>总结，对于父类的一些功能的拓展。一般情况下会遵守开闭原则。</p>\n<p>派生的类型：公有派生、私有派生、保护派生</p>\n<p>公有派生：基类的公有成员称为派生类的公有成员。基类的私有部分称为派生类的一部分，但是只能够通过基类的公有和保护方法来进行访问。</p>\n<p>父类指针指向子类对象， 通过这样的方式可以实现多态</p>\n<p>基类指针可以在不进行显示类型转换的情况下指向派生类对象；</p>\n<p>基类引用可以在不进行显示类型转化的情况下引用派生类对象；</p>\n<h4 id=\"多态公有继承\"><a href=\"#多态公有继承\" class=\"headerlink\" title=\"多态公有继承\"></a>多态公有继承</h4><p>方法1、在派生类中重新定义基类的方法，通过在父类对象和子类对象中定义同样的方法，分别使用父类和子类对象的实例来调用来实现不同对象对同一对象接口调用达到多态。</p>\n<p>方法2、使用虚方法，使用父类指针指向子类对象，在父类对象中使用虚函数，在子类对象中实现，通过一个父类指针指向子类对象来调用子类中的函数。</p>\n<ul>\n<li>虚析构函数的作用<ul>\n<li>使用虚析构函数可以确保正确的析构函数序列被调用。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"动态联编和静态联编\"><a href=\"#动态联编和静态联编\" class=\"headerlink\" title=\"动态联编和静态联编\"></a>动态联编和静态联编</h4><p>将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编。</p>\n<p>在编译过程中进行的联编称为静态联编。</p>\n<p>在程序运行时进行的联编称为动态联编，有虚函数的代码需要在函数运行过程中才能够确认虚函数中具体要执行和完成的任务。</p>\n<h4 id=\"虚函数的工作原理\"><a href=\"#虚函数的工作原理\" class=\"headerlink\" title=\"虚函数的工作原理\"></a>虚函数的工作原理</h4><p>编译器处理虚函数的方法是，为每个对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表（vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。</p>\n<p>基类对象中包含一个指针，指向基类中所有虚函数表的地址表。派生类对象将包含一个指向对立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址，如果派生类没有定义虚函数，该虚函数表将保存函数原始版本的地址。</p>\n<h4 id=\"访问控制：protected\"><a href=\"#访问控制：protected\" class=\"headerlink\" title=\"访问控制：protected\"></a>访问控制：protected</h4><p>派生类的成员可以直接访问基类的保护成员，但不能访问基类的私有成员，对于外部世界来说，保护成员的行为与私有成员相似，对于派生类来说，保护车关于的行为与公有成员相似。</p>\n<h4 id=\"抽象类\"><a href=\"#抽象类\" class=\"headerlink\" title=\"抽象类\"></a>抽象类</h4><p>C++可以通过纯虚函数提供未实现的函数，纯虚函数声明的结尾处为=0。</p>\n<p>当类声明中包含纯虚函数时，则不能够创建该类的对象。因为需要通过继承的方式来实现纯虚函数中未定义的方法实现。</p>\n<h4 id=\"继承和动态内存分配\"><a href=\"#继承和动态内存分配\" class=\"headerlink\" title=\"继承和动态内存分配\"></a>继承和动态内存分配</h4><p>1、如果在派生类中没有用到动态内存分配，则无需进行操作，析构函数也不需要修改。</p>\n<p>2、如果派生类中有定义的指针需要动态分配内存的成员变量，则必须为派生类定义<strong>显式析构函数、复制（拷贝）构造函数和赋值（=重载）构造函数</strong>，在派生类的赋值构造函数和赋值构造函数中还必须显示的调用基类的构造函数。</p>\n<p>在派生类中重定义基类的方法不是重载，将直接覆盖基类的原始方法。</p>\n"},{"title":"C++优先队列用法","date":"2024-03-06T07:13:01.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"## C++优先队列用法\n\n优先队列是C++中STL的派生容器，它仅考虑最高优先级元素，队列遵循FIFO策列，而优先队列根据优先级弹出元素，优先级最高的元素首先弹出。\n\n函数原型：`priority_queue<Type, Container, Functional> m_queue;`\n\nType：表示数据类型\n\nContainer：表示容器类型（必须是用数组实现的容器，比如vector，deque等）\n\nFunctional：表示比较的方式，当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，默认是大顶堆\n\n```c++\n// 升序队列\npriority_queue <int, vector<int>, greater<int>> q;\n// 降序队列\npriority_queue <int, vector<int>, less<int>> q;\n\n//greater和less是std实现的两个仿函数（就是使一个类的使用看上去像一个函数。其实现就是类中实现一个operator()，这个类就有了类似函数的行为）\n```\n\n### 成员函数\n\n`bool empty() const` ：返回值为true，说明队列为空\n\n`int size() const` ：返回优先队列中元素的数量\n\n`void pop()` ：删除队列顶部的元素，也即根节点\n\n`int top()` ：返回队列中的顶部元素，但不删除该元素\n\n`void push(int arg)`：将元素arg插入到队列之中\n\n### 使用仿函数重载，自定义function参数\n\n小于是升序，大于是降序\n\n> set集合，sort排序方法，也可以自定义仿函数进行比较\n>\n> `set<int, compare> my_set`，`sort(vec.begin(), vec.end(), compare)`\n\n```c++\nstruct Node {\n    int size;\n    int price;\n};\n\n// 在类中重载，（）只能重载在类里面\nclass Cmp {\npublic:\n\t// 大于表示降序，小于表示升序\n    bool operator()(const Node &a, const Node &b) {\n        return a.size == b.size ? a.price > b.price : a.size < b.size;\n    }\n};\nint main() {\n    priority_queue<Node, vector<Node>, Cmp> priorityQueue;\n    for (int i = 0; i < 5; i++) {\n        priorityQueue.push(Node{i, 5 - i});\n    }\n    while (!priorityQueue.empty()) {\n        Node top = priorityQueue.top();\n        cout << \"size:\" << top.size << \" price:\" << top.price << endl;\n        priorityQueue.pop();\n    }\n    return 0;\n}\n```\n\n","source":"_posts/c-priority-queue.md","raw":"---\ntitle: C++优先队列用法\ncategories: 技术研究\ndate: 2024-03-06 15:13:01\ntags: [C++, 优先队列]\ncover:\ntop_img:\n---\n## C++优先队列用法\n\n优先队列是C++中STL的派生容器，它仅考虑最高优先级元素，队列遵循FIFO策列，而优先队列根据优先级弹出元素，优先级最高的元素首先弹出。\n\n函数原型：`priority_queue<Type, Container, Functional> m_queue;`\n\nType：表示数据类型\n\nContainer：表示容器类型（必须是用数组实现的容器，比如vector，deque等）\n\nFunctional：表示比较的方式，当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，默认是大顶堆\n\n```c++\n// 升序队列\npriority_queue <int, vector<int>, greater<int>> q;\n// 降序队列\npriority_queue <int, vector<int>, less<int>> q;\n\n//greater和less是std实现的两个仿函数（就是使一个类的使用看上去像一个函数。其实现就是类中实现一个operator()，这个类就有了类似函数的行为）\n```\n\n### 成员函数\n\n`bool empty() const` ：返回值为true，说明队列为空\n\n`int size() const` ：返回优先队列中元素的数量\n\n`void pop()` ：删除队列顶部的元素，也即根节点\n\n`int top()` ：返回队列中的顶部元素，但不删除该元素\n\n`void push(int arg)`：将元素arg插入到队列之中\n\n### 使用仿函数重载，自定义function参数\n\n小于是升序，大于是降序\n\n> set集合，sort排序方法，也可以自定义仿函数进行比较\n>\n> `set<int, compare> my_set`，`sort(vec.begin(), vec.end(), compare)`\n\n```c++\nstruct Node {\n    int size;\n    int price;\n};\n\n// 在类中重载，（）只能重载在类里面\nclass Cmp {\npublic:\n\t// 大于表示降序，小于表示升序\n    bool operator()(const Node &a, const Node &b) {\n        return a.size == b.size ? a.price > b.price : a.size < b.size;\n    }\n};\nint main() {\n    priority_queue<Node, vector<Node>, Cmp> priorityQueue;\n    for (int i = 0; i < 5; i++) {\n        priorityQueue.push(Node{i, 5 - i});\n    }\n    while (!priorityQueue.empty()) {\n        Node top = priorityQueue.top();\n        cout << \"size:\" << top.size << \" price:\" << top.price << endl;\n        priorityQueue.pop();\n    }\n    return 0;\n}\n```\n\n","slug":"c-priority-queue","published":1,"updated":"2024-06-05T09:03:03.633Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttp001508jvgjr906v2","content":"<h2 id=\"C-优先队列用法\"><a href=\"#C-优先队列用法\" class=\"headerlink\" title=\"C++优先队列用法\"></a>C++优先队列用法</h2><p>优先队列是C++中STL的派生容器，它仅考虑最高优先级元素，队列遵循FIFO策列，而优先队列根据优先级弹出元素，优先级最高的元素首先弹出。</p>\n<p>函数原型：<code>priority_queue&lt;Type, Container, Functional&gt; m_queue;</code></p>\n<p>Type：表示数据类型</p>\n<p>Container：表示容器类型（必须是用数组实现的容器，比如vector，deque等）</p>\n<p>Functional：表示比较的方式，当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，默认是大顶堆</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 升序队列</span><br>priority_queue &lt;<span class=\"hljs-type\">int</span>, vector&lt;<span class=\"hljs-type\">int</span>&gt;, greater&lt;<span class=\"hljs-type\">int</span>&gt;&gt; q;<br><span class=\"hljs-comment\">// 降序队列</span><br>priority_queue &lt;<span class=\"hljs-type\">int</span>, vector&lt;<span class=\"hljs-type\">int</span>&gt;, less&lt;<span class=\"hljs-type\">int</span>&gt;&gt; q;<br><br><span class=\"hljs-comment\">//greater和less是std实现的两个仿函数（就是使一个类的使用看上去像一个函数。其实现就是类中实现一个operator()，这个类就有了类似函数的行为）</span><br></code></pre></td></tr></table></figure>\n<h3 id=\"成员函数\"><a href=\"#成员函数\" class=\"headerlink\" title=\"成员函数\"></a>成员函数</h3><p><code>bool empty() const</code> ：返回值为true，说明队列为空</p>\n<p><code>int size() const</code> ：返回优先队列中元素的数量</p>\n<p><code>void pop()</code> ：删除队列顶部的元素，也即根节点</p>\n<p><code>int top()</code> ：返回队列中的顶部元素，但不删除该元素</p>\n<p><code>void push(int arg)</code>：将元素arg插入到队列之中</p>\n<h3 id=\"使用仿函数重载，自定义function参数\"><a href=\"#使用仿函数重载，自定义function参数\" class=\"headerlink\" title=\"使用仿函数重载，自定义function参数\"></a>使用仿函数重载，自定义function参数</h3><p>小于是升序，大于是降序</p>\n<blockquote>\n<p>set集合，sort排序方法，也可以自定义仿函数进行比较</p>\n<p><code>set&lt;int, compare&gt; my_set</code>，<code>sort(vec.begin(), vec.end(), compare)</code></p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">Node</span> &#123;<br>    <span class=\"hljs-type\">int</span> size;<br>    <span class=\"hljs-type\">int</span> price;<br>&#125;;<br><br><span class=\"hljs-comment\">// 在类中重载，（）只能重载在类里面</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Cmp</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>\t<span class=\"hljs-comment\">// 大于表示降序，小于表示升序</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">operator</span><span class=\"hljs-params\">()</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> Node &amp;a, <span class=\"hljs-type\">const</span> Node &amp;b)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> a.size == b.size ? a.price &gt; b.price : a.size &lt; b.size;<br>    &#125;<br>&#125;;<br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    priority_queue&lt;Node, vector&lt;Node&gt;, Cmp&gt; priorityQueue;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) &#123;<br>        priorityQueue.<span class=\"hljs-built_in\">push</span>(Node&#123;i, <span class=\"hljs-number\">5</span> - i&#125;);<br>    &#125;<br>    <span class=\"hljs-keyword\">while</span> (!priorityQueue.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>        Node top = priorityQueue.<span class=\"hljs-built_in\">top</span>();<br>        cout &lt;&lt; <span class=\"hljs-string\">&quot;size:&quot;</span> &lt;&lt; top.size &lt;&lt; <span class=\"hljs-string\">&quot; price:&quot;</span> &lt;&lt; top.price &lt;&lt; endl;<br>        priorityQueue.<span class=\"hljs-built_in\">pop</span>();<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"C-优先队列用法\"><a href=\"#C-优先队列用法\" class=\"headerlink\" title=\"C++优先队列用法\"></a>C++优先队列用法</h2><p>优先队列是C++中STL的派生容器，它仅考虑最高优先级元素，队列遵循FIFO策列，而优先队列根据优先级弹出元素，优先级最高的元素首先弹出。</p>\n<p>函数原型：<code>priority_queue&lt;Type, Container, Functional&gt; m_queue;</code></p>\n<p>Type：表示数据类型</p>\n<p>Container：表示容器类型（必须是用数组实现的容器，比如vector，deque等）</p>\n<p>Functional：表示比较的方式，当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，默认是大顶堆</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 升序队列</span><br>priority_queue &lt;<span class=\"hljs-type\">int</span>, vector&lt;<span class=\"hljs-type\">int</span>&gt;, greater&lt;<span class=\"hljs-type\">int</span>&gt;&gt; q;<br><span class=\"hljs-comment\">// 降序队列</span><br>priority_queue &lt;<span class=\"hljs-type\">int</span>, vector&lt;<span class=\"hljs-type\">int</span>&gt;, less&lt;<span class=\"hljs-type\">int</span>&gt;&gt; q;<br><br><span class=\"hljs-comment\">//greater和less是std实现的两个仿函数（就是使一个类的使用看上去像一个函数。其实现就是类中实现一个operator()，这个类就有了类似函数的行为）</span><br></code></pre></td></tr></table></figure>\n<h3 id=\"成员函数\"><a href=\"#成员函数\" class=\"headerlink\" title=\"成员函数\"></a>成员函数</h3><p><code>bool empty() const</code> ：返回值为true，说明队列为空</p>\n<p><code>int size() const</code> ：返回优先队列中元素的数量</p>\n<p><code>void pop()</code> ：删除队列顶部的元素，也即根节点</p>\n<p><code>int top()</code> ：返回队列中的顶部元素，但不删除该元素</p>\n<p><code>void push(int arg)</code>：将元素arg插入到队列之中</p>\n<h3 id=\"使用仿函数重载，自定义function参数\"><a href=\"#使用仿函数重载，自定义function参数\" class=\"headerlink\" title=\"使用仿函数重载，自定义function参数\"></a>使用仿函数重载，自定义function参数</h3><p>小于是升序，大于是降序</p>\n<blockquote>\n<p>set集合，sort排序方法，也可以自定义仿函数进行比较</p>\n<p><code>set&lt;int, compare&gt; my_set</code>，<code>sort(vec.begin(), vec.end(), compare)</code></p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title class_\">Node</span> &#123;<br>    <span class=\"hljs-type\">int</span> size;<br>    <span class=\"hljs-type\">int</span> price;<br>&#125;;<br><br><span class=\"hljs-comment\">// 在类中重载，（）只能重载在类里面</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Cmp</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>\t<span class=\"hljs-comment\">// 大于表示降序，小于表示升序</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">operator</span><span class=\"hljs-params\">()</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> Node &amp;a, <span class=\"hljs-type\">const</span> Node &amp;b)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> a.size == b.size ? a.price &gt; b.price : a.size &lt; b.size;<br>    &#125;<br>&#125;;<br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    priority_queue&lt;Node, vector&lt;Node&gt;, Cmp&gt; priorityQueue;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) &#123;<br>        priorityQueue.<span class=\"hljs-built_in\">push</span>(Node&#123;i, <span class=\"hljs-number\">5</span> - i&#125;);<br>    &#125;<br>    <span class=\"hljs-keyword\">while</span> (!priorityQueue.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>        Node top = priorityQueue.<span class=\"hljs-built_in\">top</span>();<br>        cout &lt;&lt; <span class=\"hljs-string\">&quot;size:&quot;</span> &lt;&lt; top.size &lt;&lt; <span class=\"hljs-string\">&quot; price:&quot;</span> &lt;&lt; top.price &lt;&lt; endl;<br>        priorityQueue.<span class=\"hljs-built_in\">pop</span>();<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n"},{"title":"Cmake学习笔记","date":"2023-07-26T00:24:31.000Z","cover":"/img/default_cover02.jpg","top_img":null,"_content":"# CMake\n\n# 说明\n\ncmake的定义  -----高级编译配置工具\n\n当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）需要用到---CMake\n\n所有操作都是通过编译CMakeLists.txt来完成的—简单\n\n官网 [www.cmake.org](http://www.cmake.org/)\n\n# CMake安装\n\n[http://www.cmake.org/HTML/Download.htm](http://www.cmake.org/HTML/Download.html)l  可以下载安装\n\n# CMake一个HelloWord\n\n1、写一个HelloWord\n\n```cpp\n#main.cpp\n\n#include <iostream>\n\nint main(){\nstd::cout <<  \"hello word\" << std::endl;\n}\n```\n\n2、写CMakeLists.txt\n\n```cpp\n#CMakeLists.txt\n\nPROJECT (HELLO)\n\nSET(SRC_LIST main.cpp)\n\nMESSAGE(STATUS \"This is BINARY dir \" ${HELLO_BINARY_DIR})\n\nMESSAGE(STATUS \"This is SOURCE dir \"${HELLO_SOURCE_DIR})\n\nADD_EXECUTABLE(hello ${SRC_LIST})\n```\n\n3、使用cmake，生成makefile文件\n\n```cpp\ncmake .\n\n输出：\n[root@localhost cmake]# cmake .\nCMake Warning (dev) in CMakeLists.txt:\n  Syntax Warning in cmake code at\n\n    /root/cmake/CMakeLists.txt:7:37\n\n  Argument not separated from preceding token by whitespace.\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\n-- The C compiler identification is GNU 10.2.1\n-- The CXX compiler identification is GNU 10.2.1\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- This is BINARY dir /root/cmake\n-- This is SOURCE dir /root/cmake\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /root/cmake\n```\n\n目录下就生成-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile.\n\n4、使用make命令编译\n\n```cpp\nroot@localhost cmake]# make\nScanning dependencies of target hello\n[100%] Building CXX object CMakeFiles/hello.dir/main.cpp.o\nLinking CXX executable hello\n[100%] Built target hello\n```\n\n5、最终生成了Hello的可执行程序\n\n# CMake一个HelloWord-的语法介绍\n\n## PROJECT关键字\n\n可以用来指定工程的名字和支持的语言，默认支持所有语言\n\nPROJECT (HELLO)   指定了工程的名字，并且支持所有语言—建议\n\nPROJECT (HELLO CXX)      指定了工程的名字，并且支持语言是C++\n\nPROJECT (HELLO C CXX)      指定了工程的名字，并且支持语言是C和C++\n\n该指定隐式定义了两个CMAKE的变量\n\n<projectname>_BINARY_DIR，HELLO_BINARY_DIR\n\n<projectname>_SOURCE_DIR，HELLO_SOURCE_DIR\n\nMESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译\n\n问题：如果改了工程名，这两个变量名也会改变\n\n解决：再定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系\n\n## SET关键字\n\n用来显示的指定变量的\n\nSET(SRC_LIST main.cpp)    SRC_LIST变量就包含了main.cpp\n\n也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp)\n\n## MESSAGE关键字\n\n向终端输出用户自定义的信息\n\n主要包含三种信息：\n\n- SEND_ERROR，产生错误，生成过程被跳过。\n- SATUS，输出前缀为—的信息。\n- FATAL_ERROR，立即终止所有 cmake 过程.\n\n## ADD_EXECUTABLE关键字\n\n生成可执行文件\n\nADD_EXECUTABLE(hello ${SRC_LIST})     生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容\n\n也可以直接写 ADD_EXECUTABLE(hello main.cpp)\n\n上述例子可以简化的写成\n\nPROJECT(HELLO)\nADD_EXECUTABLE(hello main.cpp)\n\n注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的\n\n# 语法的基本原则\n\n- 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名\n\n- 指令(参数 1 参数 2...) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件\n\n  就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp)\n\n- 指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令\n\n## 语法注意事项\n\n- SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号\n- ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main\n\n# 内部构建和外部构建\n\n- 上述例子就是内部构建，生产的临时文件特别多，不方便清理\n- 外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式\n\n## 外部构建方式举例\n\n```cpp\n//例子目录，CMakeLists.txt和上面例子一致\n[root@localhost cmake]# pwd\n/root/cmake\n[root@localhost cmake]# ll\ntotal 8\n-rw-r--r--. 1 root root 198 Dec 28 20:59 CMakeLists.txt\n-rw-r--r--. 1 root root  76 Dec 28 00:18 main.cpp\n```\n\n1、建立一个build目录，可以在任何地方，建议在当前目录下\n\n2、进入build，运行cmake ..    当然..表示上一级目录，可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了\n\n3、在build目录下，运行make来构建工程\n\n注意外部构建的两个变量\n\n1、HELLO_SOURCE_DIR  还是工程路径\n\n2、HELLO_BINARY_DIR   编译路径 也就是 /root/cmake/bulid\n\n# 让Hello World看起来更像一个工程\n\n- 为工程添加一个子目录 src，用来放置工程源代码\n- 添加一个子目录 doc，用来放置这个工程的文档 hello.txt\n- 在工程目录添加文本文件 COPYRIGHT, README\n- 在工程目录添加一个 [runhello.sh](http://runhello.sh/) 脚本，用来调用 hello 二进制\n- 将构建后的目标文件放入构建目录的 bin 子目录\n- 将 doc 目录 的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/\n\n## 将目标文件放入构建目录的 bin 子目录\n\n每个目录下都要有一个CMakeLists.txt说明\n\n```cpp\n[root@localhost cmake]# tree\n.\n├── build\n├── CMakeLists.txt\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n```\n\n外层CMakeLists.txt\n\n```cpp\nPROJECT(HELLO)\nADD_SUBDIRECTORY(src bin)\n```\n\nsrc下的CMakeLists.txt\n\n```cpp\nADD_EXECUTABLE(hello main.cpp)\n```\n\n### ADD_SUBDIRECTORY 指令\n\nADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL])\n\n- 这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置\n\n- EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example\n\n- ADD_SUBDIRECTORY(src bin)\n\n  将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录\n\n  如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录\n\n### 更改二进制的保存路径\n\nSET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置\n\nSET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)\nSET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)\n\n思考：加载哪个CMakeLists.txt当中\n\n哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写\n\n# 安装\n\n- 一种是从代码编译后直接 make install 安装\n- 一种是打包时的指定 目录安装。\n  - 简单的可以这样指定目录：make install DESTDIR=/tmp/test\n  - 稍微复杂一点可以这样指定目录：./configure –prefix=/usr\n\n## 如何安装HelloWord\n\n使用CMAKE一个新的指令：INSTALL\n\nINSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等\n\n使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX\n\n```cpp\n// 目录树结构\n[root@localhost cmake]# tree\n.\n├── build\n├── CMakeLists.txt\n├── COPYRIGHT\n├── doc\n│   └── hello.txt\n├── README\n├── runhello.sh\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n\n3 directories, 7 files\n```\n\n### 安装文件COPYRIGHT和README\n\nINSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/)\n\nFILES：文件\n\nDESTINATION：\n\n1、写绝对路径\n\n2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/<DESTINATION 定义的路径>\n\nCMAKE_INSTALL_PREFIX  默认是在 /usr/local/\n\ncmake -DCMAKE_INSTALL_PREFIX=/usr    在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径\n\n### 安装脚本runhello.sh\n\nPROGRAMS：非目标文件的可执行程序安装(比如脚本之类)\n\nINSTALL(PROGRAMS runhello.sh DESTINATION bin)\n\n说明：实际安装到的是 /usr/bin\n\n### 安装 doc 中的 hello.txt\n\n- 一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file\n\n- 二、是直接在工程目录通过\n\n  INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake)\n\n\nDIRECTORY 后面连接的是所在 Source 目录的相对路径\n\n注意：abc 和 abc/有很大的区别\n\n目录名不以/结尾：这个目录将被安装为目标路径下的\n\n目录名以/结尾：将这个目录中的内容安装到目标路径\n\n### 安装过程\n\ncmake ..\n\nmake\n\nmake install\n\n# 静态库和动态库的构建\n\n任务：\n\n１，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 \n\n２，安装头文件与共享库。\n\n静态库和动态库的区别\n\n- 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。\n- 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行\n- 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。\n\n## 构建实例\n\n```cpp\n[root@localhost cmake2]# tree\n.\n├── build\n├── CMakeLists.txt\n└── lib\n    ├── CMakeLists.txt\n    ├── hello.cpp\n    └── hello.h\n```\n\nhello.h中的内容\n\n```cpp\n#ifndef HELLO_H\n#define Hello_H\n\nvoid HelloFunc();\n\n#endif\n```\n\nhello.cpp中的内容\n\n```cpp\n#include \"hello.h\"\n#include <iostream>\nvoid HelloFunc(){\n    std::cout << \"Hello World\" << std::endl;\n}\n```\n\n项目中的cmake内容\n\n```cpp\nPROJECT(HELLO)\nADD_SUBDIRECTORY(lib bin)\n```\n\nlib中CMakeLists.txt中的内容\n\n```cpp\nSET(LIBHELLO_SRC hello.cpp)\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n```\n\n### ADD_LIBRARY\n\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n\n- hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so\n- SHARED，动态库    STATIC，静态库\n- ${LIBHELLO_SRC} ：源文件\n\n### 同时构建静态和动态库\n\n```cpp\n// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\nADD_LIBRARY(hello STATIC ${LIBHELLO_SRC})\n\n// 修改静态库的名字，但是往往希望他们的名字是相同的，只是后缀不同\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\nADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC})\n```\n\n### SET_TARGET_PROPERTIES\n\n这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本\n\n同时构建静态和动态库\n\n```cpp\nSET(LIBHELLO_SRC hello.cpp)\n\nADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC})\n\n//对hello_static的重名为hello\nSET_TARGET_PROPERTIES(hello_static PROPERTIES  OUTPUT_NAME \"hello\")\n//cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a\nSET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1)\n\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n\nSET_TARGET_PROPERTIES(hello PROPERTIES  OUTPUT_NAME \"hello\")\nSET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1)\n\n```\n\n### 动态库的版本号\n\n一般动态库都有一个版本号的关联\n\n```cpp\nlibhello.so.1.2\nlibhello.so ->libhello.so.1\nlibhello.so.1->libhello.so.1.2\n```\n\nCMakeLists.txt 插入如下\n\n`SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)`\n\nVERSION 指代动态库版本，SOVERSION 指代 API 版本。\n\n### 安装共享库和头文件\n\n本例中将 hello 的共享库安装到<prefix>/lib目录，\n\n将 hello.h 安装到<prefix>/include/hello 目录\n\n```cpp\n//文件放到该目录下\nINSTALL(FILES hello.h DESTINATION include/hello)\n\n//二进制，静态库，动态库安装都用TARGETS\n//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。\nINSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib)\n```\n\n注意：\n\n安装的时候，指定一下路径，放到系统下\n\n`cmake -DCMAKE_INSTALL_PREFIX=/usr ..`\n\n### 使用外部共享库和头文件\n\n准备工作，新建一个目录来使用外部共享库和头文件\n\n```cpp\n[root@MiWiFi-R4CM-srv cmake3]# tree\n.\n├── build\n├── CMakeLists.txt\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n```\n\nmain.cpp\n\n```cpp\n#include <hello.h>\n\nint main(){\n\tHelloFunc();\n}\n```\n\n### 解决：make后头文件找不到的问题\n\nPS：include <hello/hello.h>  这样include是可以，这么做的话，就没啥好讲的了\n\n关键字：INCLUDE_DIRECTORIES    这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割\n\n在CMakeLists.txt中加入头文件搜索路径\n\nINCLUDE_DIRECTORIES(/usr/include/hello)\n\n### 解决：找到引用的函数问题\n\n报错信息：undefined reference to `HelloFunc()'\n\n关键字：LINK_DIRECTORIES     添加非标准的共享库搜索路径\n\n指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs)\n\n关键字：TARGET_LINK_LIBRARIES    添加需要链接的共享库\n\nTARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字。\n\n在CMakeLists.txt中插入链接共享库，主要要插在executable的后面\n\n查看main的链接情况\n\n```cpp\n[root@MiWiFi-R4CM-srv bin]# ldd main \n\tlinux-vdso.so.1 =>  (0x00007ffedfda4000)\n\tlibhello.so => /lib64/libhello.so (0x00007f41c0d8f000)\n\tlibstdc++.so.6 => /lib64/libstdc++.so.6 (0x00007f41c0874000)\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007f41c0572000)\n\tlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f41c035c000)\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007f41bff8e000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f41c0b7c000)\n```\n\n链接静态库\n\n`TARGET_LINK_LIBRARIES(main libhello.a)`\n\n### 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH\n\n注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置\n\n我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置\n\n还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello\n\n补充：生产debug版本的方法：\ncmake .. -DCMAKE_BUILD_TYPE=debug","source":"_posts/cmake-study.md","raw":"---\ntitle: Cmake学习笔记\ncategories: 学习笔记\ndate: 2023-07-26 08:24:31\ntags: [C++, Cmake, 编译]\ncover: \ntop_img:\n---\n# CMake\n\n# 说明\n\ncmake的定义  -----高级编译配置工具\n\n当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）需要用到---CMake\n\n所有操作都是通过编译CMakeLists.txt来完成的—简单\n\n官网 [www.cmake.org](http://www.cmake.org/)\n\n# CMake安装\n\n[http://www.cmake.org/HTML/Download.htm](http://www.cmake.org/HTML/Download.html)l  可以下载安装\n\n# CMake一个HelloWord\n\n1、写一个HelloWord\n\n```cpp\n#main.cpp\n\n#include <iostream>\n\nint main(){\nstd::cout <<  \"hello word\" << std::endl;\n}\n```\n\n2、写CMakeLists.txt\n\n```cpp\n#CMakeLists.txt\n\nPROJECT (HELLO)\n\nSET(SRC_LIST main.cpp)\n\nMESSAGE(STATUS \"This is BINARY dir \" ${HELLO_BINARY_DIR})\n\nMESSAGE(STATUS \"This is SOURCE dir \"${HELLO_SOURCE_DIR})\n\nADD_EXECUTABLE(hello ${SRC_LIST})\n```\n\n3、使用cmake，生成makefile文件\n\n```cpp\ncmake .\n\n输出：\n[root@localhost cmake]# cmake .\nCMake Warning (dev) in CMakeLists.txt:\n  Syntax Warning in cmake code at\n\n    /root/cmake/CMakeLists.txt:7:37\n\n  Argument not separated from preceding token by whitespace.\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\n-- The C compiler identification is GNU 10.2.1\n-- The CXX compiler identification is GNU 10.2.1\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- This is BINARY dir /root/cmake\n-- This is SOURCE dir /root/cmake\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /root/cmake\n```\n\n目录下就生成-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile.\n\n4、使用make命令编译\n\n```cpp\nroot@localhost cmake]# make\nScanning dependencies of target hello\n[100%] Building CXX object CMakeFiles/hello.dir/main.cpp.o\nLinking CXX executable hello\n[100%] Built target hello\n```\n\n5、最终生成了Hello的可执行程序\n\n# CMake一个HelloWord-的语法介绍\n\n## PROJECT关键字\n\n可以用来指定工程的名字和支持的语言，默认支持所有语言\n\nPROJECT (HELLO)   指定了工程的名字，并且支持所有语言—建议\n\nPROJECT (HELLO CXX)      指定了工程的名字，并且支持语言是C++\n\nPROJECT (HELLO C CXX)      指定了工程的名字，并且支持语言是C和C++\n\n该指定隐式定义了两个CMAKE的变量\n\n<projectname>_BINARY_DIR，HELLO_BINARY_DIR\n\n<projectname>_SOURCE_DIR，HELLO_SOURCE_DIR\n\nMESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译\n\n问题：如果改了工程名，这两个变量名也会改变\n\n解决：再定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系\n\n## SET关键字\n\n用来显示的指定变量的\n\nSET(SRC_LIST main.cpp)    SRC_LIST变量就包含了main.cpp\n\n也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp)\n\n## MESSAGE关键字\n\n向终端输出用户自定义的信息\n\n主要包含三种信息：\n\n- SEND_ERROR，产生错误，生成过程被跳过。\n- SATUS，输出前缀为—的信息。\n- FATAL_ERROR，立即终止所有 cmake 过程.\n\n## ADD_EXECUTABLE关键字\n\n生成可执行文件\n\nADD_EXECUTABLE(hello ${SRC_LIST})     生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容\n\n也可以直接写 ADD_EXECUTABLE(hello main.cpp)\n\n上述例子可以简化的写成\n\nPROJECT(HELLO)\nADD_EXECUTABLE(hello main.cpp)\n\n注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的\n\n# 语法的基本原则\n\n- 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名\n\n- 指令(参数 1 参数 2...) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件\n\n  就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp)\n\n- 指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令\n\n## 语法注意事项\n\n- SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号\n- ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main\n\n# 内部构建和外部构建\n\n- 上述例子就是内部构建，生产的临时文件特别多，不方便清理\n- 外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式\n\n## 外部构建方式举例\n\n```cpp\n//例子目录，CMakeLists.txt和上面例子一致\n[root@localhost cmake]# pwd\n/root/cmake\n[root@localhost cmake]# ll\ntotal 8\n-rw-r--r--. 1 root root 198 Dec 28 20:59 CMakeLists.txt\n-rw-r--r--. 1 root root  76 Dec 28 00:18 main.cpp\n```\n\n1、建立一个build目录，可以在任何地方，建议在当前目录下\n\n2、进入build，运行cmake ..    当然..表示上一级目录，可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了\n\n3、在build目录下，运行make来构建工程\n\n注意外部构建的两个变量\n\n1、HELLO_SOURCE_DIR  还是工程路径\n\n2、HELLO_BINARY_DIR   编译路径 也就是 /root/cmake/bulid\n\n# 让Hello World看起来更像一个工程\n\n- 为工程添加一个子目录 src，用来放置工程源代码\n- 添加一个子目录 doc，用来放置这个工程的文档 hello.txt\n- 在工程目录添加文本文件 COPYRIGHT, README\n- 在工程目录添加一个 [runhello.sh](http://runhello.sh/) 脚本，用来调用 hello 二进制\n- 将构建后的目标文件放入构建目录的 bin 子目录\n- 将 doc 目录 的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/\n\n## 将目标文件放入构建目录的 bin 子目录\n\n每个目录下都要有一个CMakeLists.txt说明\n\n```cpp\n[root@localhost cmake]# tree\n.\n├── build\n├── CMakeLists.txt\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n```\n\n外层CMakeLists.txt\n\n```cpp\nPROJECT(HELLO)\nADD_SUBDIRECTORY(src bin)\n```\n\nsrc下的CMakeLists.txt\n\n```cpp\nADD_EXECUTABLE(hello main.cpp)\n```\n\n### ADD_SUBDIRECTORY 指令\n\nADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL])\n\n- 这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置\n\n- EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example\n\n- ADD_SUBDIRECTORY(src bin)\n\n  将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录\n\n  如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录\n\n### 更改二进制的保存路径\n\nSET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置\n\nSET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)\nSET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)\n\n思考：加载哪个CMakeLists.txt当中\n\n哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写\n\n# 安装\n\n- 一种是从代码编译后直接 make install 安装\n- 一种是打包时的指定 目录安装。\n  - 简单的可以这样指定目录：make install DESTDIR=/tmp/test\n  - 稍微复杂一点可以这样指定目录：./configure –prefix=/usr\n\n## 如何安装HelloWord\n\n使用CMAKE一个新的指令：INSTALL\n\nINSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等\n\n使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX\n\n```cpp\n// 目录树结构\n[root@localhost cmake]# tree\n.\n├── build\n├── CMakeLists.txt\n├── COPYRIGHT\n├── doc\n│   └── hello.txt\n├── README\n├── runhello.sh\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n\n3 directories, 7 files\n```\n\n### 安装文件COPYRIGHT和README\n\nINSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/)\n\nFILES：文件\n\nDESTINATION：\n\n1、写绝对路径\n\n2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/<DESTINATION 定义的路径>\n\nCMAKE_INSTALL_PREFIX  默认是在 /usr/local/\n\ncmake -DCMAKE_INSTALL_PREFIX=/usr    在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径\n\n### 安装脚本runhello.sh\n\nPROGRAMS：非目标文件的可执行程序安装(比如脚本之类)\n\nINSTALL(PROGRAMS runhello.sh DESTINATION bin)\n\n说明：实际安装到的是 /usr/bin\n\n### 安装 doc 中的 hello.txt\n\n- 一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file\n\n- 二、是直接在工程目录通过\n\n  INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake)\n\n\nDIRECTORY 后面连接的是所在 Source 目录的相对路径\n\n注意：abc 和 abc/有很大的区别\n\n目录名不以/结尾：这个目录将被安装为目标路径下的\n\n目录名以/结尾：将这个目录中的内容安装到目标路径\n\n### 安装过程\n\ncmake ..\n\nmake\n\nmake install\n\n# 静态库和动态库的构建\n\n任务：\n\n１，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 \n\n２，安装头文件与共享库。\n\n静态库和动态库的区别\n\n- 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。\n- 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行\n- 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。\n\n## 构建实例\n\n```cpp\n[root@localhost cmake2]# tree\n.\n├── build\n├── CMakeLists.txt\n└── lib\n    ├── CMakeLists.txt\n    ├── hello.cpp\n    └── hello.h\n```\n\nhello.h中的内容\n\n```cpp\n#ifndef HELLO_H\n#define Hello_H\n\nvoid HelloFunc();\n\n#endif\n```\n\nhello.cpp中的内容\n\n```cpp\n#include \"hello.h\"\n#include <iostream>\nvoid HelloFunc(){\n    std::cout << \"Hello World\" << std::endl;\n}\n```\n\n项目中的cmake内容\n\n```cpp\nPROJECT(HELLO)\nADD_SUBDIRECTORY(lib bin)\n```\n\nlib中CMakeLists.txt中的内容\n\n```cpp\nSET(LIBHELLO_SRC hello.cpp)\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n```\n\n### ADD_LIBRARY\n\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n\n- hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so\n- SHARED，动态库    STATIC，静态库\n- ${LIBHELLO_SRC} ：源文件\n\n### 同时构建静态和动态库\n\n```cpp\n// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\nADD_LIBRARY(hello STATIC ${LIBHELLO_SRC})\n\n// 修改静态库的名字，但是往往希望他们的名字是相同的，只是后缀不同\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\nADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC})\n```\n\n### SET_TARGET_PROPERTIES\n\n这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本\n\n同时构建静态和动态库\n\n```cpp\nSET(LIBHELLO_SRC hello.cpp)\n\nADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC})\n\n//对hello_static的重名为hello\nSET_TARGET_PROPERTIES(hello_static PROPERTIES  OUTPUT_NAME \"hello\")\n//cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a\nSET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1)\n\nADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})\n\nSET_TARGET_PROPERTIES(hello PROPERTIES  OUTPUT_NAME \"hello\")\nSET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1)\n\n```\n\n### 动态库的版本号\n\n一般动态库都有一个版本号的关联\n\n```cpp\nlibhello.so.1.2\nlibhello.so ->libhello.so.1\nlibhello.so.1->libhello.so.1.2\n```\n\nCMakeLists.txt 插入如下\n\n`SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)`\n\nVERSION 指代动态库版本，SOVERSION 指代 API 版本。\n\n### 安装共享库和头文件\n\n本例中将 hello 的共享库安装到<prefix>/lib目录，\n\n将 hello.h 安装到<prefix>/include/hello 目录\n\n```cpp\n//文件放到该目录下\nINSTALL(FILES hello.h DESTINATION include/hello)\n\n//二进制，静态库，动态库安装都用TARGETS\n//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。\nINSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib)\n```\n\n注意：\n\n安装的时候，指定一下路径，放到系统下\n\n`cmake -DCMAKE_INSTALL_PREFIX=/usr ..`\n\n### 使用外部共享库和头文件\n\n准备工作，新建一个目录来使用外部共享库和头文件\n\n```cpp\n[root@MiWiFi-R4CM-srv cmake3]# tree\n.\n├── build\n├── CMakeLists.txt\n└── src\n    ├── CMakeLists.txt\n    └── main.cpp\n```\n\nmain.cpp\n\n```cpp\n#include <hello.h>\n\nint main(){\n\tHelloFunc();\n}\n```\n\n### 解决：make后头文件找不到的问题\n\nPS：include <hello/hello.h>  这样include是可以，这么做的话，就没啥好讲的了\n\n关键字：INCLUDE_DIRECTORIES    这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割\n\n在CMakeLists.txt中加入头文件搜索路径\n\nINCLUDE_DIRECTORIES(/usr/include/hello)\n\n### 解决：找到引用的函数问题\n\n报错信息：undefined reference to `HelloFunc()'\n\n关键字：LINK_DIRECTORIES     添加非标准的共享库搜索路径\n\n指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs)\n\n关键字：TARGET_LINK_LIBRARIES    添加需要链接的共享库\n\nTARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字。\n\n在CMakeLists.txt中插入链接共享库，主要要插在executable的后面\n\n查看main的链接情况\n\n```cpp\n[root@MiWiFi-R4CM-srv bin]# ldd main \n\tlinux-vdso.so.1 =>  (0x00007ffedfda4000)\n\tlibhello.so => /lib64/libhello.so (0x00007f41c0d8f000)\n\tlibstdc++.so.6 => /lib64/libstdc++.so.6 (0x00007f41c0874000)\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007f41c0572000)\n\tlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f41c035c000)\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007f41bff8e000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f41c0b7c000)\n```\n\n链接静态库\n\n`TARGET_LINK_LIBRARIES(main libhello.a)`\n\n### 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH\n\n注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置\n\n我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置\n\n还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello\n\n补充：生产debug版本的方法：\ncmake .. -DCMAKE_BUILD_TYPE=debug","slug":"cmake-study","published":1,"updated":"2024-06-05T09:03:03.633Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttp001708jv7znkdl7g","content":"<h1 id=\"CMake\"><a href=\"#CMake\" class=\"headerlink\" title=\"CMake\"></a>CMake</h1><h1 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h1><p>cmake的定义  ——-高级编译配置工具</p>\n<p>当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）需要用到—-CMake</p>\n<p>所有操作都是通过编译CMakeLists.txt来完成的—简单</p>\n<p>官网 <a href=\"http://www.cmake.org/\">www.cmake.org</a></p>\n<h1 id=\"CMake安装\"><a href=\"#CMake安装\" class=\"headerlink\" title=\"CMake安装\"></a>CMake安装</h1><p><a href=\"http://www.cmake.org/HTML/Download.html\">http://www.cmake.org/HTML/Download.htm</a>l  可以下载安装</p>\n<h1 id=\"CMake一个HelloWord\"><a href=\"#CMake一个HelloWord\" class=\"headerlink\" title=\"CMake一个HelloWord\"></a>CMake一个HelloWord</h1><p>1、写一个HelloWord</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#main.cpp</span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>std::cout &lt;&lt;  <span class=\"hljs-string\">&quot;hello word&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>2、写CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">#CMakeLists.<span class=\"hljs-function\">txt</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">PROJECT</span> <span class=\"hljs-params\">(HELLO)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">SET</span><span class=\"hljs-params\">(SRC_LIST main.cpp)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">MESSAGE</span><span class=\"hljs-params\">(STATUS <span class=\"hljs-string\">&quot;This is BINARY dir &quot;</span> $&#123;HELLO_BINARY_DIR&#125;)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">MESSAGE</span><span class=\"hljs-params\">(STATUS <span class=\"hljs-string\">&quot;This is SOURCE dir &quot;</span>$&#123;HELLO_SOURCE_DIR&#125;)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">ADD_EXECUTABLE</span><span class=\"hljs-params\">(hello $&#123;SRC_LIST&#125;)</span></span><br></code></pre></td></tr></table></figure>\n<p>3、使用cmake，生成makefile文件</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">cmake .<br><br>输出：<br>[root@localhost cmake]<span class=\"hljs-meta\"># cmake .</span><br><span class=\"hljs-function\">CMake <span class=\"hljs-title\">Warning</span> <span class=\"hljs-params\">(dev)</span> in CMakeLists.txt:</span><br><span class=\"hljs-function\">  Syntax Warning in cmake code at</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">    /root/cmake/CMakeLists.txt:<span class=\"hljs-number\">7</span>:<span class=\"hljs-number\">37</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">  Argument not separated from preceding token by whitespace.</span><br><span class=\"hljs-function\">This warning is for project developers.  Use -Wno-dev to suppress it.</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">-- The C compiler identification is GNU <span class=\"hljs-number\">10.2</span><span class=\"hljs-number\">.1</span></span><br><span class=\"hljs-function\">-- The CXX compiler identification is GNU <span class=\"hljs-number\">10.2</span><span class=\"hljs-number\">.1</span></span><br><span class=\"hljs-function\">-- Check for working C compiler: /usr/bin/cc</span><br><span class=\"hljs-function\">-- Check for working C compiler: /usr/bin/cc -- works</span><br><span class=\"hljs-function\">-- Detecting C compiler ABI info</span><br><span class=\"hljs-function\">-- Detecting C compiler ABI info - done</span><br><span class=\"hljs-function\">-- Check for working CXX compiler: /usr/bin/c++</span><br><span class=\"hljs-function\">-- Check for working CXX compiler: /usr/bin/c++ -- works</span><br><span class=\"hljs-function\">-- Detecting CXX compiler ABI info</span><br><span class=\"hljs-function\">-- Detecting CXX compiler ABI info - done</span><br><span class=\"hljs-function\">-- This is BINARY dir /root/cmake</span><br><span class=\"hljs-function\">-- This is SOURCE dir /root/cmake</span><br><span class=\"hljs-function\">-- Configuring done</span><br><span class=\"hljs-function\">-- Generating done</span><br><span class=\"hljs-function\">-- Build files have been written to: /root/cmake</span><br></code></pre></td></tr></table></figure>\n<p>目录下就生成-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile.</p>\n<p>4、使用make命令编译</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">root@localhost cmake]<span class=\"hljs-meta\"># make</span><br>Scanning dependencies of target hello<br>[<span class=\"hljs-number\">100</span>%] Building CXX object CMakeFiles/hello.dir/main.cpp.o<br>Linking CXX executable hello<br>[<span class=\"hljs-number\">100</span>%] Built target hello<br></code></pre></td></tr></table></figure>\n<p>5、最终生成了Hello的可执行程序</p>\n<h1 id=\"CMake一个HelloWord-的语法介绍\"><a href=\"#CMake一个HelloWord-的语法介绍\" class=\"headerlink\" title=\"CMake一个HelloWord-的语法介绍\"></a>CMake一个HelloWord-的语法介绍</h1><h2 id=\"PROJECT关键字\"><a href=\"#PROJECT关键字\" class=\"headerlink\" title=\"PROJECT关键字\"></a>PROJECT关键字</h2><p>可以用来指定工程的名字和支持的语言，默认支持所有语言</p>\n<p>PROJECT (HELLO)   指定了工程的名字，并且支持所有语言—建议</p>\n<p>PROJECT (HELLO CXX)      指定了工程的名字，并且支持语言是C++</p>\n<p>PROJECT (HELLO C CXX)      指定了工程的名字，并且支持语言是C和C++</p>\n<p>该指定隐式定义了两个CMAKE的变量</p>\n<p><projectname>_BINARY_DIR，HELLO_BINARY_DIR</p>\n<p><projectname>_SOURCE_DIR，HELLO_SOURCE_DIR</p>\n<p>MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译</p>\n<p>问题：如果改了工程名，这两个变量名也会改变</p>\n<p>解决：再定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系</p>\n<h2 id=\"SET关键字\"><a href=\"#SET关键字\" class=\"headerlink\" title=\"SET关键字\"></a>SET关键字</h2><p>用来显示的指定变量的</p>\n<p>SET(SRC_LIST main.cpp)    SRC_LIST变量就包含了main.cpp</p>\n<p>也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp)</p>\n<h2 id=\"MESSAGE关键字\"><a href=\"#MESSAGE关键字\" class=\"headerlink\" title=\"MESSAGE关键字\"></a>MESSAGE关键字</h2><p>向终端输出用户自定义的信息</p>\n<p>主要包含三种信息：</p>\n<ul>\n<li>SEND_ERROR，产生错误，生成过程被跳过。</li>\n<li>SATUS，输出前缀为—的信息。</li>\n<li>FATAL_ERROR，立即终止所有 cmake 过程.</li>\n</ul>\n<h2 id=\"ADD-EXECUTABLE关键字\"><a href=\"#ADD-EXECUTABLE关键字\" class=\"headerlink\" title=\"ADD_EXECUTABLE关键字\"></a>ADD_EXECUTABLE关键字</h2><p>生成可执行文件</p>\n<p>ADD_EXECUTABLE(hello ${SRC_LIST})     生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容</p>\n<p>也可以直接写 ADD_EXECUTABLE(hello main.cpp)</p>\n<p>上述例子可以简化的写成</p>\n<p>PROJECT(HELLO)<br>ADD_EXECUTABLE(hello main.cpp)</p>\n<p>注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的</p>\n<h1 id=\"语法的基本原则\"><a href=\"#语法的基本原则\" class=\"headerlink\" title=\"语法的基本原则\"></a>语法的基本原则</h1><ul>\n<li><p>变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名</p>\n</li>\n<li><p>指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件</p>\n<p>就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp)</p>\n</li>\n<li><p>指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令</p>\n</li>\n</ul>\n<h2 id=\"语法注意事项\"><a href=\"#语法注意事项\" class=\"headerlink\" title=\"语法注意事项\"></a>语法注意事项</h2><ul>\n<li>SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号</li>\n<li>ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main</li>\n</ul>\n<h1 id=\"内部构建和外部构建\"><a href=\"#内部构建和外部构建\" class=\"headerlink\" title=\"内部构建和外部构建\"></a>内部构建和外部构建</h1><ul>\n<li>上述例子就是内部构建，生产的临时文件特别多，不方便清理</li>\n<li>外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式</li>\n</ul>\n<h2 id=\"外部构建方式举例\"><a href=\"#外部构建方式举例\" class=\"headerlink\" title=\"外部构建方式举例\"></a>外部构建方式举例</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//例子目录，CMakeLists.txt和上面例子一致</span><br>[root@localhost cmake]<span class=\"hljs-meta\"># pwd</span><br>/root/cmake<br>[root@localhost cmake]<span class=\"hljs-meta\"># ll</span><br>total <span class=\"hljs-number\">8</span><br>-rw-r--r--. <span class=\"hljs-number\">1</span> root root <span class=\"hljs-number\">198</span> Dec <span class=\"hljs-number\">28</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">59</span> CMakeLists.txt<br>-rw-r--r--. <span class=\"hljs-number\">1</span> root root  <span class=\"hljs-number\">76</span> Dec <span class=\"hljs-number\">28</span> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span> main.cpp<br></code></pre></td></tr></table></figure>\n<p>1、建立一个build目录，可以在任何地方，建议在当前目录下</p>\n<p>2、进入build，运行cmake ..    当然..表示上一级目录，可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了</p>\n<p>3、在build目录下，运行make来构建工程</p>\n<p>注意外部构建的两个变量</p>\n<p>1、HELLO_SOURCE_DIR  还是工程路径</p>\n<p>2、HELLO_BINARY_DIR   编译路径 也就是 /root/cmake/bulid</p>\n<h1 id=\"让Hello-World看起来更像一个工程\"><a href=\"#让Hello-World看起来更像一个工程\" class=\"headerlink\" title=\"让Hello World看起来更像一个工程\"></a>让Hello World看起来更像一个工程</h1><ul>\n<li>为工程添加一个子目录 src，用来放置工程源代码</li>\n<li>添加一个子目录 doc，用来放置这个工程的文档 hello.txt</li>\n<li>在工程目录添加文本文件 COPYRIGHT, README</li>\n<li>在工程目录添加一个 <a href=\"http://runhello.sh/\">runhello.sh</a> 脚本，用来调用 hello 二进制</li>\n<li>将构建后的目标文件放入构建目录的 bin 子目录</li>\n<li>将 doc 目录 的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/</li>\n</ul>\n<h2 id=\"将目标文件放入构建目录的-bin-子目录\"><a href=\"#将目标文件放入构建目录的-bin-子目录\" class=\"headerlink\" title=\"将目标文件放入构建目录的 bin 子目录\"></a>将目标文件放入构建目录的 bin 子目录</h2><p>每个目录下都要有一个CMakeLists.txt说明</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@localhost cmake]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br></code></pre></td></tr></table></figure>\n<p>外层CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">PROJECT</span>(HELLO)<br><span class=\"hljs-built_in\">ADD_SUBDIRECTORY</span>(src bin)<br></code></pre></td></tr></table></figure>\n<p>src下的CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">ADD_EXECUTABLE</span>(hello main.cpp)<br></code></pre></td></tr></table></figure>\n<h3 id=\"ADD-SUBDIRECTORY-指令\"><a href=\"#ADD-SUBDIRECTORY-指令\" class=\"headerlink\" title=\"ADD_SUBDIRECTORY 指令\"></a>ADD_SUBDIRECTORY 指令</h3><p>ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL])</p>\n<ul>\n<li><p>这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置</p>\n</li>\n<li><p>EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example</p>\n</li>\n<li><p>ADD_SUBDIRECTORY(src bin)</p>\n<p>将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录</p>\n<p>如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录</p>\n</li>\n</ul>\n<h3 id=\"更改二进制的保存路径\"><a href=\"#更改二进制的保存路径\" class=\"headerlink\" title=\"更改二进制的保存路径\"></a>更改二进制的保存路径</h3><p>SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置</p>\n<p>SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)<br>SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)</p>\n<p>思考：加载哪个CMakeLists.txt当中</p>\n<p>哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><ul>\n<li>一种是从代码编译后直接 make install 安装</li>\n<li>一种是打包时的指定 目录安装。<ul>\n<li>简单的可以这样指定目录：make install DESTDIR=/tmp/test</li>\n<li>稍微复杂一点可以这样指定目录：./configure –prefix=/usr</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"如何安装HelloWord\"><a href=\"#如何安装HelloWord\" class=\"headerlink\" title=\"如何安装HelloWord\"></a>如何安装HelloWord</h2><p>使用CMAKE一个新的指令：INSTALL</p>\n<p>INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等</p>\n<p>使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 目录树结构</span><br>[root@localhost cmake]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>├── COPYRIGHT<br>├── doc<br>│   └── hello.txt<br>├── README<br>├── runhello.sh<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br><br><span class=\"hljs-number\">3</span> directories, <span class=\"hljs-number\">7</span> files<br></code></pre></td></tr></table></figure>\n<h3 id=\"安装文件COPYRIGHT和README\"><a href=\"#安装文件COPYRIGHT和README\" class=\"headerlink\" title=\"安装文件COPYRIGHT和README\"></a>安装文件COPYRIGHT和README</h3><p>INSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/)</p>\n<p>FILES：文件</p>\n<p>DESTINATION：</p>\n<p>1、写绝对路径</p>\n<p>2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/<DESTINATION 定义的路径></p>\n<p>CMAKE_INSTALL_PREFIX  默认是在 /usr/local/</p>\n<p>cmake -DCMAKE_INSTALL_PREFIX=/usr    在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径</p>\n<h3 id=\"安装脚本runhello-sh\"><a href=\"#安装脚本runhello-sh\" class=\"headerlink\" title=\"安装脚本runhello.sh\"></a>安装脚本runhello.sh</h3><p>PROGRAMS：非目标文件的可执行程序安装(比如脚本之类)</p>\n<p>INSTALL(PROGRAMS runhello.sh DESTINATION bin)</p>\n<p>说明：实际安装到的是 /usr/bin</p>\n<h3 id=\"安装-doc-中的-hello-txt\"><a href=\"#安装-doc-中的-hello-txt\" class=\"headerlink\" title=\"安装 doc 中的 hello.txt\"></a>安装 doc 中的 hello.txt</h3><ul>\n<li><p>一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file</p>\n</li>\n<li><p>二、是直接在工程目录通过</p>\n<p>INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake)</p>\n</li>\n</ul>\n<p>DIRECTORY 后面连接的是所在 Source 目录的相对路径</p>\n<p>注意：abc 和 abc/有很大的区别</p>\n<p>目录名不以/结尾：这个目录将被安装为目标路径下的</p>\n<p>目录名以/结尾：将这个目录中的内容安装到目标路径</p>\n<h3 id=\"安装过程\"><a href=\"#安装过程\" class=\"headerlink\" title=\"安装过程\"></a>安装过程</h3><p>cmake ..</p>\n<p>make</p>\n<p>make install</p>\n<h1 id=\"静态库和动态库的构建\"><a href=\"#静态库和动态库的构建\" class=\"headerlink\" title=\"静态库和动态库的构建\"></a>静态库和动态库的构建</h1><p>任务：</p>\n<p>１，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 </p>\n<p>２，安装头文件与共享库。</p>\n<p>静态库和动态库的区别</p>\n<ul>\n<li>静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。</li>\n<li>静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行</li>\n<li>动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。</li>\n</ul>\n<h2 id=\"构建实例\"><a href=\"#构建实例\" class=\"headerlink\" title=\"构建实例\"></a>构建实例</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@localhost cmake2]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── lib<br>    ├── CMakeLists.txt<br>    ├── hello.cpp<br>    └── hello.h<br></code></pre></td></tr></table></figure>\n<p>hello.h中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">ifndef</span> HELLO_H</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> Hello_H</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HelloFunc</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">endif</span></span><br></code></pre></td></tr></table></figure>\n<p>hello.cpp中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&quot;hello.h&quot;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HelloFunc</span><span class=\"hljs-params\">()</span></span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Hello World&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>项目中的cmake内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">PROJECT</span>(HELLO)<br><span class=\"hljs-built_in\">ADD_SUBDIRECTORY</span>(lib bin)<br></code></pre></td></tr></table></figure>\n<p>lib中CMakeLists.txt中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">SET</span>(LIBHELLO_SRC hello.cpp)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br></code></pre></td></tr></table></figure>\n<h3 id=\"ADD-LIBRARY\"><a href=\"#ADD-LIBRARY\" class=\"headerlink\" title=\"ADD_LIBRARY\"></a>ADD_LIBRARY</h3><p>ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})</p>\n<ul>\n<li>hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so</li>\n<li>SHARED，动态库    STATIC，静态库</li>\n<li>${LIBHELLO_SRC} ：源文件</li>\n</ul>\n<h3 id=\"同时构建静态和动态库\"><a href=\"#同时构建静态和动态库\" class=\"headerlink\" title=\"同时构建静态和动态库\"></a>同时构建静态和动态库</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a</span><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello STATIC $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-comment\">// 修改静态库的名字，但是往往希望他们的名字是相同的，只是后缀不同</span><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)<br></code></pre></td></tr></table></figure>\n<h3 id=\"SET-TARGET-PROPERTIES\"><a href=\"#SET-TARGET-PROPERTIES\" class=\"headerlink\" title=\"SET_TARGET_PROPERTIES\"></a>SET_TARGET_PROPERTIES</h3><p>这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本</p>\n<p>同时构建静态和动态库</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">SET</span>(LIBHELLO_SRC hello.cpp)<br><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-comment\">//对hello_static的重名为hello</span><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello_static PROPERTIES  OUTPUT_NAME <span class=\"hljs-string\">&quot;hello&quot;</span>)<br><span class=\"hljs-comment\">//cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a</span><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT <span class=\"hljs-number\">1</span>)<br><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello PROPERTIES  OUTPUT_NAME <span class=\"hljs-string\">&quot;hello&quot;</span>)<br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello PROPERTIES CLEAN_DIRECT_OUTPUT <span class=\"hljs-number\">1</span>)<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"动态库的版本号\"><a href=\"#动态库的版本号\" class=\"headerlink\" title=\"动态库的版本号\"></a>动态库的版本号</h3><p>一般动态库都有一个版本号的关联</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">libhello.so<span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.2</span><br>libhello.so -&gt;libhello.so<span class=\"hljs-number\">.1</span><br>libhello.so<span class=\"hljs-number\">.1</span>-&gt;libhello.so<span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.2</span><br></code></pre></td></tr></table></figure>\n<p>CMakeLists.txt 插入如下</p>\n<p><code>SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)</code></p>\n<p>VERSION 指代动态库版本，SOVERSION 指代 API 版本。</p>\n<h3 id=\"安装共享库和头文件\"><a href=\"#安装共享库和头文件\" class=\"headerlink\" title=\"安装共享库和头文件\"></a>安装共享库和头文件</h3><p>本例中将 hello 的共享库安装到<prefix>/lib目录，</p>\n<p>将 hello.h 安装到<prefix>/include/hello 目录</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//文件放到该目录下</span><br><span class=\"hljs-built_in\">INSTALL</span>(FILES hello.h DESTINATION include/hello)<br><br><span class=\"hljs-comment\">//二进制，静态库，动态库安装都用TARGETS</span><br><span class=\"hljs-comment\">//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。</span><br><span class=\"hljs-built_in\">INSTALL</span>(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib)<br></code></pre></td></tr></table></figure>\n<p>注意：</p>\n<p>安装的时候，指定一下路径，放到系统下</p>\n<p><code>cmake -DCMAKE_INSTALL_PREFIX=/usr ..</code></p>\n<h3 id=\"使用外部共享库和头文件\"><a href=\"#使用外部共享库和头文件\" class=\"headerlink\" title=\"使用外部共享库和头文件\"></a>使用外部共享库和头文件</h3><p>准备工作，新建一个目录来使用外部共享库和头文件</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@MiWiFi-R4CM-srv cmake3]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br></code></pre></td></tr></table></figure>\n<p>main.cpp</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;hello.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>\t<span class=\"hljs-built_in\">HelloFunc</span>();<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"解决：make后头文件找不到的问题\"><a href=\"#解决：make后头文件找不到的问题\" class=\"headerlink\" title=\"解决：make后头文件找不到的问题\"></a>解决：make后头文件找不到的问题</h3><p>PS：include <hello/hello.h>  这样include是可以，这么做的话，就没啥好讲的了</p>\n<p>关键字：INCLUDE_DIRECTORIES    这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割</p>\n<p>在CMakeLists.txt中加入头文件搜索路径</p>\n<p>INCLUDE_DIRECTORIES(/usr/include/hello)</p>\n<h3 id=\"解决：找到引用的函数问题\"><a href=\"#解决：找到引用的函数问题\" class=\"headerlink\" title=\"解决：找到引用的函数问题\"></a>解决：找到引用的函数问题</h3><p>报错信息：undefined reference to `HelloFunc()’</p>\n<p>关键字：LINK_DIRECTORIES     添加非标准的共享库搜索路径</p>\n<p>指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs)</p>\n<p>关键字：TARGET_LINK_LIBRARIES    添加需要链接的共享库</p>\n<p>TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字。</p>\n<p>在CMakeLists.txt中插入链接共享库，主要要插在executable的后面</p>\n<p>查看main的链接情况</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@MiWiFi-R4CM-srv bin]<span class=\"hljs-meta\"># ldd main </span><br>\tlinux-vdso.so<span class=\"hljs-number\">.1</span> =&gt;  (<span class=\"hljs-number\">0x00007ffedfda4000</span>)<br>\tlibhello.so =&gt; /lib64/libhello.<span class=\"hljs-built_in\">so</span> (<span class=\"hljs-number\">0x00007f41c0d8f000</span>)<br>\tlibstdc++.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libstdc++.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41c0874000</span>)<br>\tlibm.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libm.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41c0572000</span>)<br>\tlibgcc_s.so<span class=\"hljs-number\">.1</span> =&gt; /lib64/libgcc_s.so<span class=\"hljs-number\">.1</span> (<span class=\"hljs-number\">0x00007f41c035c000</span>)<br>\tlibc.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libc.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41bff8e000</span>)<br>\t/lib64/ld-linux-x86<span class=\"hljs-number\">-64.</span>so<span class=\"hljs-number\">.2</span> (<span class=\"hljs-number\">0x00007f41c0b7c000</span>)<br></code></pre></td></tr></table></figure>\n<p>链接静态库</p>\n<p><code>TARGET_LINK_LIBRARIES(main libhello.a)</code></p>\n<h3 id=\"特殊的环境变量-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH\"><a href=\"#特殊的环境变量-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH\" class=\"headerlink\" title=\"特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH\"></a>特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH</h3><p>注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置</p>\n<p>我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置</p>\n<p>还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello</p>\n<p>补充：生产debug版本的方法：<br>cmake .. -DCMAKE_BUILD_TYPE=debug</p>\n","cover_type":"img","excerpt":"","more":"<h1 id=\"CMake\"><a href=\"#CMake\" class=\"headerlink\" title=\"CMake\"></a>CMake</h1><h1 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h1><p>cmake的定义  ——-高级编译配置工具</p>\n<p>当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）需要用到—-CMake</p>\n<p>所有操作都是通过编译CMakeLists.txt来完成的—简单</p>\n<p>官网 <a href=\"http://www.cmake.org/\">www.cmake.org</a></p>\n<h1 id=\"CMake安装\"><a href=\"#CMake安装\" class=\"headerlink\" title=\"CMake安装\"></a>CMake安装</h1><p><a href=\"http://www.cmake.org/HTML/Download.html\">http://www.cmake.org/HTML/Download.htm</a>l  可以下载安装</p>\n<h1 id=\"CMake一个HelloWord\"><a href=\"#CMake一个HelloWord\" class=\"headerlink\" title=\"CMake一个HelloWord\"></a>CMake一个HelloWord</h1><p>1、写一个HelloWord</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#main.cpp</span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>std::cout &lt;&lt;  <span class=\"hljs-string\">&quot;hello word&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>2、写CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">#CMakeLists.<span class=\"hljs-function\">txt</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">PROJECT</span> <span class=\"hljs-params\">(HELLO)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">SET</span><span class=\"hljs-params\">(SRC_LIST main.cpp)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">MESSAGE</span><span class=\"hljs-params\">(STATUS <span class=\"hljs-string\">&quot;This is BINARY dir &quot;</span> $&#123;HELLO_BINARY_DIR&#125;)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">MESSAGE</span><span class=\"hljs-params\">(STATUS <span class=\"hljs-string\">&quot;This is SOURCE dir &quot;</span>$&#123;HELLO_SOURCE_DIR&#125;)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\"><span class=\"hljs-title\">ADD_EXECUTABLE</span><span class=\"hljs-params\">(hello $&#123;SRC_LIST&#125;)</span></span><br></code></pre></td></tr></table></figure>\n<p>3、使用cmake，生成makefile文件</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">cmake .<br><br>输出：<br>[root@localhost cmake]<span class=\"hljs-meta\"># cmake .</span><br><span class=\"hljs-function\">CMake <span class=\"hljs-title\">Warning</span> <span class=\"hljs-params\">(dev)</span> in CMakeLists.txt:</span><br><span class=\"hljs-function\">  Syntax Warning in cmake code at</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">    /root/cmake/CMakeLists.txt:<span class=\"hljs-number\">7</span>:<span class=\"hljs-number\">37</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">  Argument not separated from preceding token by whitespace.</span><br><span class=\"hljs-function\">This warning is for project developers.  Use -Wno-dev to suppress it.</span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">-- The C compiler identification is GNU <span class=\"hljs-number\">10.2</span><span class=\"hljs-number\">.1</span></span><br><span class=\"hljs-function\">-- The CXX compiler identification is GNU <span class=\"hljs-number\">10.2</span><span class=\"hljs-number\">.1</span></span><br><span class=\"hljs-function\">-- Check for working C compiler: /usr/bin/cc</span><br><span class=\"hljs-function\">-- Check for working C compiler: /usr/bin/cc -- works</span><br><span class=\"hljs-function\">-- Detecting C compiler ABI info</span><br><span class=\"hljs-function\">-- Detecting C compiler ABI info - done</span><br><span class=\"hljs-function\">-- Check for working CXX compiler: /usr/bin/c++</span><br><span class=\"hljs-function\">-- Check for working CXX compiler: /usr/bin/c++ -- works</span><br><span class=\"hljs-function\">-- Detecting CXX compiler ABI info</span><br><span class=\"hljs-function\">-- Detecting CXX compiler ABI info - done</span><br><span class=\"hljs-function\">-- This is BINARY dir /root/cmake</span><br><span class=\"hljs-function\">-- This is SOURCE dir /root/cmake</span><br><span class=\"hljs-function\">-- Configuring done</span><br><span class=\"hljs-function\">-- Generating done</span><br><span class=\"hljs-function\">-- Build files have been written to: /root/cmake</span><br></code></pre></td></tr></table></figure>\n<p>目录下就生成-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile.</p>\n<p>4、使用make命令编译</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">root@localhost cmake]<span class=\"hljs-meta\"># make</span><br>Scanning dependencies of target hello<br>[<span class=\"hljs-number\">100</span>%] Building CXX object CMakeFiles/hello.dir/main.cpp.o<br>Linking CXX executable hello<br>[<span class=\"hljs-number\">100</span>%] Built target hello<br></code></pre></td></tr></table></figure>\n<p>5、最终生成了Hello的可执行程序</p>\n<h1 id=\"CMake一个HelloWord-的语法介绍\"><a href=\"#CMake一个HelloWord-的语法介绍\" class=\"headerlink\" title=\"CMake一个HelloWord-的语法介绍\"></a>CMake一个HelloWord-的语法介绍</h1><h2 id=\"PROJECT关键字\"><a href=\"#PROJECT关键字\" class=\"headerlink\" title=\"PROJECT关键字\"></a>PROJECT关键字</h2><p>可以用来指定工程的名字和支持的语言，默认支持所有语言</p>\n<p>PROJECT (HELLO)   指定了工程的名字，并且支持所有语言—建议</p>\n<p>PROJECT (HELLO CXX)      指定了工程的名字，并且支持语言是C++</p>\n<p>PROJECT (HELLO C CXX)      指定了工程的名字，并且支持语言是C和C++</p>\n<p>该指定隐式定义了两个CMAKE的变量</p>\n<p><projectname>_BINARY_DIR，HELLO_BINARY_DIR</p>\n<p><projectname>_SOURCE_DIR，HELLO_SOURCE_DIR</p>\n<p>MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译</p>\n<p>问题：如果改了工程名，这两个变量名也会改变</p>\n<p>解决：再定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系</p>\n<h2 id=\"SET关键字\"><a href=\"#SET关键字\" class=\"headerlink\" title=\"SET关键字\"></a>SET关键字</h2><p>用来显示的指定变量的</p>\n<p>SET(SRC_LIST main.cpp)    SRC_LIST变量就包含了main.cpp</p>\n<p>也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp)</p>\n<h2 id=\"MESSAGE关键字\"><a href=\"#MESSAGE关键字\" class=\"headerlink\" title=\"MESSAGE关键字\"></a>MESSAGE关键字</h2><p>向终端输出用户自定义的信息</p>\n<p>主要包含三种信息：</p>\n<ul>\n<li>SEND_ERROR，产生错误，生成过程被跳过。</li>\n<li>SATUS，输出前缀为—的信息。</li>\n<li>FATAL_ERROR，立即终止所有 cmake 过程.</li>\n</ul>\n<h2 id=\"ADD-EXECUTABLE关键字\"><a href=\"#ADD-EXECUTABLE关键字\" class=\"headerlink\" title=\"ADD_EXECUTABLE关键字\"></a>ADD_EXECUTABLE关键字</h2><p>生成可执行文件</p>\n<p>ADD_EXECUTABLE(hello ${SRC_LIST})     生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容</p>\n<p>也可以直接写 ADD_EXECUTABLE(hello main.cpp)</p>\n<p>上述例子可以简化的写成</p>\n<p>PROJECT(HELLO)<br>ADD_EXECUTABLE(hello main.cpp)</p>\n<p>注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的</p>\n<h1 id=\"语法的基本原则\"><a href=\"#语法的基本原则\" class=\"headerlink\" title=\"语法的基本原则\"></a>语法的基本原则</h1><ul>\n<li><p>变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名</p>\n</li>\n<li><p>指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件</p>\n<p>就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp)</p>\n</li>\n<li><p>指令是大小写无关的，参数和变量是大小写相关的。推荐全部使用大写指令</p>\n</li>\n</ul>\n<h2 id=\"语法注意事项\"><a href=\"#语法注意事项\" class=\"headerlink\" title=\"语法注意事项\"></a>语法注意事项</h2><ul>\n<li>SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号</li>\n<li>ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main</li>\n</ul>\n<h1 id=\"内部构建和外部构建\"><a href=\"#内部构建和外部构建\" class=\"headerlink\" title=\"内部构建和外部构建\"></a>内部构建和外部构建</h1><ul>\n<li>上述例子就是内部构建，生产的临时文件特别多，不方便清理</li>\n<li>外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式</li>\n</ul>\n<h2 id=\"外部构建方式举例\"><a href=\"#外部构建方式举例\" class=\"headerlink\" title=\"外部构建方式举例\"></a>外部构建方式举例</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//例子目录，CMakeLists.txt和上面例子一致</span><br>[root@localhost cmake]<span class=\"hljs-meta\"># pwd</span><br>/root/cmake<br>[root@localhost cmake]<span class=\"hljs-meta\"># ll</span><br>total <span class=\"hljs-number\">8</span><br>-rw-r--r--. <span class=\"hljs-number\">1</span> root root <span class=\"hljs-number\">198</span> Dec <span class=\"hljs-number\">28</span> <span class=\"hljs-number\">20</span>:<span class=\"hljs-number\">59</span> CMakeLists.txt<br>-rw-r--r--. <span class=\"hljs-number\">1</span> root root  <span class=\"hljs-number\">76</span> Dec <span class=\"hljs-number\">28</span> <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">18</span> main.cpp<br></code></pre></td></tr></table></figure>\n<p>1、建立一个build目录，可以在任何地方，建议在当前目录下</p>\n<p>2、进入build，运行cmake ..    当然..表示上一级目录，可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了</p>\n<p>3、在build目录下，运行make来构建工程</p>\n<p>注意外部构建的两个变量</p>\n<p>1、HELLO_SOURCE_DIR  还是工程路径</p>\n<p>2、HELLO_BINARY_DIR   编译路径 也就是 /root/cmake/bulid</p>\n<h1 id=\"让Hello-World看起来更像一个工程\"><a href=\"#让Hello-World看起来更像一个工程\" class=\"headerlink\" title=\"让Hello World看起来更像一个工程\"></a>让Hello World看起来更像一个工程</h1><ul>\n<li>为工程添加一个子目录 src，用来放置工程源代码</li>\n<li>添加一个子目录 doc，用来放置这个工程的文档 hello.txt</li>\n<li>在工程目录添加文本文件 COPYRIGHT, README</li>\n<li>在工程目录添加一个 <a href=\"http://runhello.sh/\">runhello.sh</a> 脚本，用来调用 hello 二进制</li>\n<li>将构建后的目标文件放入构建目录的 bin 子目录</li>\n<li>将 doc 目录 的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/</li>\n</ul>\n<h2 id=\"将目标文件放入构建目录的-bin-子目录\"><a href=\"#将目标文件放入构建目录的-bin-子目录\" class=\"headerlink\" title=\"将目标文件放入构建目录的 bin 子目录\"></a>将目标文件放入构建目录的 bin 子目录</h2><p>每个目录下都要有一个CMakeLists.txt说明</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@localhost cmake]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br></code></pre></td></tr></table></figure>\n<p>外层CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">PROJECT</span>(HELLO)<br><span class=\"hljs-built_in\">ADD_SUBDIRECTORY</span>(src bin)<br></code></pre></td></tr></table></figure>\n<p>src下的CMakeLists.txt</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">ADD_EXECUTABLE</span>(hello main.cpp)<br></code></pre></td></tr></table></figure>\n<h3 id=\"ADD-SUBDIRECTORY-指令\"><a href=\"#ADD-SUBDIRECTORY-指令\" class=\"headerlink\" title=\"ADD_SUBDIRECTORY 指令\"></a>ADD_SUBDIRECTORY 指令</h3><p>ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL])</p>\n<ul>\n<li><p>这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置</p>\n</li>\n<li><p>EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example</p>\n</li>\n<li><p>ADD_SUBDIRECTORY(src bin)</p>\n<p>将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录</p>\n<p>如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录</p>\n</li>\n</ul>\n<h3 id=\"更改二进制的保存路径\"><a href=\"#更改二进制的保存路径\" class=\"headerlink\" title=\"更改二进制的保存路径\"></a>更改二进制的保存路径</h3><p>SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置</p>\n<p>SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)<br>SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)</p>\n<p>思考：加载哪个CMakeLists.txt当中</p>\n<p>哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><ul>\n<li>一种是从代码编译后直接 make install 安装</li>\n<li>一种是打包时的指定 目录安装。<ul>\n<li>简单的可以这样指定目录：make install DESTDIR=/tmp/test</li>\n<li>稍微复杂一点可以这样指定目录：./configure –prefix=/usr</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"如何安装HelloWord\"><a href=\"#如何安装HelloWord\" class=\"headerlink\" title=\"如何安装HelloWord\"></a>如何安装HelloWord</h2><p>使用CMAKE一个新的指令：INSTALL</p>\n<p>INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等</p>\n<p>使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 目录树结构</span><br>[root@localhost cmake]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>├── COPYRIGHT<br>├── doc<br>│   └── hello.txt<br>├── README<br>├── runhello.sh<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br><br><span class=\"hljs-number\">3</span> directories, <span class=\"hljs-number\">7</span> files<br></code></pre></td></tr></table></figure>\n<h3 id=\"安装文件COPYRIGHT和README\"><a href=\"#安装文件COPYRIGHT和README\" class=\"headerlink\" title=\"安装文件COPYRIGHT和README\"></a>安装文件COPYRIGHT和README</h3><p>INSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/)</p>\n<p>FILES：文件</p>\n<p>DESTINATION：</p>\n<p>1、写绝对路径</p>\n<p>2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/<DESTINATION 定义的路径></p>\n<p>CMAKE_INSTALL_PREFIX  默认是在 /usr/local/</p>\n<p>cmake -DCMAKE_INSTALL_PREFIX=/usr    在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径</p>\n<h3 id=\"安装脚本runhello-sh\"><a href=\"#安装脚本runhello-sh\" class=\"headerlink\" title=\"安装脚本runhello.sh\"></a>安装脚本runhello.sh</h3><p>PROGRAMS：非目标文件的可执行程序安装(比如脚本之类)</p>\n<p>INSTALL(PROGRAMS runhello.sh DESTINATION bin)</p>\n<p>说明：实际安装到的是 /usr/bin</p>\n<h3 id=\"安装-doc-中的-hello-txt\"><a href=\"#安装-doc-中的-hello-txt\" class=\"headerlink\" title=\"安装 doc 中的 hello.txt\"></a>安装 doc 中的 hello.txt</h3><ul>\n<li><p>一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file</p>\n</li>\n<li><p>二、是直接在工程目录通过</p>\n<p>INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake)</p>\n</li>\n</ul>\n<p>DIRECTORY 后面连接的是所在 Source 目录的相对路径</p>\n<p>注意：abc 和 abc/有很大的区别</p>\n<p>目录名不以/结尾：这个目录将被安装为目标路径下的</p>\n<p>目录名以/结尾：将这个目录中的内容安装到目标路径</p>\n<h3 id=\"安装过程\"><a href=\"#安装过程\" class=\"headerlink\" title=\"安装过程\"></a>安装过程</h3><p>cmake ..</p>\n<p>make</p>\n<p>make install</p>\n<h1 id=\"静态库和动态库的构建\"><a href=\"#静态库和动态库的构建\" class=\"headerlink\" title=\"静态库和动态库的构建\"></a>静态库和动态库的构建</h1><p>任务：</p>\n<p>１，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 </p>\n<p>２，安装头文件与共享库。</p>\n<p>静态库和动态库的区别</p>\n<ul>\n<li>静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。</li>\n<li>静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行</li>\n<li>动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。</li>\n</ul>\n<h2 id=\"构建实例\"><a href=\"#构建实例\" class=\"headerlink\" title=\"构建实例\"></a>构建实例</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@localhost cmake2]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── lib<br>    ├── CMakeLists.txt<br>    ├── hello.cpp<br>    └── hello.h<br></code></pre></td></tr></table></figure>\n<p>hello.h中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">ifndef</span> HELLO_H</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> Hello_H</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HelloFunc</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">endif</span></span><br></code></pre></td></tr></table></figure>\n<p>hello.cpp中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&quot;hello.h&quot;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">HelloFunc</span><span class=\"hljs-params\">()</span></span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Hello World&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>项目中的cmake内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">PROJECT</span>(HELLO)<br><span class=\"hljs-built_in\">ADD_SUBDIRECTORY</span>(lib bin)<br></code></pre></td></tr></table></figure>\n<p>lib中CMakeLists.txt中的内容</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">SET</span>(LIBHELLO_SRC hello.cpp)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br></code></pre></td></tr></table></figure>\n<h3 id=\"ADD-LIBRARY\"><a href=\"#ADD-LIBRARY\" class=\"headerlink\" title=\"ADD_LIBRARY\"></a>ADD_LIBRARY</h3><p>ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})</p>\n<ul>\n<li>hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so</li>\n<li>SHARED，动态库    STATIC，静态库</li>\n<li>${LIBHELLO_SRC} ：源文件</li>\n</ul>\n<h3 id=\"同时构建静态和动态库\"><a href=\"#同时构建静态和动态库\" class=\"headerlink\" title=\"同时构建静态和动态库\"></a>同时构建静态和动态库</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a</span><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello STATIC $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-comment\">// 修改静态库的名字，但是往往希望他们的名字是相同的，只是后缀不同</span><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)<br></code></pre></td></tr></table></figure>\n<h3 id=\"SET-TARGET-PROPERTIES\"><a href=\"#SET-TARGET-PROPERTIES\" class=\"headerlink\" title=\"SET_TARGET_PROPERTIES\"></a>SET_TARGET_PROPERTIES</h3><p>这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本</p>\n<p>同时构建静态和动态库</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">SET</span>(LIBHELLO_SRC hello.cpp)<br><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-comment\">//对hello_static的重名为hello</span><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello_static PROPERTIES  OUTPUT_NAME <span class=\"hljs-string\">&quot;hello&quot;</span>)<br><span class=\"hljs-comment\">//cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a</span><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT <span class=\"hljs-number\">1</span>)<br><br><span class=\"hljs-built_in\">ADD_LIBRARY</span>(hello SHARED $&#123;LIBHELLO_SRC&#125;)<br><br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello PROPERTIES  OUTPUT_NAME <span class=\"hljs-string\">&quot;hello&quot;</span>)<br><span class=\"hljs-built_in\">SET_TARGET_PROPERTIES</span>(hello PROPERTIES CLEAN_DIRECT_OUTPUT <span class=\"hljs-number\">1</span>)<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"动态库的版本号\"><a href=\"#动态库的版本号\" class=\"headerlink\" title=\"动态库的版本号\"></a>动态库的版本号</h3><p>一般动态库都有一个版本号的关联</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">libhello.so<span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.2</span><br>libhello.so -&gt;libhello.so<span class=\"hljs-number\">.1</span><br>libhello.so<span class=\"hljs-number\">.1</span>-&gt;libhello.so<span class=\"hljs-number\">.1</span><span class=\"hljs-number\">.2</span><br></code></pre></td></tr></table></figure>\n<p>CMakeLists.txt 插入如下</p>\n<p><code>SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)</code></p>\n<p>VERSION 指代动态库版本，SOVERSION 指代 API 版本。</p>\n<h3 id=\"安装共享库和头文件\"><a href=\"#安装共享库和头文件\" class=\"headerlink\" title=\"安装共享库和头文件\"></a>安装共享库和头文件</h3><p>本例中将 hello 的共享库安装到<prefix>/lib目录，</p>\n<p>将 hello.h 安装到<prefix>/include/hello 目录</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//文件放到该目录下</span><br><span class=\"hljs-built_in\">INSTALL</span>(FILES hello.h DESTINATION include/hello)<br><br><span class=\"hljs-comment\">//二进制，静态库，动态库安装都用TARGETS</span><br><span class=\"hljs-comment\">//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。</span><br><span class=\"hljs-built_in\">INSTALL</span>(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib)<br></code></pre></td></tr></table></figure>\n<p>注意：</p>\n<p>安装的时候，指定一下路径，放到系统下</p>\n<p><code>cmake -DCMAKE_INSTALL_PREFIX=/usr ..</code></p>\n<h3 id=\"使用外部共享库和头文件\"><a href=\"#使用外部共享库和头文件\" class=\"headerlink\" title=\"使用外部共享库和头文件\"></a>使用外部共享库和头文件</h3><p>准备工作，新建一个目录来使用外部共享库和头文件</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@MiWiFi-R4CM-srv cmake3]<span class=\"hljs-meta\"># tree</span><br>.<br>├── build<br>├── CMakeLists.txt<br>└── src<br>    ├── CMakeLists.txt<br>    └── main.cpp<br></code></pre></td></tr></table></figure>\n<p>main.cpp</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;hello.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>\t<span class=\"hljs-built_in\">HelloFunc</span>();<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"解决：make后头文件找不到的问题\"><a href=\"#解决：make后头文件找不到的问题\" class=\"headerlink\" title=\"解决：make后头文件找不到的问题\"></a>解决：make后头文件找不到的问题</h3><p>PS：include <hello/hello.h>  这样include是可以，这么做的话，就没啥好讲的了</p>\n<p>关键字：INCLUDE_DIRECTORIES    这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割</p>\n<p>在CMakeLists.txt中加入头文件搜索路径</p>\n<p>INCLUDE_DIRECTORIES(/usr/include/hello)</p>\n<h3 id=\"解决：找到引用的函数问题\"><a href=\"#解决：找到引用的函数问题\" class=\"headerlink\" title=\"解决：找到引用的函数问题\"></a>解决：找到引用的函数问题</h3><p>报错信息：undefined reference to `HelloFunc()’</p>\n<p>关键字：LINK_DIRECTORIES     添加非标准的共享库搜索路径</p>\n<p>指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs)</p>\n<p>关键字：TARGET_LINK_LIBRARIES    添加需要链接的共享库</p>\n<p>TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字。</p>\n<p>在CMakeLists.txt中插入链接共享库，主要要插在executable的后面</p>\n<p>查看main的链接情况</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\">[root@MiWiFi-R4CM-srv bin]<span class=\"hljs-meta\"># ldd main </span><br>\tlinux-vdso.so<span class=\"hljs-number\">.1</span> =&gt;  (<span class=\"hljs-number\">0x00007ffedfda4000</span>)<br>\tlibhello.so =&gt; /lib64/libhello.<span class=\"hljs-built_in\">so</span> (<span class=\"hljs-number\">0x00007f41c0d8f000</span>)<br>\tlibstdc++.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libstdc++.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41c0874000</span>)<br>\tlibm.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libm.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41c0572000</span>)<br>\tlibgcc_s.so<span class=\"hljs-number\">.1</span> =&gt; /lib64/libgcc_s.so<span class=\"hljs-number\">.1</span> (<span class=\"hljs-number\">0x00007f41c035c000</span>)<br>\tlibc.so<span class=\"hljs-number\">.6</span> =&gt; /lib64/libc.so<span class=\"hljs-number\">.6</span> (<span class=\"hljs-number\">0x00007f41bff8e000</span>)<br>\t/lib64/ld-linux-x86<span class=\"hljs-number\">-64.</span>so<span class=\"hljs-number\">.2</span> (<span class=\"hljs-number\">0x00007f41c0b7c000</span>)<br></code></pre></td></tr></table></figure>\n<p>链接静态库</p>\n<p><code>TARGET_LINK_LIBRARIES(main libhello.a)</code></p>\n<h3 id=\"特殊的环境变量-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH\"><a href=\"#特殊的环境变量-CMAKE-INCLUDE-PATH-和-CMAKE-LIBRARY-PATH\" class=\"headerlink\" title=\"特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH\"></a>特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH</h3><p>注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置</p>\n<p>我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置</p>\n<p>还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello</p>\n<p>补充：生产debug版本的方法：<br>cmake .. -DCMAKE_BUILD_TYPE=debug</p>\n"},{"title":"数据库-MySQL","date":"2024-02-10T08:00:39.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"## 数据库-Mysql\n\n> Mysql数据库的关键词：事务、存储引擎、索引、SQL优化、**锁、日志、主从复制、读写分离、分库分表**\n\n## 数据库基础\n\n### 1、Mysql概述\n\n关系型数据库：建立在关系模型基础上，由多张互连接的二维表组成的数据库\n\n特点：使用表存储数据，便于维护；使用sql语句操作，使用方便\n\n**MySQL数据模型**\n\n> 1、客户端通过与数据库管理系统进行连接\n>\n> 2、使用sql语句通过数据库管理系统对指定的数据库进行增删改查\n>\n> 3、一个数据库模型中可以对多个数据库进行管理，一个数据库中可以拥有多个表\n\n// TODO数据库模型的图\n\n### 2、SQL\n\n**SQL分类**\n\n| 分类 | 全称                       | 说明                                                 |\n| ---- | -------------------------- | ---------------------------------------------------- |\n| DDL  | Data Definition Language   | 数据库定义语句，定义数据库对象，数据库，表，字段等   |\n| DML  | Data Manipulation Language | 数据库操作语句，用于对数据库表中的数据进行增增删改   |\n| DQL  | Data Query Language        | 数据库查询语句，查询数据库表中的记录                 |\n| DCL  | Data Control Language      | 数据库控制语句，创建数据库用户，控制数据库的访问权限 |\n\n* #### DDL\n\n  **数据库层次**\n\n```mysql\n# 查询所有数据库表格\nSHOW DATABASES;\n# 查询当前所在的数据库\nSELECT DATABASE();\n# 创建数据库，方括号可以省略\nCREATE DATABASE [IF NOT EXISTS] 数据库名 [COLLATE 排序规则]\n# 删除数据库\nDROP DATABASE [IF EXISTS] 数据库名\n# 使用数据库，切换到数据库当中\nUSE 数据库名\n```\n\n​\t\t表结构\n\n```mysql\n# 查看所有表\nSHOW TABLES;\n# 查询表结构\nDESC 表名\n# 查询指定表的建表语句\nSHOW CREATE TABLE 表名;\n```\n\n​\t\tMySQL中的数据类型\n\n| 数据类型       | 描述                                   | 大小                                 |\n| -------------- | -------------------------------------- | ------------------------------------ |\n| TINYINT        | 微小整数，有符号或无符号（UNSIGNED）   | 1 字节                               |\n| SMALLINT       | 小整数，有符号或无符号                 | 2 字节                               |\n| MEDIUMINT      | 中等整数，有符号或无符号               | 3 字节                               |\n| INT 或 INTEGER | 整数，有符号或无符号                   | 4 字节                               |\n| BIGINT         | 大整数，有符号或无符号                 | 8 字节                               |\n| FLOAT(M,D)     | 单精度浮点数，M 是总位数，D 是小数位数 | 4 字节                               |\n| DOUBLE(M,D)    | 双精度浮点数，M 是总位数，D 是小数位数 | 8 字节                               |\n| DECIMAL(M,D)   | 定点数，M 是总位数，D 是小数位数       | 取决于 M 和 D                        |\n| DATE           | 日期 YYYY-MM-DD                        | 3 字节                               |\n| TIME           | 时间 HH:MM:SS                          | 3 字节                               |\n| DATETIME       | 日期和时间                             | 8 字节                               |\n| TIMESTAMP      | 时间戳                                 | 4 字节                               |\n| CHAR(N)        | **定长**字符串，最大长度为 N           | 最大 255 字节                        |\n| VARCHAR(N)     | **变长**字符串，最大长度为 N           | 最大 65,535 字节                     |\n| TEXT           | 变长文本，最大长度为 65,535 字节       | 最大 65,535 字节                     |\n| BLOB           | 二进制大对象，最大长度为 65,535 字节   | 最大 65,535 字节                     |\n| ENUM           | 枚举类型                               | 1 或 2 字节，取决于成员数量          |\n| SET            | 集合类型                               | 1、2、3、4 或 8 字节，取决于成员数量 |\n\n创建表：\n\n```mysql\nCREATE TABLE member(\n    number INT COMMENT '编号',\n    id CHAR(10) COMMENT '员工工号',\n    name VARCHAR(10) COMMENT '员工姓名',\n    gender CHAR(4) COMMENT '员工性别',\n    age INT UNSIGNED COMMENT '年龄',\n    id_number CHAR(18) COMMENT '身份证号',\n    time DATE COMMENT '入职时间'\n)\n```\n\n**表结构的修改**\n\n```mysql\n# 添加字段\nALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释][约束];\n\n# 修改字段和字段类型\nALTER TABLE 表明 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释][约束]\n\n# 删除字段\nALTER TABLE 表名 DROP 字段名;\n\n# 修改表名\nALTER TABLE 表名 RENAME TO 新表名;\n\n# 删除表\nDROP TABLE [IF EXSITS] 表名;\n# 删除指定表并重新创建该表，清空数据\nTRUNCATE TABLE 表名;\n```\n\n* #### DML（数据操作语言）\n\n**添加数据**\n\n```mysql\n# 给指定字段添加数据\nINSERT INTO 表名(字段名1, 字段名2, ...) VALUES (值1, 值2, ...);\n\n# 给全部字段添加数据\nINSERT INTO 表名 VALUES(值1, 值2, ...);\n```\n\n**修改数据**\n\n```mysql\n# 修改数据\nUPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ...[WHERE 条件];\n```\n\n**删除数据**\n\n```mysql\n# 删除数据\nDELETE FROM 表名 [WHERE 条件];\n```\n\n* #### DQL\n\n  > 数据库查询语言，用来查询数据库中的表的记录\n  >\n  > SELECT后面加上\\G可以将某一行转化为一列查看\n\n**语法结构**\n\n```mysql\nSELECT\n\t字段列表\nFROM\n\t表名列表\nWHERE\n\t条件列表(条件查询)\nGROUP BY\n\t分组字段列表(分组查询)\nHAVING\n\t分组后条件列表\nORDER BY\n\t排序字段列表\nLIMIT\n\t分页参数\n```\n\n**基本查询**\n\n```mysql\nSELECT 字段1 [AS 别名]，字段2 [AS 别名]， FROM 表名;\n\n# 去重\nSELECT DISTINCT 字段列表 FROM 表名;\n```\n\n**条件查询**\n\n条件运算符\n\n|     比较运算符      |                   功能                   |\n| :-----------------: | :--------------------------------------: |\n|       <>或!=        |                  不等于                  |\n| BETWEEN ... AND ... |              在某个范围之内              |\n|       IN(...)       |       在in之后的列表中的值，多选一       |\n|     LIKE 占位符     | 模糊匹配(_匹配单个字符，%匹配任意个字符) |\n|       IS NULL       |                  是NULL                  |\n\n**聚和函数**\n\n> 将一列数据作为一个整体，进行纵向计算。\n\n所有的null值不参与聚合函数的计算\n\n| 函数  |   功能   |\n| :---: | :------: |\n| count | 统计数量 |\n|  max  |  最大值  |\n|  min  |  最小值  |\n|  avg  |  平均值  |\n|  sum  |   求和   |\n\n```mysql\nSELECT 聚合函数(字段列表) FROM 表名;\n```\n\n**分组查询**\n\n> 在where中不可以使用聚合函数，在having中可以使用聚合函数\n>\n> 分组之前过滤用where，分组之后过滤条件用having\n\n```mysql\nSELECT 字段列表\tFROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];\n```\n\n执行顺序：where > 聚合函数 > having\n\n**排序查询**\n\n```mysql\nSELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2\n```\n\n排序方式： ASC升序（默认），DESC降序\n\n**分页查询**\n\n```mysql\nSELECT 字段列表 FROM 表名 LIMIT 起始索引,查询记录数;\n```\n\n显示从起始索引开始的记录数条的查询结果\n\n**DQL执行顺序**\n\nFROM > WHERE > GROUP BY > SELECT > ORDER BY > LIMIT\n\n* #### DCL\n\n> 数据控制语句，用来管理数据库用户，控制数据库访问权限\n\n**DCL用户管理**\n\n```mysql\n# 查询用户\nUSE mysql;\nSELECT * FROM user;\n\n# 创建用户，主机名换成\"%\"表示可以在任意主机访问数据库\nCREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';\n\n# 修改用户密码\nALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码'\n\n# 删除用户\nDROP USER '用户名'@'主机名';\n```\n\n**权限控制**\n\n常用权限\n\n|        权限         |        说明        |\n| :-----------------: | :----------------: |\n| ALL, ALL PRIVILEGES |      所有权限      |\n|       SELECT        |      查询数据      |\n|       INSERT        |      插入数据      |\n|       UPDATE        |      修改数据      |\n|       DELETE        |      删除数据      |\n|        ALTER        |       修改表       |\n|        DROP         | 删除数据库/表/视图 |\n|       CREATE        |   创建数据库/表    |\n\n```mysql\n# 查询权限\nSHOW GRANTS FOR '用户名'@'主机名';\n\n# 授予权限\nGRANT 权限列表 ON 数据库名.表名(*.*所有表) TO '用户名'@'主机名';\n\n# 撤销权限\nREVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名';\n```\n\n### 3、函数\n\n* **字符串函数**\n\n|            函数            |                           功能                            |\n| :------------------------: | :-------------------------------------------------------: |\n|   CONCAT(S1,S2, ... Sn)    |            字符串拼接，将S1-Sn拼接成一个字符串            |\n|         LOWER(str)         |                  将字符串str全部转为小写                  |\n|         UPPER(str)         |                   将字符串全部转为大写                    |\n|     LPAD(str, n, pad)      | 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 |\n|     RPAD(str, n,  pad)     |                          右填充                           |\n|         TRIM(str)          |                去掉字符串头部和尾部的空格                 |\n| SUBSTRING(str, start, len) |         返回从字符串str从start起的len长度的字符串         |\n\n```mysql\nSELECT 函数;\n```\n\n* **数值函数**\n\n|    函数     |                功能                |\n| :---------: | :--------------------------------: |\n|   CEIL(x)   |              向上取整              |\n|  FLOOR(x)   |              向下取整              |\n|  MOD(x, y)  |            返回x/y的模             |\n|   RAND()    |         返回0~1内的随机数          |\n| ROUND(x, y) | 求参数x的四舍五入的值，保留y位小数 |\n\n* **日期函数**\n\n|                函数                |                             功能                             |\n| :--------------------------------: | :----------------------------------------------------------: |\n|             CURDATE()              |                         返回当前日期                         |\n|             CURTIME()              |                         返回当前时间                         |\n|               NOW()                |                      返回当前日期和时间                      |\n|             YEAR(date)             |                      获取指定date的年份                      |\n|            MONTH(date)             |                      获取指定date的月份                      |\n|             DAY(date)              |                      获取指定date的日期                      |\n| DATE_ADD(date, INTERVAL expr type) | 返回上一个日期加上时间间隔expr以后的时间值，type(year,month,day)指定年月天 |\n|       DATEDIFF(date1, date2)       | 返回起始时间date1和结束时间date2之间的天数，第一个时间减去第二个时间 |\n\n* **流程函数**\n\n|                            函数                            |                           功能                           |\n| :--------------------------------------------------------: | :------------------------------------------------------: |\n|                      IF(value, t. f)                       |            如果value为true，返回t，否则返回f             |\n|                   IFNULL(value1, value2)                   |       如果value1不为空，返回value1，否则返回value2       |\n|    CASE WHEN [val] THEN [res1] ... ELSE [ default ] END    |    如果val1为true，返回res1，...否则返回default默认值    |\n| CASE [expr] WHEN [val1] THEN [res1] ... ELSE [default] END | 如果expr的值等于val1，返回res1，...否则返回default默认值 |\n\n### 4、约束\n\n作用于表中字段上的规则，用于限制存储在表中的数据\n\n|   约束   | 描述 | 关键字 |\n| :------: | :--: | :----: |\n| 非空约束 |      |        |\n| 唯一约束 |      |        |\n| 主键约束 |      |        |\n| 默认约束 |      |        |\n| 检查约束 |      |        |\n| 外键约束 |      |        |\n\n\n\n### 5、多表查询\n\n* **多表关系**\n\n  一对多：在多的一方建立外键，指向一的一方的主键\n\n​\t\t多对多：建立第三张中间表，中间表至少包含两个外键，分别关联两方的主键\n\n​\t\t一对一：用于做单表拆分，基础字段放在一张表，详情字段放在另一张表。在任意一方加入外键，关联另一方的主键，并设置外键为唯一（UNIQUE）\n\n* **多表查询**\n\n  * 内连接\n\n    > 相当于查询A、B交集部分数据\n\n  ```mysql\n  # 隐式内连接\n  SELECT 字段列表 FROM 表1，表2 WHERE 条件...;\n  \n  # 显示内连接\n  SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;\n  ```\n\n  * 外连接\n\n    > 左外连接：查询左表所有数据，以及两张表交集部分数据，将左表的数据和右表的部分数据连接起来\n    >\n    > 右外连接：查询右表所有数据，以及两张表交集部分数据\n\n  ```mysql\n  # 左外连接，表1所有数据以及和表2交集部分的数据\n  SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件;\n  \n  # 右外连接，表2所有数据以及和表1交集部分的数据\n  SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件;\n  ```\n\n  * 自连接\n\n    > 自连接：当前表与自身的连接查询，自连接必须使用表别名\n\n  * 联合查询-union，union all\n\n  ```mysql\n  # 把多次查询的结果合并起来，形成一个新的查询结果集\n  # ALL去掉以后会对结果进行去重\n  SELECT 字段列表 表A\n  UNION [ALL]\n  SELECT 字段列表 表B;\n  ```\n\n* **子查询**\n\n  * 标量子查询，子查询返回一个标量\n\n  * 列子查询，子查询返回一列\n\n    | 操作符 |                 描述                 |\n    | :----: | :----------------------------------: |\n    |   IN   |     在指定的集合范围之内，多选一     |\n    | NOT IN |          不在指定的范围之内          |\n    |  ANY   | 子查询返回列表中，有任意一个满足即可 |\n    |  SOME  |              与ANY等同               |\n    |  ALL   |   子查询返回列表的所有值都必须满足   |\n\n  * 行子查询，子查询返回的结果是一行\n\n    此时column1可以使用(column1， column2)聚合成多个参数\n\n    操作符：=、<>、IN、NOT IN\n\n  * 表子查询，子查询的返回结果是一个表，可以和行子查询加上列子查询的操作符使用，表可以放到from后面\n\n```mysql\n# 对于子查询，可以将问题拆解成多个不同的查询步骤\nSELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);\n```\n\n### 6、事务\n\n> 一组操作的集合，是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，这些操作要么**同时成功，要么同时失败**\n>\n> 默认Mysql的事务是自动提交的，当执行一条DML语句，Mysql会立即隐式的提交事务\n\n* **事务操作**\n\n```mysql\n# 查看/设置事务提交方式\nSELECT @@autocommit;\n# 事务设置为手动提交\nSET @@autocommit = 0;\n\n# 提交事务\nCOMMIT;\n\n# 回滚事务\nROLLBACK;\n```\n\n```mysql\n# 不修改事务的提交方式操作事务\n# 开启事务\nSTART TRANSACTION 或 BEGIN;\n\n# 提交事务\nCOMMIT;\n\n# 回滚事务\nROLLBACK;\n```\n\n* **事务四大特性**\n\n  * 原子性(Atomicity)：事务时不可分割的最小操作单元，要么全部成功，要么全部失败\n  * 一致性(Consistency)：事务完成时，必须使所有的数据都保持一致状态\n  * 隔离性(Isolation)：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行\n  * 持久性(Durability)：事务一旦提交或者回滚，它对数据库中的数据改变就是永久的\n\n* **并发事务问题**\n\n|    问题    |                             描述                             |\n| :--------: | :----------------------------------------------------------: |\n|    脏读    |            一个事务读到另一个事务还没有提交的数据            |\n| 不可重复读 | 一个事务先后读取同一条记录，但两次读取的数据不同，称为不可重复读 |\n|    幻读    | 一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这一行数据已经存在 |\n\n* **事务隔离级别**\n\n  > 读未提交、读已提交、可重复读、串行化\n  >\n  > √表示会出现这个问题，×表示不会出现这个问题\n\n|     隔离级别     | 脏读 | 不可重复读 | 幻读 |\n| :--------------: | :--: | :--------: | :--: |\n| Read uncommitted |  √   |     √      |  √   |\n|  Read committed  |  ×   |     √      |  √   |\n| Repeatable Read  |  ×   |     ×      |  √   |\n|   Serializable   |  ×   |     ×      |  ×   |\n\n  ```mysql\n  # 查看事务的隔离级别\n  SELECT @@TRANSACTION_ISOLATION;\n  \n  # 设置事务隔离级别\n  SET [SESSION(只对当前窗口有效)|GLOBAL] TRANSACTION ISOLATION LEVEL {隔离级别}\n  ```\n\n  事务的隔离界别越高，数据越安全，但是性能越低\n\n## 数据库进阶\n\n### 1、存储引擎\n\n* Mysql体系结构 \n\n  连接层：完成一些类似于连接处理、授权认证及相关的安全方案\n\n  服务层：主要完成大多数的核心服务功能\n\n  引擎层：负责mysql中数据的存储和提取，服务器通过API和存储引擎进行通信\n\n  存储层：将数据存储在文件系统之上，并完成与存储引擎的交互\n\n  ![Mysql](database-mysql/Mysql.png)\n\n* 存储引擎\n\n  > 存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎时基于表的，而不是基于库的。一个数据库的不同的表可以选择不同的存储引擎\n  >\n  > Mysql默认InnoDB\n\n```mysql\n# 查询支持的存储引擎\nshow engines;\n```\n\n* InnoDB\n\n  * DML操作遵循ACID模型，支持事务\n  * 行级锁，提高并发访问性能\n  * 支持外键，保证事务的完整性和正确性\n\n  文件：每个表对应一个.ibd文件，代表表空间文件，可以通过命令`idb2sdi 文件名`查看表结构json文件格式\n\n  ![image-20240216162915509](database-mysql/image-20240216162915509.png)\n\n* MyISAM\n\n  * 不支持事务，不支持外键\n  * 支持表锁、不支持行锁\n  * 访问速度快\n\n  文件.MYD（数据），.MYI（索引），.sdi（表结构）\n\n* Memory\n\n  * 表数据存储在内存当中，收到硬件问题或断电影响只能作为临时表或者缓存使用\n  * 内存存放\n  * hash索引（默认）\n\n![image-20240216163439353](database-mysql/image-20240216163439353.png)\n\n* 存储引擎选择\n\n  InnoDB：如果对事务的完整性有比较高的要求，在并发情况下要求事务的一致性，数据操作除了插入和查询意外，还包括很多的更新、删除操作，InnoDB引擎比较合适\n\n  MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性和并发现要求不是很高。**这个场景被Nosql数据库MongoDB替代了**\n\n  MEMORY：将所有数据保存在内存当中，访问速度快，通常用于临时表以及缓存。MEMORY对表的大小有限制，太大的表无法缓存在内存中。**这个场景被Redis替代了**\n\n### 2、索引\n\n* **索引概述**\n  * 索引的结构\n\n* #### **索引分类**\n\n|   分类   |                含义                |           特点           |  关键字  |\n| :------: | :--------------------------------: | :----------------------: | :------: |\n| 主键索引 |      针对于表中主键创建的索引      | 默认自动创建，只能有一个 | PRIMARY  |\n| 唯一索引 |  避免同一个表中某数据列中的值重复  |        可以有多个        |  UNIQUE  |\n| 常规索引 |          快速定位特定数据          |        可以有多个        |          |\n| 全文索引 | 全文索引查找的是文本中通过的关键词 |        可以有多个        | FULLTEXT |\n\n按照索引的存储形式分类\n\n|   分类   |                            含义                            |         特点         |\n| :------: | :--------------------------------------------------------: | :------------------: |\n| 聚集索引 |                 将数据存储与索引放到了一块                 | 必须有，而且只有一个 |\n| 二级索引 | 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 |     可以存在多个     |\n\n![image-20240218203730285](database-mysql/image-20240218203730285.png)\n\n\n\n* #### **索引语法**\n\n```mysql\n# 创建索引\n# 一个索引可以关联多行，如果关联多行称为联合索引\nCREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name (index_col_name, )\n\n# 查看索引\nSHOW INDEX FROM table_name;\n\n# 删除索引\nDROP INDEX index_name ON table_name;\n```\n\n* #### **SQL性能分析**\n\n  > 使用于select的优化\n\n```mysql\n# SQL执行频率，查看当前数据库语句的访问频率\nSHOW [session|global] STATUS\n# Com七个下划线，模糊匹配\nSHOW GLOBAL STATUS LIKE 'Com_______'\n```\n\n**SQL语句的频率**\n\n![image-20240218204502697](database-mysql/image-20240218204502697.png)\n\n**慢查询日志**\n\n> 慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位：秒，默认10)的所有SQL语句的日志\n\n```mysql\n# 查看是否开启，日志文件默认在/var/lib/mysql里面\nSHOW VARIABLES LIKE 'slow_query_log';\n\n# 修改/etc/my.cnf中配置开启，配置时间\nslow_query_log=1   \nlong_query_time=2\n```\n\n**profile详情**\n\n```mysql\n# 查看是否支持prifile\nSELECT @@have_profiling;\n\n# 设置为开\nSET profiling=1;\n\n# 查看profile\nSHOW PROFILES;\n```\n\n执行完SQL语句以后，通过以下指令查看执行耗时情况\n\n```mysql\n# 查看每一条SQL耗时基本情况\nSHOW PROFILES;\n\n# 查看指定query_id的SQL语句各个阶段的耗时情况\nSHOW PROFILE FOR QUERY query_id;\n\n# 查看指定SQL语句的CPU使用情况\nSHOW PROFILE CPU FOR QUERY query_id;\n```\n\n**explain执行计划**\n\n> EXPLAIN或者DESC命令获取Mysql如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接的顺序\n\n```mysql\nEXPLAIN SELECT SQL语句;\n```\n\n![image-20240218211138993](database-mysql/image-20240218211138993.png)\n\n表头的含义：\n\n![image-20240218212814126](database-mysql/image-20240218212814126.png)\n\n![image-20240218212115878](database-mysql/image-20240218212115878.png)\n\n```txt\ntype\nconst\t以主键或以唯一的列作为索引扫描\nref\t\t非唯一的值作为查询索引\nindex\t用了索引，但是会对整个索引进行遍历\nall\t\t全表扫描\n```\n\n* #### **索引使用**\n\n**联合索引**\n\n使用要遵循**最左前缀法则**：查询**从索引的最左列开始**，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。\n\n**范围查询**：联合索引中出现范围查询（>,<)，范围查询右侧的列索引失效。但是使用大于等于和小于等于索引并不会失效。\n\n例子\n\n```mysql\n# student有联合索引(id,name,age)\n# 1、索引都可以使用\nselect * from student where id = 1 and name = \"Lili\" and age = 20;\n\n# 2、索引name，age失效\nselect * from student where id = 1 and age = 20;\n\n# 范围查询\n# name和age索引均失效\nselect * from student where id > 1 and name = \"Lili\" and age = 20;\n```\n\n**索引失效**\n\n索引列操作：不要在索引上进行列操作，否则索引会失效\n\n字符串类型：不加单引号索引会失效\n\n模糊查询：**头部进行模糊匹配(%%某某)**，索引会失效，尾部进行模糊匹配（某某%%），索引不会失效。\n\nor连接的条件：如果or前面的条件列有索引，后面的条件没有索引，所涉及的索引都不会引用到，只有两侧都有索引的时候，才有效\n\n数据分布影响：如果索引比全表扫描更慢，则不使用索引，查询的数据大于一半，走全表不走索引。\n\n**SQL提示**\n\n> 在sql语句中加入一些认为的提示来达到优化操作的目的\n\n```mysql\n# use index指定使用哪个索引\nexplain select * from table use index(idxname) ...\n\n# ignore index\n# force index 同上\n```\n\n**覆盖索引**\n\n尽量使用覆盖索引：查询使用了索引，并且需要返回的列，在该索引中已经能够全部找到，减少使用select *\n\nusing index condition：查找使用了索引，但是需要回表查询数据\n\nusing where, using index：查询使用了索引，但是不需要回表\n\n![image-20240218221642388](database-mysql/image-20240218221642388.png)\n\n前两条不需要回表，后一条需要回表\n\n**前缀索引**\n\n> 将字符串的前缀提取出来，创建索引，可以节约索引空间\n\n```mysql\n# n表示取column_name列的前n个数据\nCREATE INDEX idx_XXX ON table_name(column_name(n));\n\n# 计算前缀长度的选择性，越接近1越好\nSELECT COUNT(DISTINCT substring(email, 1, 5)) / COUNT(*) FROM table_name;\n```\n\n**单列索引和联合索引选择**\n\n如果涉及到多个查询条件，推荐使用联合索引，联合索引会更少的回表查询\n\n#### Quetion\n\n![image-20240218221919863](database-mysql/image-20240218221919863.png)\n\n建立id主键，username，password联合索引\n\n* #### **索引设计原则**\n\n![image-20240218224016746](database-mysql/image-20240218224016746.png)\n\n### 3、SQL优化\n\n* #### **插入数据**insert优化\n\n  批量插入而不是单条插入：批量插入只需要建立一次连接即可\n\n  建议手动提交事务：不需要每一次插入时自动开启和关闭事务，而是将所有insert执行结束以后统一关闭\n\n  **建议主键顺序插入**\n\n  大批量插入数据：使用Mysql数据库提供的load指令进行插入\n\n  ```mysql\n  # 如何使用load\n  # 1、连接服务器时加上参数--local-infile\n  mysql --local-infile -u root -p\n  \n  # 2、设置全局参数local_infile为1\n  set global local_infile = 1;\n  \n  # 3、执行load指令将数据加载表结构中\n  load data local infile '文件名' into table '表名' fields teminated by '分割符' lines terminated by '行分隔符\\n';\n  ```\n\n* #### **主键优化**\n\n> InnoDB中表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。\n\n页大小为16kb，每个页至少包含两行数据\n\n主键乱序插入可能会出现页分裂现象，执行删除操作会出现页合并现象\n\n主键设计原则：\n\n​\t满足业务需求的情况下，尽量降低主键的长度\n\n​\t插入时尽量按照主键顺序插入，选择自增主键\n\n​\t尽量不要使用无序的自然主键\n\n​\t业务操作，避免对主键的修改\n\n* **order by优化**\n\n排序方式\n\nUsing filesort：先找到数据再进行排序\n\nUsing index：通过有序索引直接返回，不需要额外排序\n\n默认会对索引进行升序排序\n\n* **limit优化**\n\n对于数据量大的，优化思路为使用覆盖索引+子查询\n\n* count\n\n  count(*)优于count(1)>count(主键)>count(字段)\n\n* #### **update优化**\n\n对需要更新的字段尽可能建立索引，这样如果处于多个事务情况下，只会使用行锁，如果没有建立索引，行锁会升级为表锁，无法进行并行\n\n### 4、视图/存储过程/触发器\n\n> Mysql数据库当中的存储对象\n\n* #### 视图\n\n> 视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。\n\n操作视图中的数据就和操作数据库表一样，可以将视图理解为一张不被存储的虚拟表。\n\n视图当中的数据并不存在，如果往视图里面插入数据，数据将存在基表当中，如果不想给用户表的权限，可以给用户一个视图。 \n\n```mysql\n# 创建视图\nCREATE [OR REPLACE] VIEW 视图名称(列名列表) AS SELECT语句 [WITH CASCADED|LOCAL CHECk OPTION];\n\n# 查询视图\n# 查看创建视图语句\nSHOW CREATE VIEW 视图名称;\n# 查看视图数据\nSELECT * FROM 视图名称...;\n\n# 修改视图\n# 方式一、使用创建的语句，用REPLACE替换掉\nCREATE[OR REPLACE]...\n# 方式二\nALTER VIEW 视图名称(列表名称) AS SELECT ...;\n\n# 删除视图\nDROP VIEW IF EXISTS 视图名称\n```\n\n**视图当中的检查选项**\n\n**CASCADED（向下级联）**\n\n当使用WITH CHECK OPTION子句创建视图时，Mysql会通过视图检查正在更改的每个行。进行校验，所插入的数据是否满足SELECT语句。\n\nMysql中还可以为视图再创建新的视图，新的视图如果有option选项会影响到之前的视图\n\n**LOCAL（不向下级联，只是检查有option的条件）**\n\n**视图的更新和作用**\n\n要使视图可以更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下中任何一项，则该视图不可更新：\n\n聚合函数、DISTINCT、GROUP BY、HAVING、UNION或者UNION ALL\n\n作用：1、可以简化用户对数据的理解，简化用户操作。2、控制用户对表的查看权限。3、数据独立，屏蔽真实表结构。4、可以简化多表联查的操作。\n\n* #### 存储过程\n\n> 存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输\n>\n> 思想上就是数据库SQL语言层面的代码封装与重用，下一次如果执行相同的业务直接调用存储过程\n\n**特点**\t好像跟函数有点像\n\n封装、复用\n\n可以接收参数，也可以返回数据\n\n作用：减少网络交互，提升效率\n\n> 在命令行中，执行创建存储过程的sql时，需要通过关键字`delimiter`指定SQL语句的结束符\n\n```mysql\n# 创建\n# 参数列表为IN/OUT/INOUT 参数名，分别表示参数输入，输出，输入和输出参数\nCREATE PROCEDURE 存储过程名称([参数列表])\nBEGIN\n\t--SQL语句，可以是多条\nEND;\n\n# 调用\nCALL 名称([参数列表]);\n\n# 查看\n# 方法一，查看系统的数据库表，xxx为数据库名\nSELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = 'XXX';\n# 方法二，使用show查看创建过程\nSHOW CREATE PROCEDURE 存储过程名称;\n\n# 删除\nDROP PROCEDURE [IF EXISTS] 存储过程名称;\n\n# 定义结束符为$$\ndelimiter $$\n```\n\n**系统变量**（全局GLOBAL，会话SESSION）\n\n重启以后系统参数会恢复为默认值\n\n永久修改系统参数需要修改/etc/my.cnf中配置\n\n```mysql\n# 查看所有系统变量\nSHOW [SESSION|GLOBAL] VARIABLES;\nSHOW VARIABLES LIKE '..';\n# 查看指定变量\nSELECT @@[SESSION|GLOBAL].系统变量名\n\n# 设置系统变量，默认为SESSION级别\nSET [SESSION|GLOBAL] 变量名=值;\nSET @@[SESSION|GLOBAL].系统变量名 = 值;\n```\n\n**用户自定义变量**\n\n> 作用域为当前连接\n>\n> 变量无需声明，如果拿到的是没有声明的变量，则会获得NULL\n\n```mysql\n# 赋值，可以同时赋值多个变量，用逗号隔开\nSET @var_name = expr;\nSET @var_name := expr;\n\n# SELECT赋值\nSELECT @var_name := expr;\n# 将sql查询的结果赋值给变量\nSELECT 字段名 INTO @var_name FROM 表名;\n\n# 使用\nSELECT @var_name;\n```\n\n**局部变量**\n\n> 在局部生效，需要DECLARE声明，作用域在BEGIN...END块内\n\n```mysql\n# 声明\nDECLARE 变量名 变量类型(数据库数据的类型) [DEFAULT 默认值]\n\n# 赋值\nSET 变量名 = 值;\nSET 变量名 := 值;\nSELECT 字段名 INTO @var_name FROM 表名;\n```\n\n**存储过程相关语法**\n\n> 逻辑语言都在存储过程中定义，可以使用传入的参数\n\n```mysql\n# IF 条件判断\nIF 条件1 THEN\n\t...\nELSEIF 条件2 THEN\n\t...\nELSE\n\t...\nEND IF;\n\n# CASE 条件选择，WHEN后面可以有多种选择\n# 语法一\nCASE case_value\n\tWHEN when_value1 THEN ...\n\tWHEN when_value2 THEN ...\n\tELSE ...\nEND CASE;\n# 语法二\nCASE \n\tWHEN 表达式真 THEN ...\n\tELSE ...\nEND CASE;\n\n# WHILE循环\nWHILE 条件 DO\n\tSQL逻辑\nEND WHILE：\n\n# REPEAT循环，当满足条件时，退出循环\nREPEAT\n\tSQL逻辑...\n\tUNTIL 条件\nEND REPEAT;\n\n# LOOP循环\n# LOOP实现的是简单循环\n# LEAVE：配合循环使用，退出循环，作用类似于break\n# ITERATE：必须在循环中使用，作用类似于CONTINUE\n[begin_label:] LOOP\n\tSQL逻辑\n\t\nEND LOOP[end_label]\n\n# 退出循环\nLEAVE label;\n# 跳过本次进入下一次循环\nITERATE label;\n```\n\n**游标Cursor**\n\n游标（Cursor）是一种用于在存储过程或函数中遍历结果集的机制。游标允许逐行访问结果集，并在每行上执行相应的操作\n\n通常情况下，当执行一个查询语句时，MySQL 会返回一个结果集，该结果集包含了查询返回的所有行。以使用游标来逐行处理这个结果集，而不是一次性获取所有结果。这在处理大量数据或需要逐行处理结果的情况下非常有用\n\n```mysql\n# 声明游标、打开游标、获取下一行、关闭游标\nDELIMITER //\n\nCREATE PROCEDURE process_users()\nBEGIN\n    DECLARE done INT DEFAULT FALSE;\n    DECLARE user_id INT;\n    DECLARE user_name VARCHAR(255);\n\n    -- 声明游标\n    DECLARE user_cursor CURSOR FOR \n        SELECT id, name FROM users;\n\n    -- 打开游标\n    OPEN user_cursor;\n\n    -- 循环遍历结果集\n    read_loop: LOOP\n        -- 获取下一行数据\n        FETCH user_cursor INTO user_id, user_name;\n        IF done THEN\n            LEAVE read_loop;\n        END IF;\n        \n        -- 处理当前行数据\n        -- 这里可以执行相应的操作，如输出到日志或进行其他逻辑处理\n        SELECT CONCAT('User ID: ', user_id, ', User Name: ', user_name);\n\n    END LOOP;\n\n    -- 关闭游标\n    CLOSE user_cursor;\n\nEND //\n\nDELIMITER ;\n```\n\n* #### 存储函数\n\n> 有返回值的存储过程，存储函数的参数只能时IN类型’\n\n```mysql\n# 语法结构\nCREATE FUNCTION 存储函数名称([参数列表])\nRETURNS type [characteristic...]\nBEGIN\n\t--SQL语句\n\tRETURN ...;\nEND;\n\ncharacteristics存储参数的特性\nDETERMINISTIC : 相同的输入参数总是产生相同的结果\nNO SQL : 不包含SQL语句\nREADS SQL DATA : 包含读取数据的语句，但不包含写入数据的语句\n```\n\n* #### 触发器\n\n> 在insert/update/delete之前或者之后，触发并执行触发器中定义的SQL语句集合。\n>\n> 使用别名OLD和NEW来引用触发器中发生变化的记录内容\n>\n> 触发器只支持行级触发，不支持语句级别触发：如果一个UPDATE语句影响了5行，则触发器会被出发5次\n\n|   触发器类型   |                       NEW和OLD                       |\n| :------------: | :--------------------------------------------------: |\n| INSERT型触发器 |            NEW表示将要或者已经新增的数据             |\n| UPDATE型触发器 | OLD表示修改之前的数据，NEW表示将要或已经修改后的数据 |\n| DELETE型触发器 |            OLD表示将要或者已经删除的数据             |\n\n```mysql\n# 创建触发器\nCREATE TRIGGER trigger_name\nBEFORE/AFTER(在之前还是之后) INSERT/UPDATE/DELETE(触发器类型)\nON tbl_name FOR EACH ROW --行级触发器\nBEGIN\n\ttrigger_stmt; # 触发器逻辑\nEND;\n\n# 查看\nSHOW TRIGGERS;\n\n# 删除，数据库中的触发器\nDROP TRIGGER [schema_name.]trigger_name;\n```\n\n\n\n### 5、锁\n\n> 锁是计算机协调多个进程或线程并发访问某一资源的机制，用于保证数据的一致性和有效性。\n\n* 全局锁\n\n对整个数据库进行加锁，加锁以后整个实例就处于只读状态，后续的DML的写语句，DDL语句以及更新操作的事务提交语句都会被阻塞\n\n做数据库的全库逻辑备份的时候，会对所有的表进行锁定\n\n```mysql\n# 为表加全局锁\nFLUSH TABLES WITH READ LOCK;\n\n# 备份数据库\nmusqldump -uroot -p1234 数据库>文件名\n\n# 释放全局锁\nUNLOCK TABLES;\n```\n\n* 表级锁\n\n每次操作会锁住整张表，发生锁冲突的概率最高，并发度最低\n\n**表锁**\n\n> 表共享读锁：对于所有客户端的连接都只能读，不能写\n>\n> 表独占写锁：对于获取锁资源的客户端可以写，其他客户端不能进行读也不能执行写会被阻塞\n\n语法\n\n1、加锁：lock tables 表名... read/write\n\n2、释放锁：unlock tables /  客户端断开连接\n\n**元数据锁**（meta data lock）\n\n> MDL加锁过程是系统自动控制的，无需显示使用，在访问一张表的时候会自动加上\n>\n> 元数据锁就是对表结构进行加锁\n\n当对一张表进行增删改查的时候，自动会加上MDL读锁，当对表结构进行变更时，会自动加上MDL写锁\n\n|                   对应SQL                   |                锁类型                 |\n| :-----------------------------------------: | :-----------------------------------: |\n|          lock table xx read/write           | SHARED_READ_ONLY/SHARED_NO_READ_WRITE |\n|    select、select .. lock in share mode     |              SHARED_READ              |\n| insert、update、delet、sekect...from update |             SHARED_WRITE              |\n|               alter table...                |              EXCLUSIVVE               |\n\n\n\n**意向锁**\n\n![image-20240222075448991](database-mysql/image-20240222075448991.png)\n\n![image-20240222075706155](database-mysql/image-20240222075706155.png)\n\n* 行级锁\n\n> 应用在InnoDB存储引擎当中\n\nInnoDB的数据时基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁\n\n**行锁**\n\n锁定单个行记录的锁，防止其他事务对此进行update和delete，在RC、RR隔离级别都支持\n\n1、共享锁（S）：允许一个事务去读取一行，阻止其他事务获得相同数据集的排它锁，其他事务能读不能写\n\n2、排它锁（X）：允许获取排它锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排它锁，其他事务不能写也不能读\n\n|              SQL              |  行锁类型  |   说明   |\n| :---------------------------: | :--------: | :------: |\n|            INSERT             |   排它锁   | 自动加锁 |\n|            UPDATE             |   排它锁   | 自动加锁 |\n|            DELETE             |   排它锁   | 自动加锁 |\n|            SELECT             | 不加任何锁 |          |\n| SELECT ... LOCK IN SHARE MODE |   共享锁   | 手动加锁 |\n|     SELECT ... FOR UPDATE     |   排它锁   |   手动   |\n\n**间隙锁**\n\n锁定索引记录间隙，确保索引记录间隙不变，防止其他事务在这个间隙执行insert，产生幻读，在RR级别下支持\n\n**临建锁**（next-key）\n\n同时锁住行记录也锁住间隙\n\n```mysql\n# 查询数据库中的锁\nselect object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;\n```\n\n\n\n### 6、InnoDB引擎\n\n* #### **逻辑存储结构**\n\n表空间（ibd文件）：一个mysql实例可以对应多个表空间，用于存储记录、索引等数据\n\n段：分为数据段、索引段、回滚段，InnoDB是索引组织表，数据段就是B+书的叶子节点，索引段即是B+书的非叶子节点，段用来管理多个区\n\n区：表空间的单元结构，每个区的大小为1M，一个区中一共有64个连续的页\n\n页：页大小16kB，是InnoDB存储引擎磁盘管理的最小单元，保证页的连续性，会申请4-5个区\n\n![image-20240223204149464](database-mysql/image-20240223204149464.png)\n\n* #### 架构\n\n![innodb-architecture-8-0](database-mysql/innodb-architecture-8-0.png)\n\n**内存结构**\n\n> 磁盘结构存储的是一些表空间和表数据文件，包括日志表空间，系统表空间，撤销表空间，重做表空间等等\n\nbuffer pool缓存池\n\n缓冲区是内存中的一个区域，可以缓冲存储磁盘上经常要操作的数据，利用局部性原理减少磁盘IO，加快处理速度\n\n缓冲池以page页为单位，底层采用链表数据结构管理page\n\nchange buffer更改缓存，**针对非唯一二级索引页**\n\n当需要对数据进行变更，即执行DML语句时，如果buffer pool中不存在当前数据page，不会直接操作磁盘，会先将数据变更缓存在change buffer在未来数据被读取的时候，再将数据合并恢复到buffer pool中\n\nAdaptive Hash Index自适应哈希索引\n\nlog buffer日志缓存区\n\n**后台线程**\n\n> 作用：将InnoDB缓冲区当中的数据在合适的时间写入到磁盘当中\n\n1、Master Thread\n\n核心后台线程，负责调度其他线程，将缓冲池中的数据异步刷新到磁盘当中，保持数据的一致性\n\n2、IO Thread\n\n采用的是AIO（异步非阻塞IO）来处理IO请求\n\n4个读线程、4个写线程、1个日志线程、1个插入缓存线程（写缓冲区刷新到磁盘）\n\n3、Purge Thread\n\n回收事务已经提交的undo log，在事务提交之后，undo log可能不用了，就用它来回收\n\n4、Page Cheaner Thread\n\n协助Master Thread刷新脏页到磁盘的线程\n\n* #### 事务原理\n\n事务的原子性、一致性和持久性是通过日志文件来保证的，包括redo.log和undo.log\n\n事务的隔离性是通过锁+MVCC（多版本并发控制）来进行保证的\n\n**redo log**事务的持久性（事务提交后数据的改变是永久的）\n\n重做日志，记录事务提交时数据页的物理修改，用来实现事务的持久性(事务一旦提交，对数据的改变时持久的）\n\n当系统在执行Mysql的DML语句时，会先从数据库缓存中查找是否有对应的页面，如果在缓存当中则对数据进行修改，这种在缓冲中修改后但还未写入磁盘的数据页，叫做脏页，后通过后台进程写入到磁盘当中，如果在写入的过程中发生异常，就会出现持久性消失的现象\n\nredo log会把数据页的变化记录到redo log当中，当事务提交时，会把redo log刷新到磁盘当中，可以通过log对数据进行恢复，如果redo log刷新页失败，则事务执行也就失败，不影响一致性\n\n**undo log**事务的原子性（事务是最小操作单位，要么全部成功，要么全部失败）\n\n回滚日志，用于记录数据被修改前的信息，提供回滚和MVCC。当执行DML语句时，会记录数据变化前的数据长什么样，在回滚日志中，记录的时执行sql的反向操作，逆操作\n\nundo log存放在段当中，回滚段\n\n* #### MVCC多版本并发控制\n\n> Mutil-Version Concurrency Control，多版本并发控制。维护一个数据的多个版本，使得读写此操作没有冲突。依赖于数据库记录中的三个隐式字段、undo log日志、readView\n\n**相关概念**\n\n当前读：读取的时记录的最新版本。因为Mysql的默认隔离界别是RR（repeatable read）可重复读，所以当另一个事务对数据进行修改时，当前事务读到的数据就不是当前最新的版本。要想读到最新版本，可以通过select .. lock in share mode,select .. for update来完成\n\n快照读：正常的select（不加锁）就是快照读，读取的是数据的可见版本\n\nRead Committed：每一次select 都会生成一个快照读\n\nRepeatable Read：开始事务后第一个select才是产生快照读的地方，后面的select都是查询快照\n\nSerializable：快照读会退化为当前读\n\n**记录当中的隐藏字段**\n\nDB_TRX_ID：最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID\n\nDB_ROLL_PTR：回滚指针，指向这条记录的上一个版本，用于配合undo log\nDB_ROW_ID：隐藏主键，表结构没有主键，则会自动生成隐藏字段\n\n**undo log日志**\n\n如果使用insert的时候产生的日志只在回滚的时候需要，在事务提交后，可以立即删除\n\n如果使用的是update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读的时候也需要，不会立即被删除\n\n![image-20240224160500080](database-mysql/image-20240224160500080.png)\n\n**ReadView**\n\n读视图：快照读SQL执行时MVCC提取数据的一句，记录并维护系统当前活跃的事务id\n\n字段，通过对比当前事务的id：trx_id和下面的id进行对比来实现版本访问控制\n\n|      字段      |              含义              |\n| :------------: | :----------------------------: |\n|     m_ids      |      当前活跃的事务ID集合      |\n|   min_trx_id   |         最小活跃事务ID         |\n|   max_trx_id   | 预分配事务ID，当前最大事务ID+1 |\n| creator_trx_id |     ReadView创建者的事务ID     |\n\n![image-20240224161313751](database-mysql/image-20240224161313751.png)\n\n**Read Commited**读提交下的规则\n\n> 事务中每一次执行快照读时都会生成ReadView\n\n![image-20240224162152111](database-mysql/image-20240224162152111.png)\n\n通过上面四条规则可以找到最新已经提交的事务版本\n\n**Repeatable Read**可重复读的情况\n\n> 仅在事务中第一次执行快照读的时候生成ReadView，后续会复用该ReadView\n\n![image-20240224162359110](database-mysql/image-20240224162359110.png)\n\n隔离性：保证事务不在外部并发操作影响下独立完成，通过MVCC+锁来保证\n\n一致性：事务完成时，所有数据都保持一致，通过日志实现\n\n![image-20240224162626695](database-mysql/image-20240224162626695.png)\n\n\n\n### 7、MySQL管理\n\n* 系统数据库\n\n|       数据库       |                             含义                             |\n| :----------------: | :----------------------------------------------------------: |\n|       mysql        |   存储Mysql服务器正常运行所需要的各种信息（用户、权限等）    |\n| information_schema | 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型以及访问权限 |\n| performance_schema | 为Mysql服务器运行时状态提供了一个底层监控功能，用于收集数据库服务器性能参数 |\n|        sys         |             方便开发人员进行性能调优和诊断的视图             |\n\n* 常用工具\n\n```mysql\n# mysql [option] [database]\nmysql\n\t-u, --user=\t\t # 指定用户名\n    -p, --password=\t\t# 指定密码\n    -h, --host=\t\t# 指定服务器ip或域名\n    -p, --port=\t\t# 指定端口号\n    -e, --execute=\t# 执行sql语句并推出\n```\n\nmysqladmin\n\n​\t执行管理操作的客户端程序\n\n​\t--help查看帮助文档\n\nmysqlbinlog\n\n​\t如果查看一些二进制文本的数据，使用这个可以进行数据查看\n\nmysqlshow\n\n​\t客户端对象查找工具，可以用于查找存在哪些数据库、数据库中的表、表中的列或者索引\n\n​\t--count 显示数据库及表的统计信息\n\n​\t-i 显示指定数据库或指定表的状态信息\n\n**mysqldump**\n\n​\t用于备份数据库或在不同数据库之间进行数据迁移\n\n**mysqlimport/source**\n\n​\t用于数据的导入工具\n\n\n\n## QA\n\n1、InnoDB数据页中的数据存储\n\n2、B+树是如何进行查询的\n\n3、MySql单表最大限制，为什么\n\n4、索引失效有哪些\n\n5、count（*）和count（1）哪个性能好一些\n","source":"_posts/database-mysql.md","raw":"---\ntitle: 数据库-MySQL\ntags: [Database, 数据库, Mysql, SQL]\ncategories: 学习笔记\ndate: 2024-02-10 16:00:39\ncover:\ntop_img:\n---\n## 数据库-Mysql\n\n> Mysql数据库的关键词：事务、存储引擎、索引、SQL优化、**锁、日志、主从复制、读写分离、分库分表**\n\n## 数据库基础\n\n### 1、Mysql概述\n\n关系型数据库：建立在关系模型基础上，由多张互连接的二维表组成的数据库\n\n特点：使用表存储数据，便于维护；使用sql语句操作，使用方便\n\n**MySQL数据模型**\n\n> 1、客户端通过与数据库管理系统进行连接\n>\n> 2、使用sql语句通过数据库管理系统对指定的数据库进行增删改查\n>\n> 3、一个数据库模型中可以对多个数据库进行管理，一个数据库中可以拥有多个表\n\n// TODO数据库模型的图\n\n### 2、SQL\n\n**SQL分类**\n\n| 分类 | 全称                       | 说明                                                 |\n| ---- | -------------------------- | ---------------------------------------------------- |\n| DDL  | Data Definition Language   | 数据库定义语句，定义数据库对象，数据库，表，字段等   |\n| DML  | Data Manipulation Language | 数据库操作语句，用于对数据库表中的数据进行增增删改   |\n| DQL  | Data Query Language        | 数据库查询语句，查询数据库表中的记录                 |\n| DCL  | Data Control Language      | 数据库控制语句，创建数据库用户，控制数据库的访问权限 |\n\n* #### DDL\n\n  **数据库层次**\n\n```mysql\n# 查询所有数据库表格\nSHOW DATABASES;\n# 查询当前所在的数据库\nSELECT DATABASE();\n# 创建数据库，方括号可以省略\nCREATE DATABASE [IF NOT EXISTS] 数据库名 [COLLATE 排序规则]\n# 删除数据库\nDROP DATABASE [IF EXISTS] 数据库名\n# 使用数据库，切换到数据库当中\nUSE 数据库名\n```\n\n​\t\t表结构\n\n```mysql\n# 查看所有表\nSHOW TABLES;\n# 查询表结构\nDESC 表名\n# 查询指定表的建表语句\nSHOW CREATE TABLE 表名;\n```\n\n​\t\tMySQL中的数据类型\n\n| 数据类型       | 描述                                   | 大小                                 |\n| -------------- | -------------------------------------- | ------------------------------------ |\n| TINYINT        | 微小整数，有符号或无符号（UNSIGNED）   | 1 字节                               |\n| SMALLINT       | 小整数，有符号或无符号                 | 2 字节                               |\n| MEDIUMINT      | 中等整数，有符号或无符号               | 3 字节                               |\n| INT 或 INTEGER | 整数，有符号或无符号                   | 4 字节                               |\n| BIGINT         | 大整数，有符号或无符号                 | 8 字节                               |\n| FLOAT(M,D)     | 单精度浮点数，M 是总位数，D 是小数位数 | 4 字节                               |\n| DOUBLE(M,D)    | 双精度浮点数，M 是总位数，D 是小数位数 | 8 字节                               |\n| DECIMAL(M,D)   | 定点数，M 是总位数，D 是小数位数       | 取决于 M 和 D                        |\n| DATE           | 日期 YYYY-MM-DD                        | 3 字节                               |\n| TIME           | 时间 HH:MM:SS                          | 3 字节                               |\n| DATETIME       | 日期和时间                             | 8 字节                               |\n| TIMESTAMP      | 时间戳                                 | 4 字节                               |\n| CHAR(N)        | **定长**字符串，最大长度为 N           | 最大 255 字节                        |\n| VARCHAR(N)     | **变长**字符串，最大长度为 N           | 最大 65,535 字节                     |\n| TEXT           | 变长文本，最大长度为 65,535 字节       | 最大 65,535 字节                     |\n| BLOB           | 二进制大对象，最大长度为 65,535 字节   | 最大 65,535 字节                     |\n| ENUM           | 枚举类型                               | 1 或 2 字节，取决于成员数量          |\n| SET            | 集合类型                               | 1、2、3、4 或 8 字节，取决于成员数量 |\n\n创建表：\n\n```mysql\nCREATE TABLE member(\n    number INT COMMENT '编号',\n    id CHAR(10) COMMENT '员工工号',\n    name VARCHAR(10) COMMENT '员工姓名',\n    gender CHAR(4) COMMENT '员工性别',\n    age INT UNSIGNED COMMENT '年龄',\n    id_number CHAR(18) COMMENT '身份证号',\n    time DATE COMMENT '入职时间'\n)\n```\n\n**表结构的修改**\n\n```mysql\n# 添加字段\nALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释][约束];\n\n# 修改字段和字段类型\nALTER TABLE 表明 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释][约束]\n\n# 删除字段\nALTER TABLE 表名 DROP 字段名;\n\n# 修改表名\nALTER TABLE 表名 RENAME TO 新表名;\n\n# 删除表\nDROP TABLE [IF EXSITS] 表名;\n# 删除指定表并重新创建该表，清空数据\nTRUNCATE TABLE 表名;\n```\n\n* #### DML（数据操作语言）\n\n**添加数据**\n\n```mysql\n# 给指定字段添加数据\nINSERT INTO 表名(字段名1, 字段名2, ...) VALUES (值1, 值2, ...);\n\n# 给全部字段添加数据\nINSERT INTO 表名 VALUES(值1, 值2, ...);\n```\n\n**修改数据**\n\n```mysql\n# 修改数据\nUPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ...[WHERE 条件];\n```\n\n**删除数据**\n\n```mysql\n# 删除数据\nDELETE FROM 表名 [WHERE 条件];\n```\n\n* #### DQL\n\n  > 数据库查询语言，用来查询数据库中的表的记录\n  >\n  > SELECT后面加上\\G可以将某一行转化为一列查看\n\n**语法结构**\n\n```mysql\nSELECT\n\t字段列表\nFROM\n\t表名列表\nWHERE\n\t条件列表(条件查询)\nGROUP BY\n\t分组字段列表(分组查询)\nHAVING\n\t分组后条件列表\nORDER BY\n\t排序字段列表\nLIMIT\n\t分页参数\n```\n\n**基本查询**\n\n```mysql\nSELECT 字段1 [AS 别名]，字段2 [AS 别名]， FROM 表名;\n\n# 去重\nSELECT DISTINCT 字段列表 FROM 表名;\n```\n\n**条件查询**\n\n条件运算符\n\n|     比较运算符      |                   功能                   |\n| :-----------------: | :--------------------------------------: |\n|       <>或!=        |                  不等于                  |\n| BETWEEN ... AND ... |              在某个范围之内              |\n|       IN(...)       |       在in之后的列表中的值，多选一       |\n|     LIKE 占位符     | 模糊匹配(_匹配单个字符，%匹配任意个字符) |\n|       IS NULL       |                  是NULL                  |\n\n**聚和函数**\n\n> 将一列数据作为一个整体，进行纵向计算。\n\n所有的null值不参与聚合函数的计算\n\n| 函数  |   功能   |\n| :---: | :------: |\n| count | 统计数量 |\n|  max  |  最大值  |\n|  min  |  最小值  |\n|  avg  |  平均值  |\n|  sum  |   求和   |\n\n```mysql\nSELECT 聚合函数(字段列表) FROM 表名;\n```\n\n**分组查询**\n\n> 在where中不可以使用聚合函数，在having中可以使用聚合函数\n>\n> 分组之前过滤用where，分组之后过滤条件用having\n\n```mysql\nSELECT 字段列表\tFROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];\n```\n\n执行顺序：where > 聚合函数 > having\n\n**排序查询**\n\n```mysql\nSELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2\n```\n\n排序方式： ASC升序（默认），DESC降序\n\n**分页查询**\n\n```mysql\nSELECT 字段列表 FROM 表名 LIMIT 起始索引,查询记录数;\n```\n\n显示从起始索引开始的记录数条的查询结果\n\n**DQL执行顺序**\n\nFROM > WHERE > GROUP BY > SELECT > ORDER BY > LIMIT\n\n* #### DCL\n\n> 数据控制语句，用来管理数据库用户，控制数据库访问权限\n\n**DCL用户管理**\n\n```mysql\n# 查询用户\nUSE mysql;\nSELECT * FROM user;\n\n# 创建用户，主机名换成\"%\"表示可以在任意主机访问数据库\nCREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';\n\n# 修改用户密码\nALTER USER '用户名'@'主机名' IDENTIFIED WITH mysql_native_password BY '新密码'\n\n# 删除用户\nDROP USER '用户名'@'主机名';\n```\n\n**权限控制**\n\n常用权限\n\n|        权限         |        说明        |\n| :-----------------: | :----------------: |\n| ALL, ALL PRIVILEGES |      所有权限      |\n|       SELECT        |      查询数据      |\n|       INSERT        |      插入数据      |\n|       UPDATE        |      修改数据      |\n|       DELETE        |      删除数据      |\n|        ALTER        |       修改表       |\n|        DROP         | 删除数据库/表/视图 |\n|       CREATE        |   创建数据库/表    |\n\n```mysql\n# 查询权限\nSHOW GRANTS FOR '用户名'@'主机名';\n\n# 授予权限\nGRANT 权限列表 ON 数据库名.表名(*.*所有表) TO '用户名'@'主机名';\n\n# 撤销权限\nREVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名';\n```\n\n### 3、函数\n\n* **字符串函数**\n\n|            函数            |                           功能                            |\n| :------------------------: | :-------------------------------------------------------: |\n|   CONCAT(S1,S2, ... Sn)    |            字符串拼接，将S1-Sn拼接成一个字符串            |\n|         LOWER(str)         |                  将字符串str全部转为小写                  |\n|         UPPER(str)         |                   将字符串全部转为大写                    |\n|     LPAD(str, n, pad)      | 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 |\n|     RPAD(str, n,  pad)     |                          右填充                           |\n|         TRIM(str)          |                去掉字符串头部和尾部的空格                 |\n| SUBSTRING(str, start, len) |         返回从字符串str从start起的len长度的字符串         |\n\n```mysql\nSELECT 函数;\n```\n\n* **数值函数**\n\n|    函数     |                功能                |\n| :---------: | :--------------------------------: |\n|   CEIL(x)   |              向上取整              |\n|  FLOOR(x)   |              向下取整              |\n|  MOD(x, y)  |            返回x/y的模             |\n|   RAND()    |         返回0~1内的随机数          |\n| ROUND(x, y) | 求参数x的四舍五入的值，保留y位小数 |\n\n* **日期函数**\n\n|                函数                |                             功能                             |\n| :--------------------------------: | :----------------------------------------------------------: |\n|             CURDATE()              |                         返回当前日期                         |\n|             CURTIME()              |                         返回当前时间                         |\n|               NOW()                |                      返回当前日期和时间                      |\n|             YEAR(date)             |                      获取指定date的年份                      |\n|            MONTH(date)             |                      获取指定date的月份                      |\n|             DAY(date)              |                      获取指定date的日期                      |\n| DATE_ADD(date, INTERVAL expr type) | 返回上一个日期加上时间间隔expr以后的时间值，type(year,month,day)指定年月天 |\n|       DATEDIFF(date1, date2)       | 返回起始时间date1和结束时间date2之间的天数，第一个时间减去第二个时间 |\n\n* **流程函数**\n\n|                            函数                            |                           功能                           |\n| :--------------------------------------------------------: | :------------------------------------------------------: |\n|                      IF(value, t. f)                       |            如果value为true，返回t，否则返回f             |\n|                   IFNULL(value1, value2)                   |       如果value1不为空，返回value1，否则返回value2       |\n|    CASE WHEN [val] THEN [res1] ... ELSE [ default ] END    |    如果val1为true，返回res1，...否则返回default默认值    |\n| CASE [expr] WHEN [val1] THEN [res1] ... ELSE [default] END | 如果expr的值等于val1，返回res1，...否则返回default默认值 |\n\n### 4、约束\n\n作用于表中字段上的规则，用于限制存储在表中的数据\n\n|   约束   | 描述 | 关键字 |\n| :------: | :--: | :----: |\n| 非空约束 |      |        |\n| 唯一约束 |      |        |\n| 主键约束 |      |        |\n| 默认约束 |      |        |\n| 检查约束 |      |        |\n| 外键约束 |      |        |\n\n\n\n### 5、多表查询\n\n* **多表关系**\n\n  一对多：在多的一方建立外键，指向一的一方的主键\n\n​\t\t多对多：建立第三张中间表，中间表至少包含两个外键，分别关联两方的主键\n\n​\t\t一对一：用于做单表拆分，基础字段放在一张表，详情字段放在另一张表。在任意一方加入外键，关联另一方的主键，并设置外键为唯一（UNIQUE）\n\n* **多表查询**\n\n  * 内连接\n\n    > 相当于查询A、B交集部分数据\n\n  ```mysql\n  # 隐式内连接\n  SELECT 字段列表 FROM 表1，表2 WHERE 条件...;\n  \n  # 显示内连接\n  SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;\n  ```\n\n  * 外连接\n\n    > 左外连接：查询左表所有数据，以及两张表交集部分数据，将左表的数据和右表的部分数据连接起来\n    >\n    > 右外连接：查询右表所有数据，以及两张表交集部分数据\n\n  ```mysql\n  # 左外连接，表1所有数据以及和表2交集部分的数据\n  SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件;\n  \n  # 右外连接，表2所有数据以及和表1交集部分的数据\n  SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件;\n  ```\n\n  * 自连接\n\n    > 自连接：当前表与自身的连接查询，自连接必须使用表别名\n\n  * 联合查询-union，union all\n\n  ```mysql\n  # 把多次查询的结果合并起来，形成一个新的查询结果集\n  # ALL去掉以后会对结果进行去重\n  SELECT 字段列表 表A\n  UNION [ALL]\n  SELECT 字段列表 表B;\n  ```\n\n* **子查询**\n\n  * 标量子查询，子查询返回一个标量\n\n  * 列子查询，子查询返回一列\n\n    | 操作符 |                 描述                 |\n    | :----: | :----------------------------------: |\n    |   IN   |     在指定的集合范围之内，多选一     |\n    | NOT IN |          不在指定的范围之内          |\n    |  ANY   | 子查询返回列表中，有任意一个满足即可 |\n    |  SOME  |              与ANY等同               |\n    |  ALL   |   子查询返回列表的所有值都必须满足   |\n\n  * 行子查询，子查询返回的结果是一行\n\n    此时column1可以使用(column1， column2)聚合成多个参数\n\n    操作符：=、<>、IN、NOT IN\n\n  * 表子查询，子查询的返回结果是一个表，可以和行子查询加上列子查询的操作符使用，表可以放到from后面\n\n```mysql\n# 对于子查询，可以将问题拆解成多个不同的查询步骤\nSELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);\n```\n\n### 6、事务\n\n> 一组操作的集合，是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，这些操作要么**同时成功，要么同时失败**\n>\n> 默认Mysql的事务是自动提交的，当执行一条DML语句，Mysql会立即隐式的提交事务\n\n* **事务操作**\n\n```mysql\n# 查看/设置事务提交方式\nSELECT @@autocommit;\n# 事务设置为手动提交\nSET @@autocommit = 0;\n\n# 提交事务\nCOMMIT;\n\n# 回滚事务\nROLLBACK;\n```\n\n```mysql\n# 不修改事务的提交方式操作事务\n# 开启事务\nSTART TRANSACTION 或 BEGIN;\n\n# 提交事务\nCOMMIT;\n\n# 回滚事务\nROLLBACK;\n```\n\n* **事务四大特性**\n\n  * 原子性(Atomicity)：事务时不可分割的最小操作单元，要么全部成功，要么全部失败\n  * 一致性(Consistency)：事务完成时，必须使所有的数据都保持一致状态\n  * 隔离性(Isolation)：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行\n  * 持久性(Durability)：事务一旦提交或者回滚，它对数据库中的数据改变就是永久的\n\n* **并发事务问题**\n\n|    问题    |                             描述                             |\n| :--------: | :----------------------------------------------------------: |\n|    脏读    |            一个事务读到另一个事务还没有提交的数据            |\n| 不可重复读 | 一个事务先后读取同一条记录，但两次读取的数据不同，称为不可重复读 |\n|    幻读    | 一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这一行数据已经存在 |\n\n* **事务隔离级别**\n\n  > 读未提交、读已提交、可重复读、串行化\n  >\n  > √表示会出现这个问题，×表示不会出现这个问题\n\n|     隔离级别     | 脏读 | 不可重复读 | 幻读 |\n| :--------------: | :--: | :--------: | :--: |\n| Read uncommitted |  √   |     √      |  √   |\n|  Read committed  |  ×   |     √      |  √   |\n| Repeatable Read  |  ×   |     ×      |  √   |\n|   Serializable   |  ×   |     ×      |  ×   |\n\n  ```mysql\n  # 查看事务的隔离级别\n  SELECT @@TRANSACTION_ISOLATION;\n  \n  # 设置事务隔离级别\n  SET [SESSION(只对当前窗口有效)|GLOBAL] TRANSACTION ISOLATION LEVEL {隔离级别}\n  ```\n\n  事务的隔离界别越高，数据越安全，但是性能越低\n\n## 数据库进阶\n\n### 1、存储引擎\n\n* Mysql体系结构 \n\n  连接层：完成一些类似于连接处理、授权认证及相关的安全方案\n\n  服务层：主要完成大多数的核心服务功能\n\n  引擎层：负责mysql中数据的存储和提取，服务器通过API和存储引擎进行通信\n\n  存储层：将数据存储在文件系统之上，并完成与存储引擎的交互\n\n  ![Mysql](database-mysql/Mysql.png)\n\n* 存储引擎\n\n  > 存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎时基于表的，而不是基于库的。一个数据库的不同的表可以选择不同的存储引擎\n  >\n  > Mysql默认InnoDB\n\n```mysql\n# 查询支持的存储引擎\nshow engines;\n```\n\n* InnoDB\n\n  * DML操作遵循ACID模型，支持事务\n  * 行级锁，提高并发访问性能\n  * 支持外键，保证事务的完整性和正确性\n\n  文件：每个表对应一个.ibd文件，代表表空间文件，可以通过命令`idb2sdi 文件名`查看表结构json文件格式\n\n  ![image-20240216162915509](database-mysql/image-20240216162915509.png)\n\n* MyISAM\n\n  * 不支持事务，不支持外键\n  * 支持表锁、不支持行锁\n  * 访问速度快\n\n  文件.MYD（数据），.MYI（索引），.sdi（表结构）\n\n* Memory\n\n  * 表数据存储在内存当中，收到硬件问题或断电影响只能作为临时表或者缓存使用\n  * 内存存放\n  * hash索引（默认）\n\n![image-20240216163439353](database-mysql/image-20240216163439353.png)\n\n* 存储引擎选择\n\n  InnoDB：如果对事务的完整性有比较高的要求，在并发情况下要求事务的一致性，数据操作除了插入和查询意外，还包括很多的更新、删除操作，InnoDB引擎比较合适\n\n  MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性和并发现要求不是很高。**这个场景被Nosql数据库MongoDB替代了**\n\n  MEMORY：将所有数据保存在内存当中，访问速度快，通常用于临时表以及缓存。MEMORY对表的大小有限制，太大的表无法缓存在内存中。**这个场景被Redis替代了**\n\n### 2、索引\n\n* **索引概述**\n  * 索引的结构\n\n* #### **索引分类**\n\n|   分类   |                含义                |           特点           |  关键字  |\n| :------: | :--------------------------------: | :----------------------: | :------: |\n| 主键索引 |      针对于表中主键创建的索引      | 默认自动创建，只能有一个 | PRIMARY  |\n| 唯一索引 |  避免同一个表中某数据列中的值重复  |        可以有多个        |  UNIQUE  |\n| 常规索引 |          快速定位特定数据          |        可以有多个        |          |\n| 全文索引 | 全文索引查找的是文本中通过的关键词 |        可以有多个        | FULLTEXT |\n\n按照索引的存储形式分类\n\n|   分类   |                            含义                            |         特点         |\n| :------: | :--------------------------------------------------------: | :------------------: |\n| 聚集索引 |                 将数据存储与索引放到了一块                 | 必须有，而且只有一个 |\n| 二级索引 | 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 |     可以存在多个     |\n\n![image-20240218203730285](database-mysql/image-20240218203730285.png)\n\n\n\n* #### **索引语法**\n\n```mysql\n# 创建索引\n# 一个索引可以关联多行，如果关联多行称为联合索引\nCREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name (index_col_name, )\n\n# 查看索引\nSHOW INDEX FROM table_name;\n\n# 删除索引\nDROP INDEX index_name ON table_name;\n```\n\n* #### **SQL性能分析**\n\n  > 使用于select的优化\n\n```mysql\n# SQL执行频率，查看当前数据库语句的访问频率\nSHOW [session|global] STATUS\n# Com七个下划线，模糊匹配\nSHOW GLOBAL STATUS LIKE 'Com_______'\n```\n\n**SQL语句的频率**\n\n![image-20240218204502697](database-mysql/image-20240218204502697.png)\n\n**慢查询日志**\n\n> 慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位：秒，默认10)的所有SQL语句的日志\n\n```mysql\n# 查看是否开启，日志文件默认在/var/lib/mysql里面\nSHOW VARIABLES LIKE 'slow_query_log';\n\n# 修改/etc/my.cnf中配置开启，配置时间\nslow_query_log=1   \nlong_query_time=2\n```\n\n**profile详情**\n\n```mysql\n# 查看是否支持prifile\nSELECT @@have_profiling;\n\n# 设置为开\nSET profiling=1;\n\n# 查看profile\nSHOW PROFILES;\n```\n\n执行完SQL语句以后，通过以下指令查看执行耗时情况\n\n```mysql\n# 查看每一条SQL耗时基本情况\nSHOW PROFILES;\n\n# 查看指定query_id的SQL语句各个阶段的耗时情况\nSHOW PROFILE FOR QUERY query_id;\n\n# 查看指定SQL语句的CPU使用情况\nSHOW PROFILE CPU FOR QUERY query_id;\n```\n\n**explain执行计划**\n\n> EXPLAIN或者DESC命令获取Mysql如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接的顺序\n\n```mysql\nEXPLAIN SELECT SQL语句;\n```\n\n![image-20240218211138993](database-mysql/image-20240218211138993.png)\n\n表头的含义：\n\n![image-20240218212814126](database-mysql/image-20240218212814126.png)\n\n![image-20240218212115878](database-mysql/image-20240218212115878.png)\n\n```txt\ntype\nconst\t以主键或以唯一的列作为索引扫描\nref\t\t非唯一的值作为查询索引\nindex\t用了索引，但是会对整个索引进行遍历\nall\t\t全表扫描\n```\n\n* #### **索引使用**\n\n**联合索引**\n\n使用要遵循**最左前缀法则**：查询**从索引的最左列开始**，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。\n\n**范围查询**：联合索引中出现范围查询（>,<)，范围查询右侧的列索引失效。但是使用大于等于和小于等于索引并不会失效。\n\n例子\n\n```mysql\n# student有联合索引(id,name,age)\n# 1、索引都可以使用\nselect * from student where id = 1 and name = \"Lili\" and age = 20;\n\n# 2、索引name，age失效\nselect * from student where id = 1 and age = 20;\n\n# 范围查询\n# name和age索引均失效\nselect * from student where id > 1 and name = \"Lili\" and age = 20;\n```\n\n**索引失效**\n\n索引列操作：不要在索引上进行列操作，否则索引会失效\n\n字符串类型：不加单引号索引会失效\n\n模糊查询：**头部进行模糊匹配(%%某某)**，索引会失效，尾部进行模糊匹配（某某%%），索引不会失效。\n\nor连接的条件：如果or前面的条件列有索引，后面的条件没有索引，所涉及的索引都不会引用到，只有两侧都有索引的时候，才有效\n\n数据分布影响：如果索引比全表扫描更慢，则不使用索引，查询的数据大于一半，走全表不走索引。\n\n**SQL提示**\n\n> 在sql语句中加入一些认为的提示来达到优化操作的目的\n\n```mysql\n# use index指定使用哪个索引\nexplain select * from table use index(idxname) ...\n\n# ignore index\n# force index 同上\n```\n\n**覆盖索引**\n\n尽量使用覆盖索引：查询使用了索引，并且需要返回的列，在该索引中已经能够全部找到，减少使用select *\n\nusing index condition：查找使用了索引，但是需要回表查询数据\n\nusing where, using index：查询使用了索引，但是不需要回表\n\n![image-20240218221642388](database-mysql/image-20240218221642388.png)\n\n前两条不需要回表，后一条需要回表\n\n**前缀索引**\n\n> 将字符串的前缀提取出来，创建索引，可以节约索引空间\n\n```mysql\n# n表示取column_name列的前n个数据\nCREATE INDEX idx_XXX ON table_name(column_name(n));\n\n# 计算前缀长度的选择性，越接近1越好\nSELECT COUNT(DISTINCT substring(email, 1, 5)) / COUNT(*) FROM table_name;\n```\n\n**单列索引和联合索引选择**\n\n如果涉及到多个查询条件，推荐使用联合索引，联合索引会更少的回表查询\n\n#### Quetion\n\n![image-20240218221919863](database-mysql/image-20240218221919863.png)\n\n建立id主键，username，password联合索引\n\n* #### **索引设计原则**\n\n![image-20240218224016746](database-mysql/image-20240218224016746.png)\n\n### 3、SQL优化\n\n* #### **插入数据**insert优化\n\n  批量插入而不是单条插入：批量插入只需要建立一次连接即可\n\n  建议手动提交事务：不需要每一次插入时自动开启和关闭事务，而是将所有insert执行结束以后统一关闭\n\n  **建议主键顺序插入**\n\n  大批量插入数据：使用Mysql数据库提供的load指令进行插入\n\n  ```mysql\n  # 如何使用load\n  # 1、连接服务器时加上参数--local-infile\n  mysql --local-infile -u root -p\n  \n  # 2、设置全局参数local_infile为1\n  set global local_infile = 1;\n  \n  # 3、执行load指令将数据加载表结构中\n  load data local infile '文件名' into table '表名' fields teminated by '分割符' lines terminated by '行分隔符\\n';\n  ```\n\n* #### **主键优化**\n\n> InnoDB中表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。\n\n页大小为16kb，每个页至少包含两行数据\n\n主键乱序插入可能会出现页分裂现象，执行删除操作会出现页合并现象\n\n主键设计原则：\n\n​\t满足业务需求的情况下，尽量降低主键的长度\n\n​\t插入时尽量按照主键顺序插入，选择自增主键\n\n​\t尽量不要使用无序的自然主键\n\n​\t业务操作，避免对主键的修改\n\n* **order by优化**\n\n排序方式\n\nUsing filesort：先找到数据再进行排序\n\nUsing index：通过有序索引直接返回，不需要额外排序\n\n默认会对索引进行升序排序\n\n* **limit优化**\n\n对于数据量大的，优化思路为使用覆盖索引+子查询\n\n* count\n\n  count(*)优于count(1)>count(主键)>count(字段)\n\n* #### **update优化**\n\n对需要更新的字段尽可能建立索引，这样如果处于多个事务情况下，只会使用行锁，如果没有建立索引，行锁会升级为表锁，无法进行并行\n\n### 4、视图/存储过程/触发器\n\n> Mysql数据库当中的存储对象\n\n* #### 视图\n\n> 视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。\n\n操作视图中的数据就和操作数据库表一样，可以将视图理解为一张不被存储的虚拟表。\n\n视图当中的数据并不存在，如果往视图里面插入数据，数据将存在基表当中，如果不想给用户表的权限，可以给用户一个视图。 \n\n```mysql\n# 创建视图\nCREATE [OR REPLACE] VIEW 视图名称(列名列表) AS SELECT语句 [WITH CASCADED|LOCAL CHECk OPTION];\n\n# 查询视图\n# 查看创建视图语句\nSHOW CREATE VIEW 视图名称;\n# 查看视图数据\nSELECT * FROM 视图名称...;\n\n# 修改视图\n# 方式一、使用创建的语句，用REPLACE替换掉\nCREATE[OR REPLACE]...\n# 方式二\nALTER VIEW 视图名称(列表名称) AS SELECT ...;\n\n# 删除视图\nDROP VIEW IF EXISTS 视图名称\n```\n\n**视图当中的检查选项**\n\n**CASCADED（向下级联）**\n\n当使用WITH CHECK OPTION子句创建视图时，Mysql会通过视图检查正在更改的每个行。进行校验，所插入的数据是否满足SELECT语句。\n\nMysql中还可以为视图再创建新的视图，新的视图如果有option选项会影响到之前的视图\n\n**LOCAL（不向下级联，只是检查有option的条件）**\n\n**视图的更新和作用**\n\n要使视图可以更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下中任何一项，则该视图不可更新：\n\n聚合函数、DISTINCT、GROUP BY、HAVING、UNION或者UNION ALL\n\n作用：1、可以简化用户对数据的理解，简化用户操作。2、控制用户对表的查看权限。3、数据独立，屏蔽真实表结构。4、可以简化多表联查的操作。\n\n* #### 存储过程\n\n> 存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输\n>\n> 思想上就是数据库SQL语言层面的代码封装与重用，下一次如果执行相同的业务直接调用存储过程\n\n**特点**\t好像跟函数有点像\n\n封装、复用\n\n可以接收参数，也可以返回数据\n\n作用：减少网络交互，提升效率\n\n> 在命令行中，执行创建存储过程的sql时，需要通过关键字`delimiter`指定SQL语句的结束符\n\n```mysql\n# 创建\n# 参数列表为IN/OUT/INOUT 参数名，分别表示参数输入，输出，输入和输出参数\nCREATE PROCEDURE 存储过程名称([参数列表])\nBEGIN\n\t--SQL语句，可以是多条\nEND;\n\n# 调用\nCALL 名称([参数列表]);\n\n# 查看\n# 方法一，查看系统的数据库表，xxx为数据库名\nSELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = 'XXX';\n# 方法二，使用show查看创建过程\nSHOW CREATE PROCEDURE 存储过程名称;\n\n# 删除\nDROP PROCEDURE [IF EXISTS] 存储过程名称;\n\n# 定义结束符为$$\ndelimiter $$\n```\n\n**系统变量**（全局GLOBAL，会话SESSION）\n\n重启以后系统参数会恢复为默认值\n\n永久修改系统参数需要修改/etc/my.cnf中配置\n\n```mysql\n# 查看所有系统变量\nSHOW [SESSION|GLOBAL] VARIABLES;\nSHOW VARIABLES LIKE '..';\n# 查看指定变量\nSELECT @@[SESSION|GLOBAL].系统变量名\n\n# 设置系统变量，默认为SESSION级别\nSET [SESSION|GLOBAL] 变量名=值;\nSET @@[SESSION|GLOBAL].系统变量名 = 值;\n```\n\n**用户自定义变量**\n\n> 作用域为当前连接\n>\n> 变量无需声明，如果拿到的是没有声明的变量，则会获得NULL\n\n```mysql\n# 赋值，可以同时赋值多个变量，用逗号隔开\nSET @var_name = expr;\nSET @var_name := expr;\n\n# SELECT赋值\nSELECT @var_name := expr;\n# 将sql查询的结果赋值给变量\nSELECT 字段名 INTO @var_name FROM 表名;\n\n# 使用\nSELECT @var_name;\n```\n\n**局部变量**\n\n> 在局部生效，需要DECLARE声明，作用域在BEGIN...END块内\n\n```mysql\n# 声明\nDECLARE 变量名 变量类型(数据库数据的类型) [DEFAULT 默认值]\n\n# 赋值\nSET 变量名 = 值;\nSET 变量名 := 值;\nSELECT 字段名 INTO @var_name FROM 表名;\n```\n\n**存储过程相关语法**\n\n> 逻辑语言都在存储过程中定义，可以使用传入的参数\n\n```mysql\n# IF 条件判断\nIF 条件1 THEN\n\t...\nELSEIF 条件2 THEN\n\t...\nELSE\n\t...\nEND IF;\n\n# CASE 条件选择，WHEN后面可以有多种选择\n# 语法一\nCASE case_value\n\tWHEN when_value1 THEN ...\n\tWHEN when_value2 THEN ...\n\tELSE ...\nEND CASE;\n# 语法二\nCASE \n\tWHEN 表达式真 THEN ...\n\tELSE ...\nEND CASE;\n\n# WHILE循环\nWHILE 条件 DO\n\tSQL逻辑\nEND WHILE：\n\n# REPEAT循环，当满足条件时，退出循环\nREPEAT\n\tSQL逻辑...\n\tUNTIL 条件\nEND REPEAT;\n\n# LOOP循环\n# LOOP实现的是简单循环\n# LEAVE：配合循环使用，退出循环，作用类似于break\n# ITERATE：必须在循环中使用，作用类似于CONTINUE\n[begin_label:] LOOP\n\tSQL逻辑\n\t\nEND LOOP[end_label]\n\n# 退出循环\nLEAVE label;\n# 跳过本次进入下一次循环\nITERATE label;\n```\n\n**游标Cursor**\n\n游标（Cursor）是一种用于在存储过程或函数中遍历结果集的机制。游标允许逐行访问结果集，并在每行上执行相应的操作\n\n通常情况下，当执行一个查询语句时，MySQL 会返回一个结果集，该结果集包含了查询返回的所有行。以使用游标来逐行处理这个结果集，而不是一次性获取所有结果。这在处理大量数据或需要逐行处理结果的情况下非常有用\n\n```mysql\n# 声明游标、打开游标、获取下一行、关闭游标\nDELIMITER //\n\nCREATE PROCEDURE process_users()\nBEGIN\n    DECLARE done INT DEFAULT FALSE;\n    DECLARE user_id INT;\n    DECLARE user_name VARCHAR(255);\n\n    -- 声明游标\n    DECLARE user_cursor CURSOR FOR \n        SELECT id, name FROM users;\n\n    -- 打开游标\n    OPEN user_cursor;\n\n    -- 循环遍历结果集\n    read_loop: LOOP\n        -- 获取下一行数据\n        FETCH user_cursor INTO user_id, user_name;\n        IF done THEN\n            LEAVE read_loop;\n        END IF;\n        \n        -- 处理当前行数据\n        -- 这里可以执行相应的操作，如输出到日志或进行其他逻辑处理\n        SELECT CONCAT('User ID: ', user_id, ', User Name: ', user_name);\n\n    END LOOP;\n\n    -- 关闭游标\n    CLOSE user_cursor;\n\nEND //\n\nDELIMITER ;\n```\n\n* #### 存储函数\n\n> 有返回值的存储过程，存储函数的参数只能时IN类型’\n\n```mysql\n# 语法结构\nCREATE FUNCTION 存储函数名称([参数列表])\nRETURNS type [characteristic...]\nBEGIN\n\t--SQL语句\n\tRETURN ...;\nEND;\n\ncharacteristics存储参数的特性\nDETERMINISTIC : 相同的输入参数总是产生相同的结果\nNO SQL : 不包含SQL语句\nREADS SQL DATA : 包含读取数据的语句，但不包含写入数据的语句\n```\n\n* #### 触发器\n\n> 在insert/update/delete之前或者之后，触发并执行触发器中定义的SQL语句集合。\n>\n> 使用别名OLD和NEW来引用触发器中发生变化的记录内容\n>\n> 触发器只支持行级触发，不支持语句级别触发：如果一个UPDATE语句影响了5行，则触发器会被出发5次\n\n|   触发器类型   |                       NEW和OLD                       |\n| :------------: | :--------------------------------------------------: |\n| INSERT型触发器 |            NEW表示将要或者已经新增的数据             |\n| UPDATE型触发器 | OLD表示修改之前的数据，NEW表示将要或已经修改后的数据 |\n| DELETE型触发器 |            OLD表示将要或者已经删除的数据             |\n\n```mysql\n# 创建触发器\nCREATE TRIGGER trigger_name\nBEFORE/AFTER(在之前还是之后) INSERT/UPDATE/DELETE(触发器类型)\nON tbl_name FOR EACH ROW --行级触发器\nBEGIN\n\ttrigger_stmt; # 触发器逻辑\nEND;\n\n# 查看\nSHOW TRIGGERS;\n\n# 删除，数据库中的触发器\nDROP TRIGGER [schema_name.]trigger_name;\n```\n\n\n\n### 5、锁\n\n> 锁是计算机协调多个进程或线程并发访问某一资源的机制，用于保证数据的一致性和有效性。\n\n* 全局锁\n\n对整个数据库进行加锁，加锁以后整个实例就处于只读状态，后续的DML的写语句，DDL语句以及更新操作的事务提交语句都会被阻塞\n\n做数据库的全库逻辑备份的时候，会对所有的表进行锁定\n\n```mysql\n# 为表加全局锁\nFLUSH TABLES WITH READ LOCK;\n\n# 备份数据库\nmusqldump -uroot -p1234 数据库>文件名\n\n# 释放全局锁\nUNLOCK TABLES;\n```\n\n* 表级锁\n\n每次操作会锁住整张表，发生锁冲突的概率最高，并发度最低\n\n**表锁**\n\n> 表共享读锁：对于所有客户端的连接都只能读，不能写\n>\n> 表独占写锁：对于获取锁资源的客户端可以写，其他客户端不能进行读也不能执行写会被阻塞\n\n语法\n\n1、加锁：lock tables 表名... read/write\n\n2、释放锁：unlock tables /  客户端断开连接\n\n**元数据锁**（meta data lock）\n\n> MDL加锁过程是系统自动控制的，无需显示使用，在访问一张表的时候会自动加上\n>\n> 元数据锁就是对表结构进行加锁\n\n当对一张表进行增删改查的时候，自动会加上MDL读锁，当对表结构进行变更时，会自动加上MDL写锁\n\n|                   对应SQL                   |                锁类型                 |\n| :-----------------------------------------: | :-----------------------------------: |\n|          lock table xx read/write           | SHARED_READ_ONLY/SHARED_NO_READ_WRITE |\n|    select、select .. lock in share mode     |              SHARED_READ              |\n| insert、update、delet、sekect...from update |             SHARED_WRITE              |\n|               alter table...                |              EXCLUSIVVE               |\n\n\n\n**意向锁**\n\n![image-20240222075448991](database-mysql/image-20240222075448991.png)\n\n![image-20240222075706155](database-mysql/image-20240222075706155.png)\n\n* 行级锁\n\n> 应用在InnoDB存储引擎当中\n\nInnoDB的数据时基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁\n\n**行锁**\n\n锁定单个行记录的锁，防止其他事务对此进行update和delete，在RC、RR隔离级别都支持\n\n1、共享锁（S）：允许一个事务去读取一行，阻止其他事务获得相同数据集的排它锁，其他事务能读不能写\n\n2、排它锁（X）：允许获取排它锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排它锁，其他事务不能写也不能读\n\n|              SQL              |  行锁类型  |   说明   |\n| :---------------------------: | :--------: | :------: |\n|            INSERT             |   排它锁   | 自动加锁 |\n|            UPDATE             |   排它锁   | 自动加锁 |\n|            DELETE             |   排它锁   | 自动加锁 |\n|            SELECT             | 不加任何锁 |          |\n| SELECT ... LOCK IN SHARE MODE |   共享锁   | 手动加锁 |\n|     SELECT ... FOR UPDATE     |   排它锁   |   手动   |\n\n**间隙锁**\n\n锁定索引记录间隙，确保索引记录间隙不变，防止其他事务在这个间隙执行insert，产生幻读，在RR级别下支持\n\n**临建锁**（next-key）\n\n同时锁住行记录也锁住间隙\n\n```mysql\n# 查询数据库中的锁\nselect object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;\n```\n\n\n\n### 6、InnoDB引擎\n\n* #### **逻辑存储结构**\n\n表空间（ibd文件）：一个mysql实例可以对应多个表空间，用于存储记录、索引等数据\n\n段：分为数据段、索引段、回滚段，InnoDB是索引组织表，数据段就是B+书的叶子节点，索引段即是B+书的非叶子节点，段用来管理多个区\n\n区：表空间的单元结构，每个区的大小为1M，一个区中一共有64个连续的页\n\n页：页大小16kB，是InnoDB存储引擎磁盘管理的最小单元，保证页的连续性，会申请4-5个区\n\n![image-20240223204149464](database-mysql/image-20240223204149464.png)\n\n* #### 架构\n\n![innodb-architecture-8-0](database-mysql/innodb-architecture-8-0.png)\n\n**内存结构**\n\n> 磁盘结构存储的是一些表空间和表数据文件，包括日志表空间，系统表空间，撤销表空间，重做表空间等等\n\nbuffer pool缓存池\n\n缓冲区是内存中的一个区域，可以缓冲存储磁盘上经常要操作的数据，利用局部性原理减少磁盘IO，加快处理速度\n\n缓冲池以page页为单位，底层采用链表数据结构管理page\n\nchange buffer更改缓存，**针对非唯一二级索引页**\n\n当需要对数据进行变更，即执行DML语句时，如果buffer pool中不存在当前数据page，不会直接操作磁盘，会先将数据变更缓存在change buffer在未来数据被读取的时候，再将数据合并恢复到buffer pool中\n\nAdaptive Hash Index自适应哈希索引\n\nlog buffer日志缓存区\n\n**后台线程**\n\n> 作用：将InnoDB缓冲区当中的数据在合适的时间写入到磁盘当中\n\n1、Master Thread\n\n核心后台线程，负责调度其他线程，将缓冲池中的数据异步刷新到磁盘当中，保持数据的一致性\n\n2、IO Thread\n\n采用的是AIO（异步非阻塞IO）来处理IO请求\n\n4个读线程、4个写线程、1个日志线程、1个插入缓存线程（写缓冲区刷新到磁盘）\n\n3、Purge Thread\n\n回收事务已经提交的undo log，在事务提交之后，undo log可能不用了，就用它来回收\n\n4、Page Cheaner Thread\n\n协助Master Thread刷新脏页到磁盘的线程\n\n* #### 事务原理\n\n事务的原子性、一致性和持久性是通过日志文件来保证的，包括redo.log和undo.log\n\n事务的隔离性是通过锁+MVCC（多版本并发控制）来进行保证的\n\n**redo log**事务的持久性（事务提交后数据的改变是永久的）\n\n重做日志，记录事务提交时数据页的物理修改，用来实现事务的持久性(事务一旦提交，对数据的改变时持久的）\n\n当系统在执行Mysql的DML语句时，会先从数据库缓存中查找是否有对应的页面，如果在缓存当中则对数据进行修改，这种在缓冲中修改后但还未写入磁盘的数据页，叫做脏页，后通过后台进程写入到磁盘当中，如果在写入的过程中发生异常，就会出现持久性消失的现象\n\nredo log会把数据页的变化记录到redo log当中，当事务提交时，会把redo log刷新到磁盘当中，可以通过log对数据进行恢复，如果redo log刷新页失败，则事务执行也就失败，不影响一致性\n\n**undo log**事务的原子性（事务是最小操作单位，要么全部成功，要么全部失败）\n\n回滚日志，用于记录数据被修改前的信息，提供回滚和MVCC。当执行DML语句时，会记录数据变化前的数据长什么样，在回滚日志中，记录的时执行sql的反向操作，逆操作\n\nundo log存放在段当中，回滚段\n\n* #### MVCC多版本并发控制\n\n> Mutil-Version Concurrency Control，多版本并发控制。维护一个数据的多个版本，使得读写此操作没有冲突。依赖于数据库记录中的三个隐式字段、undo log日志、readView\n\n**相关概念**\n\n当前读：读取的时记录的最新版本。因为Mysql的默认隔离界别是RR（repeatable read）可重复读，所以当另一个事务对数据进行修改时，当前事务读到的数据就不是当前最新的版本。要想读到最新版本，可以通过select .. lock in share mode,select .. for update来完成\n\n快照读：正常的select（不加锁）就是快照读，读取的是数据的可见版本\n\nRead Committed：每一次select 都会生成一个快照读\n\nRepeatable Read：开始事务后第一个select才是产生快照读的地方，后面的select都是查询快照\n\nSerializable：快照读会退化为当前读\n\n**记录当中的隐藏字段**\n\nDB_TRX_ID：最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID\n\nDB_ROLL_PTR：回滚指针，指向这条记录的上一个版本，用于配合undo log\nDB_ROW_ID：隐藏主键，表结构没有主键，则会自动生成隐藏字段\n\n**undo log日志**\n\n如果使用insert的时候产生的日志只在回滚的时候需要，在事务提交后，可以立即删除\n\n如果使用的是update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读的时候也需要，不会立即被删除\n\n![image-20240224160500080](database-mysql/image-20240224160500080.png)\n\n**ReadView**\n\n读视图：快照读SQL执行时MVCC提取数据的一句，记录并维护系统当前活跃的事务id\n\n字段，通过对比当前事务的id：trx_id和下面的id进行对比来实现版本访问控制\n\n|      字段      |              含义              |\n| :------------: | :----------------------------: |\n|     m_ids      |      当前活跃的事务ID集合      |\n|   min_trx_id   |         最小活跃事务ID         |\n|   max_trx_id   | 预分配事务ID，当前最大事务ID+1 |\n| creator_trx_id |     ReadView创建者的事务ID     |\n\n![image-20240224161313751](database-mysql/image-20240224161313751.png)\n\n**Read Commited**读提交下的规则\n\n> 事务中每一次执行快照读时都会生成ReadView\n\n![image-20240224162152111](database-mysql/image-20240224162152111.png)\n\n通过上面四条规则可以找到最新已经提交的事务版本\n\n**Repeatable Read**可重复读的情况\n\n> 仅在事务中第一次执行快照读的时候生成ReadView，后续会复用该ReadView\n\n![image-20240224162359110](database-mysql/image-20240224162359110.png)\n\n隔离性：保证事务不在外部并发操作影响下独立完成，通过MVCC+锁来保证\n\n一致性：事务完成时，所有数据都保持一致，通过日志实现\n\n![image-20240224162626695](database-mysql/image-20240224162626695.png)\n\n\n\n### 7、MySQL管理\n\n* 系统数据库\n\n|       数据库       |                             含义                             |\n| :----------------: | :----------------------------------------------------------: |\n|       mysql        |   存储Mysql服务器正常运行所需要的各种信息（用户、权限等）    |\n| information_schema | 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型以及访问权限 |\n| performance_schema | 为Mysql服务器运行时状态提供了一个底层监控功能，用于收集数据库服务器性能参数 |\n|        sys         |             方便开发人员进行性能调优和诊断的视图             |\n\n* 常用工具\n\n```mysql\n# mysql [option] [database]\nmysql\n\t-u, --user=\t\t # 指定用户名\n    -p, --password=\t\t# 指定密码\n    -h, --host=\t\t# 指定服务器ip或域名\n    -p, --port=\t\t# 指定端口号\n    -e, --execute=\t# 执行sql语句并推出\n```\n\nmysqladmin\n\n​\t执行管理操作的客户端程序\n\n​\t--help查看帮助文档\n\nmysqlbinlog\n\n​\t如果查看一些二进制文本的数据，使用这个可以进行数据查看\n\nmysqlshow\n\n​\t客户端对象查找工具，可以用于查找存在哪些数据库、数据库中的表、表中的列或者索引\n\n​\t--count 显示数据库及表的统计信息\n\n​\t-i 显示指定数据库或指定表的状态信息\n\n**mysqldump**\n\n​\t用于备份数据库或在不同数据库之间进行数据迁移\n\n**mysqlimport/source**\n\n​\t用于数据的导入工具\n\n\n\n## QA\n\n1、InnoDB数据页中的数据存储\n\n2、B+树是如何进行查询的\n\n3、MySql单表最大限制，为什么\n\n4、索引失效有哪些\n\n5、count（*）和count（1）哪个性能好一些\n","slug":"database-mysql","published":1,"updated":"2024-06-05T09:03:03.634Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttq001a08jvaa6v01cv","content":"<h2 id=\"数据库-Mysql\"><a href=\"#数据库-Mysql\" class=\"headerlink\" title=\"数据库-Mysql\"></a>数据库-Mysql</h2><blockquote>\n<p>Mysql数据库的关键词：事务、存储引擎、索引、SQL优化、<strong>锁、日志、主从复制、读写分离、分库分表</strong></p>\n</blockquote>\n<h2 id=\"数据库基础\"><a href=\"#数据库基础\" class=\"headerlink\" title=\"数据库基础\"></a>数据库基础</h2><h3 id=\"1、Mysql概述\"><a href=\"#1、Mysql概述\" class=\"headerlink\" title=\"1、Mysql概述\"></a>1、Mysql概述</h3><p>关系型数据库：建立在关系模型基础上，由多张互连接的二维表组成的数据库</p>\n<p>特点：使用表存储数据，便于维护；使用sql语句操作，使用方便</p>\n<p><strong>MySQL数据模型</strong></p>\n<blockquote>\n<p>1、客户端通过与数据库管理系统进行连接</p>\n<p>2、使用sql语句通过数据库管理系统对指定的数据库进行增删改查</p>\n<p>3、一个数据库模型中可以对多个数据库进行管理，一个数据库中可以拥有多个表</p>\n</blockquote>\n<p>// TODO数据库模型的图</p>\n<h3 id=\"2、SQL\"><a href=\"#2、SQL\" class=\"headerlink\" title=\"2、SQL\"></a>2、SQL</h3><p><strong>SQL分类</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分类</th>\n<th>全称</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DDL</td>\n<td>Data Definition Language</td>\n<td>数据库定义语句，定义数据库对象，数据库，表，字段等</td>\n</tr>\n<tr>\n<td>DML</td>\n<td>Data Manipulation Language</td>\n<td>数据库操作语句，用于对数据库表中的数据进行增增删改</td>\n</tr>\n<tr>\n<td>DQL</td>\n<td>Data Query Language</td>\n<td>数据库查询语句，查询数据库表中的记录</td>\n</tr>\n<tr>\n<td>DCL</td>\n<td>Data Control Language</td>\n<td>数据库控制语句，创建数据库用户，控制数据库的访问权限</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><h4 id=\"DDL\"><a href=\"#DDL\" class=\"headerlink\" title=\"DDL\"></a>DDL</h4><p><strong>数据库层次</strong></p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询所有数据库表格<br>SHOW DATABASES;<br># 查询当前所在的数据库<br>SELECT DATABASE();<br># 创建数据库，方括号可以省略<br>CREATE DATABASE [IF NOT EXISTS] 数据库名 [COLLATE 排序规则]<br># 删除数据库<br>DROP DATABASE [IF EXISTS] 数据库名<br># 使用数据库，切换到数据库当中<br>USE 数据库名<br></code></pre></td></tr></table></figure>\n<p>​        表结构</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看所有表<br>SHOW TABLES;<br># 查询表结构<br>DESC 表名<br># 查询指定表的建表语句<br>SHOW CREATE TABLE 表名;<br></code></pre></td></tr></table></figure>\n<p>​        MySQL中的数据类型</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>描述</th>\n<th>大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>TINYINT</td>\n<td>微小整数，有符号或无符号（UNSIGNED）</td>\n<td>1 字节</td>\n</tr>\n<tr>\n<td>SMALLINT</td>\n<td>小整数，有符号或无符号</td>\n<td>2 字节</td>\n</tr>\n<tr>\n<td>MEDIUMINT</td>\n<td>中等整数，有符号或无符号</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>INT 或 INTEGER</td>\n<td>整数，有符号或无符号</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>BIGINT</td>\n<td>大整数，有符号或无符号</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>FLOAT(M,D)</td>\n<td>单精度浮点数，M 是总位数，D 是小数位数</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>DOUBLE(M,D)</td>\n<td>双精度浮点数，M 是总位数，D 是小数位数</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>DECIMAL(M,D)</td>\n<td>定点数，M 是总位数，D 是小数位数</td>\n<td>取决于 M 和 D</td>\n</tr>\n<tr>\n<td>DATE</td>\n<td>日期 YYYY-MM-DD</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>TIME</td>\n<td>时间 HH:MM:SS</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>DATETIME</td>\n<td>日期和时间</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>TIMESTAMP</td>\n<td>时间戳</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>CHAR(N)</td>\n<td><strong>定长</strong>字符串，最大长度为 N</td>\n<td>最大 255 字节</td>\n</tr>\n<tr>\n<td>VARCHAR(N)</td>\n<td><strong>变长</strong>字符串，最大长度为 N</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>TEXT</td>\n<td>变长文本，最大长度为 65,535 字节</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>BLOB</td>\n<td>二进制大对象，最大长度为 65,535 字节</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>ENUM</td>\n<td>枚举类型</td>\n<td>1 或 2 字节，取决于成员数量</td>\n</tr>\n<tr>\n<td>SET</td>\n<td>集合类型</td>\n<td>1、2、3、4 或 8 字节，取决于成员数量</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>创建表：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">CREATE TABLE member(<br>    number INT COMMENT &#x27;编号&#x27;,<br>    id CHAR(10) COMMENT &#x27;员工工号&#x27;,<br>    name VARCHAR(10) COMMENT &#x27;员工姓名&#x27;,<br>    gender CHAR(4) COMMENT &#x27;员工性别&#x27;,<br>    age INT UNSIGNED COMMENT &#x27;年龄&#x27;,<br>    id_number CHAR(18) COMMENT &#x27;身份证号&#x27;,<br>    time DATE COMMENT &#x27;入职时间&#x27;<br>)<br></code></pre></td></tr></table></figure>\n<p><strong>表结构的修改</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 添加字段<br>ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释][约束];<br><br># 修改字段和字段类型<br>ALTER TABLE 表明 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释][约束]<br><br># 删除字段<br>ALTER TABLE 表名 DROP 字段名;<br><br># 修改表名<br>ALTER TABLE 表名 RENAME TO 新表名;<br><br># 删除表<br>DROP TABLE [IF EXSITS] 表名;<br># 删除指定表并重新创建该表，清空数据<br>TRUNCATE TABLE 表名;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"DML（数据操作语言）\"><a href=\"#DML（数据操作语言）\" class=\"headerlink\" title=\"DML（数据操作语言）\"></a>DML（数据操作语言）</h4></li>\n</ul>\n<p><strong>添加数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 给指定字段添加数据<br>INSERT INTO 表名(字段名1, 字段名2, ...) VALUES (值1, 值2, ...);<br><br># 给全部字段添加数据<br>INSERT INTO 表名 VALUES(值1, 值2, ...);<br></code></pre></td></tr></table></figure>\n<p><strong>修改数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 修改数据<br>UPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ...[WHERE 条件];<br></code></pre></td></tr></table></figure>\n<p><strong>删除数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 删除数据<br>DELETE FROM 表名 [WHERE 条件];<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"DQL\"><a href=\"#DQL\" class=\"headerlink\" title=\"DQL\"></a>DQL</h4><blockquote>\n<p>数据库查询语言，用来查询数据库中的表的记录</p>\n<p>SELECT后面加上\\G可以将某一行转化为一列查看</p>\n</blockquote>\n</li>\n</ul>\n<p><strong>语法结构</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT<br>\t字段列表<br>FROM<br>\t表名列表<br>WHERE<br>\t条件列表(条件查询)<br>GROUP BY<br>\t分组字段列表(分组查询)<br>HAVING<br>\t分组后条件列表<br>ORDER BY<br>\t排序字段列表<br>LIMIT<br>\t分页参数<br></code></pre></td></tr></table></figure>\n<p><strong>基本查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段1 [AS 别名]，字段2 [AS 别名]， FROM 表名;<br><br># 去重<br>SELECT DISTINCT 字段列表 FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>条件查询</strong></p>\n<p>条件运算符</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">比较运算符</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">&lt;&gt;或!=</td>\n<td style=\"text-align:center\">不等于</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BETWEEN … AND …</td>\n<td style=\"text-align:center\">在某个范围之内</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IN(…)</td>\n<td style=\"text-align:center\">在in之后的列表中的值，多选一</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LIKE 占位符</td>\n<td style=\"text-align:center\">模糊匹配(_匹配单个字符，%匹配任意个字符)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IS NULL</td>\n<td style=\"text-align:center\">是NULL</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>聚和函数</strong></p>\n<blockquote>\n<p>将一列数据作为一个整体，进行纵向计算。</p>\n</blockquote>\n<p>所有的null值不参与聚合函数的计算</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">count</td>\n<td style=\"text-align:center\">统计数量</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">max</td>\n<td style=\"text-align:center\">最大值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">min</td>\n<td style=\"text-align:center\">最小值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">avg</td>\n<td style=\"text-align:center\">平均值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">sum</td>\n<td style=\"text-align:center\">求和</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 聚合函数(字段列表) FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>分组查询</strong></p>\n<blockquote>\n<p>在where中不可以使用聚合函数，在having中可以使用聚合函数</p>\n<p>分组之前过滤用where，分组之后过滤条件用having</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表\tFROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];<br></code></pre></td></tr></table></figure>\n<p>执行顺序：where &gt; 聚合函数 &gt; having</p>\n<p><strong>排序查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2<br></code></pre></td></tr></table></figure>\n<p>排序方式： ASC升序（默认），DESC降序</p>\n<p><strong>分页查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表 FROM 表名 LIMIT 起始索引,查询记录数;<br></code></pre></td></tr></table></figure>\n<p>显示从起始索引开始的记录数条的查询结果</p>\n<p><strong>DQL执行顺序</strong></p>\n<p>FROM &gt; WHERE &gt; GROUP BY &gt; SELECT &gt; ORDER BY &gt; LIMIT</p>\n<ul>\n<li><h4 id=\"DCL\"><a href=\"#DCL\" class=\"headerlink\" title=\"DCL\"></a>DCL</h4></li>\n</ul>\n<blockquote>\n<p>数据控制语句，用来管理数据库用户，控制数据库访问权限</p>\n</blockquote>\n<p><strong>DCL用户管理</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询用户<br>USE mysql;<br>SELECT * FROM user;<br><br># 创建用户，主机名换成&quot;%&quot;表示可以在任意主机访问数据库<br>CREATE USER &#x27;用户名&#x27;@&#x27;主机名&#x27; IDENTIFIED BY &#x27;密码&#x27;;<br><br># 修改用户密码<br>ALTER USER &#x27;用户名&#x27;@&#x27;主机名&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;<br><br># 删除用户<br>DROP USER &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br></code></pre></td></tr></table></figure>\n<p><strong>权限控制</strong></p>\n<p>常用权限</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">权限</th>\n<th style=\"text-align:center\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ALL, ALL PRIVILEGES</td>\n<td style=\"text-align:center\">所有权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT</td>\n<td style=\"text-align:center\">查询数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">INSERT</td>\n<td style=\"text-align:center\">插入数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE</td>\n<td style=\"text-align:center\">修改数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE</td>\n<td style=\"text-align:center\">删除数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ALTER</td>\n<td style=\"text-align:center\">修改表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DROP</td>\n<td style=\"text-align:center\">删除数据库/表/视图</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CREATE</td>\n<td style=\"text-align:center\">创建数据库/表</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询权限<br>SHOW GRANTS FOR &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br><br># 授予权限<br>GRANT 权限列表 ON 数据库名.表名(*.*所有表) TO &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br><br># 撤销权限<br>REVOKE 权限列表 ON 数据库名.表名 FROM &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"3、函数\"><a href=\"#3、函数\" class=\"headerlink\" title=\"3、函数\"></a>3、函数</h3><ul>\n<li><strong>字符串函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CONCAT(S1,S2, … Sn)</td>\n<td style=\"text-align:center\">字符串拼接，将S1-Sn拼接成一个字符串</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LOWER(str)</td>\n<td style=\"text-align:center\">将字符串str全部转为小写</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPPER(str)</td>\n<td style=\"text-align:center\">将字符串全部转为大写</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LPAD(str, n, pad)</td>\n<td style=\"text-align:center\">左填充，用字符串pad对str的左边进行填充，达到n个字符串长度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RPAD(str, n,  pad)</td>\n<td style=\"text-align:center\">右填充</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">TRIM(str)</td>\n<td style=\"text-align:center\">去掉字符串头部和尾部的空格</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SUBSTRING(str, start, len)</td>\n<td style=\"text-align:center\">返回从字符串str从start起的len长度的字符串</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 函数;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><strong>数值函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CEIL(x)</td>\n<td style=\"text-align:center\">向上取整</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">FLOOR(x)</td>\n<td style=\"text-align:center\">向下取整</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MOD(x, y)</td>\n<td style=\"text-align:center\">返回x/y的模</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RAND()</td>\n<td style=\"text-align:center\">返回0~1内的随机数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ROUND(x, y)</td>\n<td style=\"text-align:center\">求参数x的四舍五入的值，保留y位小数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>日期函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CURDATE()</td>\n<td style=\"text-align:center\">返回当前日期</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CURTIME()</td>\n<td style=\"text-align:center\">返回当前时间</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">NOW()</td>\n<td style=\"text-align:center\">返回当前日期和时间</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">YEAR(date)</td>\n<td style=\"text-align:center\">获取指定date的年份</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MONTH(date)</td>\n<td style=\"text-align:center\">获取指定date的月份</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DAY(date)</td>\n<td style=\"text-align:center\">获取指定date的日期</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DATE_ADD(date, INTERVAL expr type)</td>\n<td style=\"text-align:center\">返回上一个日期加上时间间隔expr以后的时间值，type(year,month,day)指定年月天</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DATEDIFF(date1, date2)</td>\n<td style=\"text-align:center\">返回起始时间date1和结束时间date2之间的天数，第一个时间减去第二个时间</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>流程函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">IF(value, t. f)</td>\n<td style=\"text-align:center\">如果value为true，返回t，否则返回f</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IFNULL(value1, value2)</td>\n<td style=\"text-align:center\">如果value1不为空，返回value1，否则返回value2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CASE WHEN [val] THEN [res1] … ELSE [ default ] END</td>\n<td style=\"text-align:center\">如果val1为true，返回res1，…否则返回default默认值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CASE [expr] WHEN [val1] THEN [res1] … ELSE [default] END</td>\n<td style=\"text-align:center\">如果expr的值等于val1，返回res1，…否则返回default默认值</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"4、约束\"><a href=\"#4、约束\" class=\"headerlink\" title=\"4、约束\"></a>4、约束</h3><p>作用于表中字段上的规则，用于限制存储在表中的数据</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">约束</th>\n<th style=\"text-align:center\">描述</th>\n<th style=\"text-align:center\">关键字</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">非空约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">唯一约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">主键约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">默认约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">检查约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">外键约束</td>\n<td style=\"text-align:center\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"5、多表查询\"><a href=\"#5、多表查询\" class=\"headerlink\" title=\"5、多表查询\"></a>5、多表查询</h3><ul>\n<li><p><strong>多表关系</strong></p>\n<p>一对多：在多的一方建立外键，指向一的一方的主键</p>\n</li>\n</ul>\n<p>​        多对多：建立第三张中间表，中间表至少包含两个外键，分别关联两方的主键</p>\n<p>​        一对一：用于做单表拆分，基础字段放在一张表，详情字段放在另一张表。在任意一方加入外键，关联另一方的主键，并设置外键为唯一（UNIQUE）</p>\n<ul>\n<li><p><strong>多表查询</strong></p>\n<ul>\n<li><p>内连接</p>\n<blockquote>\n<p>相当于查询A、B交集部分数据</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 隐式内连接<br>SELECT 字段列表 FROM 表1，表2 WHERE 条件...;<br><br># 显示内连接<br>SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>外连接</p>\n<blockquote>\n<p>左外连接：查询左表所有数据，以及两张表交集部分数据，将左表的数据和右表的部分数据连接起来</p>\n<p>右外连接：查询右表所有数据，以及两张表交集部分数据</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 左外连接，表1所有数据以及和表2交集部分的数据<br>SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件;<br><br># 右外连接，表2所有数据以及和表1交集部分的数据<br>SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>自连接</p>\n<blockquote>\n<p>自连接：当前表与自身的连接查询，自连接必须使用表别名</p>\n</blockquote>\n</li>\n<li><p>联合查询-union，union all</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 把多次查询的结果合并起来，形成一个新的查询结果集<br># ALL去掉以后会对结果进行去重<br>SELECT 字段列表 表A<br>UNION [ALL]<br>SELECT 字段列表 表B;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>子查询</strong></p>\n<ul>\n<li><p>标量子查询，子查询返回一个标量</p>\n</li>\n<li><p>列子查询，子查询返回一列</p>\n<p>| 操作符 |                 描述                 |<br>| :——: | :—————————————————: |<br>|   IN   |     在指定的集合范围之内，多选一     |<br>| NOT IN |          不在指定的范围之内          |<br>|  ANY   | 子查询返回列表中，有任意一个满足即可 |<br>|  SOME  |              与ANY等同               |<br>|  ALL   |   子查询返回列表的所有值都必须满足   |</p>\n</li>\n<li><p>行子查询，子查询返回的结果是一行</p>\n<p>此时column1可以使用(column1， column2)聚合成多个参数</p>\n<p>操作符：=、&lt;&gt;、IN、NOT IN</p>\n</li>\n<li><p>表子查询，子查询的返回结果是一个表，可以和行子查询加上列子查询的操作符使用，表可以放到from后面</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 对于子查询，可以将问题拆解成多个不同的查询步骤<br>SELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);<br></code></pre></td></tr></table></figure>\n<h3 id=\"6、事务\"><a href=\"#6、事务\" class=\"headerlink\" title=\"6、事务\"></a>6、事务</h3><blockquote>\n<p>一组操作的集合，是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，这些操作要么<strong>同时成功，要么同时失败</strong></p>\n<p>默认Mysql的事务是自动提交的，当执行一条DML语句，Mysql会立即隐式的提交事务</p>\n</blockquote>\n<ul>\n<li><strong>事务操作</strong></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看/设置事务提交方式<br>SELECT @@autocommit;<br># 事务设置为手动提交<br>SET @@autocommit = 0;<br><br># 提交事务<br>COMMIT;<br><br># 回滚事务<br>ROLLBACK;<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 不修改事务的提交方式操作事务<br># 开启事务<br>START TRANSACTION 或 BEGIN;<br><br># 提交事务<br>COMMIT;<br><br># 回滚事务<br>ROLLBACK;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p><strong>事务四大特性</strong></p>\n<ul>\n<li>原子性(Atomicity)：事务时不可分割的最小操作单元，要么全部成功，要么全部失败</li>\n<li>一致性(Consistency)：事务完成时，必须使所有的数据都保持一致状态</li>\n<li>隔离性(Isolation)：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行</li>\n<li>持久性(Durability)：事务一旦提交或者回滚，它对数据库中的数据改变就是永久的</li>\n</ul>\n</li>\n<li><p><strong>并发事务问题</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">问题</th>\n<th style=\"text-align:center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">脏读</td>\n<td style=\"text-align:center\">一个事务读到另一个事务还没有提交的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">不可重复读</td>\n<td style=\"text-align:center\">一个事务先后读取同一条记录，但两次读取的数据不同，称为不可重复读</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">幻读</td>\n<td style=\"text-align:center\">一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这一行数据已经存在</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>事务隔离级别</strong></p>\n<blockquote>\n<p>读未提交、读已提交、可重复读、串行化</p>\n<p>√表示会出现这个问题，×表示不会出现这个问题</p>\n</blockquote>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">隔离级别</th>\n<th style=\"text-align:center\">脏读</th>\n<th style=\"text-align:center\">不可重复读</th>\n<th style=\"text-align:center\">幻读</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Read uncommitted</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Read committed</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Repeatable Read</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Serializable</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n</tr>\n</tbody>\n</table>\n</div>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看事务的隔离级别<br>SELECT @@TRANSACTION_ISOLATION;<br><br># 设置事务隔离级别<br>SET [SESSION(只对当前窗口有效)|GLOBAL] TRANSACTION ISOLATION LEVEL &#123;隔离级别&#125;<br></code></pre></td></tr></table></figure>\n<p>  事务的隔离界别越高，数据越安全，但是性能越低</p>\n<h2 id=\"数据库进阶\"><a href=\"#数据库进阶\" class=\"headerlink\" title=\"数据库进阶\"></a>数据库进阶</h2><h3 id=\"1、存储引擎\"><a href=\"#1、存储引擎\" class=\"headerlink\" title=\"1、存储引擎\"></a>1、存储引擎</h3><ul>\n<li><p>Mysql体系结构 </p>\n<p>连接层：完成一些类似于连接处理、授权认证及相关的安全方案</p>\n<p>服务层：主要完成大多数的核心服务功能</p>\n<p>引擎层：负责mysql中数据的存储和提取，服务器通过API和存储引擎进行通信</p>\n<p>存储层：将数据存储在文件系统之上，并完成与存储引擎的交互</p>\n<img src=\"/2024/02/10/database-mysql/Mysql.png\" class=\"\" title=\"Mysql\">\n</li>\n<li><p>存储引擎</p>\n<blockquote>\n<p>存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎时基于表的，而不是基于库的。一个数据库的不同的表可以选择不同的存储引擎</p>\n<p>Mysql默认InnoDB</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询支持的存储引擎<br>show engines;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>InnoDB</p>\n<ul>\n<li>DML操作遵循ACID模型，支持事务</li>\n<li>行级锁，提高并发访问性能</li>\n<li>支持外键，保证事务的完整性和正确性</li>\n</ul>\n<p>文件：每个表对应一个.ibd文件，代表表空间文件，可以通过命令<code>idb2sdi 文件名</code>查看表结构json文件格式</p>\n<img src=\"/2024/02/10/database-mysql/image-20240216162915509.png\" class=\"\" title=\"image-20240216162915509\">\n</li>\n<li><p>MyISAM</p>\n<ul>\n<li>不支持事务，不支持外键</li>\n<li>支持表锁、不支持行锁</li>\n<li>访问速度快</li>\n</ul>\n<p>文件.MYD（数据），.MYI（索引），.sdi（表结构）</p>\n</li>\n<li><p>Memory</p>\n<ul>\n<li>表数据存储在内存当中，收到硬件问题或断电影响只能作为临时表或者缓存使用</li>\n<li>内存存放</li>\n<li>hash索引（默认）</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/image-20240216163439353.png\" class=\"\" title=\"image-20240216163439353\">\n<ul>\n<li><p>存储引擎选择</p>\n<p>InnoDB：如果对事务的完整性有比较高的要求，在并发情况下要求事务的一致性，数据操作除了插入和查询意外，还包括很多的更新、删除操作，InnoDB引擎比较合适</p>\n<p>MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性和并发现要求不是很高。<strong>这个场景被Nosql数据库MongoDB替代了</strong></p>\n<p>MEMORY：将所有数据保存在内存当中，访问速度快，通常用于临时表以及缓存。MEMORY对表的大小有限制，太大的表无法缓存在内存中。<strong>这个场景被Redis替代了</strong></p>\n</li>\n</ul>\n<h3 id=\"2、索引\"><a href=\"#2、索引\" class=\"headerlink\" title=\"2、索引\"></a>2、索引</h3><ul>\n<li><p><strong>索引概述</strong></p>\n<ul>\n<li>索引的结构</li>\n</ul>\n</li>\n<li><h4 id=\"索引分类\"><a href=\"#索引分类\" class=\"headerlink\" title=\"索引分类\"></a><strong>索引分类</strong></h4></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">分类</th>\n<th style=\"text-align:center\">含义</th>\n<th style=\"text-align:center\">特点</th>\n<th style=\"text-align:center\">关键字</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">主键索引</td>\n<td style=\"text-align:center\">针对于表中主键创建的索引</td>\n<td style=\"text-align:center\">默认自动创建，只能有一个</td>\n<td style=\"text-align:center\">PRIMARY</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">唯一索引</td>\n<td style=\"text-align:center\">避免同一个表中某数据列中的值重复</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\">UNIQUE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">常规索引</td>\n<td style=\"text-align:center\">快速定位特定数据</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">全文索引</td>\n<td style=\"text-align:center\">全文索引查找的是文本中通过的关键词</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\">FULLTEXT</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>按照索引的存储形式分类</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">分类</th>\n<th style=\"text-align:center\">含义</th>\n<th style=\"text-align:center\">特点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">聚集索引</td>\n<td style=\"text-align:center\">将数据存储与索引放到了一块</td>\n<td style=\"text-align:center\">必须有，而且只有一个</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">二级索引</td>\n<td style=\"text-align:center\">将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键</td>\n<td style=\"text-align:center\">可以存在多个</td>\n</tr>\n</tbody>\n</table>\n</div>\n<img src=\"/2024/02/10/database-mysql/image-20240218203730285.png\" class=\"\" title=\"image-20240218203730285\">\n<ul>\n<li><h4 id=\"索引语法\"><a href=\"#索引语法\" class=\"headerlink\" title=\"索引语法\"></a><strong>索引语法</strong></h4></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建索引<br># 一个索引可以关联多行，如果关联多行称为联合索引<br>CREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name (index_col_name, )<br><br># 查看索引<br>SHOW INDEX FROM table_name;<br><br># 删除索引<br>DROP INDEX index_name ON table_name;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"SQL性能分析\"><a href=\"#SQL性能分析\" class=\"headerlink\" title=\"SQL性能分析\"></a><strong>SQL性能分析</strong></h4><blockquote>\n<p>使用于select的优化</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># SQL执行频率，查看当前数据库语句的访问频率<br>SHOW [session|global] STATUS<br># Com七个下划线，模糊匹配<br>SHOW GLOBAL STATUS LIKE &#x27;Com_______&#x27;<br></code></pre></td></tr></table></figure>\n<p><strong>SQL语句的频率</strong></p>\n<img src=\"/2024/02/10/database-mysql/image-20240218204502697.png\" class=\"\" title=\"image-20240218204502697\">\n<p><strong>慢查询日志</strong></p>\n<blockquote>\n<p>慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位：秒，默认10)的所有SQL语句的日志</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看是否开启，日志文件默认在/var/lib/mysql里面<br>SHOW VARIABLES LIKE &#x27;slow_query_log&#x27;;<br><br># 修改/etc/my.cnf中配置开启，配置时间<br>slow_query_log=1   <br>long_query_time=2<br></code></pre></td></tr></table></figure>\n<p><strong>profile详情</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看是否支持prifile<br>SELECT @@have_profiling;<br><br># 设置为开<br>SET profiling=1;<br><br># 查看profile<br>SHOW PROFILES;<br></code></pre></td></tr></table></figure>\n<p>执行完SQL语句以后，通过以下指令查看执行耗时情况</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看每一条SQL耗时基本情况<br>SHOW PROFILES;<br><br># 查看指定query_id的SQL语句各个阶段的耗时情况<br>SHOW PROFILE FOR QUERY query_id;<br><br># 查看指定SQL语句的CPU使用情况<br>SHOW PROFILE CPU FOR QUERY query_id;<br></code></pre></td></tr></table></figure>\n<p><strong>explain执行计划</strong></p>\n<blockquote>\n<p>EXPLAIN或者DESC命令获取Mysql如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接的顺序</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">EXPLAIN SELECT SQL语句;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/02/10/database-mysql/image-20240218211138993.png\" class=\"\" title=\"image-20240218211138993\">\n<p>表头的含义：</p>\n<img src=\"/2024/02/10/database-mysql/image-20240218212814126.png\" class=\"\" title=\"image-20240218212814126\">\n<img src=\"/2024/02/10/database-mysql/image-20240218212115878.png\" class=\"\" title=\"image-20240218212115878\">\n<figure class=\"highlight txt\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs txt\">type<br>const\t以主键或以唯一的列作为索引扫描<br>ref\t\t非唯一的值作为查询索引<br>index\t用了索引，但是会对整个索引进行遍历<br>all\t\t全表扫描<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"索引使用\"><a href=\"#索引使用\" class=\"headerlink\" title=\"索引使用\"></a><strong>索引使用</strong></h4></li>\n</ul>\n<p><strong>联合索引</strong></p>\n<p>使用要遵循<strong>最左前缀法则</strong>：查询<strong>从索引的最左列开始</strong>，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。</p>\n<p><strong>范围查询</strong>：联合索引中出现范围查询（&gt;,&lt;)，范围查询右侧的列索引失效。但是使用大于等于和小于等于索引并不会失效。</p>\n<p>例子</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># student有联合索引(id,name,age)<br># 1、索引都可以使用<br>select * from student where id = 1 and name = &quot;Lili&quot; and age = 20;<br><br># 2、索引name，age失效<br>select * from student where id = 1 and age = 20;<br><br># 范围查询<br># name和age索引均失效<br>select * from student where id &gt; 1 and name = &quot;Lili&quot; and age = 20;<br></code></pre></td></tr></table></figure>\n<p><strong>索引失效</strong></p>\n<p>索引列操作：不要在索引上进行列操作，否则索引会失效</p>\n<p>字符串类型：不加单引号索引会失效</p>\n<p>模糊查询：<strong>头部进行模糊匹配(%%某某)</strong>，索引会失效，尾部进行模糊匹配（某某%%），索引不会失效。</p>\n<p>or连接的条件：如果or前面的条件列有索引，后面的条件没有索引，所涉及的索引都不会引用到，只有两侧都有索引的时候，才有效</p>\n<p>数据分布影响：如果索引比全表扫描更慢，则不使用索引，查询的数据大于一半，走全表不走索引。</p>\n<p><strong>SQL提示</strong></p>\n<blockquote>\n<p>在sql语句中加入一些认为的提示来达到优化操作的目的</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># use index指定使用哪个索引<br>explain select * from table use index(idxname) ...<br><br># ignore index<br># force index 同上<br></code></pre></td></tr></table></figure>\n<p><strong>覆盖索引</strong></p>\n<p>尽量使用覆盖索引：查询使用了索引，并且需要返回的列，在该索引中已经能够全部找到，减少使用select *</p>\n<p>using index condition：查找使用了索引，但是需要回表查询数据</p>\n<p>using where, using index：查询使用了索引，但是不需要回表</p>\n<img src=\"/2024/02/10/database-mysql/image-20240218221642388.png\" class=\"\" title=\"image-20240218221642388\">\n<p>前两条不需要回表，后一条需要回表</p>\n<p><strong>前缀索引</strong></p>\n<blockquote>\n<p>将字符串的前缀提取出来，创建索引，可以节约索引空间</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># n表示取column_name列的前n个数据<br>CREATE INDEX idx_XXX ON table_name(column_name(n));<br><br># 计算前缀长度的选择性，越接近1越好<br>SELECT COUNT(DISTINCT substring(email, 1, 5)) / COUNT(*) FROM table_name;<br></code></pre></td></tr></table></figure>\n<p><strong>单列索引和联合索引选择</strong></p>\n<p>如果涉及到多个查询条件，推荐使用联合索引，联合索引会更少的回表查询</p>\n<h4 id=\"Quetion\"><a href=\"#Quetion\" class=\"headerlink\" title=\"Quetion\"></a>Quetion</h4><img src=\"/2024/02/10/database-mysql/image-20240218221919863.png\" class=\"\" title=\"image-20240218221919863\">\n<p>建立id主键，username，password联合索引</p>\n<ul>\n<li><h4 id=\"索引设计原则\"><a href=\"#索引设计原则\" class=\"headerlink\" title=\"索引设计原则\"></a><strong>索引设计原则</strong></h4></li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/image-20240218224016746.png\" class=\"\" title=\"image-20240218224016746\">\n<h3 id=\"3、SQL优化\"><a href=\"#3、SQL优化\" class=\"headerlink\" title=\"3、SQL优化\"></a>3、SQL优化</h3><ul>\n<li><h4 id=\"插入数据insert优化\"><a href=\"#插入数据insert优化\" class=\"headerlink\" title=\"插入数据insert优化\"></a><strong>插入数据</strong>insert优化</h4><p>批量插入而不是单条插入：批量插入只需要建立一次连接即可</p>\n<p>建议手动提交事务：不需要每一次插入时自动开启和关闭事务，而是将所有insert执行结束以后统一关闭</p>\n<p><strong>建议主键顺序插入</strong></p>\n<p>大批量插入数据：使用Mysql数据库提供的load指令进行插入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 如何使用load<br># 1、连接服务器时加上参数--local-infile<br>mysql --local-infile -u root -p<br><br># 2、设置全局参数local_infile为1<br>set global local_infile = 1;<br><br># 3、执行load指令将数据加载表结构中<br>load data local infile &#x27;文件名&#x27; into table &#x27;表名&#x27; fields teminated by &#x27;分割符&#x27; lines terminated by &#x27;行分隔符\\n&#x27;;<br></code></pre></td></tr></table></figure>\n</li>\n<li><h4 id=\"主键优化\"><a href=\"#主键优化\" class=\"headerlink\" title=\"主键优化\"></a><strong>主键优化</strong></h4></li>\n</ul>\n<blockquote>\n<p>InnoDB中表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。</p>\n</blockquote>\n<p>页大小为16kb，每个页至少包含两行数据</p>\n<p>主键乱序插入可能会出现页分裂现象，执行删除操作会出现页合并现象</p>\n<p>主键设计原则：</p>\n<p>​    满足业务需求的情况下，尽量降低主键的长度</p>\n<p>​    插入时尽量按照主键顺序插入，选择自增主键</p>\n<p>​    尽量不要使用无序的自然主键</p>\n<p>​    业务操作，避免对主键的修改</p>\n<ul>\n<li><strong>order by优化</strong></li>\n</ul>\n<p>排序方式</p>\n<p>Using filesort：先找到数据再进行排序</p>\n<p>Using index：通过有序索引直接返回，不需要额外排序</p>\n<p>默认会对索引进行升序排序</p>\n<ul>\n<li><strong>limit优化</strong></li>\n</ul>\n<p>对于数据量大的，优化思路为使用覆盖索引+子查询</p>\n<ul>\n<li><p>count</p>\n<p>count(*)优于count(1)&gt;count(主键)&gt;count(字段)</p>\n</li>\n<li><h4 id=\"update优化\"><a href=\"#update优化\" class=\"headerlink\" title=\"update优化\"></a><strong>update优化</strong></h4></li>\n</ul>\n<p>对需要更新的字段尽可能建立索引，这样如果处于多个事务情况下，只会使用行锁，如果没有建立索引，行锁会升级为表锁，无法进行并行</p>\n<h3 id=\"4、视图-存储过程-触发器\"><a href=\"#4、视图-存储过程-触发器\" class=\"headerlink\" title=\"4、视图/存储过程/触发器\"></a>4、视图/存储过程/触发器</h3><blockquote>\n<p>Mysql数据库当中的存储对象</p>\n</blockquote>\n<ul>\n<li><h4 id=\"视图\"><a href=\"#视图\" class=\"headerlink\" title=\"视图\"></a>视图</h4></li>\n</ul>\n<blockquote>\n<p>视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。</p>\n</blockquote>\n<p>操作视图中的数据就和操作数据库表一样，可以将视图理解为一张不被存储的虚拟表。</p>\n<p>视图当中的数据并不存在，如果往视图里面插入数据，数据将存在基表当中，如果不想给用户表的权限，可以给用户一个视图。 </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建视图<br>CREATE [OR REPLACE] VIEW 视图名称(列名列表) AS SELECT语句 [WITH CASCADED|LOCAL CHECk OPTION];<br><br># 查询视图<br># 查看创建视图语句<br>SHOW CREATE VIEW 视图名称;<br># 查看视图数据<br>SELECT * FROM 视图名称...;<br><br># 修改视图<br># 方式一、使用创建的语句，用REPLACE替换掉<br>CREATE[OR REPLACE]...<br># 方式二<br>ALTER VIEW 视图名称(列表名称) AS SELECT ...;<br><br># 删除视图<br>DROP VIEW IF EXISTS 视图名称<br></code></pre></td></tr></table></figure>\n<p><strong>视图当中的检查选项</strong></p>\n<p><strong>CASCADED（向下级联）</strong></p>\n<p>当使用WITH CHECK OPTION子句创建视图时，Mysql会通过视图检查正在更改的每个行。进行校验，所插入的数据是否满足SELECT语句。</p>\n<p>Mysql中还可以为视图再创建新的视图，新的视图如果有option选项会影响到之前的视图</p>\n<p><strong>LOCAL（不向下级联，只是检查有option的条件）</strong></p>\n<p><strong>视图的更新和作用</strong></p>\n<p>要使视图可以更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下中任何一项，则该视图不可更新：</p>\n<p>聚合函数、DISTINCT、GROUP BY、HAVING、UNION或者UNION ALL</p>\n<p>作用：1、可以简化用户对数据的理解，简化用户操作。2、控制用户对表的查看权限。3、数据独立，屏蔽真实表结构。4、可以简化多表联查的操作。</p>\n<ul>\n<li><h4 id=\"存储过程\"><a href=\"#存储过程\" class=\"headerlink\" title=\"存储过程\"></a>存储过程</h4></li>\n</ul>\n<blockquote>\n<p>存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输</p>\n<p>思想上就是数据库SQL语言层面的代码封装与重用，下一次如果执行相同的业务直接调用存储过程</p>\n</blockquote>\n<p><strong>特点</strong>    好像跟函数有点像</p>\n<p>封装、复用</p>\n<p>可以接收参数，也可以返回数据</p>\n<p>作用：减少网络交互，提升效率</p>\n<blockquote>\n<p>在命令行中，执行创建存储过程的sql时，需要通过关键字<code>delimiter</code>指定SQL语句的结束符</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建<br># 参数列表为IN/OUT/INOUT 参数名，分别表示参数输入，输出，输入和输出参数<br>CREATE PROCEDURE 存储过程名称([参数列表])<br>BEGIN<br>\t--SQL语句，可以是多条<br>END;<br><br># 调用<br>CALL 名称([参数列表]);<br><br># 查看<br># 方法一，查看系统的数据库表，xxx为数据库名<br>SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = &#x27;XXX&#x27;;<br># 方法二，使用show查看创建过程<br>SHOW CREATE PROCEDURE 存储过程名称;<br><br># 删除<br>DROP PROCEDURE [IF EXISTS] 存储过程名称;<br><br># 定义结束符为$$<br>delimiter $$<br></code></pre></td></tr></table></figure>\n<p><strong>系统变量</strong>（全局GLOBAL，会话SESSION）</p>\n<p>重启以后系统参数会恢复为默认值</p>\n<p>永久修改系统参数需要修改/etc/my.cnf中配置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看所有系统变量<br>SHOW [SESSION|GLOBAL] VARIABLES;<br>SHOW VARIABLES LIKE &#x27;..&#x27;;<br># 查看指定变量<br>SELECT @@[SESSION|GLOBAL].系统变量名<br><br># 设置系统变量，默认为SESSION级别<br>SET [SESSION|GLOBAL] 变量名=值;<br>SET @@[SESSION|GLOBAL].系统变量名 = 值;<br></code></pre></td></tr></table></figure>\n<p><strong>用户自定义变量</strong></p>\n<blockquote>\n<p>作用域为当前连接</p>\n<p>变量无需声明，如果拿到的是没有声明的变量，则会获得NULL</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 赋值，可以同时赋值多个变量，用逗号隔开<br>SET @var_name = expr;<br>SET @var_name := expr;<br><br># SELECT赋值<br>SELECT @var_name := expr;<br># 将sql查询的结果赋值给变量<br>SELECT 字段名 INTO @var_name FROM 表名;<br><br># 使用<br>SELECT @var_name;<br></code></pre></td></tr></table></figure>\n<p><strong>局部变量</strong></p>\n<blockquote>\n<p>在局部生效，需要DECLARE声明，作用域在BEGIN…END块内</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 声明<br>DECLARE 变量名 变量类型(数据库数据的类型) [DEFAULT 默认值]<br><br># 赋值<br>SET 变量名 = 值;<br>SET 变量名 := 值;<br>SELECT 字段名 INTO @var_name FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>存储过程相关语法</strong></p>\n<blockquote>\n<p>逻辑语言都在存储过程中定义，可以使用传入的参数</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># IF 条件判断<br>IF 条件1 THEN<br>\t...<br>ELSEIF 条件2 THEN<br>\t...<br>ELSE<br>\t...<br>END IF;<br><br># CASE 条件选择，WHEN后面可以有多种选择<br># 语法一<br>CASE case_value<br>\tWHEN when_value1 THEN ...<br>\tWHEN when_value2 THEN ...<br>\tELSE ...<br>END CASE;<br># 语法二<br>CASE <br>\tWHEN 表达式真 THEN ...<br>\tELSE ...<br>END CASE;<br><br># WHILE循环<br>WHILE 条件 DO<br>\tSQL逻辑<br>END WHILE：<br><br># REPEAT循环，当满足条件时，退出循环<br>REPEAT<br>\tSQL逻辑...<br>\tUNTIL 条件<br>END REPEAT;<br><br># LOOP循环<br># LOOP实现的是简单循环<br># LEAVE：配合循环使用，退出循环，作用类似于break<br># ITERATE：必须在循环中使用，作用类似于CONTINUE<br>[begin_label:] LOOP<br>\tSQL逻辑<br>\t<br>END LOOP[end_label]<br><br># 退出循环<br>LEAVE label;<br># 跳过本次进入下一次循环<br>ITERATE label;<br></code></pre></td></tr></table></figure>\n<p><strong>游标Cursor</strong></p>\n<p>游标（Cursor）是一种用于在存储过程或函数中遍历结果集的机制。游标允许逐行访问结果集，并在每行上执行相应的操作</p>\n<p>通常情况下，当执行一个查询语句时，MySQL 会返回一个结果集，该结果集包含了查询返回的所有行。以使用游标来逐行处理这个结果集，而不是一次性获取所有结果。这在处理大量数据或需要逐行处理结果的情况下非常有用</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 声明游标、打开游标、获取下一行、关闭游标<br>DELIMITER //<br><br>CREATE PROCEDURE process_users()<br>BEGIN<br>    DECLARE done INT DEFAULT FALSE;<br>    DECLARE user_id INT;<br>    DECLARE user_name VARCHAR(255);<br><br>    -- 声明游标<br>    DECLARE user_cursor CURSOR FOR <br>        SELECT id, name FROM users;<br><br>    -- 打开游标<br>    OPEN user_cursor;<br><br>    -- 循环遍历结果集<br>    read_loop: LOOP<br>        -- 获取下一行数据<br>        FETCH user_cursor INTO user_id, user_name;<br>        IF done THEN<br>            LEAVE read_loop;<br>        END IF;<br>        <br>        -- 处理当前行数据<br>        -- 这里可以执行相应的操作，如输出到日志或进行其他逻辑处理<br>        SELECT CONCAT(&#x27;User ID: &#x27;, user_id, &#x27;, User Name: &#x27;, user_name);<br><br>    END LOOP;<br><br>    -- 关闭游标<br>    CLOSE user_cursor;<br><br>END //<br><br>DELIMITER ;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"存储函数\"><a href=\"#存储函数\" class=\"headerlink\" title=\"存储函数\"></a>存储函数</h4></li>\n</ul>\n<blockquote>\n<p>有返回值的存储过程，存储函数的参数只能时IN类型’</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 语法结构<br>CREATE FUNCTION 存储函数名称([参数列表])<br>RETURNS type [characteristic...]<br>BEGIN<br>\t--SQL语句<br>\tRETURN ...;<br>END;<br><br>characteristics存储参数的特性<br>DETERMINISTIC : 相同的输入参数总是产生相同的结果<br>NO SQL : 不包含SQL语句<br>READS SQL DATA : 包含读取数据的语句，但不包含写入数据的语句<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"触发器\"><a href=\"#触发器\" class=\"headerlink\" title=\"触发器\"></a>触发器</h4></li>\n</ul>\n<blockquote>\n<p>在insert/update/delete之前或者之后，触发并执行触发器中定义的SQL语句集合。</p>\n<p>使用别名OLD和NEW来引用触发器中发生变化的记录内容</p>\n<p>触发器只支持行级触发，不支持语句级别触发：如果一个UPDATE语句影响了5行，则触发器会被出发5次</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">触发器类型</th>\n<th style=\"text-align:center\">NEW和OLD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">INSERT型触发器</td>\n<td style=\"text-align:center\">NEW表示将要或者已经新增的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE型触发器</td>\n<td style=\"text-align:center\">OLD表示修改之前的数据，NEW表示将要或已经修改后的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE型触发器</td>\n<td style=\"text-align:center\">OLD表示将要或者已经删除的数据</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建触发器<br>CREATE TRIGGER trigger_name<br>BEFORE/AFTER(在之前还是之后) INSERT/UPDATE/DELETE(触发器类型)<br>ON tbl_name FOR EACH ROW --行级触发器<br>BEGIN<br>\ttrigger_stmt; # 触发器逻辑<br>END;<br><br># 查看<br>SHOW TRIGGERS;<br><br># 删除，数据库中的触发器<br>DROP TRIGGER [schema_name.]trigger_name;<br></code></pre></td></tr></table></figure>\n<h3 id=\"5、锁\"><a href=\"#5、锁\" class=\"headerlink\" title=\"5、锁\"></a>5、锁</h3><blockquote>\n<p>锁是计算机协调多个进程或线程并发访问某一资源的机制，用于保证数据的一致性和有效性。</p>\n</blockquote>\n<ul>\n<li>全局锁</li>\n</ul>\n<p>对整个数据库进行加锁，加锁以后整个实例就处于只读状态，后续的DML的写语句，DDL语句以及更新操作的事务提交语句都会被阻塞</p>\n<p>做数据库的全库逻辑备份的时候，会对所有的表进行锁定</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 为表加全局锁<br>FLUSH TABLES WITH READ LOCK;<br><br># 备份数据库<br>musqldump -uroot -p1234 数据库&gt;文件名<br><br># 释放全局锁<br>UNLOCK TABLES;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>表级锁</li>\n</ul>\n<p>每次操作会锁住整张表，发生锁冲突的概率最高，并发度最低</p>\n<p><strong>表锁</strong></p>\n<blockquote>\n<p>表共享读锁：对于所有客户端的连接都只能读，不能写</p>\n<p>表独占写锁：对于获取锁资源的客户端可以写，其他客户端不能进行读也不能执行写会被阻塞</p>\n</blockquote>\n<p>语法</p>\n<p>1、加锁：lock tables 表名… read/write</p>\n<p>2、释放锁：unlock tables /  客户端断开连接</p>\n<p><strong>元数据锁</strong>（meta data lock）</p>\n<blockquote>\n<p>MDL加锁过程是系统自动控制的，无需显示使用，在访问一张表的时候会自动加上</p>\n<p>元数据锁就是对表结构进行加锁</p>\n</blockquote>\n<p>当对一张表进行增删改查的时候，自动会加上MDL读锁，当对表结构进行变更时，会自动加上MDL写锁</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">对应SQL</th>\n<th style=\"text-align:center\">锁类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">lock table xx read/write</td>\n<td style=\"text-align:center\">SHARED_READ_ONLY/SHARED_NO_READ_WRITE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">select、select .. lock in share mode</td>\n<td style=\"text-align:center\">SHARED_READ</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">insert、update、delet、sekect…from update</td>\n<td style=\"text-align:center\">SHARED_WRITE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">alter table…</td>\n<td style=\"text-align:center\">EXCLUSIVVE</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>意向锁</strong></p>\n<img src=\"/2024/02/10/database-mysql/image-20240222075448991.png\" class=\"\" title=\"image-20240222075448991\">\n<img src=\"/2024/02/10/database-mysql/image-20240222075706155.png\" class=\"\" title=\"image-20240222075706155\">\n<ul>\n<li>行级锁</li>\n</ul>\n<blockquote>\n<p>应用在InnoDB存储引擎当中</p>\n</blockquote>\n<p>InnoDB的数据时基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁</p>\n<p><strong>行锁</strong></p>\n<p>锁定单个行记录的锁，防止其他事务对此进行update和delete，在RC、RR隔离级别都支持</p>\n<p>1、共享锁（S）：允许一个事务去读取一行，阻止其他事务获得相同数据集的排它锁，其他事务能读不能写</p>\n<p>2、排它锁（X）：允许获取排它锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排它锁，其他事务不能写也不能读</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">SQL</th>\n<th style=\"text-align:center\">行锁类型</th>\n<th style=\"text-align:center\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">INSERT</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT</td>\n<td style=\"text-align:center\">不加任何锁</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT … LOCK IN SHARE MODE</td>\n<td style=\"text-align:center\">共享锁</td>\n<td style=\"text-align:center\">手动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT … FOR UPDATE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">手动</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>间隙锁</strong></p>\n<p>锁定索引记录间隙，确保索引记录间隙不变，防止其他事务在这个间隙执行insert，产生幻读，在RR级别下支持</p>\n<p><strong>临建锁</strong>（next-key）</p>\n<p>同时锁住行记录也锁住间隙</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询数据库中的锁<br>select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;<br></code></pre></td></tr></table></figure>\n<h3 id=\"6、InnoDB引擎\"><a href=\"#6、InnoDB引擎\" class=\"headerlink\" title=\"6、InnoDB引擎\"></a>6、InnoDB引擎</h3><ul>\n<li><h4 id=\"逻辑存储结构\"><a href=\"#逻辑存储结构\" class=\"headerlink\" title=\"逻辑存储结构\"></a><strong>逻辑存储结构</strong></h4></li>\n</ul>\n<p>表空间（ibd文件）：一个mysql实例可以对应多个表空间，用于存储记录、索引等数据</p>\n<p>段：分为数据段、索引段、回滚段，InnoDB是索引组织表，数据段就是B+书的叶子节点，索引段即是B+书的非叶子节点，段用来管理多个区</p>\n<p>区：表空间的单元结构，每个区的大小为1M，一个区中一共有64个连续的页</p>\n<p>页：页大小16kB，是InnoDB存储引擎磁盘管理的最小单元，保证页的连续性，会申请4-5个区</p>\n<img src=\"/2024/02/10/database-mysql/image-20240223204149464.png\" class=\"\" title=\"image-20240223204149464\">\n<ul>\n<li><h4 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h4></li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/innodb-architecture-8-0.png\" class=\"\" title=\"innodb-architecture-8-0\">\n<p><strong>内存结构</strong></p>\n<blockquote>\n<p>磁盘结构存储的是一些表空间和表数据文件，包括日志表空间，系统表空间，撤销表空间，重做表空间等等</p>\n</blockquote>\n<p>buffer pool缓存池</p>\n<p>缓冲区是内存中的一个区域，可以缓冲存储磁盘上经常要操作的数据，利用局部性原理减少磁盘IO，加快处理速度</p>\n<p>缓冲池以page页为单位，底层采用链表数据结构管理page</p>\n<p>change buffer更改缓存，<strong>针对非唯一二级索引页</strong></p>\n<p>当需要对数据进行变更，即执行DML语句时，如果buffer pool中不存在当前数据page，不会直接操作磁盘，会先将数据变更缓存在change buffer在未来数据被读取的时候，再将数据合并恢复到buffer pool中</p>\n<p>Adaptive Hash Index自适应哈希索引</p>\n<p>log buffer日志缓存区</p>\n<p><strong>后台线程</strong></p>\n<blockquote>\n<p>作用：将InnoDB缓冲区当中的数据在合适的时间写入到磁盘当中</p>\n</blockquote>\n<p>1、Master Thread</p>\n<p>核心后台线程，负责调度其他线程，将缓冲池中的数据异步刷新到磁盘当中，保持数据的一致性</p>\n<p>2、IO Thread</p>\n<p>采用的是AIO（异步非阻塞IO）来处理IO请求</p>\n<p>4个读线程、4个写线程、1个日志线程、1个插入缓存线程（写缓冲区刷新到磁盘）</p>\n<p>3、Purge Thread</p>\n<p>回收事务已经提交的undo log，在事务提交之后，undo log可能不用了，就用它来回收</p>\n<p>4、Page Cheaner Thread</p>\n<p>协助Master Thread刷新脏页到磁盘的线程</p>\n<ul>\n<li><h4 id=\"事务原理\"><a href=\"#事务原理\" class=\"headerlink\" title=\"事务原理\"></a>事务原理</h4></li>\n</ul>\n<p>事务的原子性、一致性和持久性是通过日志文件来保证的，包括redo.log和undo.log</p>\n<p>事务的隔离性是通过锁+MVCC（多版本并发控制）来进行保证的</p>\n<p><strong>redo log</strong>事务的持久性（事务提交后数据的改变是永久的）</p>\n<p>重做日志，记录事务提交时数据页的物理修改，用来实现事务的持久性(事务一旦提交，对数据的改变时持久的）</p>\n<p>当系统在执行Mysql的DML语句时，会先从数据库缓存中查找是否有对应的页面，如果在缓存当中则对数据进行修改，这种在缓冲中修改后但还未写入磁盘的数据页，叫做脏页，后通过后台进程写入到磁盘当中，如果在写入的过程中发生异常，就会出现持久性消失的现象</p>\n<p>redo log会把数据页的变化记录到redo log当中，当事务提交时，会把redo log刷新到磁盘当中，可以通过log对数据进行恢复，如果redo log刷新页失败，则事务执行也就失败，不影响一致性</p>\n<p><strong>undo log</strong>事务的原子性（事务是最小操作单位，要么全部成功，要么全部失败）</p>\n<p>回滚日志，用于记录数据被修改前的信息，提供回滚和MVCC。当执行DML语句时，会记录数据变化前的数据长什么样，在回滚日志中，记录的时执行sql的反向操作，逆操作</p>\n<p>undo log存放在段当中，回滚段</p>\n<ul>\n<li><h4 id=\"MVCC多版本并发控制\"><a href=\"#MVCC多版本并发控制\" class=\"headerlink\" title=\"MVCC多版本并发控制\"></a>MVCC多版本并发控制</h4></li>\n</ul>\n<blockquote>\n<p>Mutil-Version Concurrency Control，多版本并发控制。维护一个数据的多个版本，使得读写此操作没有冲突。依赖于数据库记录中的三个隐式字段、undo log日志、readView</p>\n</blockquote>\n<p><strong>相关概念</strong></p>\n<p>当前读：读取的时记录的最新版本。因为Mysql的默认隔离界别是RR（repeatable read）可重复读，所以当另一个事务对数据进行修改时，当前事务读到的数据就不是当前最新的版本。要想读到最新版本，可以通过select .. lock in share mode,select .. for update来完成</p>\n<p>快照读：正常的select（不加锁）就是快照读，读取的是数据的可见版本</p>\n<p>Read Committed：每一次select 都会生成一个快照读</p>\n<p>Repeatable Read：开始事务后第一个select才是产生快照读的地方，后面的select都是查询快照</p>\n<p>Serializable：快照读会退化为当前读</p>\n<p><strong>记录当中的隐藏字段</strong></p>\n<p>DB_TRX_ID：最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID</p>\n<p>DB_ROLL_PTR：回滚指针，指向这条记录的上一个版本，用于配合undo log<br>DB_ROW_ID：隐藏主键，表结构没有主键，则会自动生成隐藏字段</p>\n<p><strong>undo log日志</strong></p>\n<p>如果使用insert的时候产生的日志只在回滚的时候需要，在事务提交后，可以立即删除</p>\n<p>如果使用的是update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读的时候也需要，不会立即被删除</p>\n<img src=\"/2024/02/10/database-mysql/image-20240224160500080.png\" class=\"\" title=\"image-20240224160500080\">\n<p><strong>ReadView</strong></p>\n<p>读视图：快照读SQL执行时MVCC提取数据的一句，记录并维护系统当前活跃的事务id</p>\n<p>字段，通过对比当前事务的id：trx_id和下面的id进行对比来实现版本访问控制</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">字段</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">m_ids</td>\n<td style=\"text-align:center\">当前活跃的事务ID集合</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">min_trx_id</td>\n<td style=\"text-align:center\">最小活跃事务ID</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">max_trx_id</td>\n<td style=\"text-align:center\">预分配事务ID，当前最大事务ID+1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">creator_trx_id</td>\n<td style=\"text-align:center\">ReadView创建者的事务ID</td>\n</tr>\n</tbody>\n</table>\n</div>\n<img src=\"/2024/02/10/database-mysql/image-20240224161313751.png\" class=\"\" title=\"image-20240224161313751\">\n<p><strong>Read Commited</strong>读提交下的规则</p>\n<blockquote>\n<p>事务中每一次执行快照读时都会生成ReadView</p>\n</blockquote>\n<img src=\"/2024/02/10/database-mysql/image-20240224162152111.png\" class=\"\" title=\"image-20240224162152111\">\n<p>通过上面四条规则可以找到最新已经提交的事务版本</p>\n<p><strong>Repeatable Read</strong>可重复读的情况</p>\n<blockquote>\n<p>仅在事务中第一次执行快照读的时候生成ReadView，后续会复用该ReadView</p>\n</blockquote>\n<img src=\"/2024/02/10/database-mysql/image-20240224162359110.png\" class=\"\" title=\"image-20240224162359110\">\n<p>隔离性：保证事务不在外部并发操作影响下独立完成，通过MVCC+锁来保证</p>\n<p>一致性：事务完成时，所有数据都保持一致，通过日志实现</p>\n<img src=\"/2024/02/10/database-mysql/image-20240224162626695.png\" class=\"\" title=\"image-20240224162626695\">\n<h3 id=\"7、MySQL管理\"><a href=\"#7、MySQL管理\" class=\"headerlink\" title=\"7、MySQL管理\"></a>7、MySQL管理</h3><ul>\n<li>系统数据库</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">数据库</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">mysql</td>\n<td style=\"text-align:center\">存储Mysql服务器正常运行所需要的各种信息（用户、权限等）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">information_schema</td>\n<td style=\"text-align:center\">提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型以及访问权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">performance_schema</td>\n<td style=\"text-align:center\">为Mysql服务器运行时状态提供了一个底层监控功能，用于收集数据库服务器性能参数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">sys</td>\n<td style=\"text-align:center\">方便开发人员进行性能调优和诊断的视图</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>常用工具</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># mysql [option] [database]<br>mysql<br>\t-u, --user=\t\t # 指定用户名<br>    -p, --password=\t\t# 指定密码<br>    -h, --host=\t\t# 指定服务器ip或域名<br>    -p, --port=\t\t# 指定端口号<br>    -e, --execute=\t# 执行sql语句并推出<br></code></pre></td></tr></table></figure>\n<p>mysqladmin</p>\n<p>​    执行管理操作的客户端程序</p>\n<p>​    —help查看帮助文档</p>\n<p>mysqlbinlog</p>\n<p>​    如果查看一些二进制文本的数据，使用这个可以进行数据查看</p>\n<p>mysqlshow</p>\n<p>​    客户端对象查找工具，可以用于查找存在哪些数据库、数据库中的表、表中的列或者索引</p>\n<p>​    —count 显示数据库及表的统计信息</p>\n<p>​    -i 显示指定数据库或指定表的状态信息</p>\n<p><strong>mysqldump</strong></p>\n<p>​    用于备份数据库或在不同数据库之间进行数据迁移</p>\n<p><strong>mysqlimport/source</strong></p>\n<p>​    用于数据的导入工具</p>\n<h2 id=\"QA\"><a href=\"#QA\" class=\"headerlink\" title=\"QA\"></a>QA</h2><p>1、InnoDB数据页中的数据存储</p>\n<p>2、B+树是如何进行查询的</p>\n<p>3、MySql单表最大限制，为什么</p>\n<p>4、索引失效有哪些</p>\n<p>5、count（*）和count（1）哪个性能好一些</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"数据库-Mysql\"><a href=\"#数据库-Mysql\" class=\"headerlink\" title=\"数据库-Mysql\"></a>数据库-Mysql</h2><blockquote>\n<p>Mysql数据库的关键词：事务、存储引擎、索引、SQL优化、<strong>锁、日志、主从复制、读写分离、分库分表</strong></p>\n</blockquote>\n<h2 id=\"数据库基础\"><a href=\"#数据库基础\" class=\"headerlink\" title=\"数据库基础\"></a>数据库基础</h2><h3 id=\"1、Mysql概述\"><a href=\"#1、Mysql概述\" class=\"headerlink\" title=\"1、Mysql概述\"></a>1、Mysql概述</h3><p>关系型数据库：建立在关系模型基础上，由多张互连接的二维表组成的数据库</p>\n<p>特点：使用表存储数据，便于维护；使用sql语句操作，使用方便</p>\n<p><strong>MySQL数据模型</strong></p>\n<blockquote>\n<p>1、客户端通过与数据库管理系统进行连接</p>\n<p>2、使用sql语句通过数据库管理系统对指定的数据库进行增删改查</p>\n<p>3、一个数据库模型中可以对多个数据库进行管理，一个数据库中可以拥有多个表</p>\n</blockquote>\n<p>// TODO数据库模型的图</p>\n<h3 id=\"2、SQL\"><a href=\"#2、SQL\" class=\"headerlink\" title=\"2、SQL\"></a>2、SQL</h3><p><strong>SQL分类</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分类</th>\n<th>全称</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DDL</td>\n<td>Data Definition Language</td>\n<td>数据库定义语句，定义数据库对象，数据库，表，字段等</td>\n</tr>\n<tr>\n<td>DML</td>\n<td>Data Manipulation Language</td>\n<td>数据库操作语句，用于对数据库表中的数据进行增增删改</td>\n</tr>\n<tr>\n<td>DQL</td>\n<td>Data Query Language</td>\n<td>数据库查询语句，查询数据库表中的记录</td>\n</tr>\n<tr>\n<td>DCL</td>\n<td>Data Control Language</td>\n<td>数据库控制语句，创建数据库用户，控制数据库的访问权限</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><h4 id=\"DDL\"><a href=\"#DDL\" class=\"headerlink\" title=\"DDL\"></a>DDL</h4><p><strong>数据库层次</strong></p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询所有数据库表格<br>SHOW DATABASES;<br># 查询当前所在的数据库<br>SELECT DATABASE();<br># 创建数据库，方括号可以省略<br>CREATE DATABASE [IF NOT EXISTS] 数据库名 [COLLATE 排序规则]<br># 删除数据库<br>DROP DATABASE [IF EXISTS] 数据库名<br># 使用数据库，切换到数据库当中<br>USE 数据库名<br></code></pre></td></tr></table></figure>\n<p>​        表结构</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看所有表<br>SHOW TABLES;<br># 查询表结构<br>DESC 表名<br># 查询指定表的建表语句<br>SHOW CREATE TABLE 表名;<br></code></pre></td></tr></table></figure>\n<p>​        MySQL中的数据类型</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>描述</th>\n<th>大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>TINYINT</td>\n<td>微小整数，有符号或无符号（UNSIGNED）</td>\n<td>1 字节</td>\n</tr>\n<tr>\n<td>SMALLINT</td>\n<td>小整数，有符号或无符号</td>\n<td>2 字节</td>\n</tr>\n<tr>\n<td>MEDIUMINT</td>\n<td>中等整数，有符号或无符号</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>INT 或 INTEGER</td>\n<td>整数，有符号或无符号</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>BIGINT</td>\n<td>大整数，有符号或无符号</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>FLOAT(M,D)</td>\n<td>单精度浮点数，M 是总位数，D 是小数位数</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>DOUBLE(M,D)</td>\n<td>双精度浮点数，M 是总位数，D 是小数位数</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>DECIMAL(M,D)</td>\n<td>定点数，M 是总位数，D 是小数位数</td>\n<td>取决于 M 和 D</td>\n</tr>\n<tr>\n<td>DATE</td>\n<td>日期 YYYY-MM-DD</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>TIME</td>\n<td>时间 HH:MM:SS</td>\n<td>3 字节</td>\n</tr>\n<tr>\n<td>DATETIME</td>\n<td>日期和时间</td>\n<td>8 字节</td>\n</tr>\n<tr>\n<td>TIMESTAMP</td>\n<td>时间戳</td>\n<td>4 字节</td>\n</tr>\n<tr>\n<td>CHAR(N)</td>\n<td><strong>定长</strong>字符串，最大长度为 N</td>\n<td>最大 255 字节</td>\n</tr>\n<tr>\n<td>VARCHAR(N)</td>\n<td><strong>变长</strong>字符串，最大长度为 N</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>TEXT</td>\n<td>变长文本，最大长度为 65,535 字节</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>BLOB</td>\n<td>二进制大对象，最大长度为 65,535 字节</td>\n<td>最大 65,535 字节</td>\n</tr>\n<tr>\n<td>ENUM</td>\n<td>枚举类型</td>\n<td>1 或 2 字节，取决于成员数量</td>\n</tr>\n<tr>\n<td>SET</td>\n<td>集合类型</td>\n<td>1、2、3、4 或 8 字节，取决于成员数量</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>创建表：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">CREATE TABLE member(<br>    number INT COMMENT &#x27;编号&#x27;,<br>    id CHAR(10) COMMENT &#x27;员工工号&#x27;,<br>    name VARCHAR(10) COMMENT &#x27;员工姓名&#x27;,<br>    gender CHAR(4) COMMENT &#x27;员工性别&#x27;,<br>    age INT UNSIGNED COMMENT &#x27;年龄&#x27;,<br>    id_number CHAR(18) COMMENT &#x27;身份证号&#x27;,<br>    time DATE COMMENT &#x27;入职时间&#x27;<br>)<br></code></pre></td></tr></table></figure>\n<p><strong>表结构的修改</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 添加字段<br>ALTER TABLE 表名 ADD 字段名 类型(长度) [COMMENT 注释][约束];<br><br># 修改字段和字段类型<br>ALTER TABLE 表明 CHANGE 旧字段名 新字段名 类型(长度) [COMMENT 注释][约束]<br><br># 删除字段<br>ALTER TABLE 表名 DROP 字段名;<br><br># 修改表名<br>ALTER TABLE 表名 RENAME TO 新表名;<br><br># 删除表<br>DROP TABLE [IF EXSITS] 表名;<br># 删除指定表并重新创建该表，清空数据<br>TRUNCATE TABLE 表名;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"DML（数据操作语言）\"><a href=\"#DML（数据操作语言）\" class=\"headerlink\" title=\"DML（数据操作语言）\"></a>DML（数据操作语言）</h4></li>\n</ul>\n<p><strong>添加数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 给指定字段添加数据<br>INSERT INTO 表名(字段名1, 字段名2, ...) VALUES (值1, 值2, ...);<br><br># 给全部字段添加数据<br>INSERT INTO 表名 VALUES(值1, 值2, ...);<br></code></pre></td></tr></table></figure>\n<p><strong>修改数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 修改数据<br>UPDATE 表名 SET 字段名1 = 值1, 字段名2 = 值2, ...[WHERE 条件];<br></code></pre></td></tr></table></figure>\n<p><strong>删除数据</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 删除数据<br>DELETE FROM 表名 [WHERE 条件];<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"DQL\"><a href=\"#DQL\" class=\"headerlink\" title=\"DQL\"></a>DQL</h4><blockquote>\n<p>数据库查询语言，用来查询数据库中的表的记录</p>\n<p>SELECT后面加上\\G可以将某一行转化为一列查看</p>\n</blockquote>\n</li>\n</ul>\n<p><strong>语法结构</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT<br>\t字段列表<br>FROM<br>\t表名列表<br>WHERE<br>\t条件列表(条件查询)<br>GROUP BY<br>\t分组字段列表(分组查询)<br>HAVING<br>\t分组后条件列表<br>ORDER BY<br>\t排序字段列表<br>LIMIT<br>\t分页参数<br></code></pre></td></tr></table></figure>\n<p><strong>基本查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段1 [AS 别名]，字段2 [AS 别名]， FROM 表名;<br><br># 去重<br>SELECT DISTINCT 字段列表 FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>条件查询</strong></p>\n<p>条件运算符</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">比较运算符</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">&lt;&gt;或!=</td>\n<td style=\"text-align:center\">不等于</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BETWEEN … AND …</td>\n<td style=\"text-align:center\">在某个范围之内</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IN(…)</td>\n<td style=\"text-align:center\">在in之后的列表中的值，多选一</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LIKE 占位符</td>\n<td style=\"text-align:center\">模糊匹配(_匹配单个字符，%匹配任意个字符)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IS NULL</td>\n<td style=\"text-align:center\">是NULL</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>聚和函数</strong></p>\n<blockquote>\n<p>将一列数据作为一个整体，进行纵向计算。</p>\n</blockquote>\n<p>所有的null值不参与聚合函数的计算</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">count</td>\n<td style=\"text-align:center\">统计数量</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">max</td>\n<td style=\"text-align:center\">最大值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">min</td>\n<td style=\"text-align:center\">最小值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">avg</td>\n<td style=\"text-align:center\">平均值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">sum</td>\n<td style=\"text-align:center\">求和</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 聚合函数(字段列表) FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>分组查询</strong></p>\n<blockquote>\n<p>在where中不可以使用聚合函数，在having中可以使用聚合函数</p>\n<p>分组之前过滤用where，分组之后过滤条件用having</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表\tFROM 表名 [WHERE 条件] GROUP BY 分组字段名 [HAVING 分组后过滤条件];<br></code></pre></td></tr></table></figure>\n<p>执行顺序：where &gt; 聚合函数 &gt; having</p>\n<p><strong>排序查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1，字段2 排序方式2<br></code></pre></td></tr></table></figure>\n<p>排序方式： ASC升序（默认），DESC降序</p>\n<p><strong>分页查询</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 字段列表 FROM 表名 LIMIT 起始索引,查询记录数;<br></code></pre></td></tr></table></figure>\n<p>显示从起始索引开始的记录数条的查询结果</p>\n<p><strong>DQL执行顺序</strong></p>\n<p>FROM &gt; WHERE &gt; GROUP BY &gt; SELECT &gt; ORDER BY &gt; LIMIT</p>\n<ul>\n<li><h4 id=\"DCL\"><a href=\"#DCL\" class=\"headerlink\" title=\"DCL\"></a>DCL</h4></li>\n</ul>\n<blockquote>\n<p>数据控制语句，用来管理数据库用户，控制数据库访问权限</p>\n</blockquote>\n<p><strong>DCL用户管理</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询用户<br>USE mysql;<br>SELECT * FROM user;<br><br># 创建用户，主机名换成&quot;%&quot;表示可以在任意主机访问数据库<br>CREATE USER &#x27;用户名&#x27;@&#x27;主机名&#x27; IDENTIFIED BY &#x27;密码&#x27;;<br><br># 修改用户密码<br>ALTER USER &#x27;用户名&#x27;@&#x27;主机名&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;<br><br># 删除用户<br>DROP USER &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br></code></pre></td></tr></table></figure>\n<p><strong>权限控制</strong></p>\n<p>常用权限</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">权限</th>\n<th style=\"text-align:center\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ALL, ALL PRIVILEGES</td>\n<td style=\"text-align:center\">所有权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT</td>\n<td style=\"text-align:center\">查询数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">INSERT</td>\n<td style=\"text-align:center\">插入数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE</td>\n<td style=\"text-align:center\">修改数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE</td>\n<td style=\"text-align:center\">删除数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ALTER</td>\n<td style=\"text-align:center\">修改表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DROP</td>\n<td style=\"text-align:center\">删除数据库/表/视图</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CREATE</td>\n<td style=\"text-align:center\">创建数据库/表</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询权限<br>SHOW GRANTS FOR &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br><br># 授予权限<br>GRANT 权限列表 ON 数据库名.表名(*.*所有表) TO &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br><br># 撤销权限<br>REVOKE 权限列表 ON 数据库名.表名 FROM &#x27;用户名&#x27;@&#x27;主机名&#x27;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"3、函数\"><a href=\"#3、函数\" class=\"headerlink\" title=\"3、函数\"></a>3、函数</h3><ul>\n<li><strong>字符串函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CONCAT(S1,S2, … Sn)</td>\n<td style=\"text-align:center\">字符串拼接，将S1-Sn拼接成一个字符串</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LOWER(str)</td>\n<td style=\"text-align:center\">将字符串str全部转为小写</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPPER(str)</td>\n<td style=\"text-align:center\">将字符串全部转为大写</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LPAD(str, n, pad)</td>\n<td style=\"text-align:center\">左填充，用字符串pad对str的左边进行填充，达到n个字符串长度</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RPAD(str, n,  pad)</td>\n<td style=\"text-align:center\">右填充</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">TRIM(str)</td>\n<td style=\"text-align:center\">去掉字符串头部和尾部的空格</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SUBSTRING(str, start, len)</td>\n<td style=\"text-align:center\">返回从字符串str从start起的len长度的字符串</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">SELECT 函数;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><strong>数值函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CEIL(x)</td>\n<td style=\"text-align:center\">向上取整</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">FLOOR(x)</td>\n<td style=\"text-align:center\">向下取整</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MOD(x, y)</td>\n<td style=\"text-align:center\">返回x/y的模</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RAND()</td>\n<td style=\"text-align:center\">返回0~1内的随机数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">ROUND(x, y)</td>\n<td style=\"text-align:center\">求参数x的四舍五入的值，保留y位小数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>日期函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">CURDATE()</td>\n<td style=\"text-align:center\">返回当前日期</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CURTIME()</td>\n<td style=\"text-align:center\">返回当前时间</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">NOW()</td>\n<td style=\"text-align:center\">返回当前日期和时间</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">YEAR(date)</td>\n<td style=\"text-align:center\">获取指定date的年份</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MONTH(date)</td>\n<td style=\"text-align:center\">获取指定date的月份</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DAY(date)</td>\n<td style=\"text-align:center\">获取指定date的日期</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DATE_ADD(date, INTERVAL expr type)</td>\n<td style=\"text-align:center\">返回上一个日期加上时间间隔expr以后的时间值，type(year,month,day)指定年月天</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DATEDIFF(date1, date2)</td>\n<td style=\"text-align:center\">返回起始时间date1和结束时间date2之间的天数，第一个时间减去第二个时间</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>流程函数</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">函数</th>\n<th style=\"text-align:center\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">IF(value, t. f)</td>\n<td style=\"text-align:center\">如果value为true，返回t，否则返回f</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">IFNULL(value1, value2)</td>\n<td style=\"text-align:center\">如果value1不为空，返回value1，否则返回value2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CASE WHEN [val] THEN [res1] … ELSE [ default ] END</td>\n<td style=\"text-align:center\">如果val1为true，返回res1，…否则返回default默认值</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CASE [expr] WHEN [val1] THEN [res1] … ELSE [default] END</td>\n<td style=\"text-align:center\">如果expr的值等于val1，返回res1，…否则返回default默认值</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"4、约束\"><a href=\"#4、约束\" class=\"headerlink\" title=\"4、约束\"></a>4、约束</h3><p>作用于表中字段上的规则，用于限制存储在表中的数据</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">约束</th>\n<th style=\"text-align:center\">描述</th>\n<th style=\"text-align:center\">关键字</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">非空约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">唯一约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">主键约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">默认约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">检查约束</td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">外键约束</td>\n<td style=\"text-align:center\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"5、多表查询\"><a href=\"#5、多表查询\" class=\"headerlink\" title=\"5、多表查询\"></a>5、多表查询</h3><ul>\n<li><p><strong>多表关系</strong></p>\n<p>一对多：在多的一方建立外键，指向一的一方的主键</p>\n</li>\n</ul>\n<p>​        多对多：建立第三张中间表，中间表至少包含两个外键，分别关联两方的主键</p>\n<p>​        一对一：用于做单表拆分，基础字段放在一张表，详情字段放在另一张表。在任意一方加入外键，关联另一方的主键，并设置外键为唯一（UNIQUE）</p>\n<ul>\n<li><p><strong>多表查询</strong></p>\n<ul>\n<li><p>内连接</p>\n<blockquote>\n<p>相当于查询A、B交集部分数据</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 隐式内连接<br>SELECT 字段列表 FROM 表1，表2 WHERE 条件...;<br><br># 显示内连接<br>SELECT 字段列表 FROM 表1 [INNER] JOIN 表2 ON 连接条件;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>外连接</p>\n<blockquote>\n<p>左外连接：查询左表所有数据，以及两张表交集部分数据，将左表的数据和右表的部分数据连接起来</p>\n<p>右外连接：查询右表所有数据，以及两张表交集部分数据</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 左外连接，表1所有数据以及和表2交集部分的数据<br>SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件;<br><br># 右外连接，表2所有数据以及和表1交集部分的数据<br>SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>自连接</p>\n<blockquote>\n<p>自连接：当前表与自身的连接查询，自连接必须使用表别名</p>\n</blockquote>\n</li>\n<li><p>联合查询-union，union all</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 把多次查询的结果合并起来，形成一个新的查询结果集<br># ALL去掉以后会对结果进行去重<br>SELECT 字段列表 表A<br>UNION [ALL]<br>SELECT 字段列表 表B;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>子查询</strong></p>\n<ul>\n<li><p>标量子查询，子查询返回一个标量</p>\n</li>\n<li><p>列子查询，子查询返回一列</p>\n<p>| 操作符 |                 描述                 |<br>| :——: | :—————————————————: |<br>|   IN   |     在指定的集合范围之内，多选一     |<br>| NOT IN |          不在指定的范围之内          |<br>|  ANY   | 子查询返回列表中，有任意一个满足即可 |<br>|  SOME  |              与ANY等同               |<br>|  ALL   |   子查询返回列表的所有值都必须满足   |</p>\n</li>\n<li><p>行子查询，子查询返回的结果是一行</p>\n<p>此时column1可以使用(column1， column2)聚合成多个参数</p>\n<p>操作符：=、&lt;&gt;、IN、NOT IN</p>\n</li>\n<li><p>表子查询，子查询的返回结果是一个表，可以和行子查询加上列子查询的操作符使用，表可以放到from后面</p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 对于子查询，可以将问题拆解成多个不同的查询步骤<br>SELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);<br></code></pre></td></tr></table></figure>\n<h3 id=\"6、事务\"><a href=\"#6、事务\" class=\"headerlink\" title=\"6、事务\"></a>6、事务</h3><blockquote>\n<p>一组操作的集合，是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，这些操作要么<strong>同时成功，要么同时失败</strong></p>\n<p>默认Mysql的事务是自动提交的，当执行一条DML语句，Mysql会立即隐式的提交事务</p>\n</blockquote>\n<ul>\n<li><strong>事务操作</strong></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看/设置事务提交方式<br>SELECT @@autocommit;<br># 事务设置为手动提交<br>SET @@autocommit = 0;<br><br># 提交事务<br>COMMIT;<br><br># 回滚事务<br>ROLLBACK;<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 不修改事务的提交方式操作事务<br># 开启事务<br>START TRANSACTION 或 BEGIN;<br><br># 提交事务<br>COMMIT;<br><br># 回滚事务<br>ROLLBACK;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p><strong>事务四大特性</strong></p>\n<ul>\n<li>原子性(Atomicity)：事务时不可分割的最小操作单元，要么全部成功，要么全部失败</li>\n<li>一致性(Consistency)：事务完成时，必须使所有的数据都保持一致状态</li>\n<li>隔离性(Isolation)：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行</li>\n<li>持久性(Durability)：事务一旦提交或者回滚，它对数据库中的数据改变就是永久的</li>\n</ul>\n</li>\n<li><p><strong>并发事务问题</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">问题</th>\n<th style=\"text-align:center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">脏读</td>\n<td style=\"text-align:center\">一个事务读到另一个事务还没有提交的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">不可重复读</td>\n<td style=\"text-align:center\">一个事务先后读取同一条记录，但两次读取的数据不同，称为不可重复读</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">幻读</td>\n<td style=\"text-align:center\">一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这一行数据已经存在</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>事务隔离级别</strong></p>\n<blockquote>\n<p>读未提交、读已提交、可重复读、串行化</p>\n<p>√表示会出现这个问题，×表示不会出现这个问题</p>\n</blockquote>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">隔离级别</th>\n<th style=\"text-align:center\">脏读</th>\n<th style=\"text-align:center\">不可重复读</th>\n<th style=\"text-align:center\">幻读</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Read uncommitted</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Read committed</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">√</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Repeatable Read</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">√</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Serializable</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n<td style=\"text-align:center\">×</td>\n</tr>\n</tbody>\n</table>\n</div>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看事务的隔离级别<br>SELECT @@TRANSACTION_ISOLATION;<br><br># 设置事务隔离级别<br>SET [SESSION(只对当前窗口有效)|GLOBAL] TRANSACTION ISOLATION LEVEL &#123;隔离级别&#125;<br></code></pre></td></tr></table></figure>\n<p>  事务的隔离界别越高，数据越安全，但是性能越低</p>\n<h2 id=\"数据库进阶\"><a href=\"#数据库进阶\" class=\"headerlink\" title=\"数据库进阶\"></a>数据库进阶</h2><h3 id=\"1、存储引擎\"><a href=\"#1、存储引擎\" class=\"headerlink\" title=\"1、存储引擎\"></a>1、存储引擎</h3><ul>\n<li><p>Mysql体系结构 </p>\n<p>连接层：完成一些类似于连接处理、授权认证及相关的安全方案</p>\n<p>服务层：主要完成大多数的核心服务功能</p>\n<p>引擎层：负责mysql中数据的存储和提取，服务器通过API和存储引擎进行通信</p>\n<p>存储层：将数据存储在文件系统之上，并完成与存储引擎的交互</p>\n<img src=\"/2024/02/10/database-mysql/Mysql.png\" class=\"\" title=\"Mysql\">\n</li>\n<li><p>存储引擎</p>\n<blockquote>\n<p>存储引擎就是存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎时基于表的，而不是基于库的。一个数据库的不同的表可以选择不同的存储引擎</p>\n<p>Mysql默认InnoDB</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询支持的存储引擎<br>show engines;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>InnoDB</p>\n<ul>\n<li>DML操作遵循ACID模型，支持事务</li>\n<li>行级锁，提高并发访问性能</li>\n<li>支持外键，保证事务的完整性和正确性</li>\n</ul>\n<p>文件：每个表对应一个.ibd文件，代表表空间文件，可以通过命令<code>idb2sdi 文件名</code>查看表结构json文件格式</p>\n<img src=\"/2024/02/10/database-mysql/image-20240216162915509.png\" class=\"\" title=\"image-20240216162915509\">\n</li>\n<li><p>MyISAM</p>\n<ul>\n<li>不支持事务，不支持外键</li>\n<li>支持表锁、不支持行锁</li>\n<li>访问速度快</li>\n</ul>\n<p>文件.MYD（数据），.MYI（索引），.sdi（表结构）</p>\n</li>\n<li><p>Memory</p>\n<ul>\n<li>表数据存储在内存当中，收到硬件问题或断电影响只能作为临时表或者缓存使用</li>\n<li>内存存放</li>\n<li>hash索引（默认）</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/image-20240216163439353.png\" class=\"\" title=\"image-20240216163439353\">\n<ul>\n<li><p>存储引擎选择</p>\n<p>InnoDB：如果对事务的完整性有比较高的要求，在并发情况下要求事务的一致性，数据操作除了插入和查询意外，还包括很多的更新、删除操作，InnoDB引擎比较合适</p>\n<p>MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性和并发现要求不是很高。<strong>这个场景被Nosql数据库MongoDB替代了</strong></p>\n<p>MEMORY：将所有数据保存在内存当中，访问速度快，通常用于临时表以及缓存。MEMORY对表的大小有限制，太大的表无法缓存在内存中。<strong>这个场景被Redis替代了</strong></p>\n</li>\n</ul>\n<h3 id=\"2、索引\"><a href=\"#2、索引\" class=\"headerlink\" title=\"2、索引\"></a>2、索引</h3><ul>\n<li><p><strong>索引概述</strong></p>\n<ul>\n<li>索引的结构</li>\n</ul>\n</li>\n<li><h4 id=\"索引分类\"><a href=\"#索引分类\" class=\"headerlink\" title=\"索引分类\"></a><strong>索引分类</strong></h4></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">分类</th>\n<th style=\"text-align:center\">含义</th>\n<th style=\"text-align:center\">特点</th>\n<th style=\"text-align:center\">关键字</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">主键索引</td>\n<td style=\"text-align:center\">针对于表中主键创建的索引</td>\n<td style=\"text-align:center\">默认自动创建，只能有一个</td>\n<td style=\"text-align:center\">PRIMARY</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">唯一索引</td>\n<td style=\"text-align:center\">避免同一个表中某数据列中的值重复</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\">UNIQUE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">常规索引</td>\n<td style=\"text-align:center\">快速定位特定数据</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">全文索引</td>\n<td style=\"text-align:center\">全文索引查找的是文本中通过的关键词</td>\n<td style=\"text-align:center\">可以有多个</td>\n<td style=\"text-align:center\">FULLTEXT</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>按照索引的存储形式分类</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">分类</th>\n<th style=\"text-align:center\">含义</th>\n<th style=\"text-align:center\">特点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">聚集索引</td>\n<td style=\"text-align:center\">将数据存储与索引放到了一块</td>\n<td style=\"text-align:center\">必须有，而且只有一个</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">二级索引</td>\n<td style=\"text-align:center\">将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键</td>\n<td style=\"text-align:center\">可以存在多个</td>\n</tr>\n</tbody>\n</table>\n</div>\n<img src=\"/2024/02/10/database-mysql/image-20240218203730285.png\" class=\"\" title=\"image-20240218203730285\">\n<ul>\n<li><h4 id=\"索引语法\"><a href=\"#索引语法\" class=\"headerlink\" title=\"索引语法\"></a><strong>索引语法</strong></h4></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建索引<br># 一个索引可以关联多行，如果关联多行称为联合索引<br>CREATE [UNIQUE|FULLTEXT] INDEX index_name ON table_name (index_col_name, )<br><br># 查看索引<br>SHOW INDEX FROM table_name;<br><br># 删除索引<br>DROP INDEX index_name ON table_name;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"SQL性能分析\"><a href=\"#SQL性能分析\" class=\"headerlink\" title=\"SQL性能分析\"></a><strong>SQL性能分析</strong></h4><blockquote>\n<p>使用于select的优化</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># SQL执行频率，查看当前数据库语句的访问频率<br>SHOW [session|global] STATUS<br># Com七个下划线，模糊匹配<br>SHOW GLOBAL STATUS LIKE &#x27;Com_______&#x27;<br></code></pre></td></tr></table></figure>\n<p><strong>SQL语句的频率</strong></p>\n<img src=\"/2024/02/10/database-mysql/image-20240218204502697.png\" class=\"\" title=\"image-20240218204502697\">\n<p><strong>慢查询日志</strong></p>\n<blockquote>\n<p>慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位：秒，默认10)的所有SQL语句的日志</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看是否开启，日志文件默认在/var/lib/mysql里面<br>SHOW VARIABLES LIKE &#x27;slow_query_log&#x27;;<br><br># 修改/etc/my.cnf中配置开启，配置时间<br>slow_query_log=1   <br>long_query_time=2<br></code></pre></td></tr></table></figure>\n<p><strong>profile详情</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看是否支持prifile<br>SELECT @@have_profiling;<br><br># 设置为开<br>SET profiling=1;<br><br># 查看profile<br>SHOW PROFILES;<br></code></pre></td></tr></table></figure>\n<p>执行完SQL语句以后，通过以下指令查看执行耗时情况</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看每一条SQL耗时基本情况<br>SHOW PROFILES;<br><br># 查看指定query_id的SQL语句各个阶段的耗时情况<br>SHOW PROFILE FOR QUERY query_id;<br><br># 查看指定SQL语句的CPU使用情况<br>SHOW PROFILE CPU FOR QUERY query_id;<br></code></pre></td></tr></table></figure>\n<p><strong>explain执行计划</strong></p>\n<blockquote>\n<p>EXPLAIN或者DESC命令获取Mysql如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接的顺序</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">EXPLAIN SELECT SQL语句;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/02/10/database-mysql/image-20240218211138993.png\" class=\"\" title=\"image-20240218211138993\">\n<p>表头的含义：</p>\n<img src=\"/2024/02/10/database-mysql/image-20240218212814126.png\" class=\"\" title=\"image-20240218212814126\">\n<img src=\"/2024/02/10/database-mysql/image-20240218212115878.png\" class=\"\" title=\"image-20240218212115878\">\n<figure class=\"highlight txt\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs txt\">type<br>const\t以主键或以唯一的列作为索引扫描<br>ref\t\t非唯一的值作为查询索引<br>index\t用了索引，但是会对整个索引进行遍历<br>all\t\t全表扫描<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"索引使用\"><a href=\"#索引使用\" class=\"headerlink\" title=\"索引使用\"></a><strong>索引使用</strong></h4></li>\n</ul>\n<p><strong>联合索引</strong></p>\n<p>使用要遵循<strong>最左前缀法则</strong>：查询<strong>从索引的最左列开始</strong>，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。</p>\n<p><strong>范围查询</strong>：联合索引中出现范围查询（&gt;,&lt;)，范围查询右侧的列索引失效。但是使用大于等于和小于等于索引并不会失效。</p>\n<p>例子</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># student有联合索引(id,name,age)<br># 1、索引都可以使用<br>select * from student where id = 1 and name = &quot;Lili&quot; and age = 20;<br><br># 2、索引name，age失效<br>select * from student where id = 1 and age = 20;<br><br># 范围查询<br># name和age索引均失效<br>select * from student where id &gt; 1 and name = &quot;Lili&quot; and age = 20;<br></code></pre></td></tr></table></figure>\n<p><strong>索引失效</strong></p>\n<p>索引列操作：不要在索引上进行列操作，否则索引会失效</p>\n<p>字符串类型：不加单引号索引会失效</p>\n<p>模糊查询：<strong>头部进行模糊匹配(%%某某)</strong>，索引会失效，尾部进行模糊匹配（某某%%），索引不会失效。</p>\n<p>or连接的条件：如果or前面的条件列有索引，后面的条件没有索引，所涉及的索引都不会引用到，只有两侧都有索引的时候，才有效</p>\n<p>数据分布影响：如果索引比全表扫描更慢，则不使用索引，查询的数据大于一半，走全表不走索引。</p>\n<p><strong>SQL提示</strong></p>\n<blockquote>\n<p>在sql语句中加入一些认为的提示来达到优化操作的目的</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># use index指定使用哪个索引<br>explain select * from table use index(idxname) ...<br><br># ignore index<br># force index 同上<br></code></pre></td></tr></table></figure>\n<p><strong>覆盖索引</strong></p>\n<p>尽量使用覆盖索引：查询使用了索引，并且需要返回的列，在该索引中已经能够全部找到，减少使用select *</p>\n<p>using index condition：查找使用了索引，但是需要回表查询数据</p>\n<p>using where, using index：查询使用了索引，但是不需要回表</p>\n<img src=\"/2024/02/10/database-mysql/image-20240218221642388.png\" class=\"\" title=\"image-20240218221642388\">\n<p>前两条不需要回表，后一条需要回表</p>\n<p><strong>前缀索引</strong></p>\n<blockquote>\n<p>将字符串的前缀提取出来，创建索引，可以节约索引空间</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># n表示取column_name列的前n个数据<br>CREATE INDEX idx_XXX ON table_name(column_name(n));<br><br># 计算前缀长度的选择性，越接近1越好<br>SELECT COUNT(DISTINCT substring(email, 1, 5)) / COUNT(*) FROM table_name;<br></code></pre></td></tr></table></figure>\n<p><strong>单列索引和联合索引选择</strong></p>\n<p>如果涉及到多个查询条件，推荐使用联合索引，联合索引会更少的回表查询</p>\n<h4 id=\"Quetion\"><a href=\"#Quetion\" class=\"headerlink\" title=\"Quetion\"></a>Quetion</h4><img src=\"/2024/02/10/database-mysql/image-20240218221919863.png\" class=\"\" title=\"image-20240218221919863\">\n<p>建立id主键，username，password联合索引</p>\n<ul>\n<li><h4 id=\"索引设计原则\"><a href=\"#索引设计原则\" class=\"headerlink\" title=\"索引设计原则\"></a><strong>索引设计原则</strong></h4></li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/image-20240218224016746.png\" class=\"\" title=\"image-20240218224016746\">\n<h3 id=\"3、SQL优化\"><a href=\"#3、SQL优化\" class=\"headerlink\" title=\"3、SQL优化\"></a>3、SQL优化</h3><ul>\n<li><h4 id=\"插入数据insert优化\"><a href=\"#插入数据insert优化\" class=\"headerlink\" title=\"插入数据insert优化\"></a><strong>插入数据</strong>insert优化</h4><p>批量插入而不是单条插入：批量插入只需要建立一次连接即可</p>\n<p>建议手动提交事务：不需要每一次插入时自动开启和关闭事务，而是将所有insert执行结束以后统一关闭</p>\n<p><strong>建议主键顺序插入</strong></p>\n<p>大批量插入数据：使用Mysql数据库提供的load指令进行插入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 如何使用load<br># 1、连接服务器时加上参数--local-infile<br>mysql --local-infile -u root -p<br><br># 2、设置全局参数local_infile为1<br>set global local_infile = 1;<br><br># 3、执行load指令将数据加载表结构中<br>load data local infile &#x27;文件名&#x27; into table &#x27;表名&#x27; fields teminated by &#x27;分割符&#x27; lines terminated by &#x27;行分隔符\\n&#x27;;<br></code></pre></td></tr></table></figure>\n</li>\n<li><h4 id=\"主键优化\"><a href=\"#主键优化\" class=\"headerlink\" title=\"主键优化\"></a><strong>主键优化</strong></h4></li>\n</ul>\n<blockquote>\n<p>InnoDB中表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。</p>\n</blockquote>\n<p>页大小为16kb，每个页至少包含两行数据</p>\n<p>主键乱序插入可能会出现页分裂现象，执行删除操作会出现页合并现象</p>\n<p>主键设计原则：</p>\n<p>​    满足业务需求的情况下，尽量降低主键的长度</p>\n<p>​    插入时尽量按照主键顺序插入，选择自增主键</p>\n<p>​    尽量不要使用无序的自然主键</p>\n<p>​    业务操作，避免对主键的修改</p>\n<ul>\n<li><strong>order by优化</strong></li>\n</ul>\n<p>排序方式</p>\n<p>Using filesort：先找到数据再进行排序</p>\n<p>Using index：通过有序索引直接返回，不需要额外排序</p>\n<p>默认会对索引进行升序排序</p>\n<ul>\n<li><strong>limit优化</strong></li>\n</ul>\n<p>对于数据量大的，优化思路为使用覆盖索引+子查询</p>\n<ul>\n<li><p>count</p>\n<p>count(*)优于count(1)&gt;count(主键)&gt;count(字段)</p>\n</li>\n<li><h4 id=\"update优化\"><a href=\"#update优化\" class=\"headerlink\" title=\"update优化\"></a><strong>update优化</strong></h4></li>\n</ul>\n<p>对需要更新的字段尽可能建立索引，这样如果处于多个事务情况下，只会使用行锁，如果没有建立索引，行锁会升级为表锁，无法进行并行</p>\n<h3 id=\"4、视图-存储过程-触发器\"><a href=\"#4、视图-存储过程-触发器\" class=\"headerlink\" title=\"4、视图/存储过程/触发器\"></a>4、视图/存储过程/触发器</h3><blockquote>\n<p>Mysql数据库当中的存储对象</p>\n</blockquote>\n<ul>\n<li><h4 id=\"视图\"><a href=\"#视图\" class=\"headerlink\" title=\"视图\"></a>视图</h4></li>\n</ul>\n<blockquote>\n<p>视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。</p>\n</blockquote>\n<p>操作视图中的数据就和操作数据库表一样，可以将视图理解为一张不被存储的虚拟表。</p>\n<p>视图当中的数据并不存在，如果往视图里面插入数据，数据将存在基表当中，如果不想给用户表的权限，可以给用户一个视图。 </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建视图<br>CREATE [OR REPLACE] VIEW 视图名称(列名列表) AS SELECT语句 [WITH CASCADED|LOCAL CHECk OPTION];<br><br># 查询视图<br># 查看创建视图语句<br>SHOW CREATE VIEW 视图名称;<br># 查看视图数据<br>SELECT * FROM 视图名称...;<br><br># 修改视图<br># 方式一、使用创建的语句，用REPLACE替换掉<br>CREATE[OR REPLACE]...<br># 方式二<br>ALTER VIEW 视图名称(列表名称) AS SELECT ...;<br><br># 删除视图<br>DROP VIEW IF EXISTS 视图名称<br></code></pre></td></tr></table></figure>\n<p><strong>视图当中的检查选项</strong></p>\n<p><strong>CASCADED（向下级联）</strong></p>\n<p>当使用WITH CHECK OPTION子句创建视图时，Mysql会通过视图检查正在更改的每个行。进行校验，所插入的数据是否满足SELECT语句。</p>\n<p>Mysql中还可以为视图再创建新的视图，新的视图如果有option选项会影响到之前的视图</p>\n<p><strong>LOCAL（不向下级联，只是检查有option的条件）</strong></p>\n<p><strong>视图的更新和作用</strong></p>\n<p>要使视图可以更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下中任何一项，则该视图不可更新：</p>\n<p>聚合函数、DISTINCT、GROUP BY、HAVING、UNION或者UNION ALL</p>\n<p>作用：1、可以简化用户对数据的理解，简化用户操作。2、控制用户对表的查看权限。3、数据独立，屏蔽真实表结构。4、可以简化多表联查的操作。</p>\n<ul>\n<li><h4 id=\"存储过程\"><a href=\"#存储过程\" class=\"headerlink\" title=\"存储过程\"></a>存储过程</h4></li>\n</ul>\n<blockquote>\n<p>存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输</p>\n<p>思想上就是数据库SQL语言层面的代码封装与重用，下一次如果执行相同的业务直接调用存储过程</p>\n</blockquote>\n<p><strong>特点</strong>    好像跟函数有点像</p>\n<p>封装、复用</p>\n<p>可以接收参数，也可以返回数据</p>\n<p>作用：减少网络交互，提升效率</p>\n<blockquote>\n<p>在命令行中，执行创建存储过程的sql时，需要通过关键字<code>delimiter</code>指定SQL语句的结束符</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建<br># 参数列表为IN/OUT/INOUT 参数名，分别表示参数输入，输出，输入和输出参数<br>CREATE PROCEDURE 存储过程名称([参数列表])<br>BEGIN<br>\t--SQL语句，可以是多条<br>END;<br><br># 调用<br>CALL 名称([参数列表]);<br><br># 查看<br># 方法一，查看系统的数据库表，xxx为数据库名<br>SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = &#x27;XXX&#x27;;<br># 方法二，使用show查看创建过程<br>SHOW CREATE PROCEDURE 存储过程名称;<br><br># 删除<br>DROP PROCEDURE [IF EXISTS] 存储过程名称;<br><br># 定义结束符为$$<br>delimiter $$<br></code></pre></td></tr></table></figure>\n<p><strong>系统变量</strong>（全局GLOBAL，会话SESSION）</p>\n<p>重启以后系统参数会恢复为默认值</p>\n<p>永久修改系统参数需要修改/etc/my.cnf中配置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查看所有系统变量<br>SHOW [SESSION|GLOBAL] VARIABLES;<br>SHOW VARIABLES LIKE &#x27;..&#x27;;<br># 查看指定变量<br>SELECT @@[SESSION|GLOBAL].系统变量名<br><br># 设置系统变量，默认为SESSION级别<br>SET [SESSION|GLOBAL] 变量名=值;<br>SET @@[SESSION|GLOBAL].系统变量名 = 值;<br></code></pre></td></tr></table></figure>\n<p><strong>用户自定义变量</strong></p>\n<blockquote>\n<p>作用域为当前连接</p>\n<p>变量无需声明，如果拿到的是没有声明的变量，则会获得NULL</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 赋值，可以同时赋值多个变量，用逗号隔开<br>SET @var_name = expr;<br>SET @var_name := expr;<br><br># SELECT赋值<br>SELECT @var_name := expr;<br># 将sql查询的结果赋值给变量<br>SELECT 字段名 INTO @var_name FROM 表名;<br><br># 使用<br>SELECT @var_name;<br></code></pre></td></tr></table></figure>\n<p><strong>局部变量</strong></p>\n<blockquote>\n<p>在局部生效，需要DECLARE声明，作用域在BEGIN…END块内</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 声明<br>DECLARE 变量名 变量类型(数据库数据的类型) [DEFAULT 默认值]<br><br># 赋值<br>SET 变量名 = 值;<br>SET 变量名 := 值;<br>SELECT 字段名 INTO @var_name FROM 表名;<br></code></pre></td></tr></table></figure>\n<p><strong>存储过程相关语法</strong></p>\n<blockquote>\n<p>逻辑语言都在存储过程中定义，可以使用传入的参数</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># IF 条件判断<br>IF 条件1 THEN<br>\t...<br>ELSEIF 条件2 THEN<br>\t...<br>ELSE<br>\t...<br>END IF;<br><br># CASE 条件选择，WHEN后面可以有多种选择<br># 语法一<br>CASE case_value<br>\tWHEN when_value1 THEN ...<br>\tWHEN when_value2 THEN ...<br>\tELSE ...<br>END CASE;<br># 语法二<br>CASE <br>\tWHEN 表达式真 THEN ...<br>\tELSE ...<br>END CASE;<br><br># WHILE循环<br>WHILE 条件 DO<br>\tSQL逻辑<br>END WHILE：<br><br># REPEAT循环，当满足条件时，退出循环<br>REPEAT<br>\tSQL逻辑...<br>\tUNTIL 条件<br>END REPEAT;<br><br># LOOP循环<br># LOOP实现的是简单循环<br># LEAVE：配合循环使用，退出循环，作用类似于break<br># ITERATE：必须在循环中使用，作用类似于CONTINUE<br>[begin_label:] LOOP<br>\tSQL逻辑<br>\t<br>END LOOP[end_label]<br><br># 退出循环<br>LEAVE label;<br># 跳过本次进入下一次循环<br>ITERATE label;<br></code></pre></td></tr></table></figure>\n<p><strong>游标Cursor</strong></p>\n<p>游标（Cursor）是一种用于在存储过程或函数中遍历结果集的机制。游标允许逐行访问结果集，并在每行上执行相应的操作</p>\n<p>通常情况下，当执行一个查询语句时，MySQL 会返回一个结果集，该结果集包含了查询返回的所有行。以使用游标来逐行处理这个结果集，而不是一次性获取所有结果。这在处理大量数据或需要逐行处理结果的情况下非常有用</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 声明游标、打开游标、获取下一行、关闭游标<br>DELIMITER //<br><br>CREATE PROCEDURE process_users()<br>BEGIN<br>    DECLARE done INT DEFAULT FALSE;<br>    DECLARE user_id INT;<br>    DECLARE user_name VARCHAR(255);<br><br>    -- 声明游标<br>    DECLARE user_cursor CURSOR FOR <br>        SELECT id, name FROM users;<br><br>    -- 打开游标<br>    OPEN user_cursor;<br><br>    -- 循环遍历结果集<br>    read_loop: LOOP<br>        -- 获取下一行数据<br>        FETCH user_cursor INTO user_id, user_name;<br>        IF done THEN<br>            LEAVE read_loop;<br>        END IF;<br>        <br>        -- 处理当前行数据<br>        -- 这里可以执行相应的操作，如输出到日志或进行其他逻辑处理<br>        SELECT CONCAT(&#x27;User ID: &#x27;, user_id, &#x27;, User Name: &#x27;, user_name);<br><br>    END LOOP;<br><br>    -- 关闭游标<br>    CLOSE user_cursor;<br><br>END //<br><br>DELIMITER ;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"存储函数\"><a href=\"#存储函数\" class=\"headerlink\" title=\"存储函数\"></a>存储函数</h4></li>\n</ul>\n<blockquote>\n<p>有返回值的存储过程，存储函数的参数只能时IN类型’</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 语法结构<br>CREATE FUNCTION 存储函数名称([参数列表])<br>RETURNS type [characteristic...]<br>BEGIN<br>\t--SQL语句<br>\tRETURN ...;<br>END;<br><br>characteristics存储参数的特性<br>DETERMINISTIC : 相同的输入参数总是产生相同的结果<br>NO SQL : 不包含SQL语句<br>READS SQL DATA : 包含读取数据的语句，但不包含写入数据的语句<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h4 id=\"触发器\"><a href=\"#触发器\" class=\"headerlink\" title=\"触发器\"></a>触发器</h4></li>\n</ul>\n<blockquote>\n<p>在insert/update/delete之前或者之后，触发并执行触发器中定义的SQL语句集合。</p>\n<p>使用别名OLD和NEW来引用触发器中发生变化的记录内容</p>\n<p>触发器只支持行级触发，不支持语句级别触发：如果一个UPDATE语句影响了5行，则触发器会被出发5次</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">触发器类型</th>\n<th style=\"text-align:center\">NEW和OLD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">INSERT型触发器</td>\n<td style=\"text-align:center\">NEW表示将要或者已经新增的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE型触发器</td>\n<td style=\"text-align:center\">OLD表示修改之前的数据，NEW表示将要或已经修改后的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE型触发器</td>\n<td style=\"text-align:center\">OLD表示将要或者已经删除的数据</td>\n</tr>\n</tbody>\n</table>\n</div>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 创建触发器<br>CREATE TRIGGER trigger_name<br>BEFORE/AFTER(在之前还是之后) INSERT/UPDATE/DELETE(触发器类型)<br>ON tbl_name FOR EACH ROW --行级触发器<br>BEGIN<br>\ttrigger_stmt; # 触发器逻辑<br>END;<br><br># 查看<br>SHOW TRIGGERS;<br><br># 删除，数据库中的触发器<br>DROP TRIGGER [schema_name.]trigger_name;<br></code></pre></td></tr></table></figure>\n<h3 id=\"5、锁\"><a href=\"#5、锁\" class=\"headerlink\" title=\"5、锁\"></a>5、锁</h3><blockquote>\n<p>锁是计算机协调多个进程或线程并发访问某一资源的机制，用于保证数据的一致性和有效性。</p>\n</blockquote>\n<ul>\n<li>全局锁</li>\n</ul>\n<p>对整个数据库进行加锁，加锁以后整个实例就处于只读状态，后续的DML的写语句，DDL语句以及更新操作的事务提交语句都会被阻塞</p>\n<p>做数据库的全库逻辑备份的时候，会对所有的表进行锁定</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 为表加全局锁<br>FLUSH TABLES WITH READ LOCK;<br><br># 备份数据库<br>musqldump -uroot -p1234 数据库&gt;文件名<br><br># 释放全局锁<br>UNLOCK TABLES;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>表级锁</li>\n</ul>\n<p>每次操作会锁住整张表，发生锁冲突的概率最高，并发度最低</p>\n<p><strong>表锁</strong></p>\n<blockquote>\n<p>表共享读锁：对于所有客户端的连接都只能读，不能写</p>\n<p>表独占写锁：对于获取锁资源的客户端可以写，其他客户端不能进行读也不能执行写会被阻塞</p>\n</blockquote>\n<p>语法</p>\n<p>1、加锁：lock tables 表名… read/write</p>\n<p>2、释放锁：unlock tables /  客户端断开连接</p>\n<p><strong>元数据锁</strong>（meta data lock）</p>\n<blockquote>\n<p>MDL加锁过程是系统自动控制的，无需显示使用，在访问一张表的时候会自动加上</p>\n<p>元数据锁就是对表结构进行加锁</p>\n</blockquote>\n<p>当对一张表进行增删改查的时候，自动会加上MDL读锁，当对表结构进行变更时，会自动加上MDL写锁</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">对应SQL</th>\n<th style=\"text-align:center\">锁类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">lock table xx read/write</td>\n<td style=\"text-align:center\">SHARED_READ_ONLY/SHARED_NO_READ_WRITE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">select、select .. lock in share mode</td>\n<td style=\"text-align:center\">SHARED_READ</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">insert、update、delet、sekect…from update</td>\n<td style=\"text-align:center\">SHARED_WRITE</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">alter table…</td>\n<td style=\"text-align:center\">EXCLUSIVVE</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>意向锁</strong></p>\n<img src=\"/2024/02/10/database-mysql/image-20240222075448991.png\" class=\"\" title=\"image-20240222075448991\">\n<img src=\"/2024/02/10/database-mysql/image-20240222075706155.png\" class=\"\" title=\"image-20240222075706155\">\n<ul>\n<li>行级锁</li>\n</ul>\n<blockquote>\n<p>应用在InnoDB存储引擎当中</p>\n</blockquote>\n<p>InnoDB的数据时基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁</p>\n<p><strong>行锁</strong></p>\n<p>锁定单个行记录的锁，防止其他事务对此进行update和delete，在RC、RR隔离级别都支持</p>\n<p>1、共享锁（S）：允许一个事务去读取一行，阻止其他事务获得相同数据集的排它锁，其他事务能读不能写</p>\n<p>2、排它锁（X）：允许获取排它锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排它锁，其他事务不能写也不能读</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">SQL</th>\n<th style=\"text-align:center\">行锁类型</th>\n<th style=\"text-align:center\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">INSERT</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">UPDATE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DELETE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">自动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT</td>\n<td style=\"text-align:center\">不加任何锁</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT … LOCK IN SHARE MODE</td>\n<td style=\"text-align:center\">共享锁</td>\n<td style=\"text-align:center\">手动加锁</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">SELECT … FOR UPDATE</td>\n<td style=\"text-align:center\">排它锁</td>\n<td style=\"text-align:center\">手动</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>间隙锁</strong></p>\n<p>锁定索引记录间隙，确保索引记录间隙不变，防止其他事务在这个间隙执行insert，产生幻读，在RR级别下支持</p>\n<p><strong>临建锁</strong>（next-key）</p>\n<p>同时锁住行记录也锁住间隙</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 查询数据库中的锁<br>select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;<br></code></pre></td></tr></table></figure>\n<h3 id=\"6、InnoDB引擎\"><a href=\"#6、InnoDB引擎\" class=\"headerlink\" title=\"6、InnoDB引擎\"></a>6、InnoDB引擎</h3><ul>\n<li><h4 id=\"逻辑存储结构\"><a href=\"#逻辑存储结构\" class=\"headerlink\" title=\"逻辑存储结构\"></a><strong>逻辑存储结构</strong></h4></li>\n</ul>\n<p>表空间（ibd文件）：一个mysql实例可以对应多个表空间，用于存储记录、索引等数据</p>\n<p>段：分为数据段、索引段、回滚段，InnoDB是索引组织表，数据段就是B+书的叶子节点，索引段即是B+书的非叶子节点，段用来管理多个区</p>\n<p>区：表空间的单元结构，每个区的大小为1M，一个区中一共有64个连续的页</p>\n<p>页：页大小16kB，是InnoDB存储引擎磁盘管理的最小单元，保证页的连续性，会申请4-5个区</p>\n<img src=\"/2024/02/10/database-mysql/image-20240223204149464.png\" class=\"\" title=\"image-20240223204149464\">\n<ul>\n<li><h4 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h4></li>\n</ul>\n<img src=\"/2024/02/10/database-mysql/innodb-architecture-8-0.png\" class=\"\" title=\"innodb-architecture-8-0\">\n<p><strong>内存结构</strong></p>\n<blockquote>\n<p>磁盘结构存储的是一些表空间和表数据文件，包括日志表空间，系统表空间，撤销表空间，重做表空间等等</p>\n</blockquote>\n<p>buffer pool缓存池</p>\n<p>缓冲区是内存中的一个区域，可以缓冲存储磁盘上经常要操作的数据，利用局部性原理减少磁盘IO，加快处理速度</p>\n<p>缓冲池以page页为单位，底层采用链表数据结构管理page</p>\n<p>change buffer更改缓存，<strong>针对非唯一二级索引页</strong></p>\n<p>当需要对数据进行变更，即执行DML语句时，如果buffer pool中不存在当前数据page，不会直接操作磁盘，会先将数据变更缓存在change buffer在未来数据被读取的时候，再将数据合并恢复到buffer pool中</p>\n<p>Adaptive Hash Index自适应哈希索引</p>\n<p>log buffer日志缓存区</p>\n<p><strong>后台线程</strong></p>\n<blockquote>\n<p>作用：将InnoDB缓冲区当中的数据在合适的时间写入到磁盘当中</p>\n</blockquote>\n<p>1、Master Thread</p>\n<p>核心后台线程，负责调度其他线程，将缓冲池中的数据异步刷新到磁盘当中，保持数据的一致性</p>\n<p>2、IO Thread</p>\n<p>采用的是AIO（异步非阻塞IO）来处理IO请求</p>\n<p>4个读线程、4个写线程、1个日志线程、1个插入缓存线程（写缓冲区刷新到磁盘）</p>\n<p>3、Purge Thread</p>\n<p>回收事务已经提交的undo log，在事务提交之后，undo log可能不用了，就用它来回收</p>\n<p>4、Page Cheaner Thread</p>\n<p>协助Master Thread刷新脏页到磁盘的线程</p>\n<ul>\n<li><h4 id=\"事务原理\"><a href=\"#事务原理\" class=\"headerlink\" title=\"事务原理\"></a>事务原理</h4></li>\n</ul>\n<p>事务的原子性、一致性和持久性是通过日志文件来保证的，包括redo.log和undo.log</p>\n<p>事务的隔离性是通过锁+MVCC（多版本并发控制）来进行保证的</p>\n<p><strong>redo log</strong>事务的持久性（事务提交后数据的改变是永久的）</p>\n<p>重做日志，记录事务提交时数据页的物理修改，用来实现事务的持久性(事务一旦提交，对数据的改变时持久的）</p>\n<p>当系统在执行Mysql的DML语句时，会先从数据库缓存中查找是否有对应的页面，如果在缓存当中则对数据进行修改，这种在缓冲中修改后但还未写入磁盘的数据页，叫做脏页，后通过后台进程写入到磁盘当中，如果在写入的过程中发生异常，就会出现持久性消失的现象</p>\n<p>redo log会把数据页的变化记录到redo log当中，当事务提交时，会把redo log刷新到磁盘当中，可以通过log对数据进行恢复，如果redo log刷新页失败，则事务执行也就失败，不影响一致性</p>\n<p><strong>undo log</strong>事务的原子性（事务是最小操作单位，要么全部成功，要么全部失败）</p>\n<p>回滚日志，用于记录数据被修改前的信息，提供回滚和MVCC。当执行DML语句时，会记录数据变化前的数据长什么样，在回滚日志中，记录的时执行sql的反向操作，逆操作</p>\n<p>undo log存放在段当中，回滚段</p>\n<ul>\n<li><h4 id=\"MVCC多版本并发控制\"><a href=\"#MVCC多版本并发控制\" class=\"headerlink\" title=\"MVCC多版本并发控制\"></a>MVCC多版本并发控制</h4></li>\n</ul>\n<blockquote>\n<p>Mutil-Version Concurrency Control，多版本并发控制。维护一个数据的多个版本，使得读写此操作没有冲突。依赖于数据库记录中的三个隐式字段、undo log日志、readView</p>\n</blockquote>\n<p><strong>相关概念</strong></p>\n<p>当前读：读取的时记录的最新版本。因为Mysql的默认隔离界别是RR（repeatable read）可重复读，所以当另一个事务对数据进行修改时，当前事务读到的数据就不是当前最新的版本。要想读到最新版本，可以通过select .. lock in share mode,select .. for update来完成</p>\n<p>快照读：正常的select（不加锁）就是快照读，读取的是数据的可见版本</p>\n<p>Read Committed：每一次select 都会生成一个快照读</p>\n<p>Repeatable Read：开始事务后第一个select才是产生快照读的地方，后面的select都是查询快照</p>\n<p>Serializable：快照读会退化为当前读</p>\n<p><strong>记录当中的隐藏字段</strong></p>\n<p>DB_TRX_ID：最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID</p>\n<p>DB_ROLL_PTR：回滚指针，指向这条记录的上一个版本，用于配合undo log<br>DB_ROW_ID：隐藏主键，表结构没有主键，则会自动生成隐藏字段</p>\n<p><strong>undo log日志</strong></p>\n<p>如果使用insert的时候产生的日志只在回滚的时候需要，在事务提交后，可以立即删除</p>\n<p>如果使用的是update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读的时候也需要，不会立即被删除</p>\n<img src=\"/2024/02/10/database-mysql/image-20240224160500080.png\" class=\"\" title=\"image-20240224160500080\">\n<p><strong>ReadView</strong></p>\n<p>读视图：快照读SQL执行时MVCC提取数据的一句，记录并维护系统当前活跃的事务id</p>\n<p>字段，通过对比当前事务的id：trx_id和下面的id进行对比来实现版本访问控制</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">字段</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">m_ids</td>\n<td style=\"text-align:center\">当前活跃的事务ID集合</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">min_trx_id</td>\n<td style=\"text-align:center\">最小活跃事务ID</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">max_trx_id</td>\n<td style=\"text-align:center\">预分配事务ID，当前最大事务ID+1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">creator_trx_id</td>\n<td style=\"text-align:center\">ReadView创建者的事务ID</td>\n</tr>\n</tbody>\n</table>\n</div>\n<img src=\"/2024/02/10/database-mysql/image-20240224161313751.png\" class=\"\" title=\"image-20240224161313751\">\n<p><strong>Read Commited</strong>读提交下的规则</p>\n<blockquote>\n<p>事务中每一次执行快照读时都会生成ReadView</p>\n</blockquote>\n<img src=\"/2024/02/10/database-mysql/image-20240224162152111.png\" class=\"\" title=\"image-20240224162152111\">\n<p>通过上面四条规则可以找到最新已经提交的事务版本</p>\n<p><strong>Repeatable Read</strong>可重复读的情况</p>\n<blockquote>\n<p>仅在事务中第一次执行快照读的时候生成ReadView，后续会复用该ReadView</p>\n</blockquote>\n<img src=\"/2024/02/10/database-mysql/image-20240224162359110.png\" class=\"\" title=\"image-20240224162359110\">\n<p>隔离性：保证事务不在外部并发操作影响下独立完成，通过MVCC+锁来保证</p>\n<p>一致性：事务完成时，所有数据都保持一致，通过日志实现</p>\n<img src=\"/2024/02/10/database-mysql/image-20240224162626695.png\" class=\"\" title=\"image-20240224162626695\">\n<h3 id=\"7、MySQL管理\"><a href=\"#7、MySQL管理\" class=\"headerlink\" title=\"7、MySQL管理\"></a>7、MySQL管理</h3><ul>\n<li>系统数据库</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">数据库</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">mysql</td>\n<td style=\"text-align:center\">存储Mysql服务器正常运行所需要的各种信息（用户、权限等）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">information_schema</td>\n<td style=\"text-align:center\">提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型以及访问权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">performance_schema</td>\n<td style=\"text-align:center\">为Mysql服务器运行时状态提供了一个底层监控功能，用于收集数据库服务器性能参数</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">sys</td>\n<td style=\"text-align:center\">方便开发人员进行性能调优和诊断的视图</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>常用工具</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># mysql [option] [database]<br>mysql<br>\t-u, --user=\t\t # 指定用户名<br>    -p, --password=\t\t# 指定密码<br>    -h, --host=\t\t# 指定服务器ip或域名<br>    -p, --port=\t\t# 指定端口号<br>    -e, --execute=\t# 执行sql语句并推出<br></code></pre></td></tr></table></figure>\n<p>mysqladmin</p>\n<p>​    执行管理操作的客户端程序</p>\n<p>​    —help查看帮助文档</p>\n<p>mysqlbinlog</p>\n<p>​    如果查看一些二进制文本的数据，使用这个可以进行数据查看</p>\n<p>mysqlshow</p>\n<p>​    客户端对象查找工具，可以用于查找存在哪些数据库、数据库中的表、表中的列或者索引</p>\n<p>​    —count 显示数据库及表的统计信息</p>\n<p>​    -i 显示指定数据库或指定表的状态信息</p>\n<p><strong>mysqldump</strong></p>\n<p>​    用于备份数据库或在不同数据库之间进行数据迁移</p>\n<p><strong>mysqlimport/source</strong></p>\n<p>​    用于数据的导入工具</p>\n<h2 id=\"QA\"><a href=\"#QA\" class=\"headerlink\" title=\"QA\"></a>QA</h2><p>1、InnoDB数据页中的数据存储</p>\n<p>2、B+树是如何进行查询的</p>\n<p>3、MySql单表最大限制，为什么</p>\n<p>4、索引失效有哪些</p>\n<p>5、count（*）和count（1）哪个性能好一些</p>\n"},{"title":"深度学习实践实验-线性回归","date":"2023-01-03T09:19:30.000Z","cover":"/img/default_cover08.jpg","top_img":null,"_content":"# 实验一、线性回归\n\n* 已知模型y = a*x + b\n* 生成带噪声的数据拟合线性函数\n* 绘制图像拟合效果\n\n\n```python\n# 导入相关包\nimport torch\nimport numpy as np\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 生成y = a*x + b的噪声数据200个\n# 定义a = 3， b = 2\na, b = 3, 2\n\nx_datas = torch.linspace(1,20,200)\nrand_noise = torch.randn(200)*3\ny_lables = a*x_datas + b + rand_noise\n```\n\n\n```python\n# 绘制散点图\nplt.figure(figsize=(10, 8))\nplt.scatter(x_datas, y_lables)\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_3_0.png)\n​    \n\n\n\n```python\n# 将数据划分为训练集和测试集，按照180，20进行划分\n# 每十个数据中，分层抽取出一个数据作为测试集\n\ntest_index = [10*i + np.random.randint(10) for i in range(20)]\ntrain_index = [i for i in range(200) if i not in test_index]\n\nX_train1, X_test1, y_train1, y_test1 = x_datas[train_index], x_datas[test_index], y_lables[train_index], y_lables[test_index]\ny_train1\n```\n\n\n\n\n    tensor([ 3.6945,  4.7438,  7.9504,  5.5705,  5.6000,  9.5666,  8.5461,  4.9789,\n             0.6976,  5.6866,  4.2295, 10.9321, 11.2976,  7.9842, 12.1275,  8.0943,\n            10.5445, 13.4849, 18.5069, 11.6880, 16.8814, 12.7575, 10.7111, 12.1603,\n            14.7055, 14.3254, 11.4367, 17.6528, 18.5793, 17.8409, 13.8733, 16.6622,\n            18.6143, 14.5482, 16.6509, 17.4552, 20.0250, 20.3924, 20.6348, 18.2929,\n            16.6831, 20.4449, 17.3773, 18.3895, 18.2360, 24.1661, 18.2511, 16.6143,\n            20.3642, 16.5544, 19.0061, 25.6141, 20.1254, 21.4796, 23.3279, 20.1736,\n            25.3058, 26.7936, 24.8702, 23.0888, 24.2360, 26.3334, 26.8100, 22.9726,\n            25.0721, 28.1969, 27.3128, 28.3941, 27.2811, 25.5293, 29.3596, 30.8378,\n            29.3787, 30.2246, 28.6970, 19.3994, 31.6431, 35.1937, 26.6844, 31.5928,\n            32.8604, 31.2751, 26.1607, 26.1867, 27.4753, 28.5589, 32.5150, 35.3546,\n            29.3716, 30.2867, 34.1565, 36.8429, 32.5876, 41.2268, 32.7979, 35.0479,\n            38.0979, 34.0405, 35.0074, 40.8656, 39.9885, 37.4418, 37.3445, 33.4271,\n            40.4349, 41.4754, 36.4292, 41.2385, 41.1300, 39.4304, 39.1217, 40.2641,\n            41.4882, 36.4677, 45.3880, 41.7064, 46.0084, 42.7886, 48.2276, 48.9552,\n            45.7761, 46.6802, 49.1144, 47.0020, 41.9040, 47.4266, 48.3905, 51.4273,\n            46.7154, 49.9467, 45.0021, 50.9472, 55.9469, 49.3655, 44.3413, 47.9426,\n            45.9358, 54.3920, 49.9636, 53.2459, 50.3228, 46.5756, 50.2442, 54.3946,\n            50.2086, 49.6290, 50.5312, 54.7947, 47.7757, 50.7428, 52.6791, 55.2901,\n            55.9978, 57.0760, 50.6741, 53.8824, 58.6424, 53.3195, 57.1432, 54.2989,\n            49.9915, 55.4631, 56.1260, 55.4143, 54.0111, 56.7517, 59.6828, 57.2633,\n            56.1236, 63.1750, 59.2744, 54.7133, 54.5091, 57.9472, 64.0721, 63.9801,\n            61.2980, 61.6411, 62.6100, 59.2035])\n\n\n\n\n```python\n# 将训练集转化为张量，使用梯度下降法进行训练\n# 迭代次数 10000，学习率：0.001\n\na = torch.rand(1, requires_grad=True)\nb = torch.rand(1, requires_grad=True)\nloss = []\ntheta = 0.00001\n\nfor i in range(10000+1):\n    y_p = a.expand_as(X_train1)*X_train1 + b.expand_as(X_train1)\n    loss_tmp = torch.mean((y_p - y_train1)**2)\n    if i%500 == 0:\n        print(\"迭代\" , i , \"次，损失值为：\",loss_tmp.data.numpy())\n    \n    loss.append(loss_tmp.data.numpy())\n    loss_tmp.backward()\n    a.data = a.data - theta*a.grad.data\n    b.data = b.data - theta*b.grad.data\n    a.grad.data.zero_()\n    b.grad.data.zero_()\n    \nprint(a, b)\n```\n\n    迭代 0 次，损失值为： 1019.3526\n    迭代 500 次，损失值为： 68.77335\n    迭代 1000 次，损失值为： 12.962891\n    迭代 1500 次，损失值为： 9.682995\n    迭代 2000 次，损失值为： 9.4870615\n    迭代 2500 次，损失值为： 9.47218\n    迭代 3000 次，损失值为： 9.467946\n    迭代 3500 次，损失值为： 9.46435\n    迭代 4000 次，损失值为： 9.460806\n    迭代 4500 次，损失值为： 9.457279\n    迭代 5000 次，损失值为： 9.453774\n    迭代 5500 次，损失值为： 9.450276\n    迭代 6000 次，损失值为： 9.446788\n    迭代 6500 次，损失值为： 9.44333\n    迭代 7000 次，损失值为： 9.439879\n    迭代 7500 次，损失值为： 9.436436\n    迭代 8000 次，损失值为： 9.433018\n    迭代 8500 次，损失值为： 9.429613\n    迭代 9000 次，损失值为： 9.426218\n    迭代 9500 次，损失值为： 9.422838\n    迭代 10000 次，损失值为： 9.419481\n    tensor([3.1121], requires_grad=True) tensor([0.9682], requires_grad=True)\n\n\n\n```python\nplt.figure(figsize=(10, 8))\nplt.scatter(X_test1, y_test1)\n\nplt.plot(X_test1.data.numpy(), a.data.numpy()*X_test1.data.numpy() + b.data.numpy())\n\nplt.show()\n```\n\n\n![png](deep-learning-test01/output_6_0.png)\n    \n\n\n\n* 已知模型y = a*x^3 + b*x^2 + c*x + d\n* 生成带噪声的数据拟合三次函数\n* 绘制图像拟合效果\n\n\n```python\n# 生成200个噪声数据\n# 参数设置，a=0.005, b=0.01, c=0.1, d=1\n\na, b, c, d = 0.005, 0.01, 0.1, 1\n\nrand = torch.randn(200)*1.5\nX_trains = torch.linspace(1, 20, 200)\nY_labels = a*(X_trains**3) + b*(X_trains**2) + c*X_trains + d + rand\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_trains, Y_labels)\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_8_0.png)\n​    \n\n\n\n```python\n# 构造数据集和训练集标签\n\ntest_index = [10*i + np.random.randint(10) for i in range(20)]\ntrain_index = [i for i in range(200) if i not in test_index]\n\nX_train2, X_test2, y_train2, y_test2 = X_trains[train_index], X_trains[test_index], Y_labels[train_index], Y_labels[test_index]\n```\n\n\n```python\n# 开始训练\na = torch.rand(1, requires_grad=True)\nb = torch.rand(1, requires_grad=True)\nc = torch.rand(1, requires_grad=True)\nd = torch.rand(1, requires_grad=True)\ntheta = 0.0000001\ntimes = 50000\nloss = []\n\nfor i in range(times+1):\n    loss_tmp = torch.mean(((a.expand_as(X_train2) * (X_train2**3) + \n                           b.expand_as(X_train2) * (X_train2**2) + c.expand_as(X_train2) * X_train2 + \n                           d.expand_as(X_train2) - y_train2))**2)\n    if i%2500 == 0:\n        print(\"迭代\", i,\"次，损失值为：\", loss_tmp.data.numpy())\n    \n    loss_tmp.backward()\n    a.data = a.data - a.grad.data * theta\n    b.data = b.data - b.grad.data * theta\n    c.data = c.data - c.grad.data * theta\n    d.data = d.data - d.grad.data * theta\n    \n    a.grad.data.zero_()\n    b.grad.data.zero_()\n    c.grad.data.zero_()\n    d.grad.data.zero_()\n    \n```\n\n    迭代 0 次，损失值为： 3153.991\n    迭代 2500 次，损失值为： 11.566195\n    迭代 5000 次，损失值为： 5.8502893\n    迭代 7500 次，损失值为： 3.6634474\n    迭代 10000 次，损失值为： 2.8267233\n    迭代 12500 次，损失值为： 2.506517\n    迭代 15000 次，损失值为： 2.3839154\n    迭代 17500 次，损失值为： 2.3369095\n    迭代 20000 次，损失值为： 2.318825\n    迭代 22500 次，损失值为： 2.3118067\n    迭代 25000 次，损失值为： 2.3090246\n    迭代 27500 次，损失值为： 2.307857\n    迭代 30000 次，损失值为： 2.307303\n    迭代 32500 次，损失值为： 2.3069975\n    迭代 35000 次，损失值为： 2.3067696\n    迭代 37500 次，损失值为： 2.306577\n    迭代 40000 次，损失值为： 2.3063998\n    迭代 42500 次，损失值为： 2.3062305\n    迭代 45000 次，损失值为： 2.3060641\n    迭代 47500 次，损失值为： 2.3058996\n    迭代 50000 次，损失值为： 2.3057368\n\n\n\n```python\n# 对测试集进行预测拟合\nplt.figure(figsize=(10, 8))\nplt.scatter(X_test2, y_test2)\n\nplt.plot(X_test2.data.numpy(), a.data.numpy()*(X_test2.data.numpy()**3) + b.data.numpy()*(X_test2.data.numpy()**2) + c.data.numpy()*X_test2.data.numpy() + d.data.numpy())\n\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_11_0.png)\n​    \n\n\n##  设计神经网络对前面的数据进行拟合\n\n* 记录误差，绘制拟合效果\n* 直线拟合数据为：X_train1, y_train1, X_test1, y_test1\n* 曲线拟合数据为：X_train2, y_train2, X_test2, y_test2\n\n### 一、拟合直线\n\n\n```python\n# 使用网络拟合直线\n# 直线拟合只需要一个神经元就能完成拟合\n\n# 定义网络\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n)\n# 定义损失函数\nloss_fn = torch.nn.MSELoss()\n# 梯度下降方法，随机梯度下降\nopt = torch.optim.SGD(net.parameters(), lr=0.0001)\n```\n\n\n```python\n# 训练数据\nlosses = []\nfor i in range(1000):\n    pred = net(X_train1.view(-1,1))\n    loss = loss_fn(pred, y_train1.view(-1,1))\n    if i%200==0:\n        print('loss:', loss.data)\n        losses.append(loss.data)\n    \n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n    \nplt.figure(figsize=(10, 8))\nplt.plot(X_train1.data.numpy(), y_train1.data.numpy(), 'o')\nplt.plot(X_train1.data.numpy(), net(X_train1.view(-1,1)).data.numpy())\nplt.show()\n```\n\n    loss: tensor(999.4984)\n    loss: tensor(10.4790)\n    loss: tensor(10.4377)\n    loss: tensor(10.4070)\n    loss: tensor(10.3768)\n\n\n\n\n![png](deep-learning-test01/output_15_1.png)\n    \n\n\n\n```python\n# 对测试集进行预测验证\npred = net(X_test1.view(-1,1))\nplt.figure(figsize=(10, 8))\nplt.plot(X_test1.data.numpy(), y_test1.data.numpy(), 'o')\nplt.plot(X_test1.data.numpy(), pred.data.numpy())\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_16_0.png)\n​    \n\n\n### 二、拟合多项式函数\n\n* 单层神经网络只能够拟合直线\n* 对多项式函数的拟合需要多层神经网络，且需要激活函数\n\n\n```python\n# 定义model类\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# 继承nn.Module\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 第一个隐藏层\n        self.hidden1=nn.Linear(1,4)\n        # 第二个隐藏层\n        self.hidden2=nn.Linear(4,4)\n        # 第三个隐藏层\n        self.hidden3=nn.Linear(4,4)\n        # 输出层\n        self.out=nn.Linear(4,1)\n    \n    # 定义网络前向运算\n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.sigmoid(x)\n        x = self.hidden2(x)\n        x = F.sigmoid(x)\n        x = self.hidden3(x)\n        x = F.sigmoid(x)\n        x = self.out(x)\n        return x\n    \nnet = model()\nprint(net)\n```\n\n    model(\n      (hidden1): Linear(in_features=1, out_features=4, bias=True)\n      (hidden2): Linear(in_features=4, out_features=4, bias=True)\n      (hidden3): Linear(in_features=4, out_features=4, bias=True)\n      (out): Linear(in_features=4, out_features=1, bias=True)\n    )\n\n\n\n```python\n# 定义损失函数\nloss_fn = torch.nn.MSELoss()\nopt = torch.optim.SGD(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练数据\nlosses2 = []\nfor i in range(50000):\n    pred = net(X_train2.view(-1,1))\n    loss = loss_fn(pred, y_train2.view(-1,1))\n    if i%2500==0:\n        print('loss:', loss.data)\n        losses2.append(loss)\n    \n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n\n# 绘制图像\nplt.figure(figsize=(10, 8))\nplt.plot(X_train2.data.numpy(), y_train2.data.numpy(), 'o')\nplt.plot(X_train2.data.numpy(), net(X_train2.view(-1,1)).data.numpy())\nplt.show()\n```\n\n    loss: tensor(357.9143)\n\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n      warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\n    loss: tensor(146.0952)\n    loss: tensor(23.4380)\n    loss: tensor(16.6693)\n    loss: tensor(12.3312)\n    loss: tensor(10.4051)\n    loss: tensor(8.9617)\n    loss: tensor(7.7465)\n    loss: tensor(6.7640)\n    loss: tensor(5.9918)\n    loss: tensor(5.4033)\n    loss: tensor(4.9512)\n    loss: tensor(4.5902)\n    loss: tensor(4.2906)\n    loss: tensor(4.0353)\n    loss: tensor(3.8134)\n    loss: tensor(3.6182)\n    loss: tensor(3.4456)\n    loss: tensor(3.2944)\n    loss: tensor(3.1646)\n\n\n\n\n![png](deep-learning-test01/output_20_3.png)\n    \n\n\n\n```python\n# 使用训练的模型对测试集进行预测\npred2 = net(X_test2.view(-1,1))\nplt.figure(figsize=(10, 8))\nplt.plot(X_test2.data.numpy(), y_test2.data.numpy(), 'o')\nplt.plot(X_test2.data.numpy(), pred2.data.numpy())\nplt.show()\n```\n\n\n![png](deep-learning-test01/output_21_0.png)\n    \n\n","source":"_posts/deep-learning-test01.md","raw":"---\ntitle: 深度学习实践实验-线性回归\ncategories: 算法实践\ndate: 2023-01-03 17:19:30\ntags: [深度学习, 人工智能]\ncover:\ntop_img:\n---\n# 实验一、线性回归\n\n* 已知模型y = a*x + b\n* 生成带噪声的数据拟合线性函数\n* 绘制图像拟合效果\n\n\n```python\n# 导入相关包\nimport torch\nimport numpy as np\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 生成y = a*x + b的噪声数据200个\n# 定义a = 3， b = 2\na, b = 3, 2\n\nx_datas = torch.linspace(1,20,200)\nrand_noise = torch.randn(200)*3\ny_lables = a*x_datas + b + rand_noise\n```\n\n\n```python\n# 绘制散点图\nplt.figure(figsize=(10, 8))\nplt.scatter(x_datas, y_lables)\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_3_0.png)\n​    \n\n\n\n```python\n# 将数据划分为训练集和测试集，按照180，20进行划分\n# 每十个数据中，分层抽取出一个数据作为测试集\n\ntest_index = [10*i + np.random.randint(10) for i in range(20)]\ntrain_index = [i for i in range(200) if i not in test_index]\n\nX_train1, X_test1, y_train1, y_test1 = x_datas[train_index], x_datas[test_index], y_lables[train_index], y_lables[test_index]\ny_train1\n```\n\n\n\n\n    tensor([ 3.6945,  4.7438,  7.9504,  5.5705,  5.6000,  9.5666,  8.5461,  4.9789,\n             0.6976,  5.6866,  4.2295, 10.9321, 11.2976,  7.9842, 12.1275,  8.0943,\n            10.5445, 13.4849, 18.5069, 11.6880, 16.8814, 12.7575, 10.7111, 12.1603,\n            14.7055, 14.3254, 11.4367, 17.6528, 18.5793, 17.8409, 13.8733, 16.6622,\n            18.6143, 14.5482, 16.6509, 17.4552, 20.0250, 20.3924, 20.6348, 18.2929,\n            16.6831, 20.4449, 17.3773, 18.3895, 18.2360, 24.1661, 18.2511, 16.6143,\n            20.3642, 16.5544, 19.0061, 25.6141, 20.1254, 21.4796, 23.3279, 20.1736,\n            25.3058, 26.7936, 24.8702, 23.0888, 24.2360, 26.3334, 26.8100, 22.9726,\n            25.0721, 28.1969, 27.3128, 28.3941, 27.2811, 25.5293, 29.3596, 30.8378,\n            29.3787, 30.2246, 28.6970, 19.3994, 31.6431, 35.1937, 26.6844, 31.5928,\n            32.8604, 31.2751, 26.1607, 26.1867, 27.4753, 28.5589, 32.5150, 35.3546,\n            29.3716, 30.2867, 34.1565, 36.8429, 32.5876, 41.2268, 32.7979, 35.0479,\n            38.0979, 34.0405, 35.0074, 40.8656, 39.9885, 37.4418, 37.3445, 33.4271,\n            40.4349, 41.4754, 36.4292, 41.2385, 41.1300, 39.4304, 39.1217, 40.2641,\n            41.4882, 36.4677, 45.3880, 41.7064, 46.0084, 42.7886, 48.2276, 48.9552,\n            45.7761, 46.6802, 49.1144, 47.0020, 41.9040, 47.4266, 48.3905, 51.4273,\n            46.7154, 49.9467, 45.0021, 50.9472, 55.9469, 49.3655, 44.3413, 47.9426,\n            45.9358, 54.3920, 49.9636, 53.2459, 50.3228, 46.5756, 50.2442, 54.3946,\n            50.2086, 49.6290, 50.5312, 54.7947, 47.7757, 50.7428, 52.6791, 55.2901,\n            55.9978, 57.0760, 50.6741, 53.8824, 58.6424, 53.3195, 57.1432, 54.2989,\n            49.9915, 55.4631, 56.1260, 55.4143, 54.0111, 56.7517, 59.6828, 57.2633,\n            56.1236, 63.1750, 59.2744, 54.7133, 54.5091, 57.9472, 64.0721, 63.9801,\n            61.2980, 61.6411, 62.6100, 59.2035])\n\n\n\n\n```python\n# 将训练集转化为张量，使用梯度下降法进行训练\n# 迭代次数 10000，学习率：0.001\n\na = torch.rand(1, requires_grad=True)\nb = torch.rand(1, requires_grad=True)\nloss = []\ntheta = 0.00001\n\nfor i in range(10000+1):\n    y_p = a.expand_as(X_train1)*X_train1 + b.expand_as(X_train1)\n    loss_tmp = torch.mean((y_p - y_train1)**2)\n    if i%500 == 0:\n        print(\"迭代\" , i , \"次，损失值为：\",loss_tmp.data.numpy())\n    \n    loss.append(loss_tmp.data.numpy())\n    loss_tmp.backward()\n    a.data = a.data - theta*a.grad.data\n    b.data = b.data - theta*b.grad.data\n    a.grad.data.zero_()\n    b.grad.data.zero_()\n    \nprint(a, b)\n```\n\n    迭代 0 次，损失值为： 1019.3526\n    迭代 500 次，损失值为： 68.77335\n    迭代 1000 次，损失值为： 12.962891\n    迭代 1500 次，损失值为： 9.682995\n    迭代 2000 次，损失值为： 9.4870615\n    迭代 2500 次，损失值为： 9.47218\n    迭代 3000 次，损失值为： 9.467946\n    迭代 3500 次，损失值为： 9.46435\n    迭代 4000 次，损失值为： 9.460806\n    迭代 4500 次，损失值为： 9.457279\n    迭代 5000 次，损失值为： 9.453774\n    迭代 5500 次，损失值为： 9.450276\n    迭代 6000 次，损失值为： 9.446788\n    迭代 6500 次，损失值为： 9.44333\n    迭代 7000 次，损失值为： 9.439879\n    迭代 7500 次，损失值为： 9.436436\n    迭代 8000 次，损失值为： 9.433018\n    迭代 8500 次，损失值为： 9.429613\n    迭代 9000 次，损失值为： 9.426218\n    迭代 9500 次，损失值为： 9.422838\n    迭代 10000 次，损失值为： 9.419481\n    tensor([3.1121], requires_grad=True) tensor([0.9682], requires_grad=True)\n\n\n\n```python\nplt.figure(figsize=(10, 8))\nplt.scatter(X_test1, y_test1)\n\nplt.plot(X_test1.data.numpy(), a.data.numpy()*X_test1.data.numpy() + b.data.numpy())\n\nplt.show()\n```\n\n\n![png](deep-learning-test01/output_6_0.png)\n    \n\n\n\n* 已知模型y = a*x^3 + b*x^2 + c*x + d\n* 生成带噪声的数据拟合三次函数\n* 绘制图像拟合效果\n\n\n```python\n# 生成200个噪声数据\n# 参数设置，a=0.005, b=0.01, c=0.1, d=1\n\na, b, c, d = 0.005, 0.01, 0.1, 1\n\nrand = torch.randn(200)*1.5\nX_trains = torch.linspace(1, 20, 200)\nY_labels = a*(X_trains**3) + b*(X_trains**2) + c*X_trains + d + rand\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_trains, Y_labels)\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_8_0.png)\n​    \n\n\n\n```python\n# 构造数据集和训练集标签\n\ntest_index = [10*i + np.random.randint(10) for i in range(20)]\ntrain_index = [i for i in range(200) if i not in test_index]\n\nX_train2, X_test2, y_train2, y_test2 = X_trains[train_index], X_trains[test_index], Y_labels[train_index], Y_labels[test_index]\n```\n\n\n```python\n# 开始训练\na = torch.rand(1, requires_grad=True)\nb = torch.rand(1, requires_grad=True)\nc = torch.rand(1, requires_grad=True)\nd = torch.rand(1, requires_grad=True)\ntheta = 0.0000001\ntimes = 50000\nloss = []\n\nfor i in range(times+1):\n    loss_tmp = torch.mean(((a.expand_as(X_train2) * (X_train2**3) + \n                           b.expand_as(X_train2) * (X_train2**2) + c.expand_as(X_train2) * X_train2 + \n                           d.expand_as(X_train2) - y_train2))**2)\n    if i%2500 == 0:\n        print(\"迭代\", i,\"次，损失值为：\", loss_tmp.data.numpy())\n    \n    loss_tmp.backward()\n    a.data = a.data - a.grad.data * theta\n    b.data = b.data - b.grad.data * theta\n    c.data = c.data - c.grad.data * theta\n    d.data = d.data - d.grad.data * theta\n    \n    a.grad.data.zero_()\n    b.grad.data.zero_()\n    c.grad.data.zero_()\n    d.grad.data.zero_()\n    \n```\n\n    迭代 0 次，损失值为： 3153.991\n    迭代 2500 次，损失值为： 11.566195\n    迭代 5000 次，损失值为： 5.8502893\n    迭代 7500 次，损失值为： 3.6634474\n    迭代 10000 次，损失值为： 2.8267233\n    迭代 12500 次，损失值为： 2.506517\n    迭代 15000 次，损失值为： 2.3839154\n    迭代 17500 次，损失值为： 2.3369095\n    迭代 20000 次，损失值为： 2.318825\n    迭代 22500 次，损失值为： 2.3118067\n    迭代 25000 次，损失值为： 2.3090246\n    迭代 27500 次，损失值为： 2.307857\n    迭代 30000 次，损失值为： 2.307303\n    迭代 32500 次，损失值为： 2.3069975\n    迭代 35000 次，损失值为： 2.3067696\n    迭代 37500 次，损失值为： 2.306577\n    迭代 40000 次，损失值为： 2.3063998\n    迭代 42500 次，损失值为： 2.3062305\n    迭代 45000 次，损失值为： 2.3060641\n    迭代 47500 次，损失值为： 2.3058996\n    迭代 50000 次，损失值为： 2.3057368\n\n\n\n```python\n# 对测试集进行预测拟合\nplt.figure(figsize=(10, 8))\nplt.scatter(X_test2, y_test2)\n\nplt.plot(X_test2.data.numpy(), a.data.numpy()*(X_test2.data.numpy()**3) + b.data.numpy()*(X_test2.data.numpy()**2) + c.data.numpy()*X_test2.data.numpy() + d.data.numpy())\n\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_11_0.png)\n​    \n\n\n##  设计神经网络对前面的数据进行拟合\n\n* 记录误差，绘制拟合效果\n* 直线拟合数据为：X_train1, y_train1, X_test1, y_test1\n* 曲线拟合数据为：X_train2, y_train2, X_test2, y_test2\n\n### 一、拟合直线\n\n\n```python\n# 使用网络拟合直线\n# 直线拟合只需要一个神经元就能完成拟合\n\n# 定义网络\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n)\n# 定义损失函数\nloss_fn = torch.nn.MSELoss()\n# 梯度下降方法，随机梯度下降\nopt = torch.optim.SGD(net.parameters(), lr=0.0001)\n```\n\n\n```python\n# 训练数据\nlosses = []\nfor i in range(1000):\n    pred = net(X_train1.view(-1,1))\n    loss = loss_fn(pred, y_train1.view(-1,1))\n    if i%200==0:\n        print('loss:', loss.data)\n        losses.append(loss.data)\n    \n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n    \nplt.figure(figsize=(10, 8))\nplt.plot(X_train1.data.numpy(), y_train1.data.numpy(), 'o')\nplt.plot(X_train1.data.numpy(), net(X_train1.view(-1,1)).data.numpy())\nplt.show()\n```\n\n    loss: tensor(999.4984)\n    loss: tensor(10.4790)\n    loss: tensor(10.4377)\n    loss: tensor(10.4070)\n    loss: tensor(10.3768)\n\n\n\n\n![png](deep-learning-test01/output_15_1.png)\n    \n\n\n\n```python\n# 对测试集进行预测验证\npred = net(X_test1.view(-1,1))\nplt.figure(figsize=(10, 8))\nplt.plot(X_test1.data.numpy(), y_test1.data.numpy(), 'o')\nplt.plot(X_test1.data.numpy(), pred.data.numpy())\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test01/output_16_0.png)\n​    \n\n\n### 二、拟合多项式函数\n\n* 单层神经网络只能够拟合直线\n* 对多项式函数的拟合需要多层神经网络，且需要激活函数\n\n\n```python\n# 定义model类\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# 继承nn.Module\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 第一个隐藏层\n        self.hidden1=nn.Linear(1,4)\n        # 第二个隐藏层\n        self.hidden2=nn.Linear(4,4)\n        # 第三个隐藏层\n        self.hidden3=nn.Linear(4,4)\n        # 输出层\n        self.out=nn.Linear(4,1)\n    \n    # 定义网络前向运算\n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.sigmoid(x)\n        x = self.hidden2(x)\n        x = F.sigmoid(x)\n        x = self.hidden3(x)\n        x = F.sigmoid(x)\n        x = self.out(x)\n        return x\n    \nnet = model()\nprint(net)\n```\n\n    model(\n      (hidden1): Linear(in_features=1, out_features=4, bias=True)\n      (hidden2): Linear(in_features=4, out_features=4, bias=True)\n      (hidden3): Linear(in_features=4, out_features=4, bias=True)\n      (out): Linear(in_features=4, out_features=1, bias=True)\n    )\n\n\n\n```python\n# 定义损失函数\nloss_fn = torch.nn.MSELoss()\nopt = torch.optim.SGD(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练数据\nlosses2 = []\nfor i in range(50000):\n    pred = net(X_train2.view(-1,1))\n    loss = loss_fn(pred, y_train2.view(-1,1))\n    if i%2500==0:\n        print('loss:', loss.data)\n        losses2.append(loss)\n    \n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n\n# 绘制图像\nplt.figure(figsize=(10, 8))\nplt.plot(X_train2.data.numpy(), y_train2.data.numpy(), 'o')\nplt.plot(X_train2.data.numpy(), net(X_train2.view(-1,1)).data.numpy())\nplt.show()\n```\n\n    loss: tensor(357.9143)\n\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n      warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\n    loss: tensor(146.0952)\n    loss: tensor(23.4380)\n    loss: tensor(16.6693)\n    loss: tensor(12.3312)\n    loss: tensor(10.4051)\n    loss: tensor(8.9617)\n    loss: tensor(7.7465)\n    loss: tensor(6.7640)\n    loss: tensor(5.9918)\n    loss: tensor(5.4033)\n    loss: tensor(4.9512)\n    loss: tensor(4.5902)\n    loss: tensor(4.2906)\n    loss: tensor(4.0353)\n    loss: tensor(3.8134)\n    loss: tensor(3.6182)\n    loss: tensor(3.4456)\n    loss: tensor(3.2944)\n    loss: tensor(3.1646)\n\n\n\n\n![png](deep-learning-test01/output_20_3.png)\n    \n\n\n\n```python\n# 使用训练的模型对测试集进行预测\npred2 = net(X_test2.view(-1,1))\nplt.figure(figsize=(10, 8))\nplt.plot(X_test2.data.numpy(), y_test2.data.numpy(), 'o')\nplt.plot(X_test2.data.numpy(), pred2.data.numpy())\nplt.show()\n```\n\n\n![png](deep-learning-test01/output_21_0.png)\n    \n\n","slug":"deep-learning-test01","published":1,"updated":"2024-06-05T09:03:03.689Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttq001d08jv8jbz2l07","content":"<h1 id=\"实验一、线性回归\"><a href=\"#实验一、线性回归\" class=\"headerlink\" title=\"实验一、线性回归\"></a>实验一、线性回归</h1><ul>\n<li>已知模型y = a*x + b</li>\n<li>生成带噪声的数据拟合线性函数</li>\n<li>绘制图像拟合效果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关包</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br>%matplotlib inline<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成y = a*x + b的噪声数据200个</span><br><span class=\"hljs-comment\"># 定义a = 3， b = 2</span><br>a, b = <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span><br><br>x_datas = torch.linspace(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">20</span>,<span class=\"hljs-number\">200</span>)<br>rand_noise = torch.randn(<span class=\"hljs-number\">200</span>)*<span class=\"hljs-number\">3</span><br>y_lables = a*x_datas + b + rand_noise<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 绘制散点图</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(x_datas, y_lables)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_3_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将数据划分为训练集和测试集，按照180，20进行划分</span><br><span class=\"hljs-comment\"># 每十个数据中，分层抽取出一个数据作为测试集</span><br><br>test_index = [<span class=\"hljs-number\">10</span>*i + np.random.randint(<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>)]<br>train_index = [i <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>) <span class=\"hljs-keyword\">if</span> i <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> test_index]<br><br>X_train1, X_test1, y_train1, y_test1 = x_datas[train_index], x_datas[test_index], y_lables[train_index], y_lables[test_index]<br>y_train1<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([ 3.6945,  4.7438,  7.9504,  5.5705,  5.6000,  9.5666,  8.5461,  4.9789,\n         0.6976,  5.6866,  4.2295, 10.9321, 11.2976,  7.9842, 12.1275,  8.0943,\n        10.5445, 13.4849, 18.5069, 11.6880, 16.8814, 12.7575, 10.7111, 12.1603,\n        14.7055, 14.3254, 11.4367, 17.6528, 18.5793, 17.8409, 13.8733, 16.6622,\n        18.6143, 14.5482, 16.6509, 17.4552, 20.0250, 20.3924, 20.6348, 18.2929,\n        16.6831, 20.4449, 17.3773, 18.3895, 18.2360, 24.1661, 18.2511, 16.6143,\n        20.3642, 16.5544, 19.0061, 25.6141, 20.1254, 21.4796, 23.3279, 20.1736,\n        25.3058, 26.7936, 24.8702, 23.0888, 24.2360, 26.3334, 26.8100, 22.9726,\n        25.0721, 28.1969, 27.3128, 28.3941, 27.2811, 25.5293, 29.3596, 30.8378,\n        29.3787, 30.2246, 28.6970, 19.3994, 31.6431, 35.1937, 26.6844, 31.5928,\n        32.8604, 31.2751, 26.1607, 26.1867, 27.4753, 28.5589, 32.5150, 35.3546,\n        29.3716, 30.2867, 34.1565, 36.8429, 32.5876, 41.2268, 32.7979, 35.0479,\n        38.0979, 34.0405, 35.0074, 40.8656, 39.9885, 37.4418, 37.3445, 33.4271,\n        40.4349, 41.4754, 36.4292, 41.2385, 41.1300, 39.4304, 39.1217, 40.2641,\n        41.4882, 36.4677, 45.3880, 41.7064, 46.0084, 42.7886, 48.2276, 48.9552,\n        45.7761, 46.6802, 49.1144, 47.0020, 41.9040, 47.4266, 48.3905, 51.4273,\n        46.7154, 49.9467, 45.0021, 50.9472, 55.9469, 49.3655, 44.3413, 47.9426,\n        45.9358, 54.3920, 49.9636, 53.2459, 50.3228, 46.5756, 50.2442, 54.3946,\n        50.2086, 49.6290, 50.5312, 54.7947, 47.7757, 50.7428, 52.6791, 55.2901,\n        55.9978, 57.0760, 50.6741, 53.8824, 58.6424, 53.3195, 57.1432, 54.2989,\n        49.9915, 55.4631, 56.1260, 55.4143, 54.0111, 56.7517, 59.6828, 57.2633,\n        56.1236, 63.1750, 59.2744, 54.7133, 54.5091, 57.9472, 64.0721, 63.9801,\n        61.2980, 61.6411, 62.6100, 59.2035])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将训练集转化为张量，使用梯度下降法进行训练</span><br><span class=\"hljs-comment\"># 迭代次数 10000，学习率：0.001</span><br><br>a = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>b = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>loss = []<br>theta = <span class=\"hljs-number\">0.00001</span><br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">10000</span>+<span class=\"hljs-number\">1</span>):<br>    y_p = a.expand_as(X_train1)*X_train1 + b.expand_as(X_train1)<br>    loss_tmp = torch.mean((y_p - y_train1)**<span class=\"hljs-number\">2</span>)<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">500</span> == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;迭代&quot;</span> , i , <span class=\"hljs-string\">&quot;次，损失值为：&quot;</span>,loss_tmp.data.numpy())<br>    <br>    loss.append(loss_tmp.data.numpy())<br>    loss_tmp.backward()<br>    a.data = a.data - theta*a.grad.data<br>    b.data = b.data - theta*b.grad.data<br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    <br><span class=\"hljs-built_in\">print</span>(a, b)<br></code></pre></td></tr></table></figure>\n<pre><code>迭代 0 次，损失值为： 1019.3526\n迭代 500 次，损失值为： 68.77335\n迭代 1000 次，损失值为： 12.962891\n迭代 1500 次，损失值为： 9.682995\n迭代 2000 次，损失值为： 9.4870615\n迭代 2500 次，损失值为： 9.47218\n迭代 3000 次，损失值为： 9.467946\n迭代 3500 次，损失值为： 9.46435\n迭代 4000 次，损失值为： 9.460806\n迭代 4500 次，损失值为： 9.457279\n迭代 5000 次，损失值为： 9.453774\n迭代 5500 次，损失值为： 9.450276\n迭代 6000 次，损失值为： 9.446788\n迭代 6500 次，损失值为： 9.44333\n迭代 7000 次，损失值为： 9.439879\n迭代 7500 次，损失值为： 9.436436\n迭代 8000 次，损失值为： 9.433018\n迭代 8500 次，损失值为： 9.429613\n迭代 9000 次，损失值为： 9.426218\n迭代 9500 次，损失值为： 9.422838\n迭代 10000 次，损失值为： 9.419481\ntensor([3.1121], requires_grad=True) tensor([0.9682], requires_grad=True)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_test1, y_test1)<br><br>plt.plot(X_test1.data.numpy(), a.data.numpy()*X_test1.data.numpy() + b.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/01/03/deep-learning-test01/output_6_0.png\" class=\"\" title=\"png\">\n<ul>\n<li>已知模型y = a<em>x^3 + b</em>x^2 + c*x + d</li>\n<li>生成带噪声的数据拟合三次函数</li>\n<li>绘制图像拟合效果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成200个噪声数据</span><br><span class=\"hljs-comment\"># 参数设置，a=0.005, b=0.01, c=0.1, d=1</span><br><br>a, b, c, d = <span class=\"hljs-number\">0.005</span>, <span class=\"hljs-number\">0.01</span>, <span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1</span><br><br>rand = torch.randn(<span class=\"hljs-number\">200</span>)*<span class=\"hljs-number\">1.5</span><br>X_trains = torch.linspace(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">20</span>, <span class=\"hljs-number\">200</span>)<br>Y_labels = a*(X_trains**<span class=\"hljs-number\">3</span>) + b*(X_trains**<span class=\"hljs-number\">2</span>) + c*X_trains + d + rand<br><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_trains, Y_labels)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_8_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构造数据集和训练集标签</span><br><br>test_index = [<span class=\"hljs-number\">10</span>*i + np.random.randint(<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>)]<br>train_index = [i <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>) <span class=\"hljs-keyword\">if</span> i <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> test_index]<br><br>X_train2, X_test2, y_train2, y_test2 = X_trains[train_index], X_trains[test_index], Y_labels[train_index], Y_labels[test_index]<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 开始训练</span><br>a = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>b = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>c = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>d = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>theta = <span class=\"hljs-number\">0.0000001</span><br>times = <span class=\"hljs-number\">50000</span><br>loss = []<br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(times+<span class=\"hljs-number\">1</span>):<br>    loss_tmp = torch.mean(((a.expand_as(X_train2) * (X_train2**<span class=\"hljs-number\">3</span>) + <br>                           b.expand_as(X_train2) * (X_train2**<span class=\"hljs-number\">2</span>) + c.expand_as(X_train2) * X_train2 + <br>                           d.expand_as(X_train2) - y_train2))**<span class=\"hljs-number\">2</span>)<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">2500</span> == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;迭代&quot;</span>, i,<span class=\"hljs-string\">&quot;次，损失值为：&quot;</span>, loss_tmp.data.numpy())<br>    <br>    loss_tmp.backward()<br>    a.data = a.data - a.grad.data * theta<br>    b.data = b.data - b.grad.data * theta<br>    c.data = c.data - c.grad.data * theta<br>    d.data = d.data - d.grad.data * theta<br>    <br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    c.grad.data.zero_()<br>    d.grad.data.zero_()<br>    <br></code></pre></td></tr></table></figure>\n<pre><code>迭代 0 次，损失值为： 3153.991\n迭代 2500 次，损失值为： 11.566195\n迭代 5000 次，损失值为： 5.8502893\n迭代 7500 次，损失值为： 3.6634474\n迭代 10000 次，损失值为： 2.8267233\n迭代 12500 次，损失值为： 2.506517\n迭代 15000 次，损失值为： 2.3839154\n迭代 17500 次，损失值为： 2.3369095\n迭代 20000 次，损失值为： 2.318825\n迭代 22500 次，损失值为： 2.3118067\n迭代 25000 次，损失值为： 2.3090246\n迭代 27500 次，损失值为： 2.307857\n迭代 30000 次，损失值为： 2.307303\n迭代 32500 次，损失值为： 2.3069975\n迭代 35000 次，损失值为： 2.3067696\n迭代 37500 次，损失值为： 2.306577\n迭代 40000 次，损失值为： 2.3063998\n迭代 42500 次，损失值为： 2.3062305\n迭代 45000 次，损失值为： 2.3060641\n迭代 47500 次，损失值为： 2.3058996\n迭代 50000 次，损失值为： 2.3057368\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测拟合</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_test2, y_test2)<br><br>plt.plot(X_test2.data.numpy(), a.data.numpy()*(X_test2.data.numpy()**<span class=\"hljs-number\">3</span>) + b.data.numpy()*(X_test2.data.numpy()**<span class=\"hljs-number\">2</span>) + c.data.numpy()*X_test2.data.numpy() + d.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_11_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<h2 id=\"设计神经网络对前面的数据进行拟合\"><a href=\"#设计神经网络对前面的数据进行拟合\" class=\"headerlink\" title=\"设计神经网络对前面的数据进行拟合\"></a>设计神经网络对前面的数据进行拟合</h2><ul>\n<li>记录误差，绘制拟合效果</li>\n<li>直线拟合数据为：X_train1, y_train1, X_test1, y_test1</li>\n<li>曲线拟合数据为：X_train2, y_train2, X_test2, y_test2</li>\n</ul>\n<h3 id=\"一、拟合直线\"><a href=\"#一、拟合直线\" class=\"headerlink\" title=\"一、拟合直线\"></a>一、拟合直线</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 使用网络拟合直线</span><br><span class=\"hljs-comment\"># 直线拟合只需要一个神经元就能完成拟合</span><br><br><span class=\"hljs-comment\"># 定义网络</span><br>net = torch.nn.Sequential(<br>    torch.nn.Linear(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>),<br>)<br><span class=\"hljs-comment\"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br><span class=\"hljs-comment\"># 梯度下降方法，随机梯度下降</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.0001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练数据</span><br>losses = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    pred = net(X_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    loss = loss_fn(pred, y_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">200</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;loss:&#x27;</span>, loss.data)<br>        losses.append(loss.data)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br>    <br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_train1.data.numpy(), y_train1.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_train1.data.numpy(), net(X_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>loss: tensor(999.4984)\nloss: tensor(10.4790)\nloss: tensor(10.4377)\nloss: tensor(10.4070)\nloss: tensor(10.3768)\n</code></pre><img src=\"/2023/01/03/deep-learning-test01/output_15_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测验证</span><br>pred = net(X_test1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_test1.data.numpy(), y_test1.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_test1.data.numpy(), pred.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_16_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<h3 id=\"二、拟合多项式函数\"><a href=\"#二、拟合多项式函数\" class=\"headerlink\" title=\"二、拟合多项式函数\"></a>二、拟合多项式函数</h3><ul>\n<li>单层神经网络只能够拟合直线</li>\n<li>对多项式函数的拟合需要多层神经网络，且需要激活函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义model类</span><br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><br><span class=\"hljs-comment\"># 继承nn.Module</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-comment\"># 第一个隐藏层</span><br>        self.hidden1=nn.Linear(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 第二个隐藏层</span><br>        self.hidden2=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 第三个隐藏层</span><br>        self.hidden3=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 输出层</span><br>        self.out=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">1</span>)<br>    <br>    <span class=\"hljs-comment\"># 定义网络前向运算</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden2(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden3(x)<br>        x = F.sigmoid(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>    <br>net = model()<br><span class=\"hljs-built_in\">print</span>(net)<br></code></pre></td></tr></table></figure>\n<pre><code>model(\n  (hidden1): Linear(in_features=1, out_features=4, bias=True)\n  (hidden2): Linear(in_features=4, out_features=4, bias=True)\n  (hidden3): Linear(in_features=4, out_features=4, bias=True)\n  (out): Linear(in_features=4, out_features=1, bias=True)\n)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练数据</span><br>losses2 = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">50000</span>):<br>    pred = net(X_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    loss = loss_fn(pred, y_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">2500</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;loss:&#x27;</span>, loss.data)<br>        losses2.append(loss)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br><br><span class=\"hljs-comment\"># 绘制图像</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_train2.data.numpy(), y_train2.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_train2.data.numpy(), net(X_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>loss: tensor(357.9143)\n\n\nD:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)\n\n\nloss: tensor(146.0952)\nloss: tensor(23.4380)\nloss: tensor(16.6693)\nloss: tensor(12.3312)\nloss: tensor(10.4051)\nloss: tensor(8.9617)\nloss: tensor(7.7465)\nloss: tensor(6.7640)\nloss: tensor(5.9918)\nloss: tensor(5.4033)\nloss: tensor(4.9512)\nloss: tensor(4.5902)\nloss: tensor(4.2906)\nloss: tensor(4.0353)\nloss: tensor(3.8134)\nloss: tensor(3.6182)\nloss: tensor(3.4456)\nloss: tensor(3.2944)\nloss: tensor(3.1646)\n</code></pre><img src=\"/2023/01/03/deep-learning-test01/output_20_3.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 使用训练的模型对测试集进行预测</span><br>pred2 = net(X_test2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_test2.data.numpy(), y_test2.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_test2.data.numpy(), pred2.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/01/03/deep-learning-test01/output_21_0.png\" class=\"\" title=\"png\">\n","cover_type":"img","excerpt":"","more":"<h1 id=\"实验一、线性回归\"><a href=\"#实验一、线性回归\" class=\"headerlink\" title=\"实验一、线性回归\"></a>实验一、线性回归</h1><ul>\n<li>已知模型y = a*x + b</li>\n<li>生成带噪声的数据拟合线性函数</li>\n<li>绘制图像拟合效果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关包</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br>%matplotlib inline<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成y = a*x + b的噪声数据200个</span><br><span class=\"hljs-comment\"># 定义a = 3， b = 2</span><br>a, b = <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span><br><br>x_datas = torch.linspace(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">20</span>,<span class=\"hljs-number\">200</span>)<br>rand_noise = torch.randn(<span class=\"hljs-number\">200</span>)*<span class=\"hljs-number\">3</span><br>y_lables = a*x_datas + b + rand_noise<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 绘制散点图</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(x_datas, y_lables)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_3_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将数据划分为训练集和测试集，按照180，20进行划分</span><br><span class=\"hljs-comment\"># 每十个数据中，分层抽取出一个数据作为测试集</span><br><br>test_index = [<span class=\"hljs-number\">10</span>*i + np.random.randint(<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>)]<br>train_index = [i <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>) <span class=\"hljs-keyword\">if</span> i <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> test_index]<br><br>X_train1, X_test1, y_train1, y_test1 = x_datas[train_index], x_datas[test_index], y_lables[train_index], y_lables[test_index]<br>y_train1<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([ 3.6945,  4.7438,  7.9504,  5.5705,  5.6000,  9.5666,  8.5461,  4.9789,\n         0.6976,  5.6866,  4.2295, 10.9321, 11.2976,  7.9842, 12.1275,  8.0943,\n        10.5445, 13.4849, 18.5069, 11.6880, 16.8814, 12.7575, 10.7111, 12.1603,\n        14.7055, 14.3254, 11.4367, 17.6528, 18.5793, 17.8409, 13.8733, 16.6622,\n        18.6143, 14.5482, 16.6509, 17.4552, 20.0250, 20.3924, 20.6348, 18.2929,\n        16.6831, 20.4449, 17.3773, 18.3895, 18.2360, 24.1661, 18.2511, 16.6143,\n        20.3642, 16.5544, 19.0061, 25.6141, 20.1254, 21.4796, 23.3279, 20.1736,\n        25.3058, 26.7936, 24.8702, 23.0888, 24.2360, 26.3334, 26.8100, 22.9726,\n        25.0721, 28.1969, 27.3128, 28.3941, 27.2811, 25.5293, 29.3596, 30.8378,\n        29.3787, 30.2246, 28.6970, 19.3994, 31.6431, 35.1937, 26.6844, 31.5928,\n        32.8604, 31.2751, 26.1607, 26.1867, 27.4753, 28.5589, 32.5150, 35.3546,\n        29.3716, 30.2867, 34.1565, 36.8429, 32.5876, 41.2268, 32.7979, 35.0479,\n        38.0979, 34.0405, 35.0074, 40.8656, 39.9885, 37.4418, 37.3445, 33.4271,\n        40.4349, 41.4754, 36.4292, 41.2385, 41.1300, 39.4304, 39.1217, 40.2641,\n        41.4882, 36.4677, 45.3880, 41.7064, 46.0084, 42.7886, 48.2276, 48.9552,\n        45.7761, 46.6802, 49.1144, 47.0020, 41.9040, 47.4266, 48.3905, 51.4273,\n        46.7154, 49.9467, 45.0021, 50.9472, 55.9469, 49.3655, 44.3413, 47.9426,\n        45.9358, 54.3920, 49.9636, 53.2459, 50.3228, 46.5756, 50.2442, 54.3946,\n        50.2086, 49.6290, 50.5312, 54.7947, 47.7757, 50.7428, 52.6791, 55.2901,\n        55.9978, 57.0760, 50.6741, 53.8824, 58.6424, 53.3195, 57.1432, 54.2989,\n        49.9915, 55.4631, 56.1260, 55.4143, 54.0111, 56.7517, 59.6828, 57.2633,\n        56.1236, 63.1750, 59.2744, 54.7133, 54.5091, 57.9472, 64.0721, 63.9801,\n        61.2980, 61.6411, 62.6100, 59.2035])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将训练集转化为张量，使用梯度下降法进行训练</span><br><span class=\"hljs-comment\"># 迭代次数 10000，学习率：0.001</span><br><br>a = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>b = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>loss = []<br>theta = <span class=\"hljs-number\">0.00001</span><br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">10000</span>+<span class=\"hljs-number\">1</span>):<br>    y_p = a.expand_as(X_train1)*X_train1 + b.expand_as(X_train1)<br>    loss_tmp = torch.mean((y_p - y_train1)**<span class=\"hljs-number\">2</span>)<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">500</span> == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;迭代&quot;</span> , i , <span class=\"hljs-string\">&quot;次，损失值为：&quot;</span>,loss_tmp.data.numpy())<br>    <br>    loss.append(loss_tmp.data.numpy())<br>    loss_tmp.backward()<br>    a.data = a.data - theta*a.grad.data<br>    b.data = b.data - theta*b.grad.data<br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    <br><span class=\"hljs-built_in\">print</span>(a, b)<br></code></pre></td></tr></table></figure>\n<pre><code>迭代 0 次，损失值为： 1019.3526\n迭代 500 次，损失值为： 68.77335\n迭代 1000 次，损失值为： 12.962891\n迭代 1500 次，损失值为： 9.682995\n迭代 2000 次，损失值为： 9.4870615\n迭代 2500 次，损失值为： 9.47218\n迭代 3000 次，损失值为： 9.467946\n迭代 3500 次，损失值为： 9.46435\n迭代 4000 次，损失值为： 9.460806\n迭代 4500 次，损失值为： 9.457279\n迭代 5000 次，损失值为： 9.453774\n迭代 5500 次，损失值为： 9.450276\n迭代 6000 次，损失值为： 9.446788\n迭代 6500 次，损失值为： 9.44333\n迭代 7000 次，损失值为： 9.439879\n迭代 7500 次，损失值为： 9.436436\n迭代 8000 次，损失值为： 9.433018\n迭代 8500 次，损失值为： 9.429613\n迭代 9000 次，损失值为： 9.426218\n迭代 9500 次，损失值为： 9.422838\n迭代 10000 次，损失值为： 9.419481\ntensor([3.1121], requires_grad=True) tensor([0.9682], requires_grad=True)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_test1, y_test1)<br><br>plt.plot(X_test1.data.numpy(), a.data.numpy()*X_test1.data.numpy() + b.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/01/03/deep-learning-test01/output_6_0.png\" class=\"\" title=\"png\">\n<ul>\n<li>已知模型y = a<em>x^3 + b</em>x^2 + c*x + d</li>\n<li>生成带噪声的数据拟合三次函数</li>\n<li>绘制图像拟合效果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成200个噪声数据</span><br><span class=\"hljs-comment\"># 参数设置，a=0.005, b=0.01, c=0.1, d=1</span><br><br>a, b, c, d = <span class=\"hljs-number\">0.005</span>, <span class=\"hljs-number\">0.01</span>, <span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1</span><br><br>rand = torch.randn(<span class=\"hljs-number\">200</span>)*<span class=\"hljs-number\">1.5</span><br>X_trains = torch.linspace(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">20</span>, <span class=\"hljs-number\">200</span>)<br>Y_labels = a*(X_trains**<span class=\"hljs-number\">3</span>) + b*(X_trains**<span class=\"hljs-number\">2</span>) + c*X_trains + d + rand<br><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_trains, Y_labels)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_8_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构造数据集和训练集标签</span><br><br>test_index = [<span class=\"hljs-number\">10</span>*i + np.random.randint(<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>)]<br>train_index = [i <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>) <span class=\"hljs-keyword\">if</span> i <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> test_index]<br><br>X_train2, X_test2, y_train2, y_test2 = X_trains[train_index], X_trains[test_index], Y_labels[train_index], Y_labels[test_index]<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 开始训练</span><br>a = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>b = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>c = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>d = torch.rand(<span class=\"hljs-number\">1</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>theta = <span class=\"hljs-number\">0.0000001</span><br>times = <span class=\"hljs-number\">50000</span><br>loss = []<br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(times+<span class=\"hljs-number\">1</span>):<br>    loss_tmp = torch.mean(((a.expand_as(X_train2) * (X_train2**<span class=\"hljs-number\">3</span>) + <br>                           b.expand_as(X_train2) * (X_train2**<span class=\"hljs-number\">2</span>) + c.expand_as(X_train2) * X_train2 + <br>                           d.expand_as(X_train2) - y_train2))**<span class=\"hljs-number\">2</span>)<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">2500</span> == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;迭代&quot;</span>, i,<span class=\"hljs-string\">&quot;次，损失值为：&quot;</span>, loss_tmp.data.numpy())<br>    <br>    loss_tmp.backward()<br>    a.data = a.data - a.grad.data * theta<br>    b.data = b.data - b.grad.data * theta<br>    c.data = c.data - c.grad.data * theta<br>    d.data = d.data - d.grad.data * theta<br>    <br>    a.grad.data.zero_()<br>    b.grad.data.zero_()<br>    c.grad.data.zero_()<br>    d.grad.data.zero_()<br>    <br></code></pre></td></tr></table></figure>\n<pre><code>迭代 0 次，损失值为： 3153.991\n迭代 2500 次，损失值为： 11.566195\n迭代 5000 次，损失值为： 5.8502893\n迭代 7500 次，损失值为： 3.6634474\n迭代 10000 次，损失值为： 2.8267233\n迭代 12500 次，损失值为： 2.506517\n迭代 15000 次，损失值为： 2.3839154\n迭代 17500 次，损失值为： 2.3369095\n迭代 20000 次，损失值为： 2.318825\n迭代 22500 次，损失值为： 2.3118067\n迭代 25000 次，损失值为： 2.3090246\n迭代 27500 次，损失值为： 2.307857\n迭代 30000 次，损失值为： 2.307303\n迭代 32500 次，损失值为： 2.3069975\n迭代 35000 次，损失值为： 2.3067696\n迭代 37500 次，损失值为： 2.306577\n迭代 40000 次，损失值为： 2.3063998\n迭代 42500 次，损失值为： 2.3062305\n迭代 45000 次，损失值为： 2.3060641\n迭代 47500 次，损失值为： 2.3058996\n迭代 50000 次，损失值为： 2.3057368\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测拟合</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.scatter(X_test2, y_test2)<br><br>plt.plot(X_test2.data.numpy(), a.data.numpy()*(X_test2.data.numpy()**<span class=\"hljs-number\">3</span>) + b.data.numpy()*(X_test2.data.numpy()**<span class=\"hljs-number\">2</span>) + c.data.numpy()*X_test2.data.numpy() + d.data.numpy())<br><br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_11_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<h2 id=\"设计神经网络对前面的数据进行拟合\"><a href=\"#设计神经网络对前面的数据进行拟合\" class=\"headerlink\" title=\"设计神经网络对前面的数据进行拟合\"></a>设计神经网络对前面的数据进行拟合</h2><ul>\n<li>记录误差，绘制拟合效果</li>\n<li>直线拟合数据为：X_train1, y_train1, X_test1, y_test1</li>\n<li>曲线拟合数据为：X_train2, y_train2, X_test2, y_test2</li>\n</ul>\n<h3 id=\"一、拟合直线\"><a href=\"#一、拟合直线\" class=\"headerlink\" title=\"一、拟合直线\"></a>一、拟合直线</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 使用网络拟合直线</span><br><span class=\"hljs-comment\"># 直线拟合只需要一个神经元就能完成拟合</span><br><br><span class=\"hljs-comment\"># 定义网络</span><br>net = torch.nn.Sequential(<br>    torch.nn.Linear(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>),<br>)<br><span class=\"hljs-comment\"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br><span class=\"hljs-comment\"># 梯度下降方法，随机梯度下降</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.0001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练数据</span><br>losses = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    pred = net(X_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    loss = loss_fn(pred, y_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">200</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;loss:&#x27;</span>, loss.data)<br>        losses.append(loss.data)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br>    <br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_train1.data.numpy(), y_train1.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_train1.data.numpy(), net(X_train1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>loss: tensor(999.4984)\nloss: tensor(10.4790)\nloss: tensor(10.4377)\nloss: tensor(10.4070)\nloss: tensor(10.3768)\n</code></pre><img src=\"/2023/01/03/deep-learning-test01/output_15_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测验证</span><br>pred = net(X_test1.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_test1.data.numpy(), y_test1.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_test1.data.numpy(), pred.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/03/deep-learning-test01/output_16_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<h3 id=\"二、拟合多项式函数\"><a href=\"#二、拟合多项式函数\" class=\"headerlink\" title=\"二、拟合多项式函数\"></a>二、拟合多项式函数</h3><ul>\n<li>单层神经网络只能够拟合直线</li>\n<li>对多项式函数的拟合需要多层神经网络，且需要激活函数</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义model类</span><br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><br><span class=\"hljs-comment\"># 继承nn.Module</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-comment\"># 第一个隐藏层</span><br>        self.hidden1=nn.Linear(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 第二个隐藏层</span><br>        self.hidden2=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 第三个隐藏层</span><br>        self.hidden3=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>)<br>        <span class=\"hljs-comment\"># 输出层</span><br>        self.out=nn.Linear(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">1</span>)<br>    <br>    <span class=\"hljs-comment\"># 定义网络前向运算</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden2(x)<br>        x = F.sigmoid(x)<br>        x = self.hidden3(x)<br>        x = F.sigmoid(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>    <br>net = model()<br><span class=\"hljs-built_in\">print</span>(net)<br></code></pre></td></tr></table></figure>\n<pre><code>model(\n  (hidden1): Linear(in_features=1, out_features=4, bias=True)\n  (hidden2): Linear(in_features=4, out_features=4, bias=True)\n  (hidden3): Linear(in_features=4, out_features=4, bias=True)\n  (out): Linear(in_features=4, out_features=1, bias=True)\n)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义损失函数</span><br>loss_fn = torch.nn.MSELoss()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练数据</span><br>losses2 = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">50000</span>):<br>    pred = net(X_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    loss = loss_fn(pred, y_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">2500</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;loss:&#x27;</span>, loss.data)<br>        losses2.append(loss)<br>    <br>    opt.zero_grad()<br>    loss.backward()<br>    opt.step()<br><br><span class=\"hljs-comment\"># 绘制图像</span><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_train2.data.numpy(), y_train2.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_train2.data.numpy(), net(X_train2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)).data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>loss: tensor(357.9143)\n\n\nD:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)\n\n\nloss: tensor(146.0952)\nloss: tensor(23.4380)\nloss: tensor(16.6693)\nloss: tensor(12.3312)\nloss: tensor(10.4051)\nloss: tensor(8.9617)\nloss: tensor(7.7465)\nloss: tensor(6.7640)\nloss: tensor(5.9918)\nloss: tensor(5.4033)\nloss: tensor(4.9512)\nloss: tensor(4.5902)\nloss: tensor(4.2906)\nloss: tensor(4.0353)\nloss: tensor(3.8134)\nloss: tensor(3.6182)\nloss: tensor(3.4456)\nloss: tensor(3.2944)\nloss: tensor(3.1646)\n</code></pre><img src=\"/2023/01/03/deep-learning-test01/output_20_3.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 使用训练的模型对测试集进行预测</span><br>pred2 = net(X_test2.view(-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))<br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(X_test2.data.numpy(), y_test2.data.numpy(), <span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.plot(X_test2.data.numpy(), pred2.data.numpy())<br>plt.show()<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/01/03/deep-learning-test01/output_21_0.png\" class=\"\" title=\"png\">\n"},{"title":"深度学习实践实验-共享单车预测","date":"2023-01-04T09:24:51.000Z","cover":"/img/default_cover02.jpg","top_img":null,"_content":"# 实验二、共享单车预测\n\n### **内容**\n\n1、通过历史数据预测某一地区接下来一段时间内的共享单车的数量。数据保存在文件bikes.csv中，请按11：1的比例划分训练集和测试集，首先对数据进行预处理，然后在训练集上训练，并在测试集上验证模型。\n\n2、设计神经网络对数据进行拟合，利用训练后的模型对数据拟合并进行预测，记录误差，并绘制拟合效果。\n\n### **完成情况**\n\n1、数据预处理\n\n完成程度：使用pandas读取原始数据bikes.csv，对离散数据使用one-hot编码处理，对连续数据进行标准化处理，将数据划分成11训练集：1测试集。删除某些处理过后的列，将标签列于数据分离。\n\n2、设计神经网络拟合\n\n完成程度：搭建神经网络，隐藏层包含10个Linear，通过Sigmoid函数进行非线性化处理，再通过输出层对数据进行输出。使用MSELoss损失误差，采用随机梯度下降的方法，设置学习率为0.01，batch_size=128。对训练集进行训练，用得到的模型对测试集进行测试，通过绘制图像进行对比分析。\n\n\n\n## 读取原始数据，进行数据预处理\n\n\n```python\n# 导入相关包和函数\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.optim as optim\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 读入数据并进行数据处理\ndata = pd.read_csv('bikes.csv')\ncol_titles = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\nfor i in col_titles:\n    dummies = pd.get_dummies(data[i], prefix=i)\n    data = pd.concat([data, dummies], axis=1)\n\ncol_titles_to_drop = ['instant', 'dteday'] + col_titles\nprint(col_titles_to_drop)\ndata = data.drop(col_titles_to_drop, axis=1)\ndata.head()\n```\n\n    ['instant', 'dteday', 'season', 'weathersit', 'mnth', 'hr', 'weekday']\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>temp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>cnt</th>\n      <th>season_1</th>\n      <th>season_2</th>\n      <th>season_3</th>\n      <th>season_4</th>\n      <th>...</th>\n      <th>hr_21</th>\n      <th>hr_22</th>\n      <th>hr_23</th>\n      <th>weekday_0</th>\n      <th>weekday_1</th>\n      <th>weekday_2</th>\n      <th>weekday_3</th>\n      <th>weekday_4</th>\n      <th>weekday_5</th>\n      <th>weekday_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.81</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n\n</div>\n\n\n\n\n```python\n# 对连续数据进行标准化处理\ncol_titles = ['cnt', 'temp', 'hum', 'windspeed']\nfor i in col_titles:\n    mean, std = data[i].mean(), data[i].std()\n    if i == 'cnt':\n        mean_cnt, std_cnt = mean, std\n    \n    data[i] = (data[i] - mean)/std\n```\n\n\n```python\n# 数据集处理\ntest_data = data[-30*24:]\ntrain_data = data[:-30*24]\n\n# 删除标签类\nX = train_data.drop(['cnt'], axis=1)\nX = X.values\nY = train_data['cnt']\nY = Y.values.astype(float)\nY = np.reshape(Y, [len(Y), 1])\n```\n\n\n```python\n# 搭建神经网络\ninput_size = X.shape[1]\nhidden_size = 10\noutput_size = 1\nbatch_size = 128\n\nneu = torch.nn.Sequential(\n    torch.nn.Linear(input_size, hidden_size),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(hidden_size, output_size)\n)\nloss_fn = torch.nn.MSELoss()\nopt = torch.optim.SGD(neu.parameters(), lr=0.01)\n```\n\n\n```python\n# 训练模型\nlosses = []\nfor i in range(1000):\n    batch_loss = []\n    for start in range(0, len(X), batch_size):\n        if start+batch_size<len(X):\n            end = start+batch_size\n        else:\n            end = len(X)\n\n        # 生成一个batch的训练数据\n        x = torch.FloatTensor(X[start:end])\n        y = torch.FloatTensor(Y[start:end])\n\n        pred = neu(x)\n        loss = loss_fn(pred, y)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        batch_loss.append(loss.data.numpy())\n    if i%100==0:\n        losses.append(np.mean(batch_loss))\n        print(i, np.mean(batch_loss))\n        \nplt.figure(figsize=(10, 8))\nplt.plot(np.arange(len(losses))*100, losses)\nplt.xlabel('batch')\nplt.ylabel('MSE')\nplt.show()\n```\n\n    0 0.8939656\n    100 0.30960146\n    200 0.26964802\n    300 0.18884033\n    400 0.14483929\n    500 0.1316976\n    600 0.12759094\n    700 0.12547289\n    800 0.12405107\n    900 0.12297937\n\n\n\n\n![png](deep-learning-test02/output_7_1.png)\n    \n\n\n\n```python\n# 测试，验证\nX = test_data.drop(['cnt'], axis=1)\nY = test_data['cnt']\nY = Y.values.reshape([len(Y), 1])\nX = torch.FloatTensor(X.values)\nY = torch.FloatTensor(Y)\npred = neu(X)\n\nY = Y.data.numpy()*std_cnt+mean_cnt\npred = pred.data.numpy()*std_cnt+mean_cnt\n\nplt.figure(figsize=(10, 8))\nxplot, = plt.plot(np.arange(X.size(0)), Y)\nyplot, = plt.plot(np.arange(X.size(0)), pred, ':')\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test02/output_8_0.png)\n​    \n\n","source":"_posts/deep-learning-test02.md","raw":"---\ntitle: 深度学习实践实验-共享单车预测\ncategories: 算法实践\ndate: 2023-01-04 17:24:51\ntags: [深度学习, 人工智能]\ncover:\ntop_img:\n---\n# 实验二、共享单车预测\n\n### **内容**\n\n1、通过历史数据预测某一地区接下来一段时间内的共享单车的数量。数据保存在文件bikes.csv中，请按11：1的比例划分训练集和测试集，首先对数据进行预处理，然后在训练集上训练，并在测试集上验证模型。\n\n2、设计神经网络对数据进行拟合，利用训练后的模型对数据拟合并进行预测，记录误差，并绘制拟合效果。\n\n### **完成情况**\n\n1、数据预处理\n\n完成程度：使用pandas读取原始数据bikes.csv，对离散数据使用one-hot编码处理，对连续数据进行标准化处理，将数据划分成11训练集：1测试集。删除某些处理过后的列，将标签列于数据分离。\n\n2、设计神经网络拟合\n\n完成程度：搭建神经网络，隐藏层包含10个Linear，通过Sigmoid函数进行非线性化处理，再通过输出层对数据进行输出。使用MSELoss损失误差，采用随机梯度下降的方法，设置学习率为0.01，batch_size=128。对训练集进行训练，用得到的模型对测试集进行测试，通过绘制图像进行对比分析。\n\n\n\n## 读取原始数据，进行数据预处理\n\n\n```python\n# 导入相关包和函数\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.optim as optim\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 读入数据并进行数据处理\ndata = pd.read_csv('bikes.csv')\ncol_titles = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\nfor i in col_titles:\n    dummies = pd.get_dummies(data[i], prefix=i)\n    data = pd.concat([data, dummies], axis=1)\n\ncol_titles_to_drop = ['instant', 'dteday'] + col_titles\nprint(col_titles_to_drop)\ndata = data.drop(col_titles_to_drop, axis=1)\ndata.head()\n```\n\n    ['instant', 'dteday', 'season', 'weathersit', 'mnth', 'hr', 'weekday']\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>temp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>cnt</th>\n      <th>season_1</th>\n      <th>season_2</th>\n      <th>season_3</th>\n      <th>season_4</th>\n      <th>...</th>\n      <th>hr_21</th>\n      <th>hr_22</th>\n      <th>hr_23</th>\n      <th>weekday_0</th>\n      <th>weekday_1</th>\n      <th>weekday_2</th>\n      <th>weekday_3</th>\n      <th>weekday_4</th>\n      <th>weekday_5</th>\n      <th>weekday_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.81</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n\n</div>\n\n\n\n\n```python\n# 对连续数据进行标准化处理\ncol_titles = ['cnt', 'temp', 'hum', 'windspeed']\nfor i in col_titles:\n    mean, std = data[i].mean(), data[i].std()\n    if i == 'cnt':\n        mean_cnt, std_cnt = mean, std\n    \n    data[i] = (data[i] - mean)/std\n```\n\n\n```python\n# 数据集处理\ntest_data = data[-30*24:]\ntrain_data = data[:-30*24]\n\n# 删除标签类\nX = train_data.drop(['cnt'], axis=1)\nX = X.values\nY = train_data['cnt']\nY = Y.values.astype(float)\nY = np.reshape(Y, [len(Y), 1])\n```\n\n\n```python\n# 搭建神经网络\ninput_size = X.shape[1]\nhidden_size = 10\noutput_size = 1\nbatch_size = 128\n\nneu = torch.nn.Sequential(\n    torch.nn.Linear(input_size, hidden_size),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(hidden_size, output_size)\n)\nloss_fn = torch.nn.MSELoss()\nopt = torch.optim.SGD(neu.parameters(), lr=0.01)\n```\n\n\n```python\n# 训练模型\nlosses = []\nfor i in range(1000):\n    batch_loss = []\n    for start in range(0, len(X), batch_size):\n        if start+batch_size<len(X):\n            end = start+batch_size\n        else:\n            end = len(X)\n\n        # 生成一个batch的训练数据\n        x = torch.FloatTensor(X[start:end])\n        y = torch.FloatTensor(Y[start:end])\n\n        pred = neu(x)\n        loss = loss_fn(pred, y)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        batch_loss.append(loss.data.numpy())\n    if i%100==0:\n        losses.append(np.mean(batch_loss))\n        print(i, np.mean(batch_loss))\n        \nplt.figure(figsize=(10, 8))\nplt.plot(np.arange(len(losses))*100, losses)\nplt.xlabel('batch')\nplt.ylabel('MSE')\nplt.show()\n```\n\n    0 0.8939656\n    100 0.30960146\n    200 0.26964802\n    300 0.18884033\n    400 0.14483929\n    500 0.1316976\n    600 0.12759094\n    700 0.12547289\n    800 0.12405107\n    900 0.12297937\n\n\n\n\n![png](deep-learning-test02/output_7_1.png)\n    \n\n\n\n```python\n# 测试，验证\nX = test_data.drop(['cnt'], axis=1)\nY = test_data['cnt']\nY = Y.values.reshape([len(Y), 1])\nX = torch.FloatTensor(X.values)\nY = torch.FloatTensor(Y)\npred = neu(X)\n\nY = Y.data.numpy()*std_cnt+mean_cnt\npred = pred.data.numpy()*std_cnt+mean_cnt\n\nplt.figure(figsize=(10, 8))\nxplot, = plt.plot(np.arange(X.size(0)), Y)\nyplot, = plt.plot(np.arange(X.size(0)), pred, ':')\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test02/output_8_0.png)\n​    \n\n","slug":"deep-learning-test02","published":1,"updated":"2024-06-05T09:03:03.693Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttr001h08jv6axkc048","content":"<h1 id=\"实验二、共享单车预测\"><a href=\"#实验二、共享单车预测\" class=\"headerlink\" title=\"实验二、共享单车预测\"></a>实验二、共享单车预测</h1><h3 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a><strong>内容</strong></h3><p>1、通过历史数据预测某一地区接下来一段时间内的共享单车的数量。数据保存在文件bikes.csv中，请按11：1的比例划分训练集和测试集，首先对数据进行预处理，然后在训练集上训练，并在测试集上验证模型。</p>\n<p>2、设计神经网络对数据进行拟合，利用训练后的模型对数据拟合并进行预测，记录误差，并绘制拟合效果。</p>\n<h3 id=\"完成情况\"><a href=\"#完成情况\" class=\"headerlink\" title=\"完成情况\"></a><strong>完成情况</strong></h3><p>1、数据预处理</p>\n<p>完成程度：使用pandas读取原始数据bikes.csv，对离散数据使用one-hot编码处理，对连续数据进行标准化处理，将数据划分成11训练集：1测试集。删除某些处理过后的列，将标签列于数据分离。</p>\n<p>2、设计神经网络拟合</p>\n<p>完成程度：搭建神经网络，隐藏层包含10个Linear，通过Sigmoid函数进行非线性化处理，再通过输出层对数据进行输出。使用MSELoss损失误差，采用随机梯度下降的方法，设置学习率为0.01，batch_size=128。对训练集进行训练，用得到的模型对测试集进行测试，通过绘制图像进行对比分析。</p>\n<h2 id=\"读取原始数据，进行数据预处理\"><a href=\"#读取原始数据，进行数据预处理\" class=\"headerlink\" title=\"读取原始数据，进行数据预处理\"></a>读取原始数据，进行数据预处理</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关包和函数</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 读入数据并进行数据处理</span><br>data = pd.read_csv(<span class=\"hljs-string\">&#x27;bikes.csv&#x27;</span>)<br>col_titles = [<span class=\"hljs-string\">&#x27;season&#x27;</span>, <span class=\"hljs-string\">&#x27;weathersit&#x27;</span>, <span class=\"hljs-string\">&#x27;mnth&#x27;</span>, <span class=\"hljs-string\">&#x27;hr&#x27;</span>, <span class=\"hljs-string\">&#x27;weekday&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    dummies = pd.get_dummies(data[i], prefix=i)<br>    data = pd.concat([data, dummies], axis=<span class=\"hljs-number\">1</span>)<br><br>col_titles_to_drop = [<span class=\"hljs-string\">&#x27;instant&#x27;</span>, <span class=\"hljs-string\">&#x27;dteday&#x27;</span>] + col_titles<br><span class=\"hljs-built_in\">print</span>(col_titles_to_drop)<br>data = data.drop(col_titles_to_drop, axis=<span class=\"hljs-number\">1</span>)<br>data.head()<br></code></pre></td></tr></table></figure>\n<pre><code>[&#39;instant&#39;, &#39;dteday&#39;, &#39;season&#39;, &#39;weathersit&#39;, &#39;mnth&#39;, &#39;hr&#39;, &#39;weekday&#39;]\n</code></pre><p><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>temp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>cnt</th>\n      <th>season_1</th>\n      <th>season_2</th>\n      <th>season_3</th>\n      <th>season_4</th>\n      <th>...</th>\n      <th>hr_21</th>\n      <th>hr_22</th>\n      <th>hr_23</th>\n      <th>weekday_0</th>\n      <th>weekday_1</th>\n      <th>weekday_2</th>\n      <th>weekday_3</th>\n      <th>weekday_4</th>\n      <th>weekday_5</th>\n      <th>weekday_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.81</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table></p>\n<p>5 rows × 57 columns</p>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对连续数据进行标准化处理</span><br>col_titles = [<span class=\"hljs-string\">&#x27;cnt&#x27;</span>, <span class=\"hljs-string\">&#x27;temp&#x27;</span>, <span class=\"hljs-string\">&#x27;hum&#x27;</span>, <span class=\"hljs-string\">&#x27;windspeed&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    mean, std = data[i].mean(), data[i].std()<br>    <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-string\">&#x27;cnt&#x27;</span>:<br>        mean_cnt, std_cnt = mean, std<br>    <br>    data[i] = (data[i] - mean)/std<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据集处理</span><br>test_data = data[-<span class=\"hljs-number\">30</span>*<span class=\"hljs-number\">24</span>:]<br>train_data = data[:-<span class=\"hljs-number\">30</span>*<span class=\"hljs-number\">24</span>]<br><br><span class=\"hljs-comment\"># 删除标签类</span><br>X = train_data.drop([<span class=\"hljs-string\">&#x27;cnt&#x27;</span>], axis=<span class=\"hljs-number\">1</span>)<br>X = X.values<br>Y = train_data[<span class=\"hljs-string\">&#x27;cnt&#x27;</span>]<br>Y = Y.values.astype(<span class=\"hljs-built_in\">float</span>)<br>Y = np.reshape(Y, [<span class=\"hljs-built_in\">len</span>(Y), <span class=\"hljs-number\">1</span>])<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 搭建神经网络</span><br>input_size = X.shape[<span class=\"hljs-number\">1</span>]<br>hidden_size = <span class=\"hljs-number\">10</span><br>output_size = <span class=\"hljs-number\">1</span><br>batch_size = <span class=\"hljs-number\">128</span><br><br>neu = torch.nn.Sequential(<br>    torch.nn.Linear(input_size, hidden_size),<br>    torch.nn.Sigmoid(),<br>    torch.nn.Linear(hidden_size, output_size)<br>)<br>loss_fn = torch.nn.MSELoss()<br>opt = torch.optim.SGD(neu.parameters(), lr=<span class=\"hljs-number\">0.01</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练模型</span><br>losses = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    batch_loss = []<br>    <span class=\"hljs-keyword\">for</span> start <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(X), batch_size):<br>        <span class=\"hljs-keyword\">if</span> start+batch_size&lt;<span class=\"hljs-built_in\">len</span>(X):<br>            end = start+batch_size<br>        <span class=\"hljs-keyword\">else</span>:<br>            end = <span class=\"hljs-built_in\">len</span>(X)<br><br>        <span class=\"hljs-comment\"># 生成一个batch的训练数据</span><br>        x = torch.FloatTensor(X[start:end])<br>        y = torch.FloatTensor(Y[start:end])<br><br>        pred = neu(x)<br>        loss = loss_fn(pred, y)<br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        batch_loss.append(loss.data.numpy())<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>:<br>        losses.append(np.mean(batch_loss))<br>        <span class=\"hljs-built_in\">print</span>(i, np.mean(batch_loss))<br>        <br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(np.arange(<span class=\"hljs-built_in\">len</span>(losses))*<span class=\"hljs-number\">100</span>, losses)<br>plt.xlabel(<span class=\"hljs-string\">&#x27;batch&#x27;</span>)<br>plt.ylabel(<span class=\"hljs-string\">&#x27;MSE&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>0 0.8939656\n100 0.30960146\n200 0.26964802\n300 0.18884033\n400 0.14483929\n500 0.1316976\n600 0.12759094\n700 0.12547289\n800 0.12405107\n900 0.12297937\n</code></pre><img src=\"/2023/01/04/deep-learning-test02/output_7_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试，验证</span><br>X = test_data.drop([<span class=\"hljs-string\">&#x27;cnt&#x27;</span>], axis=<span class=\"hljs-number\">1</span>)<br>Y = test_data[<span class=\"hljs-string\">&#x27;cnt&#x27;</span>]<br>Y = Y.values.reshape([<span class=\"hljs-built_in\">len</span>(Y), <span class=\"hljs-number\">1</span>])<br>X = torch.FloatTensor(X.values)<br>Y = torch.FloatTensor(Y)<br>pred = neu(X)<br><br>Y = Y.data.numpy()*std_cnt+mean_cnt<br>pred = pred.data.numpy()*std_cnt+mean_cnt<br><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>xplot, = plt.plot(np.arange(X.size(<span class=\"hljs-number\">0</span>)), Y)<br>yplot, = plt.plot(np.arange(X.size(<span class=\"hljs-number\">0</span>)), pred, <span class=\"hljs-string\">&#x27;:&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/04/deep-learning-test02/output_8_0.png\" class=\"\" title=\"png\"><br>​    </p>\n","cover_type":"img","excerpt":"","more":"<h1 id=\"实验二、共享单车预测\"><a href=\"#实验二、共享单车预测\" class=\"headerlink\" title=\"实验二、共享单车预测\"></a>实验二、共享单车预测</h1><h3 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a><strong>内容</strong></h3><p>1、通过历史数据预测某一地区接下来一段时间内的共享单车的数量。数据保存在文件bikes.csv中，请按11：1的比例划分训练集和测试集，首先对数据进行预处理，然后在训练集上训练，并在测试集上验证模型。</p>\n<p>2、设计神经网络对数据进行拟合，利用训练后的模型对数据拟合并进行预测，记录误差，并绘制拟合效果。</p>\n<h3 id=\"完成情况\"><a href=\"#完成情况\" class=\"headerlink\" title=\"完成情况\"></a><strong>完成情况</strong></h3><p>1、数据预处理</p>\n<p>完成程度：使用pandas读取原始数据bikes.csv，对离散数据使用one-hot编码处理，对连续数据进行标准化处理，将数据划分成11训练集：1测试集。删除某些处理过后的列，将标签列于数据分离。</p>\n<p>2、设计神经网络拟合</p>\n<p>完成程度：搭建神经网络，隐藏层包含10个Linear，通过Sigmoid函数进行非线性化处理，再通过输出层对数据进行输出。使用MSELoss损失误差，采用随机梯度下降的方法，设置学习率为0.01，batch_size=128。对训练集进行训练，用得到的模型对测试集进行测试，通过绘制图像进行对比分析。</p>\n<h2 id=\"读取原始数据，进行数据预处理\"><a href=\"#读取原始数据，进行数据预处理\" class=\"headerlink\" title=\"读取原始数据，进行数据预处理\"></a>读取原始数据，进行数据预处理</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关包和函数</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 读入数据并进行数据处理</span><br>data = pd.read_csv(<span class=\"hljs-string\">&#x27;bikes.csv&#x27;</span>)<br>col_titles = [<span class=\"hljs-string\">&#x27;season&#x27;</span>, <span class=\"hljs-string\">&#x27;weathersit&#x27;</span>, <span class=\"hljs-string\">&#x27;mnth&#x27;</span>, <span class=\"hljs-string\">&#x27;hr&#x27;</span>, <span class=\"hljs-string\">&#x27;weekday&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    dummies = pd.get_dummies(data[i], prefix=i)<br>    data = pd.concat([data, dummies], axis=<span class=\"hljs-number\">1</span>)<br><br>col_titles_to_drop = [<span class=\"hljs-string\">&#x27;instant&#x27;</span>, <span class=\"hljs-string\">&#x27;dteday&#x27;</span>] + col_titles<br><span class=\"hljs-built_in\">print</span>(col_titles_to_drop)<br>data = data.drop(col_titles_to_drop, axis=<span class=\"hljs-number\">1</span>)<br>data.head()<br></code></pre></td></tr></table></figure>\n<pre><code>[&#39;instant&#39;, &#39;dteday&#39;, &#39;season&#39;, &#39;weathersit&#39;, &#39;mnth&#39;, &#39;hr&#39;, &#39;weekday&#39;]\n</code></pre><p><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>temp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>cnt</th>\n      <th>season_1</th>\n      <th>season_2</th>\n      <th>season_3</th>\n      <th>season_4</th>\n      <th>...</th>\n      <th>hr_21</th>\n      <th>hr_22</th>\n      <th>hr_23</th>\n      <th>weekday_0</th>\n      <th>weekday_1</th>\n      <th>weekday_2</th>\n      <th>weekday_3</th>\n      <th>weekday_4</th>\n      <th>weekday_5</th>\n      <th>weekday_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.81</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.24</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table></p>\n<p>5 rows × 57 columns</p>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对连续数据进行标准化处理</span><br>col_titles = [<span class=\"hljs-string\">&#x27;cnt&#x27;</span>, <span class=\"hljs-string\">&#x27;temp&#x27;</span>, <span class=\"hljs-string\">&#x27;hum&#x27;</span>, <span class=\"hljs-string\">&#x27;windspeed&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    mean, std = data[i].mean(), data[i].std()<br>    <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-string\">&#x27;cnt&#x27;</span>:<br>        mean_cnt, std_cnt = mean, std<br>    <br>    data[i] = (data[i] - mean)/std<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据集处理</span><br>test_data = data[-<span class=\"hljs-number\">30</span>*<span class=\"hljs-number\">24</span>:]<br>train_data = data[:-<span class=\"hljs-number\">30</span>*<span class=\"hljs-number\">24</span>]<br><br><span class=\"hljs-comment\"># 删除标签类</span><br>X = train_data.drop([<span class=\"hljs-string\">&#x27;cnt&#x27;</span>], axis=<span class=\"hljs-number\">1</span>)<br>X = X.values<br>Y = train_data[<span class=\"hljs-string\">&#x27;cnt&#x27;</span>]<br>Y = Y.values.astype(<span class=\"hljs-built_in\">float</span>)<br>Y = np.reshape(Y, [<span class=\"hljs-built_in\">len</span>(Y), <span class=\"hljs-number\">1</span>])<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 搭建神经网络</span><br>input_size = X.shape[<span class=\"hljs-number\">1</span>]<br>hidden_size = <span class=\"hljs-number\">10</span><br>output_size = <span class=\"hljs-number\">1</span><br>batch_size = <span class=\"hljs-number\">128</span><br><br>neu = torch.nn.Sequential(<br>    torch.nn.Linear(input_size, hidden_size),<br>    torch.nn.Sigmoid(),<br>    torch.nn.Linear(hidden_size, output_size)<br>)<br>loss_fn = torch.nn.MSELoss()<br>opt = torch.optim.SGD(neu.parameters(), lr=<span class=\"hljs-number\">0.01</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练模型</span><br>losses = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    batch_loss = []<br>    <span class=\"hljs-keyword\">for</span> start <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(X), batch_size):<br>        <span class=\"hljs-keyword\">if</span> start+batch_size&lt;<span class=\"hljs-built_in\">len</span>(X):<br>            end = start+batch_size<br>        <span class=\"hljs-keyword\">else</span>:<br>            end = <span class=\"hljs-built_in\">len</span>(X)<br><br>        <span class=\"hljs-comment\"># 生成一个batch的训练数据</span><br>        x = torch.FloatTensor(X[start:end])<br>        y = torch.FloatTensor(Y[start:end])<br><br>        pred = neu(x)<br>        loss = loss_fn(pred, y)<br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        batch_loss.append(loss.data.numpy())<br>    <span class=\"hljs-keyword\">if</span> i%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>:<br>        losses.append(np.mean(batch_loss))<br>        <span class=\"hljs-built_in\">print</span>(i, np.mean(batch_loss))<br>        <br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>plt.plot(np.arange(<span class=\"hljs-built_in\">len</span>(losses))*<span class=\"hljs-number\">100</span>, losses)<br>plt.xlabel(<span class=\"hljs-string\">&#x27;batch&#x27;</span>)<br>plt.ylabel(<span class=\"hljs-string\">&#x27;MSE&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>0 0.8939656\n100 0.30960146\n200 0.26964802\n300 0.18884033\n400 0.14483929\n500 0.1316976\n600 0.12759094\n700 0.12547289\n800 0.12405107\n900 0.12297937\n</code></pre><img src=\"/2023/01/04/deep-learning-test02/output_7_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试，验证</span><br>X = test_data.drop([<span class=\"hljs-string\">&#x27;cnt&#x27;</span>], axis=<span class=\"hljs-number\">1</span>)<br>Y = test_data[<span class=\"hljs-string\">&#x27;cnt&#x27;</span>]<br>Y = Y.values.reshape([<span class=\"hljs-built_in\">len</span>(Y), <span class=\"hljs-number\">1</span>])<br>X = torch.FloatTensor(X.values)<br>Y = torch.FloatTensor(Y)<br>pred = neu(X)<br><br>Y = Y.data.numpy()*std_cnt+mean_cnt<br>pred = pred.data.numpy()*std_cnt+mean_cnt<br><br>plt.figure(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">8</span>))<br>xplot, = plt.plot(np.arange(X.size(<span class=\"hljs-number\">0</span>)), Y)<br>yplot, = plt.plot(np.arange(X.size(<span class=\"hljs-number\">0</span>)), pred, <span class=\"hljs-string\">&#x27;:&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/04/deep-learning-test02/output_8_0.png\" class=\"\" title=\"png\"><br>​    </p>\n"},{"title":"深度学习实践实验-SoftMax回归","date":"2023-01-08T10:03:21.000Z","cover":"/img/default_cover11.jpg","top_img":null,"_content":"# SoftMax回归\n\n### 1、聚类和分类\n\n通过sklearn库提供的聚类算法生成K类数据，以这些数据做为数据集训练神经网络，利用softmax层和交叉熵损失函数对数据进行分类。聚类参数要求K>3，数据样本不少于1000，其他参数参考课件。对聚类后的数据按9：1的原则划分训练集和测试集，利用在训练集上训练得到的模型对测试集上的数据进行验证，要求模型的准确率不低于99%。\n\n**完成程度**：使用sklearn.datasets中的make_blobs函数生成1200个样本数据，样本种类为4，样本中心分别为[-5, 5], [0, -2], [4, 8], [7, 3]，方差分别为[1.5,1.5,1.2,1]，每样样本数为300个，对样本数据进行划分，按照9训练集：1测试集的比例进行划分，构建网络，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。\n\n\n\n### 2、鸢尾花分类\n\n  Iris数据集包含150个样本，对应数据集的每行数据。每行数据包含每个样本的四个特征和样本的类别信息，iris数据集是用来给鸢尾花做分类的数据集，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征，请用神经网络训练一个分类器，分类器可以通过样本的四个特征来判断样本属于山鸢尾花、变色鸢尾还是维吉尼亚鸢尾。数据集文件iris.csv。要求模型的准确率不低于99%。\n\n**完成程度**：加载鸢尾花数据集iris.csv，查看样本数据，对数据进行标准化处理，将使用到的数据划分为训练集和测试集，搭建网络模型，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。\n\n\n\n## 聚类和分类\n\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport torch.nn.functional as F\nfrom sklearn.datasets import make_blobs\n\ndata, target = make_blobs(n_samples=1200, n_features=2, centers=[[-5, 5], [0, -2], [4, 8], [7, 3]], cluster_std=[1.5,1.5,1.2,1])\nplt.scatter(data[:, 0], data[:, 1], c=target, marker='o')\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test03/output_1_0.png)\n​    \n\n\n\n```python\n# 数据准备\n# 将训练集和测试集按照9：1的比例进行划分\n# 一共1200个数据，1080个训练集，120个测试集\ndata = torch.from_numpy(data)\ndata = data.type(torch.FloatTensor)\ntarget = torch.from_numpy(target)\ntarget = target.type(torch.LongTensor)\n\ntrain_x = data[:1080]\ntrain_y = target[:1080]\n\ntest_x = data[1080:]\ntest_y = target[1080:]\n\n# 训练数据集\ntrain_dataset = TensorDataset(train_x, train_y)\n# 测试数据集\ntest_dataset = TensorDataset(test_x, test_y)\n\n# 加载器\ntrain_loader = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset,batch_size=16,shuffle=True)\n```\n\n\n```python\n# 构建网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(2, 5)\n        self.out = nn.Linear(5, 4)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n\nnet = model()\n# 交叉熵损失函数\nloss_fn = nn.CrossEntropyLoss()\n# 优化器\nopt = torch.optim.SGD(net.parameters(), lr=0.01)\n```\n\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport numpy as np\nimport pandas as pd\nimport torch.nn.functional as F\nimport torch.optim as optim\n```\n\n\n```python\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(2, 4)\n        self.out = nn.liner(4, 1)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n```\n\n\n```python\nnet = model()\n\nloss_fn = nn.MSELoss()\nopt = opt\n```\n\n\n```python\n# 训练\nfor epoch in range(1000):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if(epoch%100==0):\n        print(loss)\n```\n\n    tensor(1.2986, grad_fn=<NllLossBackward0>)\n    tensor(0.0348, grad_fn=<NllLossBackward0>)\n    tensor(0.0084, grad_fn=<NllLossBackward0>)\n    tensor(0.0275, grad_fn=<NllLossBackward0>)\n    tensor(0.0479, grad_fn=<NllLossBackward0>)\n    tensor(0.0559, grad_fn=<NllLossBackward0>)\n    tensor(0.0055, grad_fn=<NllLossBackward0>)\n    tensor(0.0015, grad_fn=<NllLossBackward0>)\n    tensor(0.0134, grad_fn=<NllLossBackward0>)\n    tensor(0.0884, grad_fn=<NllLossBackward0>)\n\n\n\n```python\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 对测试集进行预测\n# 将测试集绘制出来\nprint(test_x.shape, test_y.shape, test_x[2], target)\nplt.scatter(test_x[:, 0], test_y, c=target[1080:], marker='o')\n\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n    print(y)\n    print(torch.max(pred.data, 1)[1], '\\n')\n\nprint(rights, length, rights/length)\n```\n\n    torch.Size([120, 2]) torch.Size([120]) tensor([4.7586, 6.5412]) tensor([1, 0, 1,  ..., 0, 0, 1])\n    tensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1])\n    tensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1]) \n    \n    tensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 1, 3, 2, 2])\n    tensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 0, 3, 2, 2]) \n    \n    tensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0])\n    tensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0]) \n    \n    tensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3])\n    tensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3]) \n    \n    tensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0])\n    tensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0]) \n    \n    tensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2])\n    tensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2]) \n    \n    tensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0])\n    tensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0]) \n    \n    tensor([2, 1, 2, 1, 1, 1, 0, 3])\n    tensor([2, 1, 2, 1, 1, 1, 0, 3]) \n    \n    tensor(119) 120 tensor(0.9917)\n\n\n\n\n![png](deep-learning-test03/output_9_1.png)\n    \n\n## 鸢尾花分类\n\n* 通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征\n* 使用神经网络训练一个分类器对数据集iris.csv进行分类\n\n\n```python\n# 导入相关函数\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\n```\n\n\n```python\n# 数据预处理\ndata = pd.read_csv('iris.csv')\nfor i in range(len(data)):\n    if data.loc[i, 'Species'] == 'setosa':\n        data.loc[i, 'Species'] = 0\n    if data.loc[i, 'Species'] == 'versicolor':\n        data.loc[i, 'Species'] = 1\n    if data.loc[i, 'Species'] == 'virginica':\n        data.loc[i, 'Species'] = 2\n\ndata.head()\n```\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\ndata = data.drop('Unnamed: 0', axis=1)\ndata.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n    \n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\ndata = shuffle(data)\nprint(data.head())\ndata.index = range(len(data))\ndata.head()\n```\n\n         Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n    62            6.0          2.2           4.0          1.0       1\n    122           7.7          2.8           6.7          2.0       2\n    130           7.4          2.8           6.1          1.9       2\n    125           7.2          3.2           6.0          1.8       2\n    112           6.8          3.0           5.5          2.1       2\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.7</td>\n      <td>2.8</td>\n      <td>6.7</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>3.2</td>\n      <td>6.0</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.8</td>\n      <td>3.0</td>\n      <td>5.5</td>\n      <td>2.1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\n# 将数据进行标准化处理\ncol_titles = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\nfor i in col_titles:\n    mean, std = data[i].mean(), data[i].std()\n    data[i] = (data[i]-mean)/std\n\ndata.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n    \n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.189196</td>\n      <td>-1.966964</td>\n      <td>0.137087</td>\n      <td>-0.261511</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.242172</td>\n      <td>-0.590395</td>\n      <td>1.666574</td>\n      <td>1.050416</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.879882</td>\n      <td>-0.590395</td>\n      <td>1.326688</td>\n      <td>0.919223</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.638355</td>\n      <td>0.327318</td>\n      <td>1.270040</td>\n      <td>0.788031</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.155302</td>\n      <td>-0.131539</td>\n      <td>0.986802</td>\n      <td>1.181609</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\n# 数据集处理\n# 划分训练集和测试集\ntrain_data = data[:-32]\ntrain_x = train_data.drop(['Species'], axis=1).values\ntrain_y = train_data['Species'].values.astype(int)\ntrain_x = torch.from_numpy(train_x).type(torch.FloatTensor)\ntrain_y = torch.from_numpy(train_y).type(torch.LongTensor)\n\ntest_data = data[-32:]\ntest_x = test_data.drop(['Species'], axis=1).values\ntest_y = test_data['Species'].values.astype(int)\ntest_x = torch.from_numpy(test_x).type(torch.FloatTensor)\ntest_y = torch.from_numpy(test_y).type(torch.LongTensor)\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n```\n\n\n```python\n# 构建神经网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(4, 5)\n        self.out = nn.Linear(5, 3)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n    \nnet = model()\nloss_fn = nn.CrossEntropyLoss()\nopt = torch.optim.SGD(net.parameters(), lr=0.05)\n```\n\n\n```python\n# 模型训练\nfor epoch in range(10000):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%1000==0:\n        print('第', epoch, '个epoch，损失值为：', loss)\n```\n\n    第 0 个epoch，损失值为： tensor(1.0210, grad_fn=<NllLossBackward0>)\n    第 1000 个epoch，损失值为： tensor(0.0007, grad_fn=<NllLossBackward0>)\n    第 2000 个epoch，损失值为： tensor(0.0010, grad_fn=<NllLossBackward0>)\n    第 3000 个epoch，损失值为： tensor(0.0004, grad_fn=<NllLossBackward0>)\n    第 4000 个epoch，损失值为： tensor(0.0008, grad_fn=<NllLossBackward0>)\n    第 5000 个epoch，损失值为： tensor(0.0007, grad_fn=<NllLossBackward0>)\n    第 6000 个epoch，损失值为： tensor(0.0010, grad_fn=<NllLossBackward0>)\n    第 7000 个epoch，损失值为： tensor(0.0001, grad_fn=<NllLossBackward0>)\n    第 8000 个epoch，损失值为： tensor(0.0006, grad_fn=<NllLossBackward0>)\n    第 9000 个epoch，损失值为： tensor(0.0001, grad_fn=<NllLossBackward0>)\n\n\n\n```python\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nnet = net.cpu()\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n    print(y)\n    print(torch.max(pred.data, 1)[1], '\\n')\n\nprint(rights, length, rights/length)\n```\n\n    tensor([2, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0])\n    tensor([2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0]) \n    \n    tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2])\n    tensor([2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2]) \n    \n    tensor(29) 32 tensor(0.9062)\n\n\n","source":"_posts/deep-learning-test03.md","raw":"---\ntitle: 深度学习实践实验-SoftMax回归\ncategories: 算法实践\ndate: 2023-01-08 18:03:21\ntags: [深度学习, 人工智能]\ncover:\ntop_img:\n---\n# SoftMax回归\n\n### 1、聚类和分类\n\n通过sklearn库提供的聚类算法生成K类数据，以这些数据做为数据集训练神经网络，利用softmax层和交叉熵损失函数对数据进行分类。聚类参数要求K>3，数据样本不少于1000，其他参数参考课件。对聚类后的数据按9：1的原则划分训练集和测试集，利用在训练集上训练得到的模型对测试集上的数据进行验证，要求模型的准确率不低于99%。\n\n**完成程度**：使用sklearn.datasets中的make_blobs函数生成1200个样本数据，样本种类为4，样本中心分别为[-5, 5], [0, -2], [4, 8], [7, 3]，方差分别为[1.5,1.5,1.2,1]，每样样本数为300个，对样本数据进行划分，按照9训练集：1测试集的比例进行划分，构建网络，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。\n\n\n\n### 2、鸢尾花分类\n\n  Iris数据集包含150个样本，对应数据集的每行数据。每行数据包含每个样本的四个特征和样本的类别信息，iris数据集是用来给鸢尾花做分类的数据集，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征，请用神经网络训练一个分类器，分类器可以通过样本的四个特征来判断样本属于山鸢尾花、变色鸢尾还是维吉尼亚鸢尾。数据集文件iris.csv。要求模型的准确率不低于99%。\n\n**完成程度**：加载鸢尾花数据集iris.csv，查看样本数据，对数据进行标准化处理，将使用到的数据划分为训练集和测试集，搭建网络模型，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。\n\n\n\n## 聚类和分类\n\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport torch.nn.functional as F\nfrom sklearn.datasets import make_blobs\n\ndata, target = make_blobs(n_samples=1200, n_features=2, centers=[[-5, 5], [0, -2], [4, 8], [7, 3]], cluster_std=[1.5,1.5,1.2,1])\nplt.scatter(data[:, 0], data[:, 1], c=target, marker='o')\nplt.show()\n```\n\n\n​    \n![png](deep-learning-test03/output_1_0.png)\n​    \n\n\n\n```python\n# 数据准备\n# 将训练集和测试集按照9：1的比例进行划分\n# 一共1200个数据，1080个训练集，120个测试集\ndata = torch.from_numpy(data)\ndata = data.type(torch.FloatTensor)\ntarget = torch.from_numpy(target)\ntarget = target.type(torch.LongTensor)\n\ntrain_x = data[:1080]\ntrain_y = target[:1080]\n\ntest_x = data[1080:]\ntest_y = target[1080:]\n\n# 训练数据集\ntrain_dataset = TensorDataset(train_x, train_y)\n# 测试数据集\ntest_dataset = TensorDataset(test_x, test_y)\n\n# 加载器\ntrain_loader = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset,batch_size=16,shuffle=True)\n```\n\n\n```python\n# 构建网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(2, 5)\n        self.out = nn.Linear(5, 4)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n\nnet = model()\n# 交叉熵损失函数\nloss_fn = nn.CrossEntropyLoss()\n# 优化器\nopt = torch.optim.SGD(net.parameters(), lr=0.01)\n```\n\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport numpy as np\nimport pandas as pd\nimport torch.nn.functional as F\nimport torch.optim as optim\n```\n\n\n```python\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(2, 4)\n        self.out = nn.liner(4, 1)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n```\n\n\n```python\nnet = model()\n\nloss_fn = nn.MSELoss()\nopt = opt\n```\n\n\n```python\n# 训练\nfor epoch in range(1000):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if(epoch%100==0):\n        print(loss)\n```\n\n    tensor(1.2986, grad_fn=<NllLossBackward0>)\n    tensor(0.0348, grad_fn=<NllLossBackward0>)\n    tensor(0.0084, grad_fn=<NllLossBackward0>)\n    tensor(0.0275, grad_fn=<NllLossBackward0>)\n    tensor(0.0479, grad_fn=<NllLossBackward0>)\n    tensor(0.0559, grad_fn=<NllLossBackward0>)\n    tensor(0.0055, grad_fn=<NllLossBackward0>)\n    tensor(0.0015, grad_fn=<NllLossBackward0>)\n    tensor(0.0134, grad_fn=<NllLossBackward0>)\n    tensor(0.0884, grad_fn=<NllLossBackward0>)\n\n\n\n```python\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 对测试集进行预测\n# 将测试集绘制出来\nprint(test_x.shape, test_y.shape, test_x[2], target)\nplt.scatter(test_x[:, 0], test_y, c=target[1080:], marker='o')\n\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n    print(y)\n    print(torch.max(pred.data, 1)[1], '\\n')\n\nprint(rights, length, rights/length)\n```\n\n    torch.Size([120, 2]) torch.Size([120]) tensor([4.7586, 6.5412]) tensor([1, 0, 1,  ..., 0, 0, 1])\n    tensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1])\n    tensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1]) \n    \n    tensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 1, 3, 2, 2])\n    tensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 0, 3, 2, 2]) \n    \n    tensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0])\n    tensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0]) \n    \n    tensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3])\n    tensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3]) \n    \n    tensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0])\n    tensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0]) \n    \n    tensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2])\n    tensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2]) \n    \n    tensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0])\n    tensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0]) \n    \n    tensor([2, 1, 2, 1, 1, 1, 0, 3])\n    tensor([2, 1, 2, 1, 1, 1, 0, 3]) \n    \n    tensor(119) 120 tensor(0.9917)\n\n\n\n\n![png](deep-learning-test03/output_9_1.png)\n    \n\n## 鸢尾花分类\n\n* 通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征\n* 使用神经网络训练一个分类器对数据集iris.csv进行分类\n\n\n```python\n# 导入相关函数\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\n```\n\n\n```python\n# 数据预处理\ndata = pd.read_csv('iris.csv')\nfor i in range(len(data)):\n    if data.loc[i, 'Species'] == 'setosa':\n        data.loc[i, 'Species'] = 0\n    if data.loc[i, 'Species'] == 'versicolor':\n        data.loc[i, 'Species'] = 1\n    if data.loc[i, 'Species'] == 'virginica':\n        data.loc[i, 'Species'] = 2\n\ndata.head()\n```\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\ndata = data.drop('Unnamed: 0', axis=1)\ndata.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n    \n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\ndata = shuffle(data)\nprint(data.head())\ndata.index = range(len(data))\ndata.head()\n```\n\n         Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n    62            6.0          2.2           4.0          1.0       1\n    122           7.7          2.8           6.7          2.0       2\n    130           7.4          2.8           6.1          1.9       2\n    125           7.2          3.2           6.0          1.8       2\n    112           6.8          3.0           5.5          2.1       2\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.7</td>\n      <td>2.8</td>\n      <td>6.7</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>3.2</td>\n      <td>6.0</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.8</td>\n      <td>3.0</td>\n      <td>5.5</td>\n      <td>2.1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\n# 将数据进行标准化处理\ncol_titles = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\nfor i in col_titles:\n    mean, std = data[i].mean(), data[i].std()\n    data[i] = (data[i]-mean)/std\n\ndata.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n    \n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.189196</td>\n      <td>-1.966964</td>\n      <td>0.137087</td>\n      <td>-0.261511</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.242172</td>\n      <td>-0.590395</td>\n      <td>1.666574</td>\n      <td>1.050416</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.879882</td>\n      <td>-0.590395</td>\n      <td>1.326688</td>\n      <td>0.919223</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.638355</td>\n      <td>0.327318</td>\n      <td>1.270040</td>\n      <td>0.788031</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.155302</td>\n      <td>-0.131539</td>\n      <td>0.986802</td>\n      <td>1.181609</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n```python\n# 数据集处理\n# 划分训练集和测试集\ntrain_data = data[:-32]\ntrain_x = train_data.drop(['Species'], axis=1).values\ntrain_y = train_data['Species'].values.astype(int)\ntrain_x = torch.from_numpy(train_x).type(torch.FloatTensor)\ntrain_y = torch.from_numpy(train_y).type(torch.LongTensor)\n\ntest_data = data[-32:]\ntest_x = test_data.drop(['Species'], axis=1).values\ntest_y = test_data['Species'].values.astype(int)\ntest_x = torch.from_numpy(test_x).type(torch.FloatTensor)\ntest_y = torch.from_numpy(test_y).type(torch.LongTensor)\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n```\n\n\n```python\n# 构建神经网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(4, 5)\n        self.out = nn.Linear(5, 3)\n    \n    def forward(self, x):\n        x = self.hidden1(x)\n        x = F.relu(x)\n        x = self.out(x)\n        return x\n    \nnet = model()\nloss_fn = nn.CrossEntropyLoss()\nopt = torch.optim.SGD(net.parameters(), lr=0.05)\n```\n\n\n```python\n# 模型训练\nfor epoch in range(10000):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%1000==0:\n        print('第', epoch, '个epoch，损失值为：', loss)\n```\n\n    第 0 个epoch，损失值为： tensor(1.0210, grad_fn=<NllLossBackward0>)\n    第 1000 个epoch，损失值为： tensor(0.0007, grad_fn=<NllLossBackward0>)\n    第 2000 个epoch，损失值为： tensor(0.0010, grad_fn=<NllLossBackward0>)\n    第 3000 个epoch，损失值为： tensor(0.0004, grad_fn=<NllLossBackward0>)\n    第 4000 个epoch，损失值为： tensor(0.0008, grad_fn=<NllLossBackward0>)\n    第 5000 个epoch，损失值为： tensor(0.0007, grad_fn=<NllLossBackward0>)\n    第 6000 个epoch，损失值为： tensor(0.0010, grad_fn=<NllLossBackward0>)\n    第 7000 个epoch，损失值为： tensor(0.0001, grad_fn=<NllLossBackward0>)\n    第 8000 个epoch，损失值为： tensor(0.0006, grad_fn=<NllLossBackward0>)\n    第 9000 个epoch，损失值为： tensor(0.0001, grad_fn=<NllLossBackward0>)\n\n\n\n```python\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nnet = net.cpu()\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n    print(y)\n    print(torch.max(pred.data, 1)[1], '\\n')\n\nprint(rights, length, rights/length)\n```\n\n    tensor([2, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0])\n    tensor([2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0]) \n    \n    tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2])\n    tensor([2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2]) \n    \n    tensor(29) 32 tensor(0.9062)\n\n\n","slug":"deep-learning-test03","published":1,"updated":"2024-06-05T09:03:03.695Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttr001k08jv7son6iau","content":"<h1 id=\"SoftMax回归\"><a href=\"#SoftMax回归\" class=\"headerlink\" title=\"SoftMax回归\"></a>SoftMax回归</h1><h3 id=\"1、聚类和分类\"><a href=\"#1、聚类和分类\" class=\"headerlink\" title=\"1、聚类和分类\"></a>1、聚类和分类</h3><p>通过sklearn库提供的聚类算法生成K类数据，以这些数据做为数据集训练神经网络，利用softmax层和交叉熵损失函数对数据进行分类。聚类参数要求K&gt;3，数据样本不少于1000，其他参数参考课件。对聚类后的数据按9：1的原则划分训练集和测试集，利用在训练集上训练得到的模型对测试集上的数据进行验证，要求模型的准确率不低于99%。</p>\n<p><strong>完成程度</strong>：使用sklearn.datasets中的make_blobs函数生成1200个样本数据，样本种类为4，样本中心分别为[-5, 5], [0, -2], [4, 8], [7, 3]，方差分别为[1.5,1.5,1.2,1]，每样样本数为300个，对样本数据进行划分，按照9训练集：1测试集的比例进行划分，构建网络，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。</p>\n<h3 id=\"2、鸢尾花分类\"><a href=\"#2、鸢尾花分类\" class=\"headerlink\" title=\"2、鸢尾花分类\"></a>2、鸢尾花分类</h3><p>  Iris数据集包含150个样本，对应数据集的每行数据。每行数据包含每个样本的四个特征和样本的类别信息，iris数据集是用来给鸢尾花做分类的数据集，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征，请用神经网络训练一个分类器，分类器可以通过样本的四个特征来判断样本属于山鸢尾花、变色鸢尾还是维吉尼亚鸢尾。数据集文件iris.csv。要求模型的准确率不低于99%。</p>\n<p><strong>完成程度</strong>：加载鸢尾花数据集iris.csv，查看样本数据，对数据进行标准化处理，将使用到的数据划分为训练集和测试集，搭建网络模型，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。</p>\n<h2 id=\"聚类和分类\"><a href=\"#聚类和分类\" class=\"headerlink\" title=\"聚类和分类\"></a>聚类和分类</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, TensorDataset, Dataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> sklearn.datasets <span class=\"hljs-keyword\">import</span> make_blobs<br><br>data, target = make_blobs(n_samples=<span class=\"hljs-number\">1200</span>, n_features=<span class=\"hljs-number\">2</span>, centers=[[-<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>], [<span class=\"hljs-number\">0</span>, -<span class=\"hljs-number\">2</span>], [<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>], [<span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">3</span>]], cluster_std=[<span class=\"hljs-number\">1.5</span>,<span class=\"hljs-number\">1.5</span>,<span class=\"hljs-number\">1.2</span>,<span class=\"hljs-number\">1</span>])<br>plt.scatter(data[:, <span class=\"hljs-number\">0</span>], data[:, <span class=\"hljs-number\">1</span>], c=target, marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/08/deep-learning-test03/output_1_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据准备</span><br><span class=\"hljs-comment\"># 将训练集和测试集按照9：1的比例进行划分</span><br><span class=\"hljs-comment\"># 一共1200个数据，1080个训练集，120个测试集</span><br>data = torch.from_numpy(data)<br>data = data.<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>target = torch.from_numpy(target)<br>target = target.<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>train_x = data[:<span class=\"hljs-number\">1080</span>]<br>train_y = target[:<span class=\"hljs-number\">1080</span>]<br><br>test_x = data[<span class=\"hljs-number\">1080</span>:]<br>test_y = target[<span class=\"hljs-number\">1080</span>:]<br><br><span class=\"hljs-comment\"># 训练数据集</span><br>train_dataset = TensorDataset(train_x, train_y)<br><span class=\"hljs-comment\"># 测试数据集</span><br>test_dataset = TensorDataset(test_x, test_y)<br><br><span class=\"hljs-comment\"># 加载器</span><br>train_loader = DataLoader(dataset=train_dataset,batch_size=<span class=\"hljs-number\">32</span>,shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset,batch_size=<span class=\"hljs-number\">16</span>,shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">5</span>)<br>        self.out = nn.Linear(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">4</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br>net = model()<br><span class=\"hljs-comment\"># 交叉熵损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br><span class=\"hljs-comment\"># 优化器</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.01</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, TensorDataset, Dataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>)<br>        self.out = nn.liner(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = model()<br><br>loss_fn = nn.MSELoss()<br>opt = opt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span>(epoch%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>):<br>        <span class=\"hljs-built_in\">print</span>(loss)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(1.2986, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0348, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0084, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0275, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0479, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0559, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0055, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0015, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0134, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0884, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测</span><br><span class=\"hljs-comment\"># 将测试集绘制出来</span><br><span class=\"hljs-built_in\">print</span>(test_x.shape, test_y.shape, test_x[<span class=\"hljs-number\">2</span>], target)<br>plt.scatter(test_x[:, <span class=\"hljs-number\">0</span>], test_y, c=target[<span class=\"hljs-number\">1080</span>:], marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-built_in\">print</span>(y)<br>    <span class=\"hljs-built_in\">print</span>(torch.<span class=\"hljs-built_in\">max</span>(pred.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>torch.Size([120, 2]) torch.Size([120]) tensor([4.7586, 6.5412]) tensor([1, 0, 1,  ..., 0, 0, 1])\ntensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1])\ntensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1]) \n\ntensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 1, 3, 2, 2])\ntensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 0, 3, 2, 2]) \n\ntensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0])\ntensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0]) \n\ntensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3])\ntensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3]) \n\ntensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0])\ntensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0]) \n\ntensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2])\ntensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2]) \n\ntensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0])\ntensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0]) \n\ntensor([2, 1, 2, 1, 1, 1, 0, 3])\ntensor([2, 1, 2, 1, 1, 1, 0, 3]) \n\ntensor(119) 120 tensor(0.9917)\n</code></pre><img src=\"/2023/01/08/deep-learning-test03/output_9_1.png\" class=\"\" title=\"png\">\n<h2 id=\"鸢尾花分类\"><a href=\"#鸢尾花分类\" class=\"headerlink\" title=\"鸢尾花分类\"></a>鸢尾花分类</h2><ul>\n<li>通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征</li>\n<li>使用神经网络训练一个分类器对数据集iris.csv进行分类</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关函数</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">from</span> sklearn.utils <span class=\"hljs-keyword\">import</span> shuffle<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据预处理</span><br>data = pd.read_csv(<span class=\"hljs-string\">&#x27;iris.csv&#x27;</span>)<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(data)):<br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;setosa&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;versicolor&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">1</span><br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;virginica&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">2</span><br><br>data.head()<br></code></pre></td></tr></table></figure>\n<p>&lt;/style&gt;</p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = data.drop(<span class=\"hljs-string\">&#x27;Unnamed: 0&#x27;</span>, axis=<span class=\"hljs-number\">1</span>)<br>data.head()<br></code></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = shuffle(data)<br><span class=\"hljs-built_in\">print</span>(data.head())<br>data.index = <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(data))<br>data.head()<br></code></pre></td></tr></table></figure>\n<pre><code>     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n62            6.0          2.2           4.0          1.0       1\n122           7.7          2.8           6.7          2.0       2\n130           7.4          2.8           6.1          1.9       2\n125           7.2          3.2           6.0          1.8       2\n112           6.8          3.0           5.5          2.1       2\n</code></pre><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.7</td>\n      <td>2.8</td>\n      <td>6.7</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>3.2</td>\n      <td>6.0</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.8</td>\n      <td>3.0</td>\n      <td>5.5</td>\n      <td>2.1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将数据进行标准化处理</span><br>col_titles = [<span class=\"hljs-string\">&#x27;Sepal.Length&#x27;</span>, <span class=\"hljs-string\">&#x27;Sepal.Width&#x27;</span>, <span class=\"hljs-string\">&#x27;Petal.Length&#x27;</span>, <span class=\"hljs-string\">&#x27;Petal.Width&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    mean, std = data[i].mean(), data[i].std()<br>    data[i] = (data[i]-mean)/std<br><br>data.head()<br></code></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.189196</td>\n      <td>-1.966964</td>\n      <td>0.137087</td>\n      <td>-0.261511</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.242172</td>\n      <td>-0.590395</td>\n      <td>1.666574</td>\n      <td>1.050416</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.879882</td>\n      <td>-0.590395</td>\n      <td>1.326688</td>\n      <td>0.919223</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.638355</td>\n      <td>0.327318</td>\n      <td>1.270040</td>\n      <td>0.788031</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.155302</td>\n      <td>-0.131539</td>\n      <td>0.986802</td>\n      <td>1.181609</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据集处理</span><br><span class=\"hljs-comment\"># 划分训练集和测试集</span><br>train_data = data[:-<span class=\"hljs-number\">32</span>]<br>train_x = train_data.drop([<span class=\"hljs-string\">&#x27;Species&#x27;</span>], axis=<span class=\"hljs-number\">1</span>).values<br>train_y = train_data[<span class=\"hljs-string\">&#x27;Species&#x27;</span>].values.astype(<span class=\"hljs-built_in\">int</span>)<br>train_x = torch.from_numpy(train_x).<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>train_y = torch.from_numpy(train_y).<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>test_data = data[-<span class=\"hljs-number\">32</span>:]<br>test_x = test_data.drop([<span class=\"hljs-string\">&#x27;Species&#x27;</span>], axis=<span class=\"hljs-number\">1</span>).values<br>test_y = test_data[<span class=\"hljs-string\">&#x27;Species&#x27;</span>].values.astype(<span class=\"hljs-built_in\">int</span>)<br>test_x = torch.from_numpy(test_x).<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>test_y = torch.from_numpy(test_y).<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(dataset=train_dataset, batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建神经网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>)<br>        self.out = nn.Linear(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>    <br>net = model()<br>loss_fn = nn.CrossEntropyLoss()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.05</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">10000</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">1000</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>, epoch, <span class=\"hljs-string\">&#x27;个epoch，损失值为：&#x27;</span>, loss)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 个epoch，损失值为： tensor(1.0210, grad_fn=&lt;NllLossBackward0&gt;)\n第 1000 个epoch，损失值为： tensor(0.0007, grad_fn=&lt;NllLossBackward0&gt;)\n第 2000 个epoch，损失值为： tensor(0.0010, grad_fn=&lt;NllLossBackward0&gt;)\n第 3000 个epoch，损失值为： tensor(0.0004, grad_fn=&lt;NllLossBackward0&gt;)\n第 4000 个epoch，损失值为： tensor(0.0008, grad_fn=&lt;NllLossBackward0&gt;)\n第 5000 个epoch，损失值为： tensor(0.0007, grad_fn=&lt;NllLossBackward0&gt;)\n第 6000 个epoch，损失值为： tensor(0.0010, grad_fn=&lt;NllLossBackward0&gt;)\n第 7000 个epoch，损失值为： tensor(0.0001, grad_fn=&lt;NllLossBackward0&gt;)\n第 8000 个epoch，损失值为： tensor(0.0006, grad_fn=&lt;NllLossBackward0&gt;)\n第 9000 个epoch，损失值为： tensor(0.0001, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>net = net.cpu()<br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-built_in\">print</span>(y)<br>    <span class=\"hljs-built_in\">print</span>(torch.<span class=\"hljs-built_in\">max</span>(pred.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([2, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0])\ntensor([2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0]) \n\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2])\ntensor([2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2]) \n\ntensor(29) 32 tensor(0.9062)\n</code></pre>","cover_type":"img","excerpt":"","more":"<h1 id=\"SoftMax回归\"><a href=\"#SoftMax回归\" class=\"headerlink\" title=\"SoftMax回归\"></a>SoftMax回归</h1><h3 id=\"1、聚类和分类\"><a href=\"#1、聚类和分类\" class=\"headerlink\" title=\"1、聚类和分类\"></a>1、聚类和分类</h3><p>通过sklearn库提供的聚类算法生成K类数据，以这些数据做为数据集训练神经网络，利用softmax层和交叉熵损失函数对数据进行分类。聚类参数要求K&gt;3，数据样本不少于1000，其他参数参考课件。对聚类后的数据按9：1的原则划分训练集和测试集，利用在训练集上训练得到的模型对测试集上的数据进行验证，要求模型的准确率不低于99%。</p>\n<p><strong>完成程度</strong>：使用sklearn.datasets中的make_blobs函数生成1200个样本数据，样本种类为4，样本中心分别为[-5, 5], [0, -2], [4, 8], [7, 3]，方差分别为[1.5,1.5,1.2,1]，每样样本数为300个，对样本数据进行划分，按照9训练集：1测试集的比例进行划分，构建网络，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。</p>\n<h3 id=\"2、鸢尾花分类\"><a href=\"#2、鸢尾花分类\" class=\"headerlink\" title=\"2、鸢尾花分类\"></a>2、鸢尾花分类</h3><p>  Iris数据集包含150个样本，对应数据集的每行数据。每行数据包含每个样本的四个特征和样本的类别信息，iris数据集是用来给鸢尾花做分类的数据集，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征，请用神经网络训练一个分类器，分类器可以通过样本的四个特征来判断样本属于山鸢尾花、变色鸢尾还是维吉尼亚鸢尾。数据集文件iris.csv。要求模型的准确率不低于99%。</p>\n<p><strong>完成程度</strong>：加载鸢尾花数据集iris.csv，查看样本数据，对数据进行标准化处理，将使用到的数据划分为训练集和测试集，搭建网络模型，使用交叉熵损失函数，使用训练集对模型进行训练，在测试集上完成测试验证。</p>\n<h2 id=\"聚类和分类\"><a href=\"#聚类和分类\" class=\"headerlink\" title=\"聚类和分类\"></a>聚类和分类</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, TensorDataset, Dataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> sklearn.datasets <span class=\"hljs-keyword\">import</span> make_blobs<br><br>data, target = make_blobs(n_samples=<span class=\"hljs-number\">1200</span>, n_features=<span class=\"hljs-number\">2</span>, centers=[[-<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">5</span>], [<span class=\"hljs-number\">0</span>, -<span class=\"hljs-number\">2</span>], [<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>], [<span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">3</span>]], cluster_std=[<span class=\"hljs-number\">1.5</span>,<span class=\"hljs-number\">1.5</span>,<span class=\"hljs-number\">1.2</span>,<span class=\"hljs-number\">1</span>])<br>plt.scatter(data[:, <span class=\"hljs-number\">0</span>], data[:, <span class=\"hljs-number\">1</span>], c=target, marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<p>​<br><img src=\"/2023/01/08/deep-learning-test03/output_1_0.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据准备</span><br><span class=\"hljs-comment\"># 将训练集和测试集按照9：1的比例进行划分</span><br><span class=\"hljs-comment\"># 一共1200个数据，1080个训练集，120个测试集</span><br>data = torch.from_numpy(data)<br>data = data.<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>target = torch.from_numpy(target)<br>target = target.<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>train_x = data[:<span class=\"hljs-number\">1080</span>]<br>train_y = target[:<span class=\"hljs-number\">1080</span>]<br><br>test_x = data[<span class=\"hljs-number\">1080</span>:]<br>test_y = target[<span class=\"hljs-number\">1080</span>:]<br><br><span class=\"hljs-comment\"># 训练数据集</span><br>train_dataset = TensorDataset(train_x, train_y)<br><span class=\"hljs-comment\"># 测试数据集</span><br>test_dataset = TensorDataset(test_x, test_y)<br><br><span class=\"hljs-comment\"># 加载器</span><br>train_loader = DataLoader(dataset=train_dataset,batch_size=<span class=\"hljs-number\">32</span>,shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset,batch_size=<span class=\"hljs-number\">16</span>,shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">5</span>)<br>        self.out = nn.Linear(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">4</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br>net = model()<br><span class=\"hljs-comment\"># 交叉熵损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br><span class=\"hljs-comment\"># 优化器</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.01</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, TensorDataset, Dataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>)<br>        self.out = nn.liner(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = model()<br><br>loss_fn = nn.MSELoss()<br>opt = opt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1000</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span>(epoch%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>):<br>        <span class=\"hljs-built_in\">print</span>(loss)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(1.2986, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0348, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0084, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0275, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0479, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0559, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0055, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0015, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0134, grad_fn=&lt;NllLossBackward0&gt;)\ntensor(0.0884, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 对测试集进行预测</span><br><span class=\"hljs-comment\"># 将测试集绘制出来</span><br><span class=\"hljs-built_in\">print</span>(test_x.shape, test_y.shape, test_x[<span class=\"hljs-number\">2</span>], target)<br>plt.scatter(test_x[:, <span class=\"hljs-number\">0</span>], test_y, c=target[<span class=\"hljs-number\">1080</span>:], marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-built_in\">print</span>(y)<br>    <span class=\"hljs-built_in\">print</span>(torch.<span class=\"hljs-built_in\">max</span>(pred.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>torch.Size([120, 2]) torch.Size([120]) tensor([4.7586, 6.5412]) tensor([1, 0, 1,  ..., 0, 0, 1])\ntensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1])\ntensor([0, 0, 2, 1, 1, 0, 1, 0, 3, 0, 1, 3, 3, 1, 1, 1]) \n\ntensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 1, 3, 2, 2])\ntensor([0, 1, 2, 1, 2, 0, 0, 1, 2, 2, 3, 2, 0, 3, 2, 2]) \n\ntensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0])\ntensor([0, 0, 3, 0, 3, 0, 2, 0, 2, 1, 3, 0, 3, 2, 0, 0]) \n\ntensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3])\ntensor([3, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 2, 3, 3]) \n\ntensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0])\ntensor([0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 1, 2, 2, 2, 0, 0]) \n\ntensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2])\ntensor([2, 1, 1, 0, 3, 2, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2]) \n\ntensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0])\ntensor([0, 1, 3, 2, 2, 2, 3, 1, 1, 0, 3, 2, 0, 3, 1, 0]) \n\ntensor([2, 1, 2, 1, 1, 1, 0, 3])\ntensor([2, 1, 2, 1, 1, 1, 0, 3]) \n\ntensor(119) 120 tensor(0.9917)\n</code></pre><img src=\"/2023/01/08/deep-learning-test03/output_9_1.png\" class=\"\" title=\"png\">\n<h2 id=\"鸢尾花分类\"><a href=\"#鸢尾花分类\" class=\"headerlink\" title=\"鸢尾花分类\"></a>鸢尾花分类</h2><ul>\n<li>通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个特征</li>\n<li>使用神经网络训练一个分类器对数据集iris.csv进行分类</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 导入相关函数</span><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">from</span> sklearn.utils <span class=\"hljs-keyword\">import</span> shuffle<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据预处理</span><br>data = pd.read_csv(<span class=\"hljs-string\">&#x27;iris.csv&#x27;</span>)<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(data)):<br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;setosa&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;versicolor&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">1</span><br>    <span class=\"hljs-keyword\">if</span> data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] == <span class=\"hljs-string\">&#x27;virginica&#x27;</span>:<br>        data.loc[i, <span class=\"hljs-string\">&#x27;Species&#x27;</span>] = <span class=\"hljs-number\">2</span><br><br>data.head()<br></code></pre></td></tr></table></figure>\n<p>&lt;/style&gt;</p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = data.drop(<span class=\"hljs-string\">&#x27;Unnamed: 0&#x27;</span>, axis=<span class=\"hljs-number\">1</span>)<br>data.head()<br></code></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = shuffle(data)<br><span class=\"hljs-built_in\">print</span>(data.head())<br>data.index = <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(data))<br>data.head()<br></code></pre></td></tr></table></figure>\n<pre><code>     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n62            6.0          2.2           4.0          1.0       1\n122           7.7          2.8           6.7          2.0       2\n130           7.4          2.8           6.1          1.9       2\n125           7.2          3.2           6.0          1.8       2\n112           6.8          3.0           5.5          2.1       2\n</code></pre><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.7</td>\n      <td>2.8</td>\n      <td>6.7</td>\n      <td>2.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>3.2</td>\n      <td>6.0</td>\n      <td>1.8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.8</td>\n      <td>3.0</td>\n      <td>5.5</td>\n      <td>2.1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>&lt;/div&gt;</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 将数据进行标准化处理</span><br>col_titles = [<span class=\"hljs-string\">&#x27;Sepal.Length&#x27;</span>, <span class=\"hljs-string\">&#x27;Sepal.Width&#x27;</span>, <span class=\"hljs-string\">&#x27;Petal.Length&#x27;</span>, <span class=\"hljs-string\">&#x27;Petal.Width&#x27;</span>]<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> col_titles:<br>    mean, std = data[i].mean(), data[i].std()<br>    data[i] = (data[i]-mean)/std<br><br>data.head()<br></code></pre></td></tr></table></figure>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.189196</td>\n      <td>-1.966964</td>\n      <td>0.137087</td>\n      <td>-0.261511</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.242172</td>\n      <td>-0.590395</td>\n      <td>1.666574</td>\n      <td>1.050416</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.879882</td>\n      <td>-0.590395</td>\n      <td>1.326688</td>\n      <td>0.919223</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.638355</td>\n      <td>0.327318</td>\n      <td>1.270040</td>\n      <td>0.788031</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.155302</td>\n      <td>-0.131539</td>\n      <td>0.986802</td>\n      <td>1.181609</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据集处理</span><br><span class=\"hljs-comment\"># 划分训练集和测试集</span><br>train_data = data[:-<span class=\"hljs-number\">32</span>]<br>train_x = train_data.drop([<span class=\"hljs-string\">&#x27;Species&#x27;</span>], axis=<span class=\"hljs-number\">1</span>).values<br>train_y = train_data[<span class=\"hljs-string\">&#x27;Species&#x27;</span>].values.astype(<span class=\"hljs-built_in\">int</span>)<br>train_x = torch.from_numpy(train_x).<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>train_y = torch.from_numpy(train_y).<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>test_data = data[-<span class=\"hljs-number\">32</span>:]<br>test_x = test_data.drop([<span class=\"hljs-string\">&#x27;Species&#x27;</span>], axis=<span class=\"hljs-number\">1</span>).values<br>test_y = test_data[<span class=\"hljs-string\">&#x27;Species&#x27;</span>].values.astype(<span class=\"hljs-built_in\">int</span>)<br>test_x = torch.from_numpy(test_x).<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>test_y = torch.from_numpy(test_y).<span class=\"hljs-built_in\">type</span>(torch.LongTensor)<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(dataset=train_dataset, batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建神经网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.hidden1 = nn.Linear(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>)<br>        self.out = nn.Linear(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>    <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        x = self.hidden1(x)<br>        x = F.relu(x)<br>        x = self.out(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>    <br>net = model()<br>loss_fn = nn.CrossEntropyLoss()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.05</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 模型训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">10000</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">1000</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>, epoch, <span class=\"hljs-string\">&#x27;个epoch，损失值为：&#x27;</span>, loss)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 个epoch，损失值为： tensor(1.0210, grad_fn=&lt;NllLossBackward0&gt;)\n第 1000 个epoch，损失值为： tensor(0.0007, grad_fn=&lt;NllLossBackward0&gt;)\n第 2000 个epoch，损失值为： tensor(0.0010, grad_fn=&lt;NllLossBackward0&gt;)\n第 3000 个epoch，损失值为： tensor(0.0004, grad_fn=&lt;NllLossBackward0&gt;)\n第 4000 个epoch，损失值为： tensor(0.0008, grad_fn=&lt;NllLossBackward0&gt;)\n第 5000 个epoch，损失值为： tensor(0.0007, grad_fn=&lt;NllLossBackward0&gt;)\n第 6000 个epoch，损失值为： tensor(0.0010, grad_fn=&lt;NllLossBackward0&gt;)\n第 7000 个epoch，损失值为： tensor(0.0001, grad_fn=&lt;NllLossBackward0&gt;)\n第 8000 个epoch，损失值为： tensor(0.0006, grad_fn=&lt;NllLossBackward0&gt;)\n第 9000 个epoch，损失值为： tensor(0.0001, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>net = net.cpu()<br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-built_in\">print</span>(y)<br>    <span class=\"hljs-built_in\">print</span>(torch.<span class=\"hljs-built_in\">max</span>(pred.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([2, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0])\ntensor([2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 0]) \n\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2])\ntensor([2, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 2]) \n\ntensor(29) 32 tensor(0.9062)\n</code></pre>"},{"title":"深度学习实践实验-卷积神经网络","date":"2023-01-15T10:10:11.000Z","cover":"/img/default_cover06.jpg","top_img":null,"_content":"# 卷积神经网络\n\n### 1、手写数字识别\n\n  通过MNIST数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸不小于5*5，要求训后的得到的网络在测试集准确率不低于96%（要求在网络中使用dropout）\n\n **完成程度：**获取MNIST数据集并保存，获取图片的训练集和测试集，构建卷积神经网络模型，包含2个卷积层，2个池化层，2个全连接层，在最后一个全连接前加入一个dropout层。定义模型和损失函数，并将模型和损失函数送入到GPU当中去，使用训练集训练模型，用测试集进行测试验证，最终准确率有99.35%。\n\n### 2、CIFAR-10分类网络\n\n  通过CIFAR-10数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸统一采用3*3，要求训后的得到的网络在测试集上的准确率不低于70%（要求在网络中使用BatchNorm）\n\n**完成程度：**下载CIFAR-10实验数据集，并将其划分成训练集和测试集，查看图片的尺寸，图片尺寸为32*32，一共有3个通道，定义卷积神经网络，一共包含5个卷积层，5个BN层，3个池化层，2个全连接层，最后一个全连接层前加一个dropout层。在GPU上利用训练集训练网络模型，一共进行20测迭代，最终在测试集上进行测试验证，模型训练的准确性为78.84%。\n\n\n\n## 手写数字识别\n\n\n```python\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torchvision import transforms\nfrom torchvision import datasets\n```\n\n\n```python\n# 获取训练数据\ntrain_data = datasets.MNIST(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ]),\n                      download=True\n                     )\n```\n\n\n```python\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\ntrain_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n\ntest_data = datasets.MNIST(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ])\n                     )\n\n\ntest_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n```\n\n\n```python\n# 查看图片示例\nprint(train_data[50][0].numpy().shape)\nfrom matplotlib import pyplot as plt\nimg = train_data[50][0].numpy()\nlabel = train_data[50][1]\n\nplt.imshow(img[0, :])\nplt.show()\n```\n\n    (1, 28, 28)\n\n\n\n\n![png](deep-learning-test04/output_5_1.png)\n    \n\n\n\n```python\n# 网络构建\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(4, 8, 5, padding=2)\n        self.fc1 = nn.Linear((28*28)//(4*4)*8, 512)\n        self.fc2 = nn.Linear(512, 10)\n        \n    def forward(self, x):\n        # 1*28*28, 4*28*28\n        x = self.conv1(x)\n        x = F.relu(x)\n        # 4*14*14\n        x = self.pool(x)\n        \n        # 8*14*14\n        x = self.conv2(x)\n        x = F.relu(x)\n        # 8*7*7\n        x = self.pool(x)\n        \n        x = x.view(-1, (28*28)//(4*4)*8)\n        x = self.fc1(x)\n        x = F.relu(x)\n        \n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x\n        \n    def feature_maps(self, x):\n        map1 = self.conv1(x)\n        map1 = F.relu(map1)\n        map2 = self.pool(map1)\n        map2 = self.conv2(map2)\n        map2 = F.relu(map2)\n        return (map1, map2)\n    \n```\n\n\n```python\nnet = model()\nnet = net.cuda()\nloss_fn = nn.CrossEntropyLoss()\nloss_fn = loss_fn.cuda()\nopt = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n\n```python\n# 训练\nfor epoch in range(20):\n    for i,data in enumerate(train_loader):\n        x, y = data\n        net.train()\n        pred = net(x.cuda())\n        loss = loss_fn(pred, y.cuda())\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n    print(epoch, \"损失值:\",loss)\n```\n\n    0 损失值: tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n    1 损失值: tensor(0.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n    2 损失值: tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n    3 损失值: tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n    4 损失值: tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n    5 损失值: tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n    6 损失值: tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n    7 损失值: tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n    8 损失值: tensor(0.1654, device='cuda:0', grad_fn=<NllLossBackward0>)\n    9 损失值: tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n    10 损失值: tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n    11 损失值: tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n    12 损失值: tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n    13 损失值: tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n    14 损失值: tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n    15 损失值: tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n    16 损失值: tensor(0.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n    17 损失值: tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n    18 损失值: tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n    19 损失值: tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n\n\n\n```python\n# 测试验证\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    net.eval()\n    pred = net(x.cuda())\n    rights = rights + rightness(pred, y.cuda())[0]\n    length = length + rightness(pred, y.cuda())[1]\n\nprint(rights, length, rights/length)\n```\n\n    tensor(59609, device='cuda:0') 60000 tensor(0.9935, device='cuda:0')\n\n\n\n## CIFAR-10分类网络\n\n```python\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\n```\n\n\n```python\n# 获取训练数据\ntrain_data = datasets.CIFAR10(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ]),\n                      download=True\n                     )\n```\n\n    Files already downloaded and verified\n\n\n\n```python\n# 获取训练数据\ntest_data = datasets.CIFAR10(root='./',\n                      train=False,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ])\n                     )\n```\n\n\n```python\n# 数据加载器\ntrain_dataset = DataLoader(train_data, batch_size=4, shuffle=True)\ntest_dataset = DataLoader(test_data, batch_size=4, shuffle=True)\n```\n\n\n```python\n# 随机查看一张图片\nprint(np.random.randint(3000))\nprint(train_data[0][0].shape)\nfrom matplotlib import pyplot as plt\nimg = train_data[50][0].numpy()\n\nplt.figure(figsize=(12, 12))\n# 在plt.imshow()输入彩色图像时，需要对通道进行转化\n# pytorch中时(3, height, width)，imshow中是（height, width, 3）\nplt.imshow(img.transpose(1, 2, 0))\n```\n\n    638\n    torch.Size([3, 32, 32])\n\n\n    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n    <matplotlib.image.AxesImage at 0x27e882a9c70>\n\n\n\n\n​    \n![png](deep-learning-test04/output_4_3.png)\n​    \n\n\n\n```python\n# 定义网络\n# 要求至少包含5个卷积层和池化层\n# 卷积核的尺寸统一为3*3\n# 要求网络中使用BatchNorm\nclass model(nn.Module):\n    def __init__(self):\n        # 图片尺寸为[3, 32, 32]\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 4, 3, padding=1)\n        self.conv2 = nn.Conv2d(4, 8, 3, padding=1)\n        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n        self.conv4 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.pool2 = nn.AvgPool2d(2, 2)\n        self.dropout = nn.Dropout2d(0.5)\n        self.batch_norm1 = nn.BatchNorm2d(4)\n        self.batch_norm2 = nn.BatchNorm2d(8)\n        self.batch_norm3 = nn.BatchNorm2d(16)\n        self.batch_norm4 = nn.BatchNorm2d(32)\n        self.batch_norm5 = nn.BatchNorm2d(64)\n        self.fc1 = nn.Linear(64*4*4, 512)\n        self.fc2 = nn.Linear(512, 10)\n        \n    def forward(self, x):\n        # 第一个卷积层，输入3*32*32，输出4*32*32\n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = F.relu(x)\n        \n        # 第二个卷积层，输入4*32*32，输出8*32*32\n        x = self.conv2(x)\n        x = self.batch_norm2(x)\n        x = F.relu(x)\n        \n        # 第三个卷积层，输入8*32*32，输出16*32*32\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.batch_norm3(x)\n        # 输入16*32*32，输出16*16*16\n        x = self.pool1(x)\n        \n        # 第四个卷积层，输入16*16*16，输出32*16*16\n        x = self.conv4(x)\n        x = self.batch_norm4(x)\n        x = F.relu(x)\n        # 输入32*16*16，输出32*8*8\n        x = self.pool2(x)\n        \n        # 第五个卷积层，输入32*8*8，输出64*8*8\n        x = self.conv5(x)\n        x = self.batch_norm5(x)\n        x = F.relu(x)\n        # 输入64*8*8，输出64*4*4\n        x = self.pool1(x)\n        \n        # 全连接层\n        x = x.view(-1, 64*4*4)\n        x = self.fc1(x)\n        x = F.relu(x)\n        \n        # 随机失活20%参数\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# 使用GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \nnet = model()\nprint(net)\nnet.to(device)\n# 使用交叉熵损失函数\nloss_fn = nn.CrossEntropyLoss()\nloss_fn.to(device)\n# 最优化方法\nopt = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n    model(\n      (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (dropout): Dropout2d(p=0.5, inplace=False)\n      (batch_norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n      (fc2): Linear(in_features=512, out_features=10, bias=True)\n    )\n\n\n\n```python\nfrom torchinfo import summary\nsummary(net, input_size=(64, 3, 32, 32))\n```\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n      warnings.warn(warn_msg)\n\n\n\n\n\n    ==========================================================================================\n    Layer (type:depth-idx)                   Output Shape              Param #\n    ==========================================================================================\n    model                                    [64, 10]                  --\n    ├─Conv2d: 1-1                            [64, 4, 32, 32]           112\n    ├─BatchNorm2d: 1-2                       [64, 4, 32, 32]           8\n    ├─Conv2d: 1-3                            [64, 8, 32, 32]           296\n    ├─BatchNorm2d: 1-4                       [64, 8, 32, 32]           16\n    ├─Conv2d: 1-5                            [64, 16, 32, 32]          1,168\n    ├─BatchNorm2d: 1-6                       [64, 16, 32, 32]          32\n    ├─MaxPool2d: 1-7                         [64, 16, 16, 16]          --\n    ├─Conv2d: 1-8                            [64, 32, 16, 16]          4,640\n    ├─BatchNorm2d: 1-9                       [64, 32, 16, 16]          64\n    ├─AvgPool2d: 1-10                        [64, 32, 8, 8]            --\n    ├─Conv2d: 1-11                           [64, 64, 8, 8]            18,496\n    ├─BatchNorm2d: 1-12                      [64, 64, 8, 8]            128\n    ├─MaxPool2d: 1-13                        [64, 64, 4, 4]            --\n    ├─Linear: 1-14                           [64, 512]                 524,800\n    ├─Dropout2d: 1-15                        [64, 512]                 --\n    ├─Linear: 1-16                           [64, 10]                  5,130\n    ==========================================================================================\n    Total params: 554,890\n    Trainable params: 554,890\n    Non-trainable params: 0\n    Total mult-adds (M): 289.00\n    ==========================================================================================\n    Input size (MB): 0.79\n    Forward/backward pass size (MB): 42.21\n    Params size (MB): 2.22\n    Estimated Total Size (MB): 45.22\n    ==========================================================================================\n\n\n\n\n```python\n# 开始训练\nfor epoch in range(20):\n    for i, data in enumerate(train_dataset):\n        x, y = data\n        x = x.to(device)\n        y = y.to(device)\n        net.train()\n        pred = net(x)\n        loss = loss_fn(pred, y)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n    \n    print('第', epoch, '个epoch，loss为：', loss)\n```\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n      warnings.warn(warn_msg)\n\n\n    第 0 个epoch，loss为： tensor(1.4621, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 1 个epoch，loss为： tensor(1.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 2 个epoch，loss为： tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 3 个epoch，loss为： tensor(1.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 4 个epoch，loss为： tensor(1.1270, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 5 个epoch，loss为： tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 6 个epoch，loss为： tensor(2.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 7 个epoch，loss为： tensor(0.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 8 个epoch，loss为： tensor(0.3833, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 9 个epoch，loss为： tensor(1.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 10 个epoch，loss为： tensor(0.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 11 个epoch，loss为： tensor(0.8256, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 12 个epoch，loss为： tensor(0.8673, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 13 个epoch，loss为： tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 14 个epoch，loss为： tensor(0.8387, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 15 个epoch，loss为： tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 16 个epoch，loss为： tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 17 个epoch，loss为： tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 18 个epoch，loss为： tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 19 个epoch，loss为： tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n\n\n\n```python\n# 测试验证\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nrights = 0\nlength = 0\nfor i, data in enumerate(test_dataset):\n    x, y = data\n    x = x.to(device)\n    y = y.to(device)\n    net.eval()\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n\nprint(rights, length, rights/length)\n```\n\n    tensor(7884, device='cuda:0') 10000 tensor(0.7884, device='cuda:0')\n\n\n","source":"_posts/deep-learning-test04.md","raw":"---\ntitle: 深度学习实践实验-卷积神经网络\ncategories: 算法实践\ndate: 2023-01-15 18:10:11\ntags: [深度学习, 人工智能, 神经网络]\ncover:\ntop_img:\n---\n# 卷积神经网络\n\n### 1、手写数字识别\n\n  通过MNIST数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸不小于5*5，要求训后的得到的网络在测试集准确率不低于96%（要求在网络中使用dropout）\n\n **完成程度：**获取MNIST数据集并保存，获取图片的训练集和测试集，构建卷积神经网络模型，包含2个卷积层，2个池化层，2个全连接层，在最后一个全连接前加入一个dropout层。定义模型和损失函数，并将模型和损失函数送入到GPU当中去，使用训练集训练模型，用测试集进行测试验证，最终准确率有99.35%。\n\n### 2、CIFAR-10分类网络\n\n  通过CIFAR-10数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸统一采用3*3，要求训后的得到的网络在测试集上的准确率不低于70%（要求在网络中使用BatchNorm）\n\n**完成程度：**下载CIFAR-10实验数据集，并将其划分成训练集和测试集，查看图片的尺寸，图片尺寸为32*32，一共有3个通道，定义卷积神经网络，一共包含5个卷积层，5个BN层，3个池化层，2个全连接层，最后一个全连接层前加一个dropout层。在GPU上利用训练集训练网络模型，一共进行20测迭代，最终在测试集上进行测试验证，模型训练的准确性为78.84%。\n\n\n\n## 手写数字识别\n\n\n```python\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torchvision import transforms\nfrom torchvision import datasets\n```\n\n\n```python\n# 获取训练数据\ntrain_data = datasets.MNIST(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ]),\n                      download=True\n                     )\n```\n\n\n```python\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\ntrain_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n\ntest_data = datasets.MNIST(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ])\n                     )\n\n\ntest_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n```\n\n\n```python\n# 查看图片示例\nprint(train_data[50][0].numpy().shape)\nfrom matplotlib import pyplot as plt\nimg = train_data[50][0].numpy()\nlabel = train_data[50][1]\n\nplt.imshow(img[0, :])\nplt.show()\n```\n\n    (1, 28, 28)\n\n\n\n\n![png](deep-learning-test04/output_5_1.png)\n    \n\n\n\n```python\n# 网络构建\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(4, 8, 5, padding=2)\n        self.fc1 = nn.Linear((28*28)//(4*4)*8, 512)\n        self.fc2 = nn.Linear(512, 10)\n        \n    def forward(self, x):\n        # 1*28*28, 4*28*28\n        x = self.conv1(x)\n        x = F.relu(x)\n        # 4*14*14\n        x = self.pool(x)\n        \n        # 8*14*14\n        x = self.conv2(x)\n        x = F.relu(x)\n        # 8*7*7\n        x = self.pool(x)\n        \n        x = x.view(-1, (28*28)//(4*4)*8)\n        x = self.fc1(x)\n        x = F.relu(x)\n        \n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x\n        \n    def feature_maps(self, x):\n        map1 = self.conv1(x)\n        map1 = F.relu(map1)\n        map2 = self.pool(map1)\n        map2 = self.conv2(map2)\n        map2 = F.relu(map2)\n        return (map1, map2)\n    \n```\n\n\n```python\nnet = model()\nnet = net.cuda()\nloss_fn = nn.CrossEntropyLoss()\nloss_fn = loss_fn.cuda()\nopt = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n\n```python\n# 训练\nfor epoch in range(20):\n    for i,data in enumerate(train_loader):\n        x, y = data\n        net.train()\n        pred = net(x.cuda())\n        loss = loss_fn(pred, y.cuda())\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n    print(epoch, \"损失值:\",loss)\n```\n\n    0 损失值: tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n    1 损失值: tensor(0.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n    2 损失值: tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n    3 损失值: tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n    4 损失值: tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n    5 损失值: tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n    6 损失值: tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n    7 损失值: tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n    8 损失值: tensor(0.1654, device='cuda:0', grad_fn=<NllLossBackward0>)\n    9 损失值: tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n    10 损失值: tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n    11 损失值: tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n    12 损失值: tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n    13 损失值: tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n    14 损失值: tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n    15 损失值: tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n    16 损失值: tensor(0.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n    17 损失值: tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n    18 损失值: tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n    19 损失值: tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n\n\n\n```python\n# 测试验证\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n    net.eval()\n    pred = net(x.cuda())\n    rights = rights + rightness(pred, y.cuda())[0]\n    length = length + rightness(pred, y.cuda())[1]\n\nprint(rights, length, rights/length)\n```\n\n    tensor(59609, device='cuda:0') 60000 tensor(0.9935, device='cuda:0')\n\n\n\n## CIFAR-10分类网络\n\n```python\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\n```\n\n\n```python\n# 获取训练数据\ntrain_data = datasets.CIFAR10(root='./',\n                      train=True,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ]),\n                      download=True\n                     )\n```\n\n    Files already downloaded and verified\n\n\n\n```python\n# 获取训练数据\ntest_data = datasets.CIFAR10(root='./',\n                      train=False,\n                      transform=transforms.Compose([\n                         transforms.ToTensor(),\n                         transforms.Normalize([0.1307, ], [0.3081, ])\n                      ])\n                     )\n```\n\n\n```python\n# 数据加载器\ntrain_dataset = DataLoader(train_data, batch_size=4, shuffle=True)\ntest_dataset = DataLoader(test_data, batch_size=4, shuffle=True)\n```\n\n\n```python\n# 随机查看一张图片\nprint(np.random.randint(3000))\nprint(train_data[0][0].shape)\nfrom matplotlib import pyplot as plt\nimg = train_data[50][0].numpy()\n\nplt.figure(figsize=(12, 12))\n# 在plt.imshow()输入彩色图像时，需要对通道进行转化\n# pytorch中时(3, height, width)，imshow中是（height, width, 3）\nplt.imshow(img.transpose(1, 2, 0))\n```\n\n    638\n    torch.Size([3, 32, 32])\n\n\n    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n    <matplotlib.image.AxesImage at 0x27e882a9c70>\n\n\n\n\n​    \n![png](deep-learning-test04/output_4_3.png)\n​    \n\n\n\n```python\n# 定义网络\n# 要求至少包含5个卷积层和池化层\n# 卷积核的尺寸统一为3*3\n# 要求网络中使用BatchNorm\nclass model(nn.Module):\n    def __init__(self):\n        # 图片尺寸为[3, 32, 32]\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 4, 3, padding=1)\n        self.conv2 = nn.Conv2d(4, 8, 3, padding=1)\n        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n        self.conv4 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.pool2 = nn.AvgPool2d(2, 2)\n        self.dropout = nn.Dropout2d(0.5)\n        self.batch_norm1 = nn.BatchNorm2d(4)\n        self.batch_norm2 = nn.BatchNorm2d(8)\n        self.batch_norm3 = nn.BatchNorm2d(16)\n        self.batch_norm4 = nn.BatchNorm2d(32)\n        self.batch_norm5 = nn.BatchNorm2d(64)\n        self.fc1 = nn.Linear(64*4*4, 512)\n        self.fc2 = nn.Linear(512, 10)\n        \n    def forward(self, x):\n        # 第一个卷积层，输入3*32*32，输出4*32*32\n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = F.relu(x)\n        \n        # 第二个卷积层，输入4*32*32，输出8*32*32\n        x = self.conv2(x)\n        x = self.batch_norm2(x)\n        x = F.relu(x)\n        \n        # 第三个卷积层，输入8*32*32，输出16*32*32\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.batch_norm3(x)\n        # 输入16*32*32，输出16*16*16\n        x = self.pool1(x)\n        \n        # 第四个卷积层，输入16*16*16，输出32*16*16\n        x = self.conv4(x)\n        x = self.batch_norm4(x)\n        x = F.relu(x)\n        # 输入32*16*16，输出32*8*8\n        x = self.pool2(x)\n        \n        # 第五个卷积层，输入32*8*8，输出64*8*8\n        x = self.conv5(x)\n        x = self.batch_norm5(x)\n        x = F.relu(x)\n        # 输入64*8*8，输出64*4*4\n        x = self.pool1(x)\n        \n        # 全连接层\n        x = x.view(-1, 64*4*4)\n        x = self.fc1(x)\n        x = F.relu(x)\n        \n        # 随机失活20%参数\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# 使用GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \nnet = model()\nprint(net)\nnet.to(device)\n# 使用交叉熵损失函数\nloss_fn = nn.CrossEntropyLoss()\nloss_fn.to(device)\n# 最优化方法\nopt = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\n    model(\n      (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      (dropout): Dropout2d(p=0.5, inplace=False)\n      (batch_norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (batch_norm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n      (fc2): Linear(in_features=512, out_features=10, bias=True)\n    )\n\n\n\n```python\nfrom torchinfo import summary\nsummary(net, input_size=(64, 3, 32, 32))\n```\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n      warnings.warn(warn_msg)\n\n\n\n\n\n    ==========================================================================================\n    Layer (type:depth-idx)                   Output Shape              Param #\n    ==========================================================================================\n    model                                    [64, 10]                  --\n    ├─Conv2d: 1-1                            [64, 4, 32, 32]           112\n    ├─BatchNorm2d: 1-2                       [64, 4, 32, 32]           8\n    ├─Conv2d: 1-3                            [64, 8, 32, 32]           296\n    ├─BatchNorm2d: 1-4                       [64, 8, 32, 32]           16\n    ├─Conv2d: 1-5                            [64, 16, 32, 32]          1,168\n    ├─BatchNorm2d: 1-6                       [64, 16, 32, 32]          32\n    ├─MaxPool2d: 1-7                         [64, 16, 16, 16]          --\n    ├─Conv2d: 1-8                            [64, 32, 16, 16]          4,640\n    ├─BatchNorm2d: 1-9                       [64, 32, 16, 16]          64\n    ├─AvgPool2d: 1-10                        [64, 32, 8, 8]            --\n    ├─Conv2d: 1-11                           [64, 64, 8, 8]            18,496\n    ├─BatchNorm2d: 1-12                      [64, 64, 8, 8]            128\n    ├─MaxPool2d: 1-13                        [64, 64, 4, 4]            --\n    ├─Linear: 1-14                           [64, 512]                 524,800\n    ├─Dropout2d: 1-15                        [64, 512]                 --\n    ├─Linear: 1-16                           [64, 10]                  5,130\n    ==========================================================================================\n    Total params: 554,890\n    Trainable params: 554,890\n    Non-trainable params: 0\n    Total mult-adds (M): 289.00\n    ==========================================================================================\n    Input size (MB): 0.79\n    Forward/backward pass size (MB): 42.21\n    Params size (MB): 2.22\n    Estimated Total Size (MB): 45.22\n    ==========================================================================================\n\n\n\n\n```python\n# 开始训练\nfor epoch in range(20):\n    for i, data in enumerate(train_dataset):\n        x, y = data\n        x = x.to(device)\n        y = y.to(device)\n        net.train()\n        pred = net(x)\n        loss = loss_fn(pred, y)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n    \n    print('第', epoch, '个epoch，loss为：', loss)\n```\n\n    D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n      warnings.warn(warn_msg)\n\n\n    第 0 个epoch，loss为： tensor(1.4621, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 1 个epoch，loss为： tensor(1.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 2 个epoch，loss为： tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 3 个epoch，loss为： tensor(1.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 4 个epoch，loss为： tensor(1.1270, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 5 个epoch，loss为： tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 6 个epoch，loss为： tensor(2.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 7 个epoch，loss为： tensor(0.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 8 个epoch，loss为： tensor(0.3833, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 9 个epoch，loss为： tensor(1.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 10 个epoch，loss为： tensor(0.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 11 个epoch，loss为： tensor(0.8256, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 12 个epoch，loss为： tensor(0.8673, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 13 个epoch，loss为： tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 14 个epoch，loss为： tensor(0.8387, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 15 个epoch，loss为： tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 16 个epoch，loss为： tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 17 个epoch，loss为： tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 18 个epoch，loss为： tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n    第 19 个epoch，loss为： tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n\n\n\n```python\n# 测试验证\ndef rightness(predictions, labels):\n    pred = torch.max(predictions.data, 1)[1]\n    rights = pred.eq(labels.data.view_as(pred)).sum()\n    return rights, len(labels)\n```\n\n\n```python\n# 验证测试\nrights = 0\nlength = 0\nfor i, data in enumerate(test_dataset):\n    x, y = data\n    x = x.to(device)\n    y = y.to(device)\n    net.eval()\n    pred = net(x)\n    rights = rights + rightness(pred, y)[0]\n    length = length + rightness(pred, y)[1]\n\nprint(rights, length, rights/length)\n```\n\n    tensor(7884, device='cuda:0') 10000 tensor(0.7884, device='cuda:0')\n\n\n","slug":"deep-learning-test04","published":1,"updated":"2024-06-05T09:03:03.697Z","comments":1,"layout":"post","photos":[],"_id":"clyfintts001o08jv7vf34z3b","content":"<h1 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h1><h3 id=\"1、手写数字识别\"><a href=\"#1、手写数字识别\" class=\"headerlink\" title=\"1、手写数字识别\"></a>1、手写数字识别</h3><p>  通过MNIST数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸不小于5*5，要求训后的得到的网络在测试集准确率不低于96%（要求在网络中使用dropout）</p>\n<p> <strong>完成程度：</strong>获取MNIST数据集并保存，获取图片的训练集和测试集，构建卷积神经网络模型，包含2个卷积层，2个池化层，2个全连接层，在最后一个全连接前加入一个dropout层。定义模型和损失函数，并将模型和损失函数送入到GPU当中去，使用训练集训练模型，用测试集进行测试验证，最终准确率有99.35%。</p>\n<h3 id=\"2、CIFAR-10分类网络\"><a href=\"#2、CIFAR-10分类网络\" class=\"headerlink\" title=\"2、CIFAR-10分类网络\"></a>2、CIFAR-10分类网络</h3><p>  通过CIFAR-10数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸统一采用3*3，要求训后的得到的网络在测试集上的准确率不低于70%（要求在网络中使用BatchNorm）</p>\n<p><strong>完成程度：</strong>下载CIFAR-10实验数据集，并将其划分成训练集和测试集，查看图片的尺寸，图片尺寸为32*32，一共有3个通道，定义卷积神经网络，一共包含5个卷积层，5个BN层，3个池化层，2个全连接层，最后一个全连接层前加一个dropout层。在GPU上利用训练集训练网络模型，一共进行20测迭代，最终在测试集上进行测试验证，模型训练的准确性为78.84%。</p>\n<h2 id=\"手写数字识别\"><a href=\"#手写数字识别\" class=\"headerlink\" title=\"手写数字识别\"></a>手写数字识别</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> transforms<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>train_data = datasets.MNIST(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ]),<br>                      download=<span class=\"hljs-literal\">True</span><br>                     )<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> TensorDataset, DataLoader, Dataset<br>train_loader = DataLoader(dataset=train_data, batch_size=<span class=\"hljs-number\">64</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br><br>test_data = datasets.MNIST(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ])<br>                     )<br><br><br>test_loader = DataLoader(dataset=test_data, batch_size=<span class=\"hljs-number\">64</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看图片示例</span><br><span class=\"hljs-built_in\">print</span>(train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy().shape)<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br>img = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy()<br>label = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">1</span>]<br><br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>(1, 28, 28)\n</code></pre><img src=\"/2023/01/15/deep-learning-test04/output_5_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 网络构建</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, padding=<span class=\"hljs-number\">2</span>)<br>        self.pool = nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">5</span>, padding=<span class=\"hljs-number\">2</span>)<br>        self.fc1 = nn.Linear((<span class=\"hljs-number\">28</span>*<span class=\"hljs-number\">28</span>)//(<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)*<span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">512</span>)<br>        self.fc2 = nn.Linear(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">10</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 1*28*28, 4*28*28</span><br>        x = self.conv1(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 4*14*14</span><br>        x = self.pool(x)<br>        <br>        <span class=\"hljs-comment\"># 8*14*14</span><br>        x = self.conv2(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 8*7*7</span><br>        x = self.pool(x)<br>        <br>        x = x.view(-<span class=\"hljs-number\">1</span>, (<span class=\"hljs-number\">28</span>*<span class=\"hljs-number\">28</span>)//(<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)*<span class=\"hljs-number\">8</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        <br>        x = F.dropout(x, training=self.training)<br>        x = self.fc2(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">feature_maps</span>(<span class=\"hljs-params\">self, x</span>):<br>        map1 = self.conv1(x)<br>        map1 = F.relu(map1)<br>        map2 = self.pool(map1)<br>        map2 = self.conv2(map2)<br>        map2 = F.relu(map2)<br>        <span class=\"hljs-keyword\">return</span> (map1, map2)<br>    <br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = model()<br>net = net.cuda()<br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn = loss_fn.cuda()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-keyword\">for</span> i,data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        net.train()<br>        pred = net(x.cuda())<br>        loss = loss_fn(pred, y.cuda())<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>    <span class=\"hljs-built_in\">print</span>(epoch, <span class=\"hljs-string\">&quot;损失值:&quot;</span>,loss)<br></code></pre></td></tr></table></figure>\n<pre><code>0 损失值: tensor(0.1942, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n1 损失值: tensor(0.3168, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n2 损失值: tensor(0.0090, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n3 损失值: tensor(0.2042, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n4 损失值: tensor(0.0557, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n5 损失值: tensor(0.1490, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n6 损失值: tensor(0.0090, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n7 损失值: tensor(0.0358, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n8 损失值: tensor(0.1654, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n9 损失值: tensor(0.0103, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n10 损失值: tensor(0.0287, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n11 损失值: tensor(0.0289, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n12 损失值: tensor(0.1634, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n13 损失值: tensor(0.0111, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n14 损失值: tensor(0.0598, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n15 损失值: tensor(0.0598, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n16 损失值: tensor(0.0384, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n17 损失值: tensor(0.0041, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n18 损失值: tensor(0.0288, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n19 损失值: tensor(0.0030, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    net.<span class=\"hljs-built_in\">eval</span>()<br>    pred = net(x.cuda())<br>    rights = rights + rightness(pred, y.cuda())[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y.cuda())[<span class=\"hljs-number\">1</span>]<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(59609, device=&#39;cuda:0&#39;) 60000 tensor(0.9935, device=&#39;cuda:0&#39;)\n</code></pre><h2 id=\"CIFAR-10分类网络\"><a href=\"#CIFAR-10分类网络\" class=\"headerlink\" title=\"CIFAR-10分类网络\"></a>CIFAR-10分类网络</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> transforms<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, Dataset, TensorDataset<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>train_data = datasets.CIFAR10(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ]),<br>                      download=<span class=\"hljs-literal\">True</span><br>                     )<br></code></pre></td></tr></table></figure>\n<pre><code>Files already downloaded and verified\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>test_data = datasets.CIFAR10(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">False</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ])<br>                     )<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据加载器</span><br>train_dataset = DataLoader(train_data, batch_size=<span class=\"hljs-number\">4</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_dataset = DataLoader(test_data, batch_size=<span class=\"hljs-number\">4</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 随机查看一张图片</span><br><span class=\"hljs-built_in\">print</span>(np.random.randint(<span class=\"hljs-number\">3000</span>))<br><span class=\"hljs-built_in\">print</span>(train_data[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>].shape)<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br>img = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy()<br><br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">12</span>))<br><span class=\"hljs-comment\"># 在plt.imshow()输入彩色图像时，需要对通道进行转化</span><br><span class=\"hljs-comment\"># pytorch中时(3, height, width)，imshow中是（height, width, 3）</span><br>plt.imshow(img.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">0</span>))<br></code></pre></td></tr></table></figure>\n<pre><code>638\ntorch.Size([3, 32, 32])\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n&lt;matplotlib.image.AxesImage at 0x27e882a9c70&gt;\n</code></pre><p>​<br><img src=\"/2023/01/15/deep-learning-test04/output_4_3.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义网络</span><br><span class=\"hljs-comment\"># 要求至少包含5个卷积层和池化层</span><br><span class=\"hljs-comment\"># 卷积核的尺寸统一为3*3</span><br><span class=\"hljs-comment\"># 要求网络中使用BatchNorm</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-comment\"># 图片尺寸为[3, 32, 32]</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv3 = nn.Conv2d(<span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv4 = nn.Conv2d(<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv5 = nn.Conv2d(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.pool1 = nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.pool2 = nn.AvgPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.dropout = nn.Dropout2d(<span class=\"hljs-number\">0.5</span>)<br>        self.batch_norm1 = nn.BatchNorm2d(<span class=\"hljs-number\">4</span>)<br>        self.batch_norm2 = nn.BatchNorm2d(<span class=\"hljs-number\">8</span>)<br>        self.batch_norm3 = nn.BatchNorm2d(<span class=\"hljs-number\">16</span>)<br>        self.batch_norm4 = nn.BatchNorm2d(<span class=\"hljs-number\">32</span>)<br>        self.batch_norm5 = nn.BatchNorm2d(<span class=\"hljs-number\">64</span>)<br>        self.fc1 = nn.Linear(<span class=\"hljs-number\">64</span>*<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">512</span>)<br>        self.fc2 = nn.Linear(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">10</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 第一个卷积层，输入3*32*32，输出4*32*32</span><br>        x = self.conv1(x)<br>        x = self.batch_norm1(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 第二个卷积层，输入4*32*32，输出8*32*32</span><br>        x = self.conv2(x)<br>        x = self.batch_norm2(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 第三个卷积层，输入8*32*32，输出16*32*32</span><br>        x = self.conv3(x)<br>        x = F.relu(x)<br>        x = self.batch_norm3(x)<br>        <span class=\"hljs-comment\"># 输入16*32*32，输出16*16*16</span><br>        x = self.pool1(x)<br>        <br>        <span class=\"hljs-comment\"># 第四个卷积层，输入16*16*16，输出32*16*16</span><br>        x = self.conv4(x)<br>        x = self.batch_norm4(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 输入32*16*16，输出32*8*8</span><br>        x = self.pool2(x)<br>        <br>        <span class=\"hljs-comment\"># 第五个卷积层，输入32*8*8，输出64*8*8</span><br>        x = self.conv5(x)<br>        x = self.batch_norm5(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 输入64*8*8，输出64*4*4</span><br>        x = self.pool1(x)<br>        <br>        <span class=\"hljs-comment\"># 全连接层</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">64</span>*<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 随机失活20%参数</span><br>        x = self.dropout(x)<br>        x = self.fc2(x)<br>        <br>        <span class=\"hljs-keyword\">return</span> x<br><br><span class=\"hljs-comment\"># 使用GPU</span><br>device = torch.device(<span class=\"hljs-string\">&quot;cuda&quot;</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">&quot;cpu&quot;</span>)<br>        <br>net = model()<br><span class=\"hljs-built_in\">print</span>(net)<br>net.to(device)<br><span class=\"hljs-comment\"># 使用交叉熵损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn.to(device)<br><span class=\"hljs-comment\"># 最优化方法</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<pre><code>model(\n  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (dropout): Dropout2d(p=0.5, inplace=False)\n  (batch_norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=10, bias=True)\n)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torchinfo <span class=\"hljs-keyword\">import</span> summary<br>summary(net, input_size=(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">32</span>))<br></code></pre></td></tr></table></figure>\n<pre><code>D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n  warnings.warn(warn_msg)\n\n\n\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nmodel                                    [64, 10]                  --\n├─Conv2d: 1-1                            [64, 4, 32, 32]           112\n├─BatchNorm2d: 1-2                       [64, 4, 32, 32]           8\n├─Conv2d: 1-3                            [64, 8, 32, 32]           296\n├─BatchNorm2d: 1-4                       [64, 8, 32, 32]           16\n├─Conv2d: 1-5                            [64, 16, 32, 32]          1,168\n├─BatchNorm2d: 1-6                       [64, 16, 32, 32]          32\n├─MaxPool2d: 1-7                         [64, 16, 16, 16]          --\n├─Conv2d: 1-8                            [64, 32, 16, 16]          4,640\n├─BatchNorm2d: 1-9                       [64, 32, 16, 16]          64\n├─AvgPool2d: 1-10                        [64, 32, 8, 8]            --\n├─Conv2d: 1-11                           [64, 64, 8, 8]            18,496\n├─BatchNorm2d: 1-12                      [64, 64, 8, 8]            128\n├─MaxPool2d: 1-13                        [64, 64, 4, 4]            --\n├─Linear: 1-14                           [64, 512]                 524,800\n├─Dropout2d: 1-15                        [64, 512]                 --\n├─Linear: 1-16                           [64, 10]                  5,130\n==========================================================================================\nTotal params: 554,890\nTrainable params: 554,890\nNon-trainable params: 0\nTotal mult-adds (M): 289.00\n==========================================================================================\nInput size (MB): 0.79\nForward/backward pass size (MB): 42.21\nParams size (MB): 2.22\nEstimated Total Size (MB): 45.22\n==========================================================================================\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 开始训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_dataset):<br>        x, y = data<br>        x = x.to(device)<br>        y = y.to(device)<br>        net.train()<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br><br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>    <br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>, epoch, <span class=\"hljs-string\">&#x27;个epoch，loss为：&#x27;</span>, loss)<br></code></pre></td></tr></table></figure>\n<pre><code>D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n  warnings.warn(warn_msg)\n\n\n第 0 个epoch，loss为： tensor(1.4621, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 1 个epoch，loss为： tensor(1.1412, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 2 个epoch，loss为： tensor(0.7093, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 3 个epoch，loss为： tensor(1.1387, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 4 个epoch，loss为： tensor(1.1270, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 5 个epoch，loss为： tensor(0.1355, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 6 个epoch，loss为： tensor(2.1455, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 7 个epoch，loss为： tensor(0.2261, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 8 个epoch，loss为： tensor(0.3833, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 9 个epoch，loss为： tensor(1.3244, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 10 个epoch，loss为： tensor(0.1666, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 11 个epoch，loss为： tensor(0.8256, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 12 个epoch，loss为： tensor(0.8673, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 13 个epoch，loss为： tensor(0.0255, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 14 个epoch，loss为： tensor(0.8387, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 15 个epoch，loss为： tensor(0.1123, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 16 个epoch，loss为： tensor(0.0009, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 17 个epoch，loss为： tensor(0.0298, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 18 个epoch，loss为： tensor(0.5178, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 19 个epoch，loss为： tensor(0.3033, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_dataset):<br>    x, y = data<br>    x = x.to(device)<br>    y = y.to(device)<br>    net.<span class=\"hljs-built_in\">eval</span>()<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(7884, device=&#39;cuda:0&#39;) 10000 tensor(0.7884, device=&#39;cuda:0&#39;)\n</code></pre>","cover_type":"img","excerpt":"","more":"<h1 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h1><h3 id=\"1、手写数字识别\"><a href=\"#1、手写数字识别\" class=\"headerlink\" title=\"1、手写数字识别\"></a>1、手写数字识别</h3><p>  通过MNIST数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸不小于5*5，要求训后的得到的网络在测试集准确率不低于96%（要求在网络中使用dropout）</p>\n<p> <strong>完成程度：</strong>获取MNIST数据集并保存，获取图片的训练集和测试集，构建卷积神经网络模型，包含2个卷积层，2个池化层，2个全连接层，在最后一个全连接前加入一个dropout层。定义模型和损失函数，并将模型和损失函数送入到GPU当中去，使用训练集训练模型，用测试集进行测试验证，最终准确率有99.35%。</p>\n<h3 id=\"2、CIFAR-10分类网络\"><a href=\"#2、CIFAR-10分类网络\" class=\"headerlink\" title=\"2、CIFAR-10分类网络\"></a>2、CIFAR-10分类网络</h3><p>  通过CIFAR-10数据集训练得到一个手写数字分类器。要求设计一个至少包含2个卷积层和池化层的卷积神经网络。卷积核的尺寸统一采用3*3，要求训后的得到的网络在测试集上的准确率不低于70%（要求在网络中使用BatchNorm）</p>\n<p><strong>完成程度：</strong>下载CIFAR-10实验数据集，并将其划分成训练集和测试集，查看图片的尺寸，图片尺寸为32*32，一共有3个通道，定义卷积神经网络，一共包含5个卷积层，5个BN层，3个池化层，2个全连接层，最后一个全连接层前加一个dropout层。在GPU上利用训练集训练网络模型，一共进行20测迭代，最终在测试集上进行测试验证，模型训练的准确性为78.84%。</p>\n<h2 id=\"手写数字识别\"><a href=\"#手写数字识别\" class=\"headerlink\" title=\"手写数字识别\"></a>手写数字识别</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> transforms<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>train_data = datasets.MNIST(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ]),<br>                      download=<span class=\"hljs-literal\">True</span><br>                     )<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> TensorDataset, DataLoader, Dataset<br>train_loader = DataLoader(dataset=train_data, batch_size=<span class=\"hljs-number\">64</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br><br>test_data = datasets.MNIST(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ])<br>                     )<br><br><br>test_loader = DataLoader(dataset=test_data, batch_size=<span class=\"hljs-number\">64</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 查看图片示例</span><br><span class=\"hljs-built_in\">print</span>(train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy().shape)<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br>img = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy()<br>label = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">1</span>]<br><br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>(1, 28, 28)\n</code></pre><img src=\"/2023/01/15/deep-learning-test04/output_5_1.png\" class=\"\" title=\"png\">\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 网络构建</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, padding=<span class=\"hljs-number\">2</span>)<br>        self.pool = nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">5</span>, padding=<span class=\"hljs-number\">2</span>)<br>        self.fc1 = nn.Linear((<span class=\"hljs-number\">28</span>*<span class=\"hljs-number\">28</span>)//(<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)*<span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">512</span>)<br>        self.fc2 = nn.Linear(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">10</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 1*28*28, 4*28*28</span><br>        x = self.conv1(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 4*14*14</span><br>        x = self.pool(x)<br>        <br>        <span class=\"hljs-comment\"># 8*14*14</span><br>        x = self.conv2(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 8*7*7</span><br>        x = self.pool(x)<br>        <br>        x = x.view(-<span class=\"hljs-number\">1</span>, (<span class=\"hljs-number\">28</span>*<span class=\"hljs-number\">28</span>)//(<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)*<span class=\"hljs-number\">8</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        <br>        x = F.dropout(x, training=self.training)<br>        x = self.fc2(x)<br>        <span class=\"hljs-keyword\">return</span> x<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">feature_maps</span>(<span class=\"hljs-params\">self, x</span>):<br>        map1 = self.conv1(x)<br>        map1 = F.relu(map1)<br>        map2 = self.pool(map1)<br>        map2 = self.conv2(map2)<br>        map2 = F.relu(map2)<br>        <span class=\"hljs-keyword\">return</span> (map1, map2)<br>    <br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">net = model()<br>net = net.cuda()<br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn = loss_fn.cuda()<br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-keyword\">for</span> i,data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        net.train()<br>        pred = net(x.cuda())<br>        loss = loss_fn(pred, y.cuda())<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>    <span class=\"hljs-built_in\">print</span>(epoch, <span class=\"hljs-string\">&quot;损失值:&quot;</span>,loss)<br></code></pre></td></tr></table></figure>\n<pre><code>0 损失值: tensor(0.1942, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n1 损失值: tensor(0.3168, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n2 损失值: tensor(0.0090, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n3 损失值: tensor(0.2042, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n4 损失值: tensor(0.0557, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n5 损失值: tensor(0.1490, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n6 损失值: tensor(0.0090, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n7 损失值: tensor(0.0358, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n8 损失值: tensor(0.1654, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n9 损失值: tensor(0.0103, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n10 损失值: tensor(0.0287, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n11 损失值: tensor(0.0289, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n12 损失值: tensor(0.1634, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n13 损失值: tensor(0.0111, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n14 损失值: tensor(0.0598, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n15 损失值: tensor(0.0598, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n16 损失值: tensor(0.0384, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n17 损失值: tensor(0.0041, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n18 损失值: tensor(0.0288, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n19 损失值: tensor(0.0030, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    net.<span class=\"hljs-built_in\">eval</span>()<br>    pred = net(x.cuda())<br>    rights = rights + rightness(pred, y.cuda())[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y.cuda())[<span class=\"hljs-number\">1</span>]<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(59609, device=&#39;cuda:0&#39;) 60000 tensor(0.9935, device=&#39;cuda:0&#39;)\n</code></pre><h2 id=\"CIFAR-10分类网络\"><a href=\"#CIFAR-10分类网络\" class=\"headerlink\" title=\"CIFAR-10分类网络\"></a>CIFAR-10分类网络</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> transforms<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader, Dataset, TensorDataset<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>train_data = datasets.CIFAR10(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">True</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ]),<br>                      download=<span class=\"hljs-literal\">True</span><br>                     )<br></code></pre></td></tr></table></figure>\n<pre><code>Files already downloaded and verified\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取训练数据</span><br>test_data = datasets.CIFAR10(root=<span class=\"hljs-string\">&#x27;./&#x27;</span>,<br>                      train=<span class=\"hljs-literal\">False</span>,<br>                      transform=transforms.Compose([<br>                         transforms.ToTensor(),<br>                         transforms.Normalize([<span class=\"hljs-number\">0.1307</span>, ], [<span class=\"hljs-number\">0.3081</span>, ])<br>                      ])<br>                     )<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 数据加载器</span><br>train_dataset = DataLoader(train_data, batch_size=<span class=\"hljs-number\">4</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_dataset = DataLoader(test_data, batch_size=<span class=\"hljs-number\">4</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 随机查看一张图片</span><br><span class=\"hljs-built_in\">print</span>(np.random.randint(<span class=\"hljs-number\">3000</span>))<br><span class=\"hljs-built_in\">print</span>(train_data[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>].shape)<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br>img = train_data[<span class=\"hljs-number\">50</span>][<span class=\"hljs-number\">0</span>].numpy()<br><br>plt.figure(figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">12</span>))<br><span class=\"hljs-comment\"># 在plt.imshow()输入彩色图像时，需要对通道进行转化</span><br><span class=\"hljs-comment\"># pytorch中时(3, height, width)，imshow中是（height, width, 3）</span><br>plt.imshow(img.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">0</span>))<br></code></pre></td></tr></table></figure>\n<pre><code>638\ntorch.Size([3, 32, 32])\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n&lt;matplotlib.image.AxesImage at 0x27e882a9c70&gt;\n</code></pre><p>​<br><img src=\"/2023/01/15/deep-learning-test04/output_4_3.png\" class=\"\" title=\"png\"><br>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 定义网络</span><br><span class=\"hljs-comment\"># 要求至少包含5个卷积层和池化层</span><br><span class=\"hljs-comment\"># 卷积核的尺寸统一为3*3</span><br><span class=\"hljs-comment\"># 要求网络中使用BatchNorm</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-comment\"># 图片尺寸为[3, 32, 32]</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv2 = nn.Conv2d(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv3 = nn.Conv2d(<span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv4 = nn.Conv2d(<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.conv5 = nn.Conv2d(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>)<br>        self.pool1 = nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.pool2 = nn.AvgPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        self.dropout = nn.Dropout2d(<span class=\"hljs-number\">0.5</span>)<br>        self.batch_norm1 = nn.BatchNorm2d(<span class=\"hljs-number\">4</span>)<br>        self.batch_norm2 = nn.BatchNorm2d(<span class=\"hljs-number\">8</span>)<br>        self.batch_norm3 = nn.BatchNorm2d(<span class=\"hljs-number\">16</span>)<br>        self.batch_norm4 = nn.BatchNorm2d(<span class=\"hljs-number\">32</span>)<br>        self.batch_norm5 = nn.BatchNorm2d(<span class=\"hljs-number\">64</span>)<br>        self.fc1 = nn.Linear(<span class=\"hljs-number\">64</span>*<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">512</span>)<br>        self.fc2 = nn.Linear(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">10</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 第一个卷积层，输入3*32*32，输出4*32*32</span><br>        x = self.conv1(x)<br>        x = self.batch_norm1(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 第二个卷积层，输入4*32*32，输出8*32*32</span><br>        x = self.conv2(x)<br>        x = self.batch_norm2(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 第三个卷积层，输入8*32*32，输出16*32*32</span><br>        x = self.conv3(x)<br>        x = F.relu(x)<br>        x = self.batch_norm3(x)<br>        <span class=\"hljs-comment\"># 输入16*32*32，输出16*16*16</span><br>        x = self.pool1(x)<br>        <br>        <span class=\"hljs-comment\"># 第四个卷积层，输入16*16*16，输出32*16*16</span><br>        x = self.conv4(x)<br>        x = self.batch_norm4(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 输入32*16*16，输出32*8*8</span><br>        x = self.pool2(x)<br>        <br>        <span class=\"hljs-comment\"># 第五个卷积层，输入32*8*8，输出64*8*8</span><br>        x = self.conv5(x)<br>        x = self.batch_norm5(x)<br>        x = F.relu(x)<br>        <span class=\"hljs-comment\"># 输入64*8*8，输出64*4*4</span><br>        x = self.pool1(x)<br>        <br>        <span class=\"hljs-comment\"># 全连接层</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">64</span>*<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        <br>        <span class=\"hljs-comment\"># 随机失活20%参数</span><br>        x = self.dropout(x)<br>        x = self.fc2(x)<br>        <br>        <span class=\"hljs-keyword\">return</span> x<br><br><span class=\"hljs-comment\"># 使用GPU</span><br>device = torch.device(<span class=\"hljs-string\">&quot;cuda&quot;</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">&quot;cpu&quot;</span>)<br>        <br>net = model()<br><span class=\"hljs-built_in\">print</span>(net)<br>net.to(device)<br><span class=\"hljs-comment\"># 使用交叉熵损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn.to(device)<br><span class=\"hljs-comment\"># 最优化方法</span><br>opt = torch.optim.SGD(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<pre><code>model(\n  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (dropout): Dropout2d(p=0.5, inplace=False)\n  (batch_norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=10, bias=True)\n)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torchinfo <span class=\"hljs-keyword\">import</span> summary<br>summary(net, input_size=(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">32</span>))<br></code></pre></td></tr></table></figure>\n<pre><code>D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n  warnings.warn(warn_msg)\n\n\n\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nmodel                                    [64, 10]                  --\n├─Conv2d: 1-1                            [64, 4, 32, 32]           112\n├─BatchNorm2d: 1-2                       [64, 4, 32, 32]           8\n├─Conv2d: 1-3                            [64, 8, 32, 32]           296\n├─BatchNorm2d: 1-4                       [64, 8, 32, 32]           16\n├─Conv2d: 1-5                            [64, 16, 32, 32]          1,168\n├─BatchNorm2d: 1-6                       [64, 16, 32, 32]          32\n├─MaxPool2d: 1-7                         [64, 16, 16, 16]          --\n├─Conv2d: 1-8                            [64, 32, 16, 16]          4,640\n├─BatchNorm2d: 1-9                       [64, 32, 16, 16]          64\n├─AvgPool2d: 1-10                        [64, 32, 8, 8]            --\n├─Conv2d: 1-11                           [64, 64, 8, 8]            18,496\n├─BatchNorm2d: 1-12                      [64, 64, 8, 8]            128\n├─MaxPool2d: 1-13                        [64, 64, 4, 4]            --\n├─Linear: 1-14                           [64, 512]                 524,800\n├─Dropout2d: 1-15                        [64, 512]                 --\n├─Linear: 1-16                           [64, 10]                  5,130\n==========================================================================================\nTotal params: 554,890\nTrainable params: 554,890\nNon-trainable params: 0\nTotal mult-adds (M): 289.00\n==========================================================================================\nInput size (MB): 0.79\nForward/backward pass size (MB): 42.21\nParams size (MB): 2.22\nEstimated Total Size (MB): 45.22\n==========================================================================================\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 开始训练</span><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_dataset):<br>        x, y = data<br>        x = x.to(device)<br>        y = y.to(device)<br>        net.train()<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br><br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>    <br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>, epoch, <span class=\"hljs-string\">&#x27;个epoch，loss为：&#x27;</span>, loss)<br></code></pre></td></tr></table></figure>\n<pre><code>D:\\02_soft\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n  warnings.warn(warn_msg)\n\n\n第 0 个epoch，loss为： tensor(1.4621, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 1 个epoch，loss为： tensor(1.1412, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 2 个epoch，loss为： tensor(0.7093, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 3 个epoch，loss为： tensor(1.1387, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 4 个epoch，loss为： tensor(1.1270, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 5 个epoch，loss为： tensor(0.1355, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 6 个epoch，loss为： tensor(2.1455, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 7 个epoch，loss为： tensor(0.2261, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 8 个epoch，loss为： tensor(0.3833, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 9 个epoch，loss为： tensor(1.3244, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 10 个epoch，loss为： tensor(0.1666, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 11 个epoch，loss为： tensor(0.8256, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 12 个epoch，loss为： tensor(0.8673, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 13 个epoch，loss为： tensor(0.0255, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 14 个epoch，loss为： tensor(0.8387, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 15 个epoch，loss为： tensor(0.1123, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 16 个epoch，loss为： tensor(0.0009, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 17 个epoch，loss为： tensor(0.0298, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 18 个epoch，loss为： tensor(0.5178, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n第 19 个epoch，loss为： tensor(0.3033, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward0&gt;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">rightness</span>(<span class=\"hljs-params\">predictions, labels</span>):<br>    pred = torch.<span class=\"hljs-built_in\">max</span>(predictions.data, <span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">1</span>]<br>    rights = pred.eq(labels.data.view_as(pred)).<span class=\"hljs-built_in\">sum</span>()<br>    <span class=\"hljs-keyword\">return</span> rights, <span class=\"hljs-built_in\">len</span>(labels)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 验证测试</span><br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_dataset):<br>    x, y = data<br>    x = x.to(device)<br>    y = y.to(device)<br>    net.<span class=\"hljs-built_in\">eval</span>()<br>    pred = net(x)<br>    rights = rights + rightness(pred, y)[<span class=\"hljs-number\">0</span>]<br>    length = length + rightness(pred, y)[<span class=\"hljs-number\">1</span>]<br><br><span class=\"hljs-built_in\">print</span>(rights, length, rights/length)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor(7884, device=&#39;cuda:0&#39;) 10000 tensor(0.7884, device=&#39;cuda:0&#39;)\n</code></pre>"},{"title":"深度学习实践实验-LSTM与迁移学习","date":"2023-01-21T10:15:28.000Z","cover":"/img/default_cover06.jpg","top_img":null,"_content":"# 实验5：LSTM与迁移学习\n\n### 1、序列预测\n\n已知一个整数序列的通项公式（自行选择），根据公式生成若干长度为5的序列做为训练集，训练一个LSTM网络，对给定的序列预测下一项的值。\n\n**完成程度：**使用函数3*x+2生成100个长度为5的序列，选择前4列作为特征，第5列作为标签，按照9训练集：1测试集对生成的数据进行划分，定义LSTM网络，包含1个LSTM和一个全连接层。使用训练集对模型进行训练，在验证集上进行验证测试。\n\n### 2、正弦函数预测\n\n通过已知的样本数据对正弦函数进行预测，并绘制成图形。要求分别设计LSTM，GRU和RNN网络进行预测，记录三者的预测准确率并绘制图形\n\n**完成程度：**使用正弦函数生成200个长度为10的序列，选择前9列作为特征，第10列作为标签，按照3训练集：1测试集对生成的数据进行划分，分别定义RNN、LSTM、GRU网络，定义一个全连接层。分别使用三个模型在训练集上对模型进行训练，在测试集上进行验证测试。\n\n### 3、猫狗大战\n\n通过来自kaggle上的猫狗数据集，训练一个识别猫狗图片的分类器。要求设计一个使用ResNet18作为主干的卷积神经网络，在迁移网络时采用固定值模式，要求模型的准确率不低于90%。猫狗大战数据集训练集有25000张，猫狗各占一办。测试集12500张。\n\n**完成程度：**对训练数据进行划分，划分为训练集和测试集，其中训练集包含11250张图片，测试集包含1250张图片，随机取出一张图片查看样本图片。利用ResNet50作为基干网，定义网络模型，修改ResNet50的最后一层全连接层，再使用addmodule添加一个dropout和一个全连接层，使用交叉熵损失函数，并将模型和损失函数放入GPU中对模型开始进行训练，一共训练5个epoch，在测试集上进行测试验证，模型准确率为95.16%。\n\n## 1、序列预测\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 生成序列\ndef getSeq(start, n):\n    x = [ 3*x+2 for x in range(start, start+n)]\n    return x\n\ndata = []\nfor i in range(100):\n    rnd = np.random.randint(0, 25)\n    data.append(getSeq(rnd, 5))\n    \ndata = np.array(data)\ndata = torch.from_numpy(data)\n\n```\n\n\n```python\ntarget = data[:, -1:].type(torch.FloatTensor)\ndata = data[:, :-1].type(torch.FloatTensor)\n\ntrain_x = data[:90]\ntrain_y = target[:90]\ntest_x = data[90:]\ntest_y = target[90:]\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=5, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=5, shuffle=True)\n```\n\n\n```python\n# 构建LSTM网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(1, 10, batch_first=True)\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x, hidden):\n        # print(hidden)\n        output, hidden = self.lstm(x, hidden)\n        output = output[:, -1, :]\n        output = self.fc(output)\n        return output\n    \nnet = model()\nloss_fn = nn.MSELoss()\nopt = torch.optim.Adam(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练\n# 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数\nh0 = torch.zeros(1, 5, 10)\nc0 = torch.zeros(1, 5, 10)\n\nfor epoch in range(1200):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        #print(x)\n        x = x.view(-1, 4, 1)\n        # print(x.shape,h0.shape)\n        \n        pred = net(x, (h0, c0))\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%100==0:\n        print('第',epoch,'epoch，损失为：',loss.data)\n```\n\n    第 0 epoch，损失为： tensor(2489.9465)\n    第 100 epoch，损失为： tensor(1262.1434)\n    第 200 epoch，损失为： tensor(1057.6017)\n    第 300 epoch，损失为： tensor(109.3138)\n    第 400 epoch，损失为： tensor(167.9138)\n    第 500 epoch，损失为： tensor(47.4988)\n    第 600 epoch，损失为： tensor(0.7118)\n    第 700 epoch，损失为： tensor(0.6654)\n    第 800 epoch，损失为： tensor(0.0557)\n    第 900 epoch，损失为： tensor(0.0901)\n    第 1000 epoch，损失为： tensor(0.0679)\n    第 1100 epoch，损失为： tensor(0.0544)\n\n\n\n```python\n# 测试验证\nrights=0\nlength=0\n\nfor i, data in enumerate(test_loader):\n    x, y = data\n    x = x.view(-1, 4, 1)\n    hidden = torch.zeros(1, 5, 10)\n    pred = net(x, (h0, c0))\n    print(y.view(1, -1).data)\n    print(pred.view(1, -1).data)\n```\n\n    tensor([[17., 38., 83., 17., 53.]])\n    tensor([[16.9066, 37.6783, 82.5042, 16.9066, 52.4514]])\n    tensor([[29., 41., 86., 50., 86.]])\n    tensor([[28.9673, 40.6793, 85.1809, 49.4299, 85.1809]])\n\n## 2、正弦函数预测\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\ndata = []\nstart = 0\nfor i in range(200):\n    x = [np.sin(x/10) for x in range(start, start+11)]\n    data.append(x)\n    start = start+1\n\ndata = np.array(data)\ndata = torch.from_numpy(data)\n\ntarget = data[:, -1:].type(torch.FloatTensor)\ndata = data[:, :-1].type(torch.FloatTensor)\n\ntrain_x = data[:150]\ntrain_y = target[:150]\ntest_x = data[150:]\ntest_y = target[150:]\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n```\n\n\n```python\n# 构建模型\n# 构建LSTM网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(1, 10, batch_first=True)\n        self.cnn = nn.RNN(1, 10, batch_first=True)\n        self.gru = nn.GRU(1, 10, batch_first=True)\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x, hidden):\n        # print(hidden)\n        #output, hidden = self.lstm(x, hidden)\n        output, hidden = self.cnn(x, hidden)\n        #output, hidden = self.gru(x, hidden)\n        output = output[:, -1, :]\n        output = self.fc(output)\n        return output\n    \nnet = model()\nloss_fn = nn.MSELoss()\nopt = torch.optim.Adam(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练\n# 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数\nh0 = torch.zeros(1, 5, 10)\nc0 = torch.zeros(1, 5, 10)\n\nfor epoch in range(500):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        #print(x)\n        x = x.view(-1, 10, 1)\n        # print(x.shape,h0.shape)\n        \n        pred = net(x, h0)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%50==0:\n        print('第',epoch,'epoch，损失为：',loss.data)\n```\n\n    第 0 epoch，损失为： tensor(0.2056)\n    第 50 epoch，损失为： tensor(0.0008)\n    第 100 epoch，损失为： tensor(2.5645e-05)\n    第 150 epoch，损失为： tensor(9.5258e-06)\n    第 200 epoch，损失为： tensor(1.8686e-05)\n    第 250 epoch，损失为： tensor(4.9946e-05)\n    第 300 epoch，损失为： tensor(3.0734e-06)\n    第 350 epoch，损失为： tensor(1.7624e-06)\n    第 400 epoch，损失为： tensor(2.9713e-06)\n    第 450 epoch，损失为： tensor(5.6524e-06)\n\n\n\n```python\n# 测试验证\npreds = []\n\nfor i, data in enumerate(test_loader):\n    x, y = data\n    x = x.view(-1, 10, 1)\n    hidden = torch.zeros(1, 5, 10)\n    pred = net(x, h0)\n    preds.append(pred.data.numpy())\n    print(y.view(1, -1).data)\n    print(pred.view(1, -1).data, '\\n')\n    \nplt.scatter(range(len(train_y)), train_y.data.numpy(), marker='o')\n#plt.scatter(range(150, 200), test_y.data.numpy(), marker='o')\n\nplt.scatter(range(150, 200), preds, marker='s')\nplt.show()\n```\n\n    tensor([[-0.2879, -0.3821, -0.4724, -0.5581, -0.6381]])\n    tensor([[-0.2867, -0.3812, -0.4718, -0.5576, -0.6377]]) \n    \n    tensor([[-0.7118, -0.7784, -0.8371, -0.8876, -0.9291]])\n    tensor([[-0.7111, -0.7773, -0.8356, -0.8855, -0.9265]]) \n    \n    tensor([[-0.9614, -0.9841, -0.9969, -0.9998, -0.9927]])\n    tensor([[-0.9584, -0.9809, -0.9939, -0.9973, -0.9909]]) \n    \n    tensor([[-0.9756, -0.9488, -0.9126, -0.8672, -0.8132]])\n    tensor([[-0.9747, -0.9488, -0.9133, -0.8683, -0.8143]]) \n    \n    tensor([[-0.7510, -0.6813, -0.6048, -0.5223, -0.4346]])\n    tensor([[-0.7518, -0.6815, -0.6044, -0.5214, -0.4336]]) \n    \n    tensor([[-0.3425, -0.2470, -0.1490, -0.0495,  0.0504]])\n    tensor([[-0.3417, -0.2467, -0.1494, -0.0504,  0.0495]]) \n    \n    tensor([[0.1499, 0.2478, 0.3433, 0.4354, 0.5231]])\n    tensor([[0.1492, 0.2477, 0.3438, 0.4363, 0.5242]]) \n    \n    tensor([[0.6055, 0.6820, 0.7516, 0.8137, 0.8676]])\n    tensor([[0.6065, 0.6826, 0.7518, 0.8134, 0.8670]]) \n    \n    tensor([[0.9129, 0.9491, 0.9758, 0.9928, 0.9998]])\n    tensor([[0.9120, 0.9480, 0.9746, 0.9915, 0.9987]]) \n    \n    tensor([[0.9968, 0.9839, 0.9612, 0.9288, 0.8872]])\n    tensor([[0.9960, 0.9834, 0.9610, 0.9289, 0.8875]]) \n\n\n​    \n\n\n​    \n![png](deep-learning-test05/output_5_1.png)\n​    \n\n## 3、猫狗大战\n\n```python\nimport os\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as opt\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, models, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n```\n\n\n```python\nimport shutil\n\n# kaggle原始数据集地址\noriginal_dataset_dir = '/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/train'\ntotal_num = 12500  #int(len(os.listdir(original_dataset_dir)) / 2)\nrandom_idx = np.array(range(total_num))\nnp.random.shuffle(random_idx)\n# 待处理的数据集地址\nbase_dir = '/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data'\nif not os.path.exists(base_dir):\n    os.mkdir(base_dir)\n\n# 训练集、测试集的划分\nsub_dirs = ['train', 'test']\nanimals = ['cats', 'dogs']\ntrain_idx = random_idx[:int(total_num * 0.9)]\ntest_idx = random_idx[int(total_num * 0.9):]\nnumbers = [train_idx, test_idx]\nfor idx, sub_dir in enumerate(sub_dirs):\n    dir = os.path.join(base_dir, sub_dir)\n    if not os.path.exists(dir):\n        os.mkdir(dir)\n    for animal in animals:\n        animal_dir = os.path.join(dir, animal)  #\n        if not os.path.exists(animal_dir):\n            os.mkdir(animal_dir)\n        fnames = [animal[:-1] + '.{}.jpg'.format(i) for i in numbers[idx]]\n        for fname in fnames:\n            src = os.path.join(original_dataset_dir, fname)\n            dst = os.path.join(animal_dir, fname)\n            shutil.copyfile(src, dst)\n\n        # 验证训练集、验证集、测试集的划分的照片数目\n        print(animal_dir + ' total images : %d' % (len(os.listdir(animal_dir))))\n```\n\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/cats total images : 11250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/dogs total images : 11250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/cats total images : 1250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/dogs total images : 1250\n\n\n\n```python\n\"\"\"数据准备\"\"\"\nprint(\"开始\")\ntrain_data = datasets.ImageFolder(root=\"data/train/\",\n                                  transform=transforms.Compose(\n                                      [\n                                          transforms.Resize([224, 224]),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                      ]\n                                  ))\n```\n\n    开始\n\n\n\n```python\nprint(train_data.class_to_idx)\nprint(train_data.classes)\nindex = 11249\nimg = train_data[index][0]\nlabel = train_data[index][1]\nprint(\"label\", label)\nplt.imshow(img[0, :])\nplt.show()\nprint(\"len\", len(train_data))\n```\n\n    {'cats': 0, 'dogs': 1}\n    ['cats', 'dogs']\n    label 0\n\n\n\n\n![png](deep-learning-test05/output_3_1.png)\n    \n\n\n    len 22500\n\n\n\n```python\ntest_data = datasets.ImageFolder(root='data/test/',\n                                 transform=transforms.Compose(\n                                     [\n                                         transforms.Resize([224, 224]),\n                                         transforms.ToTensor(),\n                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                     ]\n                                 ))\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=8, shuffle=True)\nindex = 1253\nimg = test_data[index][0].numpy()\nlabel = test_data[index][1]\nprint(\"label\", label)\nplt.imshow(img[0, :])\nplt.show()\nprint(\"len\", len(test_data))\ncount = 0\nfor i in range(2500):\n    label = test_data[i][1]\n    if label == 1:\n        count += 1\n\nprint(count)\n```\n\n    label 1\n\n\n\n\n![png](deep-learning-test05/output_4_1.png)\n    \n\n\n    len 2500\n    1250\n\n\n\n```python\n\"\"\"采用固定值方式迁移Resnet18网络\"\"\"\nnet = models.resnet18(pretrained=True)\nfor param in net.parameters():\n    # 把参数冻结住，反向传播时不修改\n    param.requires_grad = False\nfeatures = net.fc.in_features\nnet.fc = nn.Linear(features, 2)\nloss_fn = nn.CrossEntropyLoss()\nopt = torch.optim.SGD(net.fc.parameters(), lr=0.001, momentum=0.9)\n```\n\n\n```python\n\"\"\"训练\"\"\"\nprint(\"开始训练\", time.ctime())\nfor epoch in range(1):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        if i % 25 == 0:\n            print(\"{:.2f}\".format(i / 28), '%')\n    # if epoch % 2 == 0:\n    print(loss.data)\n\nprint(\"训练结束\", time.ctime())\n```\n\n\n\n```python\n\"\"\"测试\"\"\"\nprint(\"测试\", time.ctime())\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n\n    pred = net(x)\n    # print(\"pred: \", pred)\n    # print(\"y: \", y)\n    for j in range(len(y)):\n        if pred[j][0] > 0 and y[j] == 0:\n            rights += 1\n        elif pred[j][1] > 0 and y[j] == 1:\n            rights += 1\n```\n\n    测试 Tue Jan  4 16:42:56 2022\n    正确数: 2245 准确率 89.8 %\n\n\n\n```python\nprint(\"正确数:\", rights, \"准确率{:1.0f}\".format(rights / len(test_data) * 100), \"%\")\n```\n\n    正确数: 2245 准确率90 %\n","source":"_posts/deep-learning-test05.md","raw":"---\ntitle: 深度学习实践实验-LSTM与迁移学习\ncategories: 算法实践\ndate: 2023-01-21 18:15:28\ntags: [深度学习, 人工智能]\ncover:\ntop_img:\n---\n# 实验5：LSTM与迁移学习\n\n### 1、序列预测\n\n已知一个整数序列的通项公式（自行选择），根据公式生成若干长度为5的序列做为训练集，训练一个LSTM网络，对给定的序列预测下一项的值。\n\n**完成程度：**使用函数3*x+2生成100个长度为5的序列，选择前4列作为特征，第5列作为标签，按照9训练集：1测试集对生成的数据进行划分，定义LSTM网络，包含1个LSTM和一个全连接层。使用训练集对模型进行训练，在验证集上进行验证测试。\n\n### 2、正弦函数预测\n\n通过已知的样本数据对正弦函数进行预测，并绘制成图形。要求分别设计LSTM，GRU和RNN网络进行预测，记录三者的预测准确率并绘制图形\n\n**完成程度：**使用正弦函数生成200个长度为10的序列，选择前9列作为特征，第10列作为标签，按照3训练集：1测试集对生成的数据进行划分，分别定义RNN、LSTM、GRU网络，定义一个全连接层。分别使用三个模型在训练集上对模型进行训练，在测试集上进行验证测试。\n\n### 3、猫狗大战\n\n通过来自kaggle上的猫狗数据集，训练一个识别猫狗图片的分类器。要求设计一个使用ResNet18作为主干的卷积神经网络，在迁移网络时采用固定值模式，要求模型的准确率不低于90%。猫狗大战数据集训练集有25000张，猫狗各占一办。测试集12500张。\n\n**完成程度：**对训练数据进行划分，划分为训练集和测试集，其中训练集包含11250张图片，测试集包含1250张图片，随机取出一张图片查看样本图片。利用ResNet50作为基干网，定义网络模型，修改ResNet50的最后一层全连接层，再使用addmodule添加一个dropout和一个全连接层，使用交叉熵损失函数，并将模型和损失函数放入GPU中对模型开始进行训练，一共训练5个epoch，在测试集上进行测试验证，模型准确率为95.16%。\n\n## 1、序列预测\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\n# 生成序列\ndef getSeq(start, n):\n    x = [ 3*x+2 for x in range(start, start+n)]\n    return x\n\ndata = []\nfor i in range(100):\n    rnd = np.random.randint(0, 25)\n    data.append(getSeq(rnd, 5))\n    \ndata = np.array(data)\ndata = torch.from_numpy(data)\n\n```\n\n\n```python\ntarget = data[:, -1:].type(torch.FloatTensor)\ndata = data[:, :-1].type(torch.FloatTensor)\n\ntrain_x = data[:90]\ntrain_y = target[:90]\ntest_x = data[90:]\ntest_y = target[90:]\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=5, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=5, shuffle=True)\n```\n\n\n```python\n# 构建LSTM网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(1, 10, batch_first=True)\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x, hidden):\n        # print(hidden)\n        output, hidden = self.lstm(x, hidden)\n        output = output[:, -1, :]\n        output = self.fc(output)\n        return output\n    \nnet = model()\nloss_fn = nn.MSELoss()\nopt = torch.optim.Adam(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练\n# 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数\nh0 = torch.zeros(1, 5, 10)\nc0 = torch.zeros(1, 5, 10)\n\nfor epoch in range(1200):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        #print(x)\n        x = x.view(-1, 4, 1)\n        # print(x.shape,h0.shape)\n        \n        pred = net(x, (h0, c0))\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%100==0:\n        print('第',epoch,'epoch，损失为：',loss.data)\n```\n\n    第 0 epoch，损失为： tensor(2489.9465)\n    第 100 epoch，损失为： tensor(1262.1434)\n    第 200 epoch，损失为： tensor(1057.6017)\n    第 300 epoch，损失为： tensor(109.3138)\n    第 400 epoch，损失为： tensor(167.9138)\n    第 500 epoch，损失为： tensor(47.4988)\n    第 600 epoch，损失为： tensor(0.7118)\n    第 700 epoch，损失为： tensor(0.6654)\n    第 800 epoch，损失为： tensor(0.0557)\n    第 900 epoch，损失为： tensor(0.0901)\n    第 1000 epoch，损失为： tensor(0.0679)\n    第 1100 epoch，损失为： tensor(0.0544)\n\n\n\n```python\n# 测试验证\nrights=0\nlength=0\n\nfor i, data in enumerate(test_loader):\n    x, y = data\n    x = x.view(-1, 4, 1)\n    hidden = torch.zeros(1, 5, 10)\n    pred = net(x, (h0, c0))\n    print(y.view(1, -1).data)\n    print(pred.view(1, -1).data)\n```\n\n    tensor([[17., 38., 83., 17., 53.]])\n    tensor([[16.9066, 37.6783, 82.5042, 16.9066, 52.4514]])\n    tensor([[29., 41., 86., 50., 86.]])\n    tensor([[28.9673, 40.6793, 85.1809, 49.4299, 85.1809]])\n\n## 2、正弦函数预测\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n```\n\n\n```python\ndata = []\nstart = 0\nfor i in range(200):\n    x = [np.sin(x/10) for x in range(start, start+11)]\n    data.append(x)\n    start = start+1\n\ndata = np.array(data)\ndata = torch.from_numpy(data)\n\ntarget = data[:, -1:].type(torch.FloatTensor)\ndata = data[:, :-1].type(torch.FloatTensor)\n\ntrain_x = data[:150]\ntrain_y = target[:150]\ntest_x = data[150:]\ntest_y = target[150:]\n\ntrain_dataset = TensorDataset(train_x, train_y)\ntest_dataset = TensorDataset(test_x, test_y)\ntrain_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n```\n\n\n```python\n# 构建模型\n# 构建LSTM网络\nclass model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(1, 10, batch_first=True)\n        self.cnn = nn.RNN(1, 10, batch_first=True)\n        self.gru = nn.GRU(1, 10, batch_first=True)\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x, hidden):\n        # print(hidden)\n        #output, hidden = self.lstm(x, hidden)\n        output, hidden = self.cnn(x, hidden)\n        #output, hidden = self.gru(x, hidden)\n        output = output[:, -1, :]\n        output = self.fc(output)\n        return output\n    \nnet = model()\nloss_fn = nn.MSELoss()\nopt = torch.optim.Adam(net.parameters(), lr=0.001)\n```\n\n\n```python\n# 训练\n# 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数\nh0 = torch.zeros(1, 5, 10)\nc0 = torch.zeros(1, 5, 10)\n\nfor epoch in range(500):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        #print(x)\n        x = x.view(-1, 10, 1)\n        # print(x.shape,h0.shape)\n        \n        pred = net(x, h0)\n        loss = loss_fn(pred, y)\n        \n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n    if epoch%50==0:\n        print('第',epoch,'epoch，损失为：',loss.data)\n```\n\n    第 0 epoch，损失为： tensor(0.2056)\n    第 50 epoch，损失为： tensor(0.0008)\n    第 100 epoch，损失为： tensor(2.5645e-05)\n    第 150 epoch，损失为： tensor(9.5258e-06)\n    第 200 epoch，损失为： tensor(1.8686e-05)\n    第 250 epoch，损失为： tensor(4.9946e-05)\n    第 300 epoch，损失为： tensor(3.0734e-06)\n    第 350 epoch，损失为： tensor(1.7624e-06)\n    第 400 epoch，损失为： tensor(2.9713e-06)\n    第 450 epoch，损失为： tensor(5.6524e-06)\n\n\n\n```python\n# 测试验证\npreds = []\n\nfor i, data in enumerate(test_loader):\n    x, y = data\n    x = x.view(-1, 10, 1)\n    hidden = torch.zeros(1, 5, 10)\n    pred = net(x, h0)\n    preds.append(pred.data.numpy())\n    print(y.view(1, -1).data)\n    print(pred.view(1, -1).data, '\\n')\n    \nplt.scatter(range(len(train_y)), train_y.data.numpy(), marker='o')\n#plt.scatter(range(150, 200), test_y.data.numpy(), marker='o')\n\nplt.scatter(range(150, 200), preds, marker='s')\nplt.show()\n```\n\n    tensor([[-0.2879, -0.3821, -0.4724, -0.5581, -0.6381]])\n    tensor([[-0.2867, -0.3812, -0.4718, -0.5576, -0.6377]]) \n    \n    tensor([[-0.7118, -0.7784, -0.8371, -0.8876, -0.9291]])\n    tensor([[-0.7111, -0.7773, -0.8356, -0.8855, -0.9265]]) \n    \n    tensor([[-0.9614, -0.9841, -0.9969, -0.9998, -0.9927]])\n    tensor([[-0.9584, -0.9809, -0.9939, -0.9973, -0.9909]]) \n    \n    tensor([[-0.9756, -0.9488, -0.9126, -0.8672, -0.8132]])\n    tensor([[-0.9747, -0.9488, -0.9133, -0.8683, -0.8143]]) \n    \n    tensor([[-0.7510, -0.6813, -0.6048, -0.5223, -0.4346]])\n    tensor([[-0.7518, -0.6815, -0.6044, -0.5214, -0.4336]]) \n    \n    tensor([[-0.3425, -0.2470, -0.1490, -0.0495,  0.0504]])\n    tensor([[-0.3417, -0.2467, -0.1494, -0.0504,  0.0495]]) \n    \n    tensor([[0.1499, 0.2478, 0.3433, 0.4354, 0.5231]])\n    tensor([[0.1492, 0.2477, 0.3438, 0.4363, 0.5242]]) \n    \n    tensor([[0.6055, 0.6820, 0.7516, 0.8137, 0.8676]])\n    tensor([[0.6065, 0.6826, 0.7518, 0.8134, 0.8670]]) \n    \n    tensor([[0.9129, 0.9491, 0.9758, 0.9928, 0.9998]])\n    tensor([[0.9120, 0.9480, 0.9746, 0.9915, 0.9987]]) \n    \n    tensor([[0.9968, 0.9839, 0.9612, 0.9288, 0.8872]])\n    tensor([[0.9960, 0.9834, 0.9610, 0.9289, 0.8875]]) \n\n\n​    \n\n\n​    \n![png](deep-learning-test05/output_5_1.png)\n​    \n\n## 3、猫狗大战\n\n```python\nimport os\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as opt\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, models, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n```\n\n\n```python\nimport shutil\n\n# kaggle原始数据集地址\noriginal_dataset_dir = '/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/train'\ntotal_num = 12500  #int(len(os.listdir(original_dataset_dir)) / 2)\nrandom_idx = np.array(range(total_num))\nnp.random.shuffle(random_idx)\n# 待处理的数据集地址\nbase_dir = '/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data'\nif not os.path.exists(base_dir):\n    os.mkdir(base_dir)\n\n# 训练集、测试集的划分\nsub_dirs = ['train', 'test']\nanimals = ['cats', 'dogs']\ntrain_idx = random_idx[:int(total_num * 0.9)]\ntest_idx = random_idx[int(total_num * 0.9):]\nnumbers = [train_idx, test_idx]\nfor idx, sub_dir in enumerate(sub_dirs):\n    dir = os.path.join(base_dir, sub_dir)\n    if not os.path.exists(dir):\n        os.mkdir(dir)\n    for animal in animals:\n        animal_dir = os.path.join(dir, animal)  #\n        if not os.path.exists(animal_dir):\n            os.mkdir(animal_dir)\n        fnames = [animal[:-1] + '.{}.jpg'.format(i) for i in numbers[idx]]\n        for fname in fnames:\n            src = os.path.join(original_dataset_dir, fname)\n            dst = os.path.join(animal_dir, fname)\n            shutil.copyfile(src, dst)\n\n        # 验证训练集、验证集、测试集的划分的照片数目\n        print(animal_dir + ' total images : %d' % (len(os.listdir(animal_dir))))\n```\n\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/cats total images : 11250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/dogs total images : 11250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/cats total images : 1250\n    /Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/dogs total images : 1250\n\n\n\n```python\n\"\"\"数据准备\"\"\"\nprint(\"开始\")\ntrain_data = datasets.ImageFolder(root=\"data/train/\",\n                                  transform=transforms.Compose(\n                                      [\n                                          transforms.Resize([224, 224]),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                      ]\n                                  ))\n```\n\n    开始\n\n\n\n```python\nprint(train_data.class_to_idx)\nprint(train_data.classes)\nindex = 11249\nimg = train_data[index][0]\nlabel = train_data[index][1]\nprint(\"label\", label)\nplt.imshow(img[0, :])\nplt.show()\nprint(\"len\", len(train_data))\n```\n\n    {'cats': 0, 'dogs': 1}\n    ['cats', 'dogs']\n    label 0\n\n\n\n\n![png](deep-learning-test05/output_3_1.png)\n    \n\n\n    len 22500\n\n\n\n```python\ntest_data = datasets.ImageFolder(root='data/test/',\n                                 transform=transforms.Compose(\n                                     [\n                                         transforms.Resize([224, 224]),\n                                         transforms.ToTensor(),\n                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                     ]\n                                 ))\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=8, shuffle=True)\nindex = 1253\nimg = test_data[index][0].numpy()\nlabel = test_data[index][1]\nprint(\"label\", label)\nplt.imshow(img[0, :])\nplt.show()\nprint(\"len\", len(test_data))\ncount = 0\nfor i in range(2500):\n    label = test_data[i][1]\n    if label == 1:\n        count += 1\n\nprint(count)\n```\n\n    label 1\n\n\n\n\n![png](deep-learning-test05/output_4_1.png)\n    \n\n\n    len 2500\n    1250\n\n\n\n```python\n\"\"\"采用固定值方式迁移Resnet18网络\"\"\"\nnet = models.resnet18(pretrained=True)\nfor param in net.parameters():\n    # 把参数冻结住，反向传播时不修改\n    param.requires_grad = False\nfeatures = net.fc.in_features\nnet.fc = nn.Linear(features, 2)\nloss_fn = nn.CrossEntropyLoss()\nopt = torch.optim.SGD(net.fc.parameters(), lr=0.001, momentum=0.9)\n```\n\n\n```python\n\"\"\"训练\"\"\"\nprint(\"开始训练\", time.ctime())\nfor epoch in range(1):\n    for i, data in enumerate(train_loader):\n        x, y = data\n        pred = net(x)\n        loss = loss_fn(pred, y)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        if i % 25 == 0:\n            print(\"{:.2f}\".format(i / 28), '%')\n    # if epoch % 2 == 0:\n    print(loss.data)\n\nprint(\"训练结束\", time.ctime())\n```\n\n\n\n```python\n\"\"\"测试\"\"\"\nprint(\"测试\", time.ctime())\nrights = 0\nlength = 0\nfor i, data in enumerate(test_loader):\n    x, y = data\n\n    pred = net(x)\n    # print(\"pred: \", pred)\n    # print(\"y: \", y)\n    for j in range(len(y)):\n        if pred[j][0] > 0 and y[j] == 0:\n            rights += 1\n        elif pred[j][1] > 0 and y[j] == 1:\n            rights += 1\n```\n\n    测试 Tue Jan  4 16:42:56 2022\n    正确数: 2245 准确率 89.8 %\n\n\n\n```python\nprint(\"正确数:\", rights, \"准确率{:1.0f}\".format(rights / len(test_data) * 100), \"%\")\n```\n\n    正确数: 2245 准确率90 %\n","slug":"deep-learning-test05","published":1,"updated":"2024-06-05T09:03:03.697Z","comments":1,"layout":"post","photos":[],"_id":"clyfintts001r08jv0eq24ir7","content":"<h1 id=\"实验5：LSTM与迁移学习\"><a href=\"#实验5：LSTM与迁移学习\" class=\"headerlink\" title=\"实验5：LSTM与迁移学习\"></a>实验5：LSTM与迁移学习</h1><h3 id=\"1、序列预测\"><a href=\"#1、序列预测\" class=\"headerlink\" title=\"1、序列预测\"></a>1、序列预测</h3><p>已知一个整数序列的通项公式（自行选择），根据公式生成若干长度为5的序列做为训练集，训练一个LSTM网络，对给定的序列预测下一项的值。</p>\n<p><strong>完成程度：</strong>使用函数3*x+2生成100个长度为5的序列，选择前4列作为特征，第5列作为标签，按照9训练集：1测试集对生成的数据进行划分，定义LSTM网络，包含1个LSTM和一个全连接层。使用训练集对模型进行训练，在验证集上进行验证测试。</p>\n<h3 id=\"2、正弦函数预测\"><a href=\"#2、正弦函数预测\" class=\"headerlink\" title=\"2、正弦函数预测\"></a>2、正弦函数预测</h3><p>通过已知的样本数据对正弦函数进行预测，并绘制成图形。要求分别设计LSTM，GRU和RNN网络进行预测，记录三者的预测准确率并绘制图形</p>\n<p><strong>完成程度：</strong>使用正弦函数生成200个长度为10的序列，选择前9列作为特征，第10列作为标签，按照3训练集：1测试集对生成的数据进行划分，分别定义RNN、LSTM、GRU网络，定义一个全连接层。分别使用三个模型在训练集上对模型进行训练，在测试集上进行验证测试。</p>\n<h3 id=\"3、猫狗大战\"><a href=\"#3、猫狗大战\" class=\"headerlink\" title=\"3、猫狗大战\"></a>3、猫狗大战</h3><p>通过来自kaggle上的猫狗数据集，训练一个识别猫狗图片的分类器。要求设计一个使用ResNet18作为主干的卷积神经网络，在迁移网络时采用固定值模式，要求模型的准确率不低于90%。猫狗大战数据集训练集有25000张，猫狗各占一办。测试集12500张。</p>\n<p><strong>完成程度：</strong>对训练数据进行划分，划分为训练集和测试集，其中训练集包含11250张图片，测试集包含1250张图片，随机取出一张图片查看样本图片。利用ResNet50作为基干网，定义网络模型，修改ResNet50的最后一层全连接层，再使用addmodule添加一个dropout和一个全连接层，使用交叉熵损失函数，并将模型和损失函数放入GPU中对模型开始进行训练，一共训练5个epoch，在测试集上进行测试验证，模型准确率为95.16%。</p>\n<h2 id=\"1、序列预测-1\"><a href=\"#1、序列预测-1\" class=\"headerlink\" title=\"1、序列预测\"></a>1、序列预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成序列</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">getSeq</span>(<span class=\"hljs-params\">start, n</span>):<br>    x = [ <span class=\"hljs-number\">3</span>*x+<span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(start, start+n)]<br>    <span class=\"hljs-keyword\">return</span> x<br><br>data = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">100</span>):<br>    rnd = np.random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">25</span>)<br>    data.append(getSeq(rnd, <span class=\"hljs-number\">5</span>))<br>    <br>data = np.array(data)<br>data = torch.from_numpy(data)<br><br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">target = data[:, -<span class=\"hljs-number\">1</span>:].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>data = data[:, :-<span class=\"hljs-number\">1</span>].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br><br>train_x = data[:<span class=\"hljs-number\">90</span>]<br>train_y = target[:<span class=\"hljs-number\">90</span>]<br>test_x = data[<span class=\"hljs-number\">90</span>:]<br>test_y = target[<span class=\"hljs-number\">90</span>:]<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(dataset=train_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建LSTM网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.lstm = nn.LSTM(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.fc = nn.Linear(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, hidden</span>):<br>        <span class=\"hljs-comment\"># print(hidden)</span><br>        output, hidden = self.lstm(x, hidden)<br>        output = output[:, -<span class=\"hljs-number\">1</span>, :]<br>        output = self.fc(output)<br>        <span class=\"hljs-keyword\">return</span> output<br>    <br>net = model()<br>loss_fn = nn.MSELoss()<br>opt = torch.optim.Adam(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-comment\"># 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数</span><br>h0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>c0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1200</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        <span class=\"hljs-comment\">#print(x)</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># print(x.shape,h0.shape)</span><br>        <br>        pred = net(x, (h0, c0))<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>,epoch,<span class=\"hljs-string\">&#x27;epoch，损失为：&#x27;</span>,loss.data)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 epoch，损失为： tensor(2489.9465)\n第 100 epoch，损失为： tensor(1262.1434)\n第 200 epoch，损失为： tensor(1057.6017)\n第 300 epoch，损失为： tensor(109.3138)\n第 400 epoch，损失为： tensor(167.9138)\n第 500 epoch，损失为： tensor(47.4988)\n第 600 epoch，损失为： tensor(0.7118)\n第 700 epoch，损失为： tensor(0.6654)\n第 800 epoch，损失为： tensor(0.0557)\n第 900 epoch，损失为： tensor(0.0901)\n第 1000 epoch，损失为： tensor(0.0679)\n第 1100 epoch，损失为： tensor(0.0544)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br>rights=<span class=\"hljs-number\">0</span><br>length=<span class=\"hljs-number\">0</span><br><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>    hidden = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>    pred = net(x, (h0, c0))<br>    <span class=\"hljs-built_in\">print</span>(y.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br>    <span class=\"hljs-built_in\">print</span>(pred.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([[17., 38., 83., 17., 53.]])\ntensor([[16.9066, 37.6783, 82.5042, 16.9066, 52.4514]])\ntensor([[29., 41., 86., 50., 86.]])\ntensor([[28.9673, 40.6793, 85.1809, 49.4299, 85.1809]])\n</code></pre><h2 id=\"2、正弦函数预测-1\"><a href=\"#2、正弦函数预测-1\" class=\"headerlink\" title=\"2、正弦函数预测\"></a>2、正弦函数预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = []<br>start = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>):<br>    x = [np.sin(x/<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(start, start+<span class=\"hljs-number\">11</span>)]<br>    data.append(x)<br>    start = start+<span class=\"hljs-number\">1</span><br><br>data = np.array(data)<br>data = torch.from_numpy(data)<br><br>target = data[:, -<span class=\"hljs-number\">1</span>:].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>data = data[:, :-<span class=\"hljs-number\">1</span>].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br><br>train_x = data[:<span class=\"hljs-number\">150</span>]<br>train_y = target[:<span class=\"hljs-number\">150</span>]<br>test_x = data[<span class=\"hljs-number\">150</span>:]<br>test_y = target[<span class=\"hljs-number\">150</span>:]<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(train_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(test_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">False</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建模型</span><br><span class=\"hljs-comment\"># 构建LSTM网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.lstm = nn.LSTM(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.cnn = nn.RNN(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.gru = nn.GRU(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.fc = nn.Linear(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, hidden</span>):<br>        <span class=\"hljs-comment\"># print(hidden)</span><br>        <span class=\"hljs-comment\">#output, hidden = self.lstm(x, hidden)</span><br>        output, hidden = self.cnn(x, hidden)<br>        <span class=\"hljs-comment\">#output, hidden = self.gru(x, hidden)</span><br>        output = output[:, -<span class=\"hljs-number\">1</span>, :]<br>        output = self.fc(output)<br>        <span class=\"hljs-keyword\">return</span> output<br>    <br>net = model()<br>loss_fn = nn.MSELoss()<br>opt = torch.optim.Adam(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-comment\"># 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数</span><br>h0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>c0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">500</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        <span class=\"hljs-comment\">#print(x)</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># print(x.shape,h0.shape)</span><br>        <br>        pred = net(x, h0)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">50</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>,epoch,<span class=\"hljs-string\">&#x27;epoch，损失为：&#x27;</span>,loss.data)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 epoch，损失为： tensor(0.2056)\n第 50 epoch，损失为： tensor(0.0008)\n第 100 epoch，损失为： tensor(2.5645e-05)\n第 150 epoch，损失为： tensor(9.5258e-06)\n第 200 epoch，损失为： tensor(1.8686e-05)\n第 250 epoch，损失为： tensor(4.9946e-05)\n第 300 epoch，损失为： tensor(3.0734e-06)\n第 350 epoch，损失为： tensor(1.7624e-06)\n第 400 epoch，损失为： tensor(2.9713e-06)\n第 450 epoch，损失为： tensor(5.6524e-06)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br>preds = []<br><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>    hidden = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>    pred = net(x, h0)<br>    preds.append(pred.data.numpy())<br>    <span class=\"hljs-built_in\">print</span>(y.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br>    <span class=\"hljs-built_in\">print</span>(pred.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br>    <br>plt.scatter(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(train_y)), train_y.data.numpy(), marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br><span class=\"hljs-comment\">#plt.scatter(range(150, 200), test_y.data.numpy(), marker=&#x27;o&#x27;)</span><br><br>plt.scatter(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">150</span>, <span class=\"hljs-number\">200</span>), preds, marker=<span class=\"hljs-string\">&#x27;s&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([[-0.2879, -0.3821, -0.4724, -0.5581, -0.6381]])\ntensor([[-0.2867, -0.3812, -0.4718, -0.5576, -0.6377]]) \n\ntensor([[-0.7118, -0.7784, -0.8371, -0.8876, -0.9291]])\ntensor([[-0.7111, -0.7773, -0.8356, -0.8855, -0.9265]]) \n\ntensor([[-0.9614, -0.9841, -0.9969, -0.9998, -0.9927]])\ntensor([[-0.9584, -0.9809, -0.9939, -0.9973, -0.9909]]) \n\ntensor([[-0.9756, -0.9488, -0.9126, -0.8672, -0.8132]])\ntensor([[-0.9747, -0.9488, -0.9133, -0.8683, -0.8143]]) \n\ntensor([[-0.7510, -0.6813, -0.6048, -0.5223, -0.4346]])\ntensor([[-0.7518, -0.6815, -0.6044, -0.5214, -0.4336]]) \n\ntensor([[-0.3425, -0.2470, -0.1490, -0.0495,  0.0504]])\ntensor([[-0.3417, -0.2467, -0.1494, -0.0504,  0.0495]]) \n\ntensor([[0.1499, 0.2478, 0.3433, 0.4354, 0.5231]])\ntensor([[0.1492, 0.2477, 0.3438, 0.4363, 0.5242]]) \n\ntensor([[0.6055, 0.6820, 0.7516, 0.8137, 0.8676]])\ntensor([[0.6065, 0.6826, 0.7518, 0.8134, 0.8670]]) \n\ntensor([[0.9129, 0.9491, 0.9758, 0.9928, 0.9998]])\ntensor([[0.9120, 0.9480, 0.9746, 0.9915, 0.9987]]) \n\ntensor([[0.9968, 0.9839, 0.9612, 0.9288, 0.8872]])\ntensor([[0.9960, 0.9834, 0.9610, 0.9289, 0.8875]]) \n</code></pre><p>​    </p>\n<p>​<br><img src=\"/2023/01/21/deep-learning-test05/output_5_1.png\" class=\"\" title=\"png\"><br>​    </p>\n<h2 id=\"3、猫狗大战-1\"><a href=\"#3、猫狗大战-1\" class=\"headerlink\" title=\"3、猫狗大战\"></a>3、猫狗大战</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> os<br><span class=\"hljs-keyword\">import</span> time<br><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> opt<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> torchvision<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets, models, transforms<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> time<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> shutil<br><br><span class=\"hljs-comment\"># kaggle原始数据集地址</span><br>original_dataset_dir = <span class=\"hljs-string\">&#x27;/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/train&#x27;</span><br>total_num = <span class=\"hljs-number\">12500</span>  <span class=\"hljs-comment\">#int(len(os.listdir(original_dataset_dir)) / 2)</span><br>random_idx = np.array(<span class=\"hljs-built_in\">range</span>(total_num))<br>np.random.shuffle(random_idx)<br><span class=\"hljs-comment\"># 待处理的数据集地址</span><br>base_dir = <span class=\"hljs-string\">&#x27;/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data&#x27;</span><br><span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(base_dir):<br>    os.mkdir(base_dir)<br><br><span class=\"hljs-comment\"># 训练集、测试集的划分</span><br>sub_dirs = [<span class=\"hljs-string\">&#x27;train&#x27;</span>, <span class=\"hljs-string\">&#x27;test&#x27;</span>]<br>animals = [<span class=\"hljs-string\">&#x27;cats&#x27;</span>, <span class=\"hljs-string\">&#x27;dogs&#x27;</span>]<br>train_idx = random_idx[:<span class=\"hljs-built_in\">int</span>(total_num * <span class=\"hljs-number\">0.9</span>)]<br>test_idx = random_idx[<span class=\"hljs-built_in\">int</span>(total_num * <span class=\"hljs-number\">0.9</span>):]<br>numbers = [train_idx, test_idx]<br><span class=\"hljs-keyword\">for</span> idx, sub_dir <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(sub_dirs):<br>    <span class=\"hljs-built_in\">dir</span> = os.path.join(base_dir, sub_dir)<br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(<span class=\"hljs-built_in\">dir</span>):<br>        os.mkdir(<span class=\"hljs-built_in\">dir</span>)<br>    <span class=\"hljs-keyword\">for</span> animal <span class=\"hljs-keyword\">in</span> animals:<br>        animal_dir = os.path.join(<span class=\"hljs-built_in\">dir</span>, animal)  <span class=\"hljs-comment\">#</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(animal_dir):<br>            os.mkdir(animal_dir)<br>        fnames = [animal[:-<span class=\"hljs-number\">1</span>] + <span class=\"hljs-string\">&#x27;.&#123;&#125;.jpg&#x27;</span>.<span class=\"hljs-built_in\">format</span>(i) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> numbers[idx]]<br>        <span class=\"hljs-keyword\">for</span> fname <span class=\"hljs-keyword\">in</span> fnames:<br>            src = os.path.join(original_dataset_dir, fname)<br>            dst = os.path.join(animal_dir, fname)<br>            shutil.copyfile(src, dst)<br><br>        <span class=\"hljs-comment\"># 验证训练集、验证集、测试集的划分的照片数目</span><br>        <span class=\"hljs-built_in\">print</span>(animal_dir + <span class=\"hljs-string\">&#x27; total images : %d&#x27;</span> % (<span class=\"hljs-built_in\">len</span>(os.listdir(animal_dir))))<br></code></pre></td></tr></table></figure>\n<pre><code>/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/cats total images : 11250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/dogs total images : 11250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/cats total images : 1250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/dogs total images : 1250\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;数据准备&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;开始&quot;</span>)<br>train_data = datasets.ImageFolder(root=<span class=\"hljs-string\">&quot;data/train/&quot;</span>,<br>                                  transform=transforms.Compose(<br>                                      [<br>                                          transforms.Resize([<span class=\"hljs-number\">224</span>, <span class=\"hljs-number\">224</span>]),<br>                                          transforms.ToTensor(),<br>                                          transforms.Normalize(mean=[<span class=\"hljs-number\">0.485</span>, <span class=\"hljs-number\">0.456</span>, <span class=\"hljs-number\">0.406</span>], std=[<span class=\"hljs-number\">0.229</span>, <span class=\"hljs-number\">0.224</span>, <span class=\"hljs-number\">0.225</span>])<br>                                      ]<br>                                  ))<br></code></pre></td></tr></table></figure>\n<pre><code>开始\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(train_data.class_to_idx)<br><span class=\"hljs-built_in\">print</span>(train_data.classes)<br>index = <span class=\"hljs-number\">11249</span><br>img = train_data[index][<span class=\"hljs-number\">0</span>]<br>label = train_data[index][<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;label&quot;</span>, label)<br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;len&quot;</span>, <span class=\"hljs-built_in\">len</span>(train_data))<br></code></pre></td></tr></table></figure>\n<pre><code>&#123;&#39;cats&#39;: 0, &#39;dogs&#39;: 1&#125;\n[&#39;cats&#39;, &#39;dogs&#39;]\nlabel 0\n</code></pre><img src=\"/2023/01/21/deep-learning-test05/output_3_1.png\" class=\"\" title=\"png\">\n<pre><code>len 22500\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">test_data = datasets.ImageFolder(root=<span class=\"hljs-string\">&#x27;data/test/&#x27;</span>,<br>                                 transform=transforms.Compose(<br>                                     [<br>                                         transforms.Resize([<span class=\"hljs-number\">224</span>, <span class=\"hljs-number\">224</span>]),<br>                                         transforms.ToTensor(),<br>                                         transforms.Normalize([<span class=\"hljs-number\">0.485</span>, <span class=\"hljs-number\">0.456</span>, <span class=\"hljs-number\">0.406</span>], [<span class=\"hljs-number\">0.229</span>, <span class=\"hljs-number\">0.224</span>, <span class=\"hljs-number\">0.225</span>])<br>                                     ]<br>                                 ))<br>train_loader = DataLoader(train_data, batch_size=<span class=\"hljs-number\">8</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(test_data, batch_size=<span class=\"hljs-number\">8</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>index = <span class=\"hljs-number\">1253</span><br>img = test_data[index][<span class=\"hljs-number\">0</span>].numpy()<br>label = test_data[index][<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;label&quot;</span>, label)<br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;len&quot;</span>, <span class=\"hljs-built_in\">len</span>(test_data))<br>count = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">2500</span>):<br>    label = test_data[i][<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-keyword\">if</span> label == <span class=\"hljs-number\">1</span>:<br>        count += <span class=\"hljs-number\">1</span><br><br><span class=\"hljs-built_in\">print</span>(count)<br></code></pre></td></tr></table></figure>\n<pre><code>label 1\n</code></pre><img src=\"/2023/01/21/deep-learning-test05/output_4_1.png\" class=\"\" title=\"png\">\n<pre><code>len 2500\n1250\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;采用固定值方式迁移Resnet18网络&quot;&quot;&quot;</span><br>net = models.resnet18(pretrained=<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-keyword\">for</span> param <span class=\"hljs-keyword\">in</span> net.parameters():<br>    <span class=\"hljs-comment\"># 把参数冻结住，反向传播时不修改</span><br>    param.requires_grad = <span class=\"hljs-literal\">False</span><br>features = net.fc.in_features<br>net.fc = nn.Linear(features, <span class=\"hljs-number\">2</span>)<br>loss_fn = nn.CrossEntropyLoss()<br>opt = torch.optim.SGD(net.fc.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;训练&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;开始训练&quot;</span>, time.ctime())<br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br><br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <span class=\"hljs-keyword\">if</span> i % <span class=\"hljs-number\">25</span> == <span class=\"hljs-number\">0</span>:<br>            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;&#123;:.2f&#125;&quot;</span>.<span class=\"hljs-built_in\">format</span>(i / <span class=\"hljs-number\">28</span>), <span class=\"hljs-string\">&#x27;%&#x27;</span>)<br>    <span class=\"hljs-comment\"># if epoch % 2 == 0:</span><br>    <span class=\"hljs-built_in\">print</span>(loss.data)<br><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;训练结束&quot;</span>, time.ctime())<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;测试&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;测试&quot;</span>, time.ctime())<br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br><br>    pred = net(x)<br>    <span class=\"hljs-comment\"># print(&quot;pred: &quot;, pred)</span><br>    <span class=\"hljs-comment\"># print(&quot;y: &quot;, y)</span><br>    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(y)):<br>        <span class=\"hljs-keyword\">if</span> pred[j][<span class=\"hljs-number\">0</span>] &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> y[j] == <span class=\"hljs-number\">0</span>:<br>            rights += <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">elif</span> pred[j][<span class=\"hljs-number\">1</span>] &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> y[j] == <span class=\"hljs-number\">1</span>:<br>            rights += <span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n<pre><code>测试 Tue Jan  4 16:42:56 2022\n正确数: 2245 准确率 89.8 %\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;正确数:&quot;</span>, rights, <span class=\"hljs-string\">&quot;准确率&#123;:1.0f&#125;&quot;</span>.<span class=\"hljs-built_in\">format</span>(rights / <span class=\"hljs-built_in\">len</span>(test_data) * <span class=\"hljs-number\">100</span>), <span class=\"hljs-string\">&quot;%&quot;</span>)<br></code></pre></td></tr></table></figure>\n<pre><code>正确数: 2245 准确率90 %\n</code></pre>","cover_type":"img","excerpt":"","more":"<h1 id=\"实验5：LSTM与迁移学习\"><a href=\"#实验5：LSTM与迁移学习\" class=\"headerlink\" title=\"实验5：LSTM与迁移学习\"></a>实验5：LSTM与迁移学习</h1><h3 id=\"1、序列预测\"><a href=\"#1、序列预测\" class=\"headerlink\" title=\"1、序列预测\"></a>1、序列预测</h3><p>已知一个整数序列的通项公式（自行选择），根据公式生成若干长度为5的序列做为训练集，训练一个LSTM网络，对给定的序列预测下一项的值。</p>\n<p><strong>完成程度：</strong>使用函数3*x+2生成100个长度为5的序列，选择前4列作为特征，第5列作为标签，按照9训练集：1测试集对生成的数据进行划分，定义LSTM网络，包含1个LSTM和一个全连接层。使用训练集对模型进行训练，在验证集上进行验证测试。</p>\n<h3 id=\"2、正弦函数预测\"><a href=\"#2、正弦函数预测\" class=\"headerlink\" title=\"2、正弦函数预测\"></a>2、正弦函数预测</h3><p>通过已知的样本数据对正弦函数进行预测，并绘制成图形。要求分别设计LSTM，GRU和RNN网络进行预测，记录三者的预测准确率并绘制图形</p>\n<p><strong>完成程度：</strong>使用正弦函数生成200个长度为10的序列，选择前9列作为特征，第10列作为标签，按照3训练集：1测试集对生成的数据进行划分，分别定义RNN、LSTM、GRU网络，定义一个全连接层。分别使用三个模型在训练集上对模型进行训练，在测试集上进行验证测试。</p>\n<h3 id=\"3、猫狗大战\"><a href=\"#3、猫狗大战\" class=\"headerlink\" title=\"3、猫狗大战\"></a>3、猫狗大战</h3><p>通过来自kaggle上的猫狗数据集，训练一个识别猫狗图片的分类器。要求设计一个使用ResNet18作为主干的卷积神经网络，在迁移网络时采用固定值模式，要求模型的准确率不低于90%。猫狗大战数据集训练集有25000张，猫狗各占一办。测试集12500张。</p>\n<p><strong>完成程度：</strong>对训练数据进行划分，划分为训练集和测试集，其中训练集包含11250张图片，测试集包含1250张图片，随机取出一张图片查看样本图片。利用ResNet50作为基干网，定义网络模型，修改ResNet50的最后一层全连接层，再使用addmodule添加一个dropout和一个全连接层，使用交叉熵损失函数，并将模型和损失函数放入GPU中对模型开始进行训练，一共训练5个epoch，在测试集上进行测试验证，模型准确率为95.16%。</p>\n<h2 id=\"1、序列预测-1\"><a href=\"#1、序列预测-1\" class=\"headerlink\" title=\"1、序列预测\"></a>1、序列预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成序列</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">getSeq</span>(<span class=\"hljs-params\">start, n</span>):<br>    x = [ <span class=\"hljs-number\">3</span>*x+<span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(start, start+n)]<br>    <span class=\"hljs-keyword\">return</span> x<br><br>data = []<br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">100</span>):<br>    rnd = np.random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">25</span>)<br>    data.append(getSeq(rnd, <span class=\"hljs-number\">5</span>))<br>    <br>data = np.array(data)<br>data = torch.from_numpy(data)<br><br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">target = data[:, -<span class=\"hljs-number\">1</span>:].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>data = data[:, :-<span class=\"hljs-number\">1</span>].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br><br>train_x = data[:<span class=\"hljs-number\">90</span>]<br>train_y = target[:<span class=\"hljs-number\">90</span>]<br>test_x = data[<span class=\"hljs-number\">90</span>:]<br>test_y = target[<span class=\"hljs-number\">90</span>:]<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(dataset=train_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建LSTM网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.lstm = nn.LSTM(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.fc = nn.Linear(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, hidden</span>):<br>        <span class=\"hljs-comment\"># print(hidden)</span><br>        output, hidden = self.lstm(x, hidden)<br>        output = output[:, -<span class=\"hljs-number\">1</span>, :]<br>        output = self.fc(output)<br>        <span class=\"hljs-keyword\">return</span> output<br>    <br>net = model()<br>loss_fn = nn.MSELoss()<br>opt = torch.optim.Adam(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-comment\"># 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数</span><br>h0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>c0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1200</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        <span class=\"hljs-comment\">#print(x)</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># print(x.shape,h0.shape)</span><br>        <br>        pred = net(x, (h0, c0))<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">100</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>,epoch,<span class=\"hljs-string\">&#x27;epoch，损失为：&#x27;</span>,loss.data)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 epoch，损失为： tensor(2489.9465)\n第 100 epoch，损失为： tensor(1262.1434)\n第 200 epoch，损失为： tensor(1057.6017)\n第 300 epoch，损失为： tensor(109.3138)\n第 400 epoch，损失为： tensor(167.9138)\n第 500 epoch，损失为： tensor(47.4988)\n第 600 epoch，损失为： tensor(0.7118)\n第 700 epoch，损失为： tensor(0.6654)\n第 800 epoch，损失为： tensor(0.0557)\n第 900 epoch，损失为： tensor(0.0901)\n第 1000 epoch，损失为： tensor(0.0679)\n第 1100 epoch，损失为： tensor(0.0544)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br>rights=<span class=\"hljs-number\">0</span><br>length=<span class=\"hljs-number\">0</span><br><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">1</span>)<br>    hidden = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>    pred = net(x, (h0, c0))<br>    <span class=\"hljs-built_in\">print</span>(y.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br>    <span class=\"hljs-built_in\">print</span>(pred.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([[17., 38., 83., 17., 53.]])\ntensor([[16.9066, 37.6783, 82.5042, 16.9066, 52.4514]])\ntensor([[29., 41., 86., 50., 86.]])\ntensor([[28.9673, 40.6793, 85.1809, 49.4299, 85.1809]])\n</code></pre><h2 id=\"2、正弦函数预测-1\"><a href=\"#2、正弦函数预测-1\" class=\"headerlink\" title=\"2、正弦函数预测\"></a>2、正弦函数预测</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader, TensorDataset<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">data = []<br>start = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">200</span>):<br>    x = [np.sin(x/<span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(start, start+<span class=\"hljs-number\">11</span>)]<br>    data.append(x)<br>    start = start+<span class=\"hljs-number\">1</span><br><br>data = np.array(data)<br>data = torch.from_numpy(data)<br><br>target = data[:, -<span class=\"hljs-number\">1</span>:].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br>data = data[:, :-<span class=\"hljs-number\">1</span>].<span class=\"hljs-built_in\">type</span>(torch.FloatTensor)<br><br>train_x = data[:<span class=\"hljs-number\">150</span>]<br>train_y = target[:<span class=\"hljs-number\">150</span>]<br>test_x = data[<span class=\"hljs-number\">150</span>:]<br>test_y = target[<span class=\"hljs-number\">150</span>:]<br><br>train_dataset = TensorDataset(train_x, train_y)<br>test_dataset = TensorDataset(test_x, test_y)<br>train_loader = DataLoader(train_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(test_dataset, batch_size=<span class=\"hljs-number\">5</span>, shuffle=<span class=\"hljs-literal\">False</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 构建模型</span><br><span class=\"hljs-comment\"># 构建LSTM网络</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">model</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        self.lstm = nn.LSTM(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.cnn = nn.RNN(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.gru = nn.GRU(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, batch_first=<span class=\"hljs-literal\">True</span>)<br>        self.fc = nn.Linear(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, hidden</span>):<br>        <span class=\"hljs-comment\"># print(hidden)</span><br>        <span class=\"hljs-comment\">#output, hidden = self.lstm(x, hidden)</span><br>        output, hidden = self.cnn(x, hidden)<br>        <span class=\"hljs-comment\">#output, hidden = self.gru(x, hidden)</span><br>        output = output[:, -<span class=\"hljs-number\">1</span>, :]<br>        output = self.fc(output)<br>        <span class=\"hljs-keyword\">return</span> output<br>    <br>net = model()<br>loss_fn = nn.MSELoss()<br>opt = torch.optim.Adam(net.parameters(), lr=<span class=\"hljs-number\">0.001</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 训练</span><br><span class=\"hljs-comment\"># 初始化h0，c0，如果batchsize不是4，要考虑最后一个batch的样本数</span><br>h0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>c0 = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br><br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">500</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        <span class=\"hljs-comment\">#print(x)</span><br>        x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># print(x.shape,h0.shape)</span><br>        <br>        pred = net(x, h0)<br>        loss = loss_fn(pred, y)<br>        <br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <br>    <span class=\"hljs-keyword\">if</span> epoch%<span class=\"hljs-number\">50</span>==<span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&#x27;第&#x27;</span>,epoch,<span class=\"hljs-string\">&#x27;epoch，损失为：&#x27;</span>,loss.data)<br></code></pre></td></tr></table></figure>\n<pre><code>第 0 epoch，损失为： tensor(0.2056)\n第 50 epoch，损失为： tensor(0.0008)\n第 100 epoch，损失为： tensor(2.5645e-05)\n第 150 epoch，损失为： tensor(9.5258e-06)\n第 200 epoch，损失为： tensor(1.8686e-05)\n第 250 epoch，损失为： tensor(4.9946e-05)\n第 300 epoch，损失为： tensor(3.0734e-06)\n第 350 epoch，损失为： tensor(1.7624e-06)\n第 400 epoch，损失为： tensor(2.9713e-06)\n第 450 epoch，损失为： tensor(5.6524e-06)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 测试验证</span><br>preds = []<br><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br>    x = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">1</span>)<br>    hidden = torch.zeros(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">10</span>)<br>    pred = net(x, h0)<br>    preds.append(pred.data.numpy())<br>    <span class=\"hljs-built_in\">print</span>(y.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data)<br>    <span class=\"hljs-built_in\">print</span>(pred.view(<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>).data, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)<br>    <br>plt.scatter(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(train_y)), train_y.data.numpy(), marker=<span class=\"hljs-string\">&#x27;o&#x27;</span>)<br><span class=\"hljs-comment\">#plt.scatter(range(150, 200), test_y.data.numpy(), marker=&#x27;o&#x27;)</span><br><br>plt.scatter(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">150</span>, <span class=\"hljs-number\">200</span>), preds, marker=<span class=\"hljs-string\">&#x27;s&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>\n<pre><code>tensor([[-0.2879, -0.3821, -0.4724, -0.5581, -0.6381]])\ntensor([[-0.2867, -0.3812, -0.4718, -0.5576, -0.6377]]) \n\ntensor([[-0.7118, -0.7784, -0.8371, -0.8876, -0.9291]])\ntensor([[-0.7111, -0.7773, -0.8356, -0.8855, -0.9265]]) \n\ntensor([[-0.9614, -0.9841, -0.9969, -0.9998, -0.9927]])\ntensor([[-0.9584, -0.9809, -0.9939, -0.9973, -0.9909]]) \n\ntensor([[-0.9756, -0.9488, -0.9126, -0.8672, -0.8132]])\ntensor([[-0.9747, -0.9488, -0.9133, -0.8683, -0.8143]]) \n\ntensor([[-0.7510, -0.6813, -0.6048, -0.5223, -0.4346]])\ntensor([[-0.7518, -0.6815, -0.6044, -0.5214, -0.4336]]) \n\ntensor([[-0.3425, -0.2470, -0.1490, -0.0495,  0.0504]])\ntensor([[-0.3417, -0.2467, -0.1494, -0.0504,  0.0495]]) \n\ntensor([[0.1499, 0.2478, 0.3433, 0.4354, 0.5231]])\ntensor([[0.1492, 0.2477, 0.3438, 0.4363, 0.5242]]) \n\ntensor([[0.6055, 0.6820, 0.7516, 0.8137, 0.8676]])\ntensor([[0.6065, 0.6826, 0.7518, 0.8134, 0.8670]]) \n\ntensor([[0.9129, 0.9491, 0.9758, 0.9928, 0.9998]])\ntensor([[0.9120, 0.9480, 0.9746, 0.9915, 0.9987]]) \n\ntensor([[0.9968, 0.9839, 0.9612, 0.9288, 0.8872]])\ntensor([[0.9960, 0.9834, 0.9610, 0.9289, 0.8875]]) \n</code></pre><p>​    </p>\n<p>​<br><img src=\"/2023/01/21/deep-learning-test05/output_5_1.png\" class=\"\" title=\"png\"><br>​    </p>\n<h2 id=\"3、猫狗大战-1\"><a href=\"#3、猫狗大战-1\" class=\"headerlink\" title=\"3、猫狗大战\"></a>3、猫狗大战</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> os<br><span class=\"hljs-keyword\">import</span> time<br><br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br><span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> opt<br><span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F<br><span class=\"hljs-keyword\">import</span> torchvision<br><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> DataLoader<br><span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> datasets, models, transforms<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> time<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> shutil<br><br><span class=\"hljs-comment\"># kaggle原始数据集地址</span><br>original_dataset_dir = <span class=\"hljs-string\">&#x27;/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/train&#x27;</span><br>total_num = <span class=\"hljs-number\">12500</span>  <span class=\"hljs-comment\">#int(len(os.listdir(original_dataset_dir)) / 2)</span><br>random_idx = np.array(<span class=\"hljs-built_in\">range</span>(total_num))<br>np.random.shuffle(random_idx)<br><span class=\"hljs-comment\"># 待处理的数据集地址</span><br>base_dir = <span class=\"hljs-string\">&#x27;/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data&#x27;</span><br><span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(base_dir):<br>    os.mkdir(base_dir)<br><br><span class=\"hljs-comment\"># 训练集、测试集的划分</span><br>sub_dirs = [<span class=\"hljs-string\">&#x27;train&#x27;</span>, <span class=\"hljs-string\">&#x27;test&#x27;</span>]<br>animals = [<span class=\"hljs-string\">&#x27;cats&#x27;</span>, <span class=\"hljs-string\">&#x27;dogs&#x27;</span>]<br>train_idx = random_idx[:<span class=\"hljs-built_in\">int</span>(total_num * <span class=\"hljs-number\">0.9</span>)]<br>test_idx = random_idx[<span class=\"hljs-built_in\">int</span>(total_num * <span class=\"hljs-number\">0.9</span>):]<br>numbers = [train_idx, test_idx]<br><span class=\"hljs-keyword\">for</span> idx, sub_dir <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(sub_dirs):<br>    <span class=\"hljs-built_in\">dir</span> = os.path.join(base_dir, sub_dir)<br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(<span class=\"hljs-built_in\">dir</span>):<br>        os.mkdir(<span class=\"hljs-built_in\">dir</span>)<br>    <span class=\"hljs-keyword\">for</span> animal <span class=\"hljs-keyword\">in</span> animals:<br>        animal_dir = os.path.join(<span class=\"hljs-built_in\">dir</span>, animal)  <span class=\"hljs-comment\">#</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(animal_dir):<br>            os.mkdir(animal_dir)<br>        fnames = [animal[:-<span class=\"hljs-number\">1</span>] + <span class=\"hljs-string\">&#x27;.&#123;&#125;.jpg&#x27;</span>.<span class=\"hljs-built_in\">format</span>(i) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> numbers[idx]]<br>        <span class=\"hljs-keyword\">for</span> fname <span class=\"hljs-keyword\">in</span> fnames:<br>            src = os.path.join(original_dataset_dir, fname)<br>            dst = os.path.join(animal_dir, fname)<br>            shutil.copyfile(src, dst)<br><br>        <span class=\"hljs-comment\"># 验证训练集、验证集、测试集的划分的照片数目</span><br>        <span class=\"hljs-built_in\">print</span>(animal_dir + <span class=\"hljs-string\">&#x27; total images : %d&#x27;</span> % (<span class=\"hljs-built_in\">len</span>(os.listdir(animal_dir))))<br></code></pre></td></tr></table></figure>\n<pre><code>/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/cats total images : 11250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/train/dogs total images : 11250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/cats total images : 1250\n/Users/jihaipeng/PycharmProjects/深度学习实践/深度学习实验/5实验5/dogs_cats/kaggle/data/test/dogs total images : 1250\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;数据准备&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;开始&quot;</span>)<br>train_data = datasets.ImageFolder(root=<span class=\"hljs-string\">&quot;data/train/&quot;</span>,<br>                                  transform=transforms.Compose(<br>                                      [<br>                                          transforms.Resize([<span class=\"hljs-number\">224</span>, <span class=\"hljs-number\">224</span>]),<br>                                          transforms.ToTensor(),<br>                                          transforms.Normalize(mean=[<span class=\"hljs-number\">0.485</span>, <span class=\"hljs-number\">0.456</span>, <span class=\"hljs-number\">0.406</span>], std=[<span class=\"hljs-number\">0.229</span>, <span class=\"hljs-number\">0.224</span>, <span class=\"hljs-number\">0.225</span>])<br>                                      ]<br>                                  ))<br></code></pre></td></tr></table></figure>\n<pre><code>开始\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(train_data.class_to_idx)<br><span class=\"hljs-built_in\">print</span>(train_data.classes)<br>index = <span class=\"hljs-number\">11249</span><br>img = train_data[index][<span class=\"hljs-number\">0</span>]<br>label = train_data[index][<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;label&quot;</span>, label)<br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;len&quot;</span>, <span class=\"hljs-built_in\">len</span>(train_data))<br></code></pre></td></tr></table></figure>\n<pre><code>&#123;&#39;cats&#39;: 0, &#39;dogs&#39;: 1&#125;\n[&#39;cats&#39;, &#39;dogs&#39;]\nlabel 0\n</code></pre><img src=\"/2023/01/21/deep-learning-test05/output_3_1.png\" class=\"\" title=\"png\">\n<pre><code>len 22500\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">test_data = datasets.ImageFolder(root=<span class=\"hljs-string\">&#x27;data/test/&#x27;</span>,<br>                                 transform=transforms.Compose(<br>                                     [<br>                                         transforms.Resize([<span class=\"hljs-number\">224</span>, <span class=\"hljs-number\">224</span>]),<br>                                         transforms.ToTensor(),<br>                                         transforms.Normalize([<span class=\"hljs-number\">0.485</span>, <span class=\"hljs-number\">0.456</span>, <span class=\"hljs-number\">0.406</span>], [<span class=\"hljs-number\">0.229</span>, <span class=\"hljs-number\">0.224</span>, <span class=\"hljs-number\">0.225</span>])<br>                                     ]<br>                                 ))<br>train_loader = DataLoader(train_data, batch_size=<span class=\"hljs-number\">8</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>test_loader = DataLoader(test_data, batch_size=<span class=\"hljs-number\">8</span>, shuffle=<span class=\"hljs-literal\">True</span>)<br>index = <span class=\"hljs-number\">1253</span><br>img = test_data[index][<span class=\"hljs-number\">0</span>].numpy()<br>label = test_data[index][<span class=\"hljs-number\">1</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;label&quot;</span>, label)<br>plt.imshow(img[<span class=\"hljs-number\">0</span>, :])<br>plt.show()<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;len&quot;</span>, <span class=\"hljs-built_in\">len</span>(test_data))<br>count = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">2500</span>):<br>    label = test_data[i][<span class=\"hljs-number\">1</span>]<br>    <span class=\"hljs-keyword\">if</span> label == <span class=\"hljs-number\">1</span>:<br>        count += <span class=\"hljs-number\">1</span><br><br><span class=\"hljs-built_in\">print</span>(count)<br></code></pre></td></tr></table></figure>\n<pre><code>label 1\n</code></pre><img src=\"/2023/01/21/deep-learning-test05/output_4_1.png\" class=\"\" title=\"png\">\n<pre><code>len 2500\n1250\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;采用固定值方式迁移Resnet18网络&quot;&quot;&quot;</span><br>net = models.resnet18(pretrained=<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-keyword\">for</span> param <span class=\"hljs-keyword\">in</span> net.parameters():<br>    <span class=\"hljs-comment\"># 把参数冻结住，反向传播时不修改</span><br>    param.requires_grad = <span class=\"hljs-literal\">False</span><br>features = net.fc.in_features<br>net.fc = nn.Linear(features, <span class=\"hljs-number\">2</span>)<br>loss_fn = nn.CrossEntropyLoss()<br>opt = torch.optim.SGD(net.fc.parameters(), lr=<span class=\"hljs-number\">0.001</span>, momentum=<span class=\"hljs-number\">0.9</span>)<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;训练&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;开始训练&quot;</span>, time.ctime())<br><span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>):<br>    <span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_loader):<br>        x, y = data<br>        pred = net(x)<br>        loss = loss_fn(pred, y)<br><br>        opt.zero_grad()<br>        loss.backward()<br>        opt.step()<br>        <span class=\"hljs-keyword\">if</span> i % <span class=\"hljs-number\">25</span> == <span class=\"hljs-number\">0</span>:<br>            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;&#123;:.2f&#125;&quot;</span>.<span class=\"hljs-built_in\">format</span>(i / <span class=\"hljs-number\">28</span>), <span class=\"hljs-string\">&#x27;%&#x27;</span>)<br>    <span class=\"hljs-comment\"># if epoch % 2 == 0:</span><br>    <span class=\"hljs-built_in\">print</span>(loss.data)<br><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;训练结束&quot;</span>, time.ctime())<br></code></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;测试&quot;&quot;&quot;</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;测试&quot;</span>, time.ctime())<br>rights = <span class=\"hljs-number\">0</span><br>length = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> i, data <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(test_loader):<br>    x, y = data<br><br>    pred = net(x)<br>    <span class=\"hljs-comment\"># print(&quot;pred: &quot;, pred)</span><br>    <span class=\"hljs-comment\"># print(&quot;y: &quot;, y)</span><br>    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(y)):<br>        <span class=\"hljs-keyword\">if</span> pred[j][<span class=\"hljs-number\">0</span>] &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> y[j] == <span class=\"hljs-number\">0</span>:<br>            rights += <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">elif</span> pred[j][<span class=\"hljs-number\">1</span>] &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> y[j] == <span class=\"hljs-number\">1</span>:<br>            rights += <span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n<pre><code>测试 Tue Jan  4 16:42:56 2022\n正确数: 2245 准确率 89.8 %\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;正确数:&quot;</span>, rights, <span class=\"hljs-string\">&quot;准确率&#123;:1.0f&#125;&quot;</span>.<span class=\"hljs-built_in\">format</span>(rights / <span class=\"hljs-built_in\">len</span>(test_data) * <span class=\"hljs-number\">100</span>), <span class=\"hljs-string\">&quot;%&quot;</span>)<br></code></pre></td></tr></table></figure>\n<pre><code>正确数: 2245 准确率90 %\n</code></pre>"},{"title":"数字图像处理实验-图像灰度变化","date":"2022-09-20T10:32:15.000Z","cover":"/img/default_cover08.jpg","top_img":null,"_content":"# 图像灰度变换\n\n### 1、利用Opencv读取图像\n\n完成程度：使用opencv中的imread（）函数完成了对图片文件“lena.bmp”的读取，并将读取的内容存储至cv中的Mat矩阵中，最后使用imshow（）函数将该图片在窗口中显示出来。\n\n```C++\n//  1、利用OpenCV读取图像\nMat read_image(String path) {\n\tMat image = imread(path, IMREAD_GRAYSCALE);\n\tMat tmp = image.clone();\n\tif (image.empty()) {\n\t\tcout << \"Can't find the path.Please input the true path.\" << endl;\n\t\treturn image;\n\t}\n\timshow(\"lena.bmp\", tmp);\n\treturn tmp;\n}\n\n```\n\n\n\n### 2、灰度图像二值化处理\n\n完成程度：遍历内容1中读取的矩阵，设置阈值为128，将矩阵中大于128的像素设置为255，将矩阵中小于等于128的像素点设置为0，使用imshow（）函数输出该图片。\n\n```C++\n// 2、灰度图像二值化处理\nvoid binary_image(Mat tmp) {\n\t// 设置阈值为128\n\n\tMat image = Mat(tmp);\n\tfor (int i = 0; i < image.rows; i++) {\n\t\tuchar* p = image.ptr(i);\n\t\tfor (int j = 0; j < image.cols; j++) {\n\t\t\tif (p[j] > 128) {\n\t\t\t\tp[j] = 255;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tp[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\timshow(\"binary_image\", image);\n}\n\n```\n\n![image-20240302183456769](digital-image-test01/image-20240302183456769.png)\n\n\n\n### 3、灰度图像的对数变换\n\n完成程度：利用对数变化公式s=c*log(1+r)，对内容1的矩阵进行对数变化。调整不同的c的值[0.5,1,2,4,8]，对比不同的c值对图像变化的影响。\n\n```c++\n// 3、灰度图像的对数变换\nvoid log_reserve(Mat image) {\n\t// 对数变化的函数s = c*log(1+r)\n\n\tMat scrimage(image);\n\tMat new_image(scrimage.size(), scrimage.type());\n\t// 对原图像进行加1操作\n\tadd(scrimage, Scalar(1.0), scrimage);\n\t// 数据类型转化\n\tscrimage.convertTo(scrimage, CV_64F);\n\tfloat c[] = { 0.5, 1, 2, 4, 8 };\n\n\tfor (int s = 0; s < 5; s++) {\n\t\tlog(scrimage, new_image);\n\t\tnew_image = c[s] * new_image;\n\n\t\t//对图像进行归一化处理调整阈值至0-255\n\t\tnormalize(new_image, new_image, 0, 255, NORM_MINMAX);\n\t\tconvertScaleAbs(new_image, new_image);\n\t\tString str = \"c=\" + to_string(c[s]);\n\t\timshow(str, new_image);\n\t}\n}\n```\n\n\n\n![image-20240302183504049](digital-image-test01/image-20240302183504049.png)\n\n\n\n![image-20240302183514481](digital-image-test01/image-20240302183514481.png)\n\n\n\n### 4、灰度图像的伽马变换\n\n完成程度：利用伽马变化公式s=c*（r**γ）完成了对图像的转化，其中令c默认为1，调整γ值分别为[0.1,0.4,1,2.5,10]，对比不同伽马值对图像变换的影响。\n\n```c++\n// 4、灰度图像的伽马变换\nvoid gama_reserve(Mat image) {\n\t// gama变化的函数s = c*(r**gama)，取c=1\n\timage.convertTo(image, CV_64F, 1.0 / 255, 0);\n\tMat new_image(image.size(),image.type());\n\n\tfloat gama[] = { 0.10, 0.40, 1, 2.5, 10 };\n\n\tfor (int i = 0; i < 5; i++) {\n\t\tpow(image, gama[i], new_image);\n\t\tnew_image.convertTo(new_image, CV_8U, 255, 0);\n\t\tString str = \"gama=\" + to_string(gama[i]);\n\t\timshow(str, new_image);\n\t}\n}\n```\n\n\n\n![image-20240302183527447](digital-image-test01/image-20240302183527447.png)\n\n![image-20240302183542527](digital-image-test01/image-20240302183542527.png)\n\n\n\n### 5、彩色图像的补色变换\n\n完成程度：通过imread（）函数读取“lenaRGB.bmp”彩色图像，并输出到窗口。使用容器存储彩色图像的三个通道的值，对不同的通道进行求补操作，具体操作为，用255减去原始值。将求补后的三个通道进行合并处理，并显示合并后的图像。\n\n```c++\n// 5、彩色图像的补色变换\nvoid color_reverse(){\n\t// 读入彩色图像\n\tString path = \"photo/lenaRGB.bmp\";\n\tMat image = imread(path);\n\tif (image.empty()) {\n\t\tcout << \"Can't find the path.Please input the true path.\" << endl;\n\t\treturn;\n\t}\n\timshow(\"scr_image\", image);\n\t// 分离三通道，并保存\n\tvector<Mat> channels;\n\tsplit(image, channels);\n\t// 求补操作\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = 255 - channels[i];\n\t}\n\t// 合并通道\n\tMat new_image(image.size(), image.type());\n\tmerge(channels, new_image);\n\timshow(\"dir_image\", new_image);\n}\n```\n\n\n\n![image-20240302183548286](digital-image-test01/image-20240302183548286.png)\n\n","source":"_posts/digital-image-test01.md","raw":"---\ntitle: 数字图像处理实验-图像灰度变化\ncategories: 算法实践\ndate: 2022-09-20 18:32:15\ntags: [数字图像, OpenCV]\ncover:\ntop_img:\n---\n# 图像灰度变换\n\n### 1、利用Opencv读取图像\n\n完成程度：使用opencv中的imread（）函数完成了对图片文件“lena.bmp”的读取，并将读取的内容存储至cv中的Mat矩阵中，最后使用imshow（）函数将该图片在窗口中显示出来。\n\n```C++\n//  1、利用OpenCV读取图像\nMat read_image(String path) {\n\tMat image = imread(path, IMREAD_GRAYSCALE);\n\tMat tmp = image.clone();\n\tif (image.empty()) {\n\t\tcout << \"Can't find the path.Please input the true path.\" << endl;\n\t\treturn image;\n\t}\n\timshow(\"lena.bmp\", tmp);\n\treturn tmp;\n}\n\n```\n\n\n\n### 2、灰度图像二值化处理\n\n完成程度：遍历内容1中读取的矩阵，设置阈值为128，将矩阵中大于128的像素设置为255，将矩阵中小于等于128的像素点设置为0，使用imshow（）函数输出该图片。\n\n```C++\n// 2、灰度图像二值化处理\nvoid binary_image(Mat tmp) {\n\t// 设置阈值为128\n\n\tMat image = Mat(tmp);\n\tfor (int i = 0; i < image.rows; i++) {\n\t\tuchar* p = image.ptr(i);\n\t\tfor (int j = 0; j < image.cols; j++) {\n\t\t\tif (p[j] > 128) {\n\t\t\t\tp[j] = 255;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tp[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\timshow(\"binary_image\", image);\n}\n\n```\n\n![image-20240302183456769](digital-image-test01/image-20240302183456769.png)\n\n\n\n### 3、灰度图像的对数变换\n\n完成程度：利用对数变化公式s=c*log(1+r)，对内容1的矩阵进行对数变化。调整不同的c的值[0.5,1,2,4,8]，对比不同的c值对图像变化的影响。\n\n```c++\n// 3、灰度图像的对数变换\nvoid log_reserve(Mat image) {\n\t// 对数变化的函数s = c*log(1+r)\n\n\tMat scrimage(image);\n\tMat new_image(scrimage.size(), scrimage.type());\n\t// 对原图像进行加1操作\n\tadd(scrimage, Scalar(1.0), scrimage);\n\t// 数据类型转化\n\tscrimage.convertTo(scrimage, CV_64F);\n\tfloat c[] = { 0.5, 1, 2, 4, 8 };\n\n\tfor (int s = 0; s < 5; s++) {\n\t\tlog(scrimage, new_image);\n\t\tnew_image = c[s] * new_image;\n\n\t\t//对图像进行归一化处理调整阈值至0-255\n\t\tnormalize(new_image, new_image, 0, 255, NORM_MINMAX);\n\t\tconvertScaleAbs(new_image, new_image);\n\t\tString str = \"c=\" + to_string(c[s]);\n\t\timshow(str, new_image);\n\t}\n}\n```\n\n\n\n![image-20240302183504049](digital-image-test01/image-20240302183504049.png)\n\n\n\n![image-20240302183514481](digital-image-test01/image-20240302183514481.png)\n\n\n\n### 4、灰度图像的伽马变换\n\n完成程度：利用伽马变化公式s=c*（r**γ）完成了对图像的转化，其中令c默认为1，调整γ值分别为[0.1,0.4,1,2.5,10]，对比不同伽马值对图像变换的影响。\n\n```c++\n// 4、灰度图像的伽马变换\nvoid gama_reserve(Mat image) {\n\t// gama变化的函数s = c*(r**gama)，取c=1\n\timage.convertTo(image, CV_64F, 1.0 / 255, 0);\n\tMat new_image(image.size(),image.type());\n\n\tfloat gama[] = { 0.10, 0.40, 1, 2.5, 10 };\n\n\tfor (int i = 0; i < 5; i++) {\n\t\tpow(image, gama[i], new_image);\n\t\tnew_image.convertTo(new_image, CV_8U, 255, 0);\n\t\tString str = \"gama=\" + to_string(gama[i]);\n\t\timshow(str, new_image);\n\t}\n}\n```\n\n\n\n![image-20240302183527447](digital-image-test01/image-20240302183527447.png)\n\n![image-20240302183542527](digital-image-test01/image-20240302183542527.png)\n\n\n\n### 5、彩色图像的补色变换\n\n完成程度：通过imread（）函数读取“lenaRGB.bmp”彩色图像，并输出到窗口。使用容器存储彩色图像的三个通道的值，对不同的通道进行求补操作，具体操作为，用255减去原始值。将求补后的三个通道进行合并处理，并显示合并后的图像。\n\n```c++\n// 5、彩色图像的补色变换\nvoid color_reverse(){\n\t// 读入彩色图像\n\tString path = \"photo/lenaRGB.bmp\";\n\tMat image = imread(path);\n\tif (image.empty()) {\n\t\tcout << \"Can't find the path.Please input the true path.\" << endl;\n\t\treturn;\n\t}\n\timshow(\"scr_image\", image);\n\t// 分离三通道，并保存\n\tvector<Mat> channels;\n\tsplit(image, channels);\n\t// 求补操作\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = 255 - channels[i];\n\t}\n\t// 合并通道\n\tMat new_image(image.size(), image.type());\n\tmerge(channels, new_image);\n\timshow(\"dir_image\", new_image);\n}\n```\n\n\n\n![image-20240302183548286](digital-image-test01/image-20240302183548286.png)\n\n","slug":"digital-image-test01","published":1,"updated":"2024-06-05T09:03:03.699Z","comments":1,"layout":"post","photos":[],"_id":"clyfintts001u08jvbi0tdlr5","content":"<h1 id=\"图像灰度变换\"><a href=\"#图像灰度变换\" class=\"headerlink\" title=\"图像灰度变换\"></a>图像灰度变换</h1><h3 id=\"1、利用Opencv读取图像\"><a href=\"#1、利用Opencv读取图像\" class=\"headerlink\" title=\"1、利用Opencv读取图像\"></a>1、利用Opencv读取图像</h3><p>完成程度：使用opencv中的imread（）函数完成了对图片文件“lena.bmp”的读取，并将读取的内容存储至cv中的Mat矩阵中，最后使用imshow（）函数将该图片在窗口中显示出来。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">//  1、利用OpenCV读取图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">read_image</span><span class=\"hljs-params\">(String path)</span> </span>&#123;<br>\tMat image = <span class=\"hljs-built_in\">imread</span>(path, IMREAD_GRAYSCALE);<br>\tMat tmp = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-keyword\">if</span> (image.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>\t\tcout &lt;&lt; <span class=\"hljs-string\">&quot;Can&#x27;t find the path.Please input the true path.&quot;</span> &lt;&lt; endl;<br>\t\t<span class=\"hljs-keyword\">return</span> image;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;lena.bmp&quot;</span>, tmp);<br>\t<span class=\"hljs-keyword\">return</span> tmp;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"2、灰度图像二值化处理\"><a href=\"#2、灰度图像二值化处理\" class=\"headerlink\" title=\"2、灰度图像二值化处理\"></a>2、灰度图像二值化处理</h3><p>完成程度：遍历内容1中读取的矩阵，设置阈值为128，将矩阵中大于128的像素设置为255，将矩阵中小于等于128的像素点设置为0，使用imshow（）函数输出该图片。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 2、灰度图像二值化处理</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">binary_image</span><span class=\"hljs-params\">(Mat tmp)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 设置阈值为128</span><br><br>\tMat image = <span class=\"hljs-built_in\">Mat</span>(tmp);<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; image.rows; i++) &#123;<br>\t\tuchar* p = image.<span class=\"hljs-built_in\">ptr</span>(i);<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; image.cols; j++) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (p[j] &gt; <span class=\"hljs-number\">128</span>) &#123;<br>\t\t\t\tp[j] = <span class=\"hljs-number\">255</span>;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">else</span> &#123;<br>\t\t\t\tp[j] = <span class=\"hljs-number\">0</span>;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;binary_image&quot;</span>, image);<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183456769.png\" class=\"\" title=\"image-20240302183456769\">\n<h3 id=\"3、灰度图像的对数变换\"><a href=\"#3、灰度图像的对数变换\" class=\"headerlink\" title=\"3、灰度图像的对数变换\"></a>3、灰度图像的对数变换</h3><p>完成程度：利用对数变化公式s=c*log(1+r)，对内容1的矩阵进行对数变化。调整不同的c的值[0.5,1,2,4,8]，对比不同的c值对图像变化的影响。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、灰度图像的对数变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">log_reserve</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 对数变化的函数s = c*log(1+r)</span><br><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">scrimage</span><span class=\"hljs-params\">(image)</span></span>;<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(scrimage.size(), scrimage.type())</span></span>;<br>\t<span class=\"hljs-comment\">// 对原图像进行加1操作</span><br>\t<span class=\"hljs-built_in\">add</span>(scrimage, <span class=\"hljs-built_in\">Scalar</span>(<span class=\"hljs-number\">1.0</span>), scrimage);<br>\t<span class=\"hljs-comment\">// 数据类型转化</span><br>\tscrimage.<span class=\"hljs-built_in\">convertTo</span>(scrimage, CV_64F);<br>\t<span class=\"hljs-type\">float</span> c[] = &#123; <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; <span class=\"hljs-number\">5</span>; s++) &#123;<br>\t\t<span class=\"hljs-built_in\">log</span>(scrimage, new_image);<br>\t\tnew_image = c[s] * new_image;<br><br>\t\t<span class=\"hljs-comment\">//对图像进行归一化处理调整阈值至0-255</span><br>\t\t<span class=\"hljs-built_in\">normalize</span>(new_image, new_image, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>, NORM_MINMAX);<br>\t\t<span class=\"hljs-built_in\">convertScaleAbs</span>(new_image, new_image);<br>\t\tString str = <span class=\"hljs-string\">&quot;c=&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(c[s]);<br>\t\t<span class=\"hljs-built_in\">imshow</span>(str, new_image);<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183504049.png\" class=\"\" title=\"image-20240302183504049\">\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183514481.png\" class=\"\" title=\"image-20240302183514481\">\n<h3 id=\"4、灰度图像的伽马变换\"><a href=\"#4、灰度图像的伽马变换\" class=\"headerlink\" title=\"4、灰度图像的伽马变换\"></a>4、灰度图像的伽马变换</h3><p>完成程度：利用伽马变化公式s=c<em>（r*</em>γ）完成了对图像的转化，其中令c默认为1，调整γ值分别为[0.1,0.4,1,2.5,10]，对比不同伽马值对图像变换的影响。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 4、灰度图像的伽马变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">gama_reserve</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// gama变化的函数s = c*(r**gama)，取c=1</span><br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_64F, <span class=\"hljs-number\">1.0</span> / <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">0</span>);<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(image.size(),image.type())</span></span>;<br><br>\t<span class=\"hljs-type\">float</span> gama[] = &#123; <span class=\"hljs-number\">0.10</span>, <span class=\"hljs-number\">0.40</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2.5</span>, <span class=\"hljs-number\">10</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) &#123;<br>\t\t<span class=\"hljs-built_in\">pow</span>(image, gama[i], new_image);<br>\t\tnew_image.<span class=\"hljs-built_in\">convertTo</span>(new_image, CV_8U, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">0</span>);<br>\t\tString str = <span class=\"hljs-string\">&quot;gama=&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(gama[i]);<br>\t\t<span class=\"hljs-built_in\">imshow</span>(str, new_image);<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183527447.png\" class=\"\" title=\"image-20240302183527447\">\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183542527.png\" class=\"\" title=\"image-20240302183542527\">\n<h3 id=\"5、彩色图像的补色变换\"><a href=\"#5、彩色图像的补色变换\" class=\"headerlink\" title=\"5、彩色图像的补色变换\"></a>5、彩色图像的补色变换</h3><p>完成程度：通过imread（）函数读取“lenaRGB.bmp”彩色图像，并输出到窗口。使用容器存储彩色图像的三个通道的值，对不同的通道进行求补操作，具体操作为，用255减去原始值。将求补后的三个通道进行合并处理，并显示合并后的图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 5、彩色图像的补色变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">color_reverse</span><span class=\"hljs-params\">()</span></span>&#123;<br>\t<span class=\"hljs-comment\">// 读入彩色图像</span><br>\tString path = <span class=\"hljs-string\">&quot;photo/lenaRGB.bmp&quot;</span>;<br>\tMat image = <span class=\"hljs-built_in\">imread</span>(path);<br>\t<span class=\"hljs-keyword\">if</span> (image.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>\t\tcout &lt;&lt; <span class=\"hljs-string\">&quot;Can&#x27;t find the path.Please input the true path.&quot;</span> &lt;&lt; endl;<br>\t\t<span class=\"hljs-keyword\">return</span>;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;scr_image&quot;</span>, image);<br>\t<span class=\"hljs-comment\">// 分离三通道，并保存</span><br>\tvector&lt;Mat&gt; channels;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\t<span class=\"hljs-comment\">// 求补操作</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-number\">255</span> - channels[i];<br>\t&#125;<br>\t<span class=\"hljs-comment\">// 合并通道</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(image.size(), image.type())</span></span>;<br>\t<span class=\"hljs-built_in\">merge</span>(channels, new_image);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;dir_image&quot;</span>, new_image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183548286.png\" class=\"\" title=\"image-20240302183548286\">\n","cover_type":"img","excerpt":"","more":"<h1 id=\"图像灰度变换\"><a href=\"#图像灰度变换\" class=\"headerlink\" title=\"图像灰度变换\"></a>图像灰度变换</h1><h3 id=\"1、利用Opencv读取图像\"><a href=\"#1、利用Opencv读取图像\" class=\"headerlink\" title=\"1、利用Opencv读取图像\"></a>1、利用Opencv读取图像</h3><p>完成程度：使用opencv中的imread（）函数完成了对图片文件“lena.bmp”的读取，并将读取的内容存储至cv中的Mat矩阵中，最后使用imshow（）函数将该图片在窗口中显示出来。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">//  1、利用OpenCV读取图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">read_image</span><span class=\"hljs-params\">(String path)</span> </span>&#123;<br>\tMat image = <span class=\"hljs-built_in\">imread</span>(path, IMREAD_GRAYSCALE);<br>\tMat tmp = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-keyword\">if</span> (image.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>\t\tcout &lt;&lt; <span class=\"hljs-string\">&quot;Can&#x27;t find the path.Please input the true path.&quot;</span> &lt;&lt; endl;<br>\t\t<span class=\"hljs-keyword\">return</span> image;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;lena.bmp&quot;</span>, tmp);<br>\t<span class=\"hljs-keyword\">return</span> tmp;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"2、灰度图像二值化处理\"><a href=\"#2、灰度图像二值化处理\" class=\"headerlink\" title=\"2、灰度图像二值化处理\"></a>2、灰度图像二值化处理</h3><p>完成程度：遍历内容1中读取的矩阵，设置阈值为128，将矩阵中大于128的像素设置为255，将矩阵中小于等于128的像素点设置为0，使用imshow（）函数输出该图片。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 2、灰度图像二值化处理</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">binary_image</span><span class=\"hljs-params\">(Mat tmp)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 设置阈值为128</span><br><br>\tMat image = <span class=\"hljs-built_in\">Mat</span>(tmp);<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; image.rows; i++) &#123;<br>\t\tuchar* p = image.<span class=\"hljs-built_in\">ptr</span>(i);<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; image.cols; j++) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (p[j] &gt; <span class=\"hljs-number\">128</span>) &#123;<br>\t\t\t\tp[j] = <span class=\"hljs-number\">255</span>;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">else</span> &#123;<br>\t\t\t\tp[j] = <span class=\"hljs-number\">0</span>;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;binary_image&quot;</span>, image);<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183456769.png\" class=\"\" title=\"image-20240302183456769\">\n<h3 id=\"3、灰度图像的对数变换\"><a href=\"#3、灰度图像的对数变换\" class=\"headerlink\" title=\"3、灰度图像的对数变换\"></a>3、灰度图像的对数变换</h3><p>完成程度：利用对数变化公式s=c*log(1+r)，对内容1的矩阵进行对数变化。调整不同的c的值[0.5,1,2,4,8]，对比不同的c值对图像变化的影响。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、灰度图像的对数变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">log_reserve</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 对数变化的函数s = c*log(1+r)</span><br><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">scrimage</span><span class=\"hljs-params\">(image)</span></span>;<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(scrimage.size(), scrimage.type())</span></span>;<br>\t<span class=\"hljs-comment\">// 对原图像进行加1操作</span><br>\t<span class=\"hljs-built_in\">add</span>(scrimage, <span class=\"hljs-built_in\">Scalar</span>(<span class=\"hljs-number\">1.0</span>), scrimage);<br>\t<span class=\"hljs-comment\">// 数据类型转化</span><br>\tscrimage.<span class=\"hljs-built_in\">convertTo</span>(scrimage, CV_64F);<br>\t<span class=\"hljs-type\">float</span> c[] = &#123; <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">8</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; <span class=\"hljs-number\">5</span>; s++) &#123;<br>\t\t<span class=\"hljs-built_in\">log</span>(scrimage, new_image);<br>\t\tnew_image = c[s] * new_image;<br><br>\t\t<span class=\"hljs-comment\">//对图像进行归一化处理调整阈值至0-255</span><br>\t\t<span class=\"hljs-built_in\">normalize</span>(new_image, new_image, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>, NORM_MINMAX);<br>\t\t<span class=\"hljs-built_in\">convertScaleAbs</span>(new_image, new_image);<br>\t\tString str = <span class=\"hljs-string\">&quot;c=&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(c[s]);<br>\t\t<span class=\"hljs-built_in\">imshow</span>(str, new_image);<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183504049.png\" class=\"\" title=\"image-20240302183504049\">\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183514481.png\" class=\"\" title=\"image-20240302183514481\">\n<h3 id=\"4、灰度图像的伽马变换\"><a href=\"#4、灰度图像的伽马变换\" class=\"headerlink\" title=\"4、灰度图像的伽马变换\"></a>4、灰度图像的伽马变换</h3><p>完成程度：利用伽马变化公式s=c<em>（r*</em>γ）完成了对图像的转化，其中令c默认为1，调整γ值分别为[0.1,0.4,1,2.5,10]，对比不同伽马值对图像变换的影响。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 4、灰度图像的伽马变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">gama_reserve</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// gama变化的函数s = c*(r**gama)，取c=1</span><br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_64F, <span class=\"hljs-number\">1.0</span> / <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">0</span>);<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(image.size(),image.type())</span></span>;<br><br>\t<span class=\"hljs-type\">float</span> gama[] = &#123; <span class=\"hljs-number\">0.10</span>, <span class=\"hljs-number\">0.40</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2.5</span>, <span class=\"hljs-number\">10</span> &#125;;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) &#123;<br>\t\t<span class=\"hljs-built_in\">pow</span>(image, gama[i], new_image);<br>\t\tnew_image.<span class=\"hljs-built_in\">convertTo</span>(new_image, CV_8U, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">0</span>);<br>\t\tString str = <span class=\"hljs-string\">&quot;gama=&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(gama[i]);<br>\t\t<span class=\"hljs-built_in\">imshow</span>(str, new_image);<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183527447.png\" class=\"\" title=\"image-20240302183527447\">\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183542527.png\" class=\"\" title=\"image-20240302183542527\">\n<h3 id=\"5、彩色图像的补色变换\"><a href=\"#5、彩色图像的补色变换\" class=\"headerlink\" title=\"5、彩色图像的补色变换\"></a>5、彩色图像的补色变换</h3><p>完成程度：通过imread（）函数读取“lenaRGB.bmp”彩色图像，并输出到窗口。使用容器存储彩色图像的三个通道的值，对不同的通道进行求补操作，具体操作为，用255减去原始值。将求补后的三个通道进行合并处理，并显示合并后的图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 5、彩色图像的补色变换</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">color_reverse</span><span class=\"hljs-params\">()</span></span>&#123;<br>\t<span class=\"hljs-comment\">// 读入彩色图像</span><br>\tString path = <span class=\"hljs-string\">&quot;photo/lenaRGB.bmp&quot;</span>;<br>\tMat image = <span class=\"hljs-built_in\">imread</span>(path);<br>\t<span class=\"hljs-keyword\">if</span> (image.<span class=\"hljs-built_in\">empty</span>()) &#123;<br>\t\tcout &lt;&lt; <span class=\"hljs-string\">&quot;Can&#x27;t find the path.Please input the true path.&quot;</span> &lt;&lt; endl;<br>\t\t<span class=\"hljs-keyword\">return</span>;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;scr_image&quot;</span>, image);<br>\t<span class=\"hljs-comment\">// 分离三通道，并保存</span><br>\tvector&lt;Mat&gt; channels;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\t<span class=\"hljs-comment\">// 求补操作</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-number\">255</span> - channels[i];<br>\t&#125;<br>\t<span class=\"hljs-comment\">// 合并通道</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">new_image</span><span class=\"hljs-params\">(image.size(), image.type())</span></span>;<br>\t<span class=\"hljs-built_in\">merge</span>(channels, new_image);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;dir_image&quot;</span>, new_image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/20/digital-image-test01/image-20240302183548286.png\" class=\"\" title=\"image-20240302183548286\">\n"},{"title":"数字图像处理实验-直方图均衡","date":"2022-09-23T10:38:32.000Z","cover":"/img/default_cover07.jpg","top_img":null,"_content":"### 1、计算灰度图像的归一化直方图\n\n具体内容：利用OpenCV对图像像素进行操作，计算归一化直方图，并在窗口中以图形的方式显示出来。\n\n完成程度：读入图片，统计不同灰度级的像素个数，并存入大小为256的数组中。设置背景画布的大小，并根据数组中的最大值最小值，将不同灰度级像素点的个数映射到画布当中，通过使用柱线的方式，绘制直方图。\n\n```C++\n// 1、计算灰度图像的归一化直方图，并绘制图像\nvoid nomalization(Mat src_image, String name) {\n\tMat image = src_image;\n\tdouble gray_scale[256] = { 0 };\n\n\tint row = image.rows;\n\tint col = image.cols;\n\n\t// 统计不同灰度级的像素个数\n\tfor (int i = 0; i < row; i++) {\n\t\tfor (int j = 0; j < col; j++) {\n\t\t\tgray_scale[int(image.at<uchar>(i, j))] = gray_scale[int(image.at<uchar>(i, j))] + 1;\n\t\t}\n\t}\n\n\t// 绘制直方图\n\t// 定义背景图像灰度为255\n\tint length = 500;\n\tint heigth = 600;\n\tint reflection = 500;\n\t// 最大值映射到500\n\tMat hist_image = Mat(heigth, length, CV_8U, Scalar(255));\n\n\t// 对灰度级进行归一化处理，先求出最大值，最小值默认为0\n\tdouble max = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tif ((gray_scale[i]) > max) {\n\t\t\tmax = gray_scale[i];\n\t\t}\n\t}\n\t// 将像素点的数量映射到画布上\n\tfor (int i = 0; i < 256; ++i) {\n\t\tgray_scale[i] = int(gray_scale[i] * reflection / max);\n\t}\n\n\t// 直线绘制\n\tfor (int i = 0; i < 256; ++i) {\n\t\tline(hist_image, Point(i * 2, heigth), Point(i * 2, heigth - gray_scale[i]), Scalar::all(0));\n\t\tline(hist_image, Point(i * 2 + 1, heigth), Point(i * 2 + 1, heigth - gray_scale[i]), Scalar::all(0));\n\t}\n\n\timshow(name, hist_image);\n}\n```\n\n![image-20240302184201998](digital-image-test02/image-20240302184201998.png)\n\n### 2、灰度图像直方图均衡处理\n\n具体内容:通过计算归一化直方图，设计算法实现直方图均衡化处理。\n\n完成程度：存储灰度图像不同灰度级的像素个数，计算不同灰度级的概率密度。利用公式Sk = （L-1）*[p(r0)到p(rk)的和]对不同灰度进行离散化，完成不同灰度的映射，将映射表存入到数组当中。遍历原始灰度图像的像素点，对照灰度映射表，完成灰度级的转化。\n\n```c++\n// 2、灰度图像直方图均衡化处理\n// 直方图均衡化的表达式为：Sk = （L-1）*[p(r0)到p(rk)的和]\nMat average_image(Mat src_image) {\n\tMat image = src_image;\n\tMat result = src_image;\n\tint row = image.rows;\n\tint col = image.cols;\n\tint all_n = row * col;\n\tint gray_table[256] = { 0 };\n\n\t// 存储不同灰度的数量\n\tdouble gray_scale[256] = { 0 };\n\n\t// 计算不同灰度的概率密度\n\tfor (int i = 0; i < row; ++i) {\n\t\tfor (int j = 0; j < col; j++) {\n\t\t\tgray_scale[image.at<uchar>(i, j)] = gray_scale[image.at<uchar>(i, j)] + 1;\n\t\t}\n\t\t\n\t}\n\n\tfor (int i = 0; i < 256; ++i) {\n\t\tgray_scale[i] = gray_scale[i] / all_n;\n\t}\n\n\t// 将不同的灰度离散化\n\tfor (int i = 0; i < 256; ++i) {\n\t\t// 求概率密度的和\n\t\tfloat sum_midu = 0;\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tsum_midu = sum_midu + gray_scale[j];\n\t\t}\n\t\tgray_table[i] = int(255 * sum_midu + 0.5);\n\t\tif (gray_table[i] > 255) {\n\t\t\tgray_table[i] = 255;\n\t\t}\n\t}\n\n\t// 完成灰度转换\n\tfor (int i = 0; i < row; i++) {\n\t\tfor (int j = 0; j < col; j++) {\n\n\t\t\tresult.at<uchar>(i, j) = gray_table[image.at<uchar>(i, j)];\n\t\t}\n\t}\n\n\treturn result;\n}\n```\n\n过亮图像\n\n![image-20240302184304968](digital-image-test02/image-20240302184304968.png)\n\n处理过后\n\n![](digital-image-test02/image-20240302184311057.png)\n\n \n\n过暗图像\n\n![](digital-image-test02/image-20240302184323543.png)\n\n处理过后  \n\n![](digital-image-test02/image-20240302184327658.png)\n\n### 3、彩色图像直方图均衡化处理\n\n具体内容:在灰度图像直方图均衡处理的基础上实现彩色直方图均衡处理。\n\n完成程度：将彩色图像的三个颜色通道进行分离并存储在Mat矩阵当中，调用内容2中的直方图均衡化函数，分别对三个通道的直方图进行均衡化处理，处理完毕以后对三个通道进行合并，最终显示该图像。\n\n```c++\n// 3、彩色图像直方图均衡化处理\n// 将彩色图像中的三个通道提取出来\n// 分别做直方图均衡化处理，然后再进行合并\nMat color_average(Mat src) {\n\n\tMat image = src;\n\tvector<Mat>channels;\n\tcv::split(image, channels);\n\n\tchannels[0] = average_image(channels[0]);\n\tchannels[1] = average_image(channels[1]);\n\tchannels[2] = average_image(channels[2]);\n\n\tcv::merge(channels, image);\n\n\t//imshow(\"color_image\", image);\n\treturn image;\n}\n```\n\n曝光不足图像处理\n\n![image-20240302184347311](digital-image-test02/image-20240302184347311.png)\n\n曝光过度图像处理\n\n![image-20240302184359230](digital-image-test02/image-20240302184359230.png)","source":"_posts/digital-image-test02.md","raw":"---\ntitle: 数字图像处理实验-直方图均衡\ncategories: 算法实践\ndate: 2022-09-23 18:38:32\ntags: [数字图像, OpenCV]\ncover:\ntop_img:\n---\n### 1、计算灰度图像的归一化直方图\n\n具体内容：利用OpenCV对图像像素进行操作，计算归一化直方图，并在窗口中以图形的方式显示出来。\n\n完成程度：读入图片，统计不同灰度级的像素个数，并存入大小为256的数组中。设置背景画布的大小，并根据数组中的最大值最小值，将不同灰度级像素点的个数映射到画布当中，通过使用柱线的方式，绘制直方图。\n\n```C++\n// 1、计算灰度图像的归一化直方图，并绘制图像\nvoid nomalization(Mat src_image, String name) {\n\tMat image = src_image;\n\tdouble gray_scale[256] = { 0 };\n\n\tint row = image.rows;\n\tint col = image.cols;\n\n\t// 统计不同灰度级的像素个数\n\tfor (int i = 0; i < row; i++) {\n\t\tfor (int j = 0; j < col; j++) {\n\t\t\tgray_scale[int(image.at<uchar>(i, j))] = gray_scale[int(image.at<uchar>(i, j))] + 1;\n\t\t}\n\t}\n\n\t// 绘制直方图\n\t// 定义背景图像灰度为255\n\tint length = 500;\n\tint heigth = 600;\n\tint reflection = 500;\n\t// 最大值映射到500\n\tMat hist_image = Mat(heigth, length, CV_8U, Scalar(255));\n\n\t// 对灰度级进行归一化处理，先求出最大值，最小值默认为0\n\tdouble max = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tif ((gray_scale[i]) > max) {\n\t\t\tmax = gray_scale[i];\n\t\t}\n\t}\n\t// 将像素点的数量映射到画布上\n\tfor (int i = 0; i < 256; ++i) {\n\t\tgray_scale[i] = int(gray_scale[i] * reflection / max);\n\t}\n\n\t// 直线绘制\n\tfor (int i = 0; i < 256; ++i) {\n\t\tline(hist_image, Point(i * 2, heigth), Point(i * 2, heigth - gray_scale[i]), Scalar::all(0));\n\t\tline(hist_image, Point(i * 2 + 1, heigth), Point(i * 2 + 1, heigth - gray_scale[i]), Scalar::all(0));\n\t}\n\n\timshow(name, hist_image);\n}\n```\n\n![image-20240302184201998](digital-image-test02/image-20240302184201998.png)\n\n### 2、灰度图像直方图均衡处理\n\n具体内容:通过计算归一化直方图，设计算法实现直方图均衡化处理。\n\n完成程度：存储灰度图像不同灰度级的像素个数，计算不同灰度级的概率密度。利用公式Sk = （L-1）*[p(r0)到p(rk)的和]对不同灰度进行离散化，完成不同灰度的映射，将映射表存入到数组当中。遍历原始灰度图像的像素点，对照灰度映射表，完成灰度级的转化。\n\n```c++\n// 2、灰度图像直方图均衡化处理\n// 直方图均衡化的表达式为：Sk = （L-1）*[p(r0)到p(rk)的和]\nMat average_image(Mat src_image) {\n\tMat image = src_image;\n\tMat result = src_image;\n\tint row = image.rows;\n\tint col = image.cols;\n\tint all_n = row * col;\n\tint gray_table[256] = { 0 };\n\n\t// 存储不同灰度的数量\n\tdouble gray_scale[256] = { 0 };\n\n\t// 计算不同灰度的概率密度\n\tfor (int i = 0; i < row; ++i) {\n\t\tfor (int j = 0; j < col; j++) {\n\t\t\tgray_scale[image.at<uchar>(i, j)] = gray_scale[image.at<uchar>(i, j)] + 1;\n\t\t}\n\t\t\n\t}\n\n\tfor (int i = 0; i < 256; ++i) {\n\t\tgray_scale[i] = gray_scale[i] / all_n;\n\t}\n\n\t// 将不同的灰度离散化\n\tfor (int i = 0; i < 256; ++i) {\n\t\t// 求概率密度的和\n\t\tfloat sum_midu = 0;\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tsum_midu = sum_midu + gray_scale[j];\n\t\t}\n\t\tgray_table[i] = int(255 * sum_midu + 0.5);\n\t\tif (gray_table[i] > 255) {\n\t\t\tgray_table[i] = 255;\n\t\t}\n\t}\n\n\t// 完成灰度转换\n\tfor (int i = 0; i < row; i++) {\n\t\tfor (int j = 0; j < col; j++) {\n\n\t\t\tresult.at<uchar>(i, j) = gray_table[image.at<uchar>(i, j)];\n\t\t}\n\t}\n\n\treturn result;\n}\n```\n\n过亮图像\n\n![image-20240302184304968](digital-image-test02/image-20240302184304968.png)\n\n处理过后\n\n![](digital-image-test02/image-20240302184311057.png)\n\n \n\n过暗图像\n\n![](digital-image-test02/image-20240302184323543.png)\n\n处理过后  \n\n![](digital-image-test02/image-20240302184327658.png)\n\n### 3、彩色图像直方图均衡化处理\n\n具体内容:在灰度图像直方图均衡处理的基础上实现彩色直方图均衡处理。\n\n完成程度：将彩色图像的三个颜色通道进行分离并存储在Mat矩阵当中，调用内容2中的直方图均衡化函数，分别对三个通道的直方图进行均衡化处理，处理完毕以后对三个通道进行合并，最终显示该图像。\n\n```c++\n// 3、彩色图像直方图均衡化处理\n// 将彩色图像中的三个通道提取出来\n// 分别做直方图均衡化处理，然后再进行合并\nMat color_average(Mat src) {\n\n\tMat image = src;\n\tvector<Mat>channels;\n\tcv::split(image, channels);\n\n\tchannels[0] = average_image(channels[0]);\n\tchannels[1] = average_image(channels[1]);\n\tchannels[2] = average_image(channels[2]);\n\n\tcv::merge(channels, image);\n\n\t//imshow(\"color_image\", image);\n\treturn image;\n}\n```\n\n曝光不足图像处理\n\n![image-20240302184347311](digital-image-test02/image-20240302184347311.png)\n\n曝光过度图像处理\n\n![image-20240302184359230](digital-image-test02/image-20240302184359230.png)","slug":"digital-image-test02","published":1,"updated":"2024-06-05T09:03:03.705Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttt001y08jv7swa13c3","content":"<h3 id=\"1、计算灰度图像的归一化直方图\"><a href=\"#1、计算灰度图像的归一化直方图\" class=\"headerlink\" title=\"1、计算灰度图像的归一化直方图\"></a>1、计算灰度图像的归一化直方图</h3><p>具体内容：利用OpenCV对图像像素进行操作，计算归一化直方图，并在窗口中以图形的方式显示出来。</p>\n<p>完成程度：读入图片，统计不同灰度级的像素个数，并存入大小为256的数组中。设置背景画布的大小，并根据数组中的最大值最小值，将不同灰度级像素点的个数映射到画布当中，通过使用柱线的方式，绘制直方图。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 1、计算灰度图像的归一化直方图，并绘制图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">nomalization</span><span class=\"hljs-params\">(Mat src_image, String name)</span> </span>&#123;<br>\tMat image = src_image;<br>\t<span class=\"hljs-type\">double</span> gray_scale[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br><br>\t<span class=\"hljs-comment\">// 统计不同灰度级的像素个数</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; i++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br>\t\t\tgray_scale[<span class=\"hljs-built_in\">int</span>(image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j))] = gray_scale[<span class=\"hljs-built_in\">int</span>(image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j))] + <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 绘制直方图</span><br>\t<span class=\"hljs-comment\">// 定义背景图像灰度为255</span><br>\t<span class=\"hljs-type\">int</span> length = <span class=\"hljs-number\">500</span>;<br>\t<span class=\"hljs-type\">int</span> heigth = <span class=\"hljs-number\">600</span>;<br>\t<span class=\"hljs-type\">int</span> reflection = <span class=\"hljs-number\">500</span>;<br>\t<span class=\"hljs-comment\">// 最大值映射到500</span><br>\tMat hist_image = <span class=\"hljs-built_in\">Mat</span>(heigth, length, CV_8U, <span class=\"hljs-built_in\">Scalar</span>(<span class=\"hljs-number\">255</span>));<br><br>\t<span class=\"hljs-comment\">// 对灰度级进行归一化处理，先求出最大值，最小值默认为0</span><br>\t<span class=\"hljs-type\">double</span> max = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">if</span> ((gray_scale[i]) &gt; max) &#123;<br>\t\t\tmax = gray_scale[i];<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-comment\">// 将像素点的数量映射到画布上</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tgray_scale[i] = <span class=\"hljs-built_in\">int</span>(gray_scale[i] * reflection / max);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 直线绘制</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-built_in\">line</span>(hist_image, <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span>, heigth), <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span>, heigth - gray_scale[i]), Scalar::<span class=\"hljs-built_in\">all</span>(<span class=\"hljs-number\">0</span>));<br>\t\t<span class=\"hljs-built_in\">line</span>(hist_image, <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span> + <span class=\"hljs-number\">1</span>, heigth), <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span> + <span class=\"hljs-number\">1</span>, heigth - gray_scale[i]), Scalar::<span class=\"hljs-built_in\">all</span>(<span class=\"hljs-number\">0</span>));<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(name, hist_image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184201998.png\" class=\"\" title=\"image-20240302184201998\">\n<h3 id=\"2、灰度图像直方图均衡处理\"><a href=\"#2、灰度图像直方图均衡处理\" class=\"headerlink\" title=\"2、灰度图像直方图均衡处理\"></a>2、灰度图像直方图均衡处理</h3><p>具体内容:通过计算归一化直方图，设计算法实现直方图均衡化处理。</p>\n<p>完成程度：存储灰度图像不同灰度级的像素个数，计算不同灰度级的概率密度。利用公式Sk = （L-1）*[p(r0)到p(rk)的和]对不同灰度进行离散化，完成不同灰度的映射，将映射表存入到数组当中。遍历原始灰度图像的像素点，对照灰度映射表，完成灰度级的转化。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 2、灰度图像直方图均衡化处理</span><br><span class=\"hljs-comment\">// 直方图均衡化的表达式为：Sk = （L-1）*[p(r0)到p(rk)的和]</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_image</span><span class=\"hljs-params\">(Mat src_image)</span> </span>&#123;<br>\tMat image = src_image;<br>\tMat result = src_image;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-type\">int</span> all_n = row * col;<br>\t<span class=\"hljs-type\">int</span> gray_table[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-comment\">// 存储不同灰度的数量</span><br>\t<span class=\"hljs-type\">double</span> gray_scale[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-comment\">// 计算不同灰度的概率密度</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br>\t\t\tgray_scale[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] = gray_scale[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] + <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t\t<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tgray_scale[i] = gray_scale[i] / all_n;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 将不同的灰度离散化</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-comment\">// 求概率密度的和</span><br>\t\t<span class=\"hljs-type\">float</span> sum_midu = <span class=\"hljs-number\">0</span>;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; i; j++) &#123;<br>\t\t\tsum_midu = sum_midu + gray_scale[j];<br>\t\t&#125;<br>\t\tgray_table[i] = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-number\">255</span> * sum_midu + <span class=\"hljs-number\">0.5</span>);<br>\t\t<span class=\"hljs-keyword\">if</span> (gray_table[i] &gt; <span class=\"hljs-number\">255</span>) &#123;<br>\t\t\tgray_table[i] = <span class=\"hljs-number\">255</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 完成灰度转换</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; i++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br><br>\t\t\tresult.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = gray_table[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)];<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>过亮图像</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184304968.png\" class=\"\" title=\"image-20240302184304968\">\n<p>处理过后</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184311057.png\" class=\"\">\n<p>过暗图像</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184323543.png\" class=\"\">\n<p>处理过后  </p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184327658.png\" class=\"\">\n<h3 id=\"3、彩色图像直方图均衡化处理\"><a href=\"#3、彩色图像直方图均衡化处理\" class=\"headerlink\" title=\"3、彩色图像直方图均衡化处理\"></a>3、彩色图像直方图均衡化处理</h3><p>具体内容:在灰度图像直方图均衡处理的基础上实现彩色直方图均衡处理。</p>\n<p>完成程度：将彩色图像的三个颜色通道进行分离并存储在Mat矩阵当中，调用内容2中的直方图均衡化函数，分别对三个通道的直方图进行均衡化处理，处理完毕以后对三个通道进行合并，最终显示该图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、彩色图像直方图均衡化处理</span><br><span class=\"hljs-comment\">// 将彩色图像中的三个通道提取出来</span><br><span class=\"hljs-comment\">// 分别做直方图均衡化处理，然后再进行合并</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">color_average</span><span class=\"hljs-params\">(Mat src)</span> </span>&#123;<br><br>\tMat image = src;<br>\tvector&lt;Mat&gt;channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\tchannels[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">0</span>]);<br>\tchannels[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">1</span>]);<br>\tchannels[<span class=\"hljs-number\">2</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">2</span>]);<br><br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-comment\">//imshow(&quot;color_image&quot;, image);</span><br>\t<span class=\"hljs-keyword\">return</span> image;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>曝光不足图像处理</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184347311.png\" class=\"\" title=\"image-20240302184347311\">\n<p>曝光过度图像处理</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184359230.png\" class=\"\" title=\"image-20240302184359230\">","cover_type":"img","excerpt":"","more":"<h3 id=\"1、计算灰度图像的归一化直方图\"><a href=\"#1、计算灰度图像的归一化直方图\" class=\"headerlink\" title=\"1、计算灰度图像的归一化直方图\"></a>1、计算灰度图像的归一化直方图</h3><p>具体内容：利用OpenCV对图像像素进行操作，计算归一化直方图，并在窗口中以图形的方式显示出来。</p>\n<p>完成程度：读入图片，统计不同灰度级的像素个数，并存入大小为256的数组中。设置背景画布的大小，并根据数组中的最大值最小值，将不同灰度级像素点的个数映射到画布当中，通过使用柱线的方式，绘制直方图。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 1、计算灰度图像的归一化直方图，并绘制图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">nomalization</span><span class=\"hljs-params\">(Mat src_image, String name)</span> </span>&#123;<br>\tMat image = src_image;<br>\t<span class=\"hljs-type\">double</span> gray_scale[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br><br>\t<span class=\"hljs-comment\">// 统计不同灰度级的像素个数</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; i++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br>\t\t\tgray_scale[<span class=\"hljs-built_in\">int</span>(image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j))] = gray_scale[<span class=\"hljs-built_in\">int</span>(image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j))] + <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 绘制直方图</span><br>\t<span class=\"hljs-comment\">// 定义背景图像灰度为255</span><br>\t<span class=\"hljs-type\">int</span> length = <span class=\"hljs-number\">500</span>;<br>\t<span class=\"hljs-type\">int</span> heigth = <span class=\"hljs-number\">600</span>;<br>\t<span class=\"hljs-type\">int</span> reflection = <span class=\"hljs-number\">500</span>;<br>\t<span class=\"hljs-comment\">// 最大值映射到500</span><br>\tMat hist_image = <span class=\"hljs-built_in\">Mat</span>(heigth, length, CV_8U, <span class=\"hljs-built_in\">Scalar</span>(<span class=\"hljs-number\">255</span>));<br><br>\t<span class=\"hljs-comment\">// 对灰度级进行归一化处理，先求出最大值，最小值默认为0</span><br>\t<span class=\"hljs-type\">double</span> max = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">if</span> ((gray_scale[i]) &gt; max) &#123;<br>\t\t\tmax = gray_scale[i];<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-comment\">// 将像素点的数量映射到画布上</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tgray_scale[i] = <span class=\"hljs-built_in\">int</span>(gray_scale[i] * reflection / max);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 直线绘制</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-built_in\">line</span>(hist_image, <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span>, heigth), <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span>, heigth - gray_scale[i]), Scalar::<span class=\"hljs-built_in\">all</span>(<span class=\"hljs-number\">0</span>));<br>\t\t<span class=\"hljs-built_in\">line</span>(hist_image, <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span> + <span class=\"hljs-number\">1</span>, heigth), <span class=\"hljs-built_in\">Point</span>(i * <span class=\"hljs-number\">2</span> + <span class=\"hljs-number\">1</span>, heigth - gray_scale[i]), Scalar::<span class=\"hljs-built_in\">all</span>(<span class=\"hljs-number\">0</span>));<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(name, hist_image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184201998.png\" class=\"\" title=\"image-20240302184201998\">\n<h3 id=\"2、灰度图像直方图均衡处理\"><a href=\"#2、灰度图像直方图均衡处理\" class=\"headerlink\" title=\"2、灰度图像直方图均衡处理\"></a>2、灰度图像直方图均衡处理</h3><p>具体内容:通过计算归一化直方图，设计算法实现直方图均衡化处理。</p>\n<p>完成程度：存储灰度图像不同灰度级的像素个数，计算不同灰度级的概率密度。利用公式Sk = （L-1）*[p(r0)到p(rk)的和]对不同灰度进行离散化，完成不同灰度的映射，将映射表存入到数组当中。遍历原始灰度图像的像素点，对照灰度映射表，完成灰度级的转化。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 2、灰度图像直方图均衡化处理</span><br><span class=\"hljs-comment\">// 直方图均衡化的表达式为：Sk = （L-1）*[p(r0)到p(rk)的和]</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_image</span><span class=\"hljs-params\">(Mat src_image)</span> </span>&#123;<br>\tMat image = src_image;<br>\tMat result = src_image;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-type\">int</span> all_n = row * col;<br>\t<span class=\"hljs-type\">int</span> gray_table[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-comment\">// 存储不同灰度的数量</span><br>\t<span class=\"hljs-type\">double</span> gray_scale[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-comment\">// 计算不同灰度的概率密度</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br>\t\t\tgray_scale[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] = gray_scale[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] + <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t\t<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tgray_scale[i] = gray_scale[i] / all_n;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 将不同的灰度离散化</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\t<span class=\"hljs-comment\">// 求概率密度的和</span><br>\t\t<span class=\"hljs-type\">float</span> sum_midu = <span class=\"hljs-number\">0</span>;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; i; j++) &#123;<br>\t\t\tsum_midu = sum_midu + gray_scale[j];<br>\t\t&#125;<br>\t\tgray_table[i] = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-number\">255</span> * sum_midu + <span class=\"hljs-number\">0.5</span>);<br>\t\t<span class=\"hljs-keyword\">if</span> (gray_table[i] &gt; <span class=\"hljs-number\">255</span>) &#123;<br>\t\t\tgray_table[i] = <span class=\"hljs-number\">255</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 完成灰度转换</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; i++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; j++) &#123;<br><br>\t\t\tresult.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = gray_table[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)];<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>过亮图像</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184304968.png\" class=\"\" title=\"image-20240302184304968\">\n<p>处理过后</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184311057.png\" class=\"\">\n<p>过暗图像</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184323543.png\" class=\"\">\n<p>处理过后  </p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184327658.png\" class=\"\">\n<h3 id=\"3、彩色图像直方图均衡化处理\"><a href=\"#3、彩色图像直方图均衡化处理\" class=\"headerlink\" title=\"3、彩色图像直方图均衡化处理\"></a>3、彩色图像直方图均衡化处理</h3><p>具体内容:在灰度图像直方图均衡处理的基础上实现彩色直方图均衡处理。</p>\n<p>完成程度：将彩色图像的三个颜色通道进行分离并存储在Mat矩阵当中，调用内容2中的直方图均衡化函数，分别对三个通道的直方图进行均衡化处理，处理完毕以后对三个通道进行合并，最终显示该图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、彩色图像直方图均衡化处理</span><br><span class=\"hljs-comment\">// 将彩色图像中的三个通道提取出来</span><br><span class=\"hljs-comment\">// 分别做直方图均衡化处理，然后再进行合并</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">color_average</span><span class=\"hljs-params\">(Mat src)</span> </span>&#123;<br><br>\tMat image = src;<br>\tvector&lt;Mat&gt;channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\tchannels[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">0</span>]);<br>\tchannels[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">1</span>]);<br>\tchannels[<span class=\"hljs-number\">2</span>] = <span class=\"hljs-built_in\">average_image</span>(channels[<span class=\"hljs-number\">2</span>]);<br><br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-comment\">//imshow(&quot;color_image&quot;, image);</span><br>\t<span class=\"hljs-keyword\">return</span> image;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>曝光不足图像处理</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184347311.png\" class=\"\" title=\"image-20240302184347311\">\n<p>曝光过度图像处理</p>\n<img src=\"/2022/09/23/digital-image-test02/image-20240302184359230.png\" class=\"\" title=\"image-20240302184359230\">"},{"title":"设计模式","date":"2024-06-26T06:19:26.000Z","cover":"/img/default_cover10.jpg","top_img":null,"_content":"### \n\n# 设计模式\n\n> 设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的代码编写经验。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。\n\n## 设计模式六大原则\n\n**1、开闭原则（Open Close Principle）**\n\n开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。\n\n**2、里氏代换原则（Liskov Substitution Principle）**\n\n里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n\n**3、依赖倒转原则（Dependence Inversion Principle）**\n\n这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。\n\n**4、接口隔离原则（Interface Segregation Principle）**\n\n这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。\n\n**5、迪米特法则，又称最少知道原则（Demeter Principle）**\n\n最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。\n\n**6、合成复用原则（Composite Reuse Principle）**\n\n合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。\n\n## 一、工厂模式\n\n> 工厂模式是一种创建对象的方式，类似于利用统一工厂类去创建不同的对象，这样就能够让创建对象的过程和使用对象的过程进行分离。\n\n![工厂模式_01](design-model/工厂模式_01.png)\n\n* 简单工厂模式\n\n    根据工厂类传入的参数来决定创建哪种类型的对象\n\n* 工厂方法模式\n\n    定义一个创建对象的接口，但由子类来决定实例化哪一个类，将对象的创建延迟到子类\n\n    不同的产品类继承于同一个抽象产品基类，同时为每一个产品类分配一个单独的创建类，创建类继承于创建基类，创建基类中有一个用于接收产品基类返回值的抽象方法，所有的创建类会重新这个方法，并在这个方法中，创建对应的产品对象，返回给产品基类接收。\n\n    在创建基类中，同时会定义一个接口方法，这个方法的实现会先通过抽象方法先创建出一个产品抽象类，并调用产品抽象类中的抽象方法，就能够达到统一调用子类方法的目的。\n\n    在实际使用中，用户只需要知道创建抽象类以及抽象类中的方法即可，当我们需要使用某一个产品的时候，我们只需要通过使用创建基类的指针指向一个某一个产品的创建子类的对象，通过调用创建基类中的方法就可以完成对应的功能。\n\n    ```C++\n    #include <iostream>\n    #include <memory>\n\n    // 产品基类\n    class Product {\n    public:\n        virtual ~Product() {}\n        virtual std::string Operation() const = 0;\n    };\n\n    // 具体产品A\n    class ConcreteProductA : public Product {\n    public:\n        std::string Operation() const override {\n            return \"Result of the ConcreteProductA\";\n        }\n    };\n\n    // 具体产品B\n    class ConcreteProductB : public Product {\n    public:\n        std::string Operation() const override {\n            return \"Result of the ConcreteProductB\";\n        }\n    };\n\n    // 创建者基类\n    class Creator {\n    public:\n        virtual ~Creator() {}\n        // 工厂方法，用于创建产品对象\n        virtual Product* FactoryMethod() const = 0;\n\n        // 创建者类的业务逻辑\n        std::string SomeOperation() const {\n            // 调用工厂方法来创建一个产品对象\n            std::unique_ptr<Product> product(this->FactoryMethod());\n            // 使用产品\n            std::string result = \"Creator: The same creator's code has just worked with \" + product->Operation();\n            return result;\n        }\n    };\n\n    // 具体创建者A\n    class ConcreteCreatorA : public Creator {\n    public:\n        Product* FactoryMethod() const override {\n            return new ConcreteProductA();\n        }\n    };\n\n    // 具体创建者B\n    class ConcreteCreatorB : public Creator {\n    public:\n        Product* FactoryMethod() const override {\n            return new ConcreteProductB();\n        }\n    };\n\n    void ClientCode(const Creator& creator) {\n        // ...\n        std::cout << \"Client: I'm not aware of the creator's class, but it still works.\\n\"\n                << creator.SomeOperation() << std::endl;\n        // ...\n    }\n\n    int main() {\n        std::unique_ptr<Creator> creator = std::make_unique<ConcreteCreatorA>();\n        ClientCode(*creator);\n\n        std::cout << std::endl;\n        \n        creator = std::make_unique<ConcreteCreatorB>();\n        ClientCode(*creator);\n        \n        return 0;\n    }\n    ```\n\n* 抽象工厂模式\n\n    ![工厂模式_02](design-model/工厂模式_02.png)\n\n    提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类\n\n    我们可以看出来工厂方法模式只关注某一类产品的构建，但是我们可以通过对抽象产品的继承来丰富这一类产品的类型。如果我们有多类产品的话，那就需要用到抽象工厂了。\n\n    因为我们有多类产品，所以我们会定义多个产品的抽象基类，这些产品基类会由多个产品子类来继承生成不同产品，在子类中会分别实现不同产品基类的抽象方法，如果我们需要在不同的产品类中进行通信的话，我们的抽象产品基类中应该还有一个能够将另一个产品基类作为形参传入的方法，在我们的具体产品中重写这一个方法。\n\n    同样我们会有一个抽象工厂，抽象工厂中会有创建不同产品的方法，这些方法都是以抽象产品基类指针作为返回值接收。抽象工厂子类会实现这些方法，它们可以选择性的去创建不同的产品子类，只需要实现对应的抽象产品方法即可，也就是说一个工厂是有可能可以创建多类产品的，尤其是当这些产品需要进行交互的时候。\n\n    下面的例子便是在具体工厂中实现多个产品的创建，当然我们只想让一个工厂对应某一类产品的话，我们只需要在对应的抽象方法中，返回`nullptr`就好了。\n\n    ```C++\n    #include <iostream>\n    #include <memory>\n\n    // 抽象产品A\n    class AbstractProductA {\n    public:\n        virtual ~AbstractProductA() {}\n        virtual std::string UsefulFunctionA() const = 0;\n    };\n\n    // 抽象产品B\n    class AbstractProductB {\n    public:\n        virtual ~AbstractProductB() {}\n        virtual std::string UsefulFunctionB() const = 0;\n        // 抽象方法，示例产品B能够与产品A进行交互\n        virtual std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const = 0;\n    };\n\n    // 具体产品A1\n    class ConcreteProductA1 : public AbstractProductA {\n    public:\n        std::string UsefulFunctionA() const override {\n            return \"The result of the product A1.\";\n        }\n    };\n\n    // 具体产品A2\n    class ConcreteProductA2 : public AbstractProductA {\n    public:\n        std::string UsefulFunctionA() const override {\n            return \"The result of the product A2.\";\n        }\n    };\n\n    // 具体产品B1\n    class ConcreteProductB1 : public AbstractProductB {\n    public:\n        std::string UsefulFunctionB() const override {\n            return \"The result of the product B1.\";\n        }\n        std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const override {\n            const std::string result = collaborator.UsefulFunctionA();\n            return \"The result of the B1 collaborating with ( \" + result + \" )\";\n        }\n    };\n\n    // 具体产品B2\n    class ConcreteProductB2 : public AbstractProductB {\n    public:\n        std::string UsefulFunctionB() const override {\n            return \"The result of the product B2.\";\n        }\n        std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const override {\n            const std::string result = collaborator.UsefulFunctionA();\n            return \"The result of the B2 collaborating with ( \" + result + \" )\";\n        }\n    };\n\n    // 抽象工厂\n    class AbstractFactory {\n    public:\n        virtual ~AbstractFactory() {}\n        virtual std::unique_ptr<AbstractProductA> CreateProductA() const = 0;\n        virtual std::unique_ptr<AbstractProductB> CreateProductB() const = 0;\n    };\n\n    // 具体工厂1\n    class ConcreteFactory1 : public AbstractFactory {\n    public:\n        std::unique_ptr<AbstractProductA> CreateProductA() const override {\n            return std::make_unique<ConcreteProductA1>();\n        }\n        std::unique_ptr<AbstractProductB> CreateProductB() const override {\n            return std::make_unique<ConcreteProductB1>();\n        }\n    };\n\n    // 具体工厂2\n    class ConcreteFactory2 : public AbstractFactory {\n    public:\n        std::unique_ptr<AbstractProductA> CreateProductA() const override {\n            return std::make_unique<ConcreteProductA2>();\n        }\n        std::unique_ptr<AbstractProductB> CreateProductB() const override {\n            return std::make_unique<ConcreteProductB2>();\n        }\n    };\n\n    void ClientCode(const AbstractFactory& factory) {\n        auto product_a = factory.CreateProductA();\n        auto product_b = factory.CreateProductB();\n        std::cout << product_b->UsefulFunctionB() << \"\\n\";\n        std::cout << product_b->AnotherUsefulFunctionB(*product_a) << \"\\n\";\n    }\n\n    int main() {\n        std::cout << \"Client: Testing client code with the first factory type:\\n\";\n        ConcreteFactory1 f1;\n        ClientCode(f1);\n\n        std::cout << std::endl;\n\n        std::cout << \"Client: Testing the same client code with the second factory type:\\n\";\n        ConcreteFactory2 f2;\n        ClientCode(f2);\n        \n        return 0;\n    }\n    ```\n\n## 二、单例模式\n> 单例模式是一种比较常见的设计模式，在应用中十分广泛，在使用过程中用于确保一个对象中只有一个实例，并且会为这个实例提供一个全局访问点。在我们实际应用中，经常会用于一些控制资源共享的场景中，比如日志记录。因为只存在一个实例，所以需要考虑到这个实例在多线程的情况下资源竞争的问题。\n\n![单例模式_01](design-model/单例模式_01.png)\n\n在我们的单例模式实际应用中，通常会提供一个统一的静态全局访问方法，方法名一般叫做`getinstance()`，用于获取当前单例的实例对象，而我们会根据单例的创建时机将单例模式分为两种，懒汉式和饿汉式。\n\n* 懒汉式\n\n    懒汉式单例模式，指的是在我的当前工作进程中，不一定程序启动以后，单例跟着也同样进行实例化，而是只有当我们需要用到这一个单例的时候才会对这个单例进行实例化，具体的实现过程就是把单例的实例化代码写入到`getinstance()`函数中，当我们第一次调用到`getinstance()`的时候，我们会实例化这一个单例。\n\n    我们会把`instance`权限设置为私有，并且提供一个静态方法，用于创建并返回单例。\n\n    ```C++\n    private:\n        // 私有静态指针变量，用于持有类的唯一实例\n        static LazySingleton* instance;\n\n    protected:\n        // 受保护的构造函数，防止外部通过 new 创建实例\n        LazySingleton() {}\n\n        // 删除拷贝构造函数和赋值操作符\n        LazySingleton(const LazySingleton&) = delete;\n        LazySingleton& operator=(const LazySingleton&) = delete;\n\n\n    public:\n        // 在类中提供公共的静态方法来获取实例\n        static LazySingleton* GetInstance() {\n            if (instance == nullptr) { // 检查是否为空\n                instance = new LazySingleton();\n            }\n            return instance;\n        }\n    ```\n    \n    我们可以看到在单线程的情况下，这样的代码是没有问题的，但是如果是多线程的环境下，如果我们有多个线程同时到达`GetInstance`这个函数，那么就存在有多次创建这个单例的风险，违背了我们单例模式的初衷。\n    \n    很显然，我们可以通过加锁来完成不同线程创建多个单例的风险规避。\n\n    ```C++\n    class Singleton {\n    private:\n        static Singleton* instance;\n        static std::mutex mutex;\n\n    protected:\n        Singleton() {}\n\n    public:\n        static Singleton* GetInstance() {\n            std::lock_guard<std::mutex> lock(mutex); // 加锁\n            if (instance == nullptr) {\n                instance = new Singleton();\n            }\n            return instance;\n        }\n    };\n\n    Singleton* Singleton::instance = nullptr;\n    std::mutex Singleton::mutex;\n    ```\n\n    这样的实现方式我们可以很明显的看出来有一些小问题，就是需要处理多线程之间的同步问题，在上面的实现方式中，无论我的实例是否已经被创建，都需要获取到锁以后才能够进入到后面的代码当中，在实际应用中，我们只有在单例未被创建的时候完成同步就可以了，如果单例已经在进程当中，那我们直接返回这个单例就行。\n\n    所以，我们有了另一种实现方式\n    ```C++\n    class Singleton {\n    private:\n        static Singleton* instance;\n        static std::mutex mutex;\n\n    protected:\n        Singleton() {}\n\n    public:\n        static Singleton* GetInstance() {\n            if (instance == nullptr) { // 第一次检查，如果单例已经存在，不需要加锁直接返回单例\n                std::lock_guard<std::mutex> lock(mutex); // 加锁\n                if (instance == nullptr) { // 第二次检查，只有当单例不存在的时候，才会确保只有一个线程创建了单例\n                    instance = new Singleton();\n                }\n            }\n            return instance;\n        }\n    };\n\n    Singleton* Singleton::instance = nullptr;\n    std::mutex Singleton::mutex;\n    ```\n\n* 饿汉式\n\n    可以看到，我们的主进程在初始化这个单例的时候，我们不像之前一样，把单例初始化为`nullptr`，而是切切实实的创建了这一个单例，而在我们的`GetInstance()`方法中会直接返回这一个单例，因为我们的单例已经不可能为空了。\n\n    这样的方式能够避免多个单例的创建，因为创建指挥发生在主进程对类加载的时候，但是牺牲的代价是便是内存的耗费，并且我们不应该提供对这个单例销毁的方法，因为，我们销毁以后想要再次用到这个单例的话，就没有单例创建的入口了。\n\n    ```C++\n    class EagerSingleton {\n    private:\n        // 在定义变量的时候就初始化实例\n        static EagerSingleton instance;\n\n        // 私有构造函数，防止外部通过 new 创建实例\n        EagerSingleton() {}\n\n        // 删除拷贝构造函数和赋值操作符，防止拷贝和赋值\n        EagerSingleton(const EagerSingleton&) = delete;\n        EagerSingleton& operator=(const EagerSingleton&) = delete;\n\n    public:\n        // 提供公共的静态方法来获取实例的引用\n        static EagerSingleton& GetInstance() {\n            return instance;\n        }\n\n    };\n\n    // 类静态成员变量，在程序开始时即完成初始化\n    EagerSingleton EagerSingleton::instance;\n    ```\n\n## 三、适配器模式\n\n> 适配器可以充当两个不兼容接口之间的桥梁，通过一个中间件，将一个类的接口转换成客户期望的另一个接口，使得原本不能工作的类能够协同工作。\n\n![适配器模式-01](design-model/适配器模式_01.png)\n\n适配器模式一般有两种方式来实现，分别是对象适配器模式，和类适配器模式。在对象适配器模式中，适配器类会继承于目标类的接口，并拥有一个需要适配的类的引用，在适配器类中就能够通过引用来调用是需要适配的方法。类适配器模式则是用到的多继承思想，适配器类通过多继承的方式，同时拥有目标类和适配类的方法。\n\n* 对象适配器模式\n    ```C++\n    #include <iostream>\n\n    // 目标接口（Target），客户端期望的接口\n    class Target {\n    public:\n        virtual void Request() const {\n            std::cout << \"Target: Default behavior.\" << std::endl;\n        }\n    };\n\n    // 被适配的类（Adaptee），拥有一个特殊的请求方法\n    class Adaptee {\n    public:\n        void SpecificRequest() const {\n            std::cout << \"Adaptee: Specific request.\" << std::endl;\n        }\n    };\n\n    // 适配器类（Adapter），使 Adaptee 与 Target 接口兼容\n    class Adapter : public Target {\n    private:\n        Adaptee* adaptee;\n\n    public:\n        Adapter(Adaptee* a) : adaptee(a) {}\n\n        void Request() const override {\n            adaptee->SpecificRequest();\n        }\n    };\n\n    int main() {\n        Adaptee* adaptee = new Adaptee();\n        Target* target = new Adapter(adaptee);\n        \n        target->Request();\n\n        delete adaptee;\n        delete target;\n        \n        return 0;\n    }\n    ```\n\n## 四、装饰器模式\n\n![装饰器模式-01](design-model/装饰器模式_01.png)\n\n通常我们在需要在不改变某一个类的功能的前提下为这个类提供新的拓展功能和方法的时候，我们会考虑的一种方式是通过对象的继承，在子类中写一些新的方法，这样子就能够通过使用子类来达到拓展父类功能的目的。而使用继承的方式，我们通常在编译的时候就确定了子类的相关行为。与此同时，如果一个父类存在有多个可能的变化方向，那么我们就需要通过继承的方式实现每一种组合，这样子无疑会使得我们子类的数量呈指数型暴增。\n\n在这样的背景下，我们有了装饰器模式的产生。装饰器可以独立存在，更加灵活，能够动态地扩展对象的功能并且可以通过组合的方式将多个装饰应用在对象上。\n\n装饰器模式通常涉及以下几个角色：\n\n* Component：定义一个对象接口，可以给这些对象动态地添加职责。\n* ConcreteComponent：定义了一个具体的对象，也可以给这个对象添加一些额外的职责。\n* Decorator：持有一个组件（Component）对象的实例，并定义一个与组件接口一致的接口。\n* ConcreteDecorator：具体的装饰类，实现了在组件的接口中定义的操作，并添加新的操作，以给组件对象增加额外的职责。\n\n我们会使用一个装饰器类继承于抽象基类，并在这个装饰器类中持有一个基类的指针对象，在实现基类的方法的时候，通过这一个指针来调用其他具体子类实体的方法。同时我们会有另一个类继承于这一个装饰器类，我们可以叫做拓展装饰器类，在我们的拓展装饰器类中，我们可以拓展具体子类的新功能。这个功能的拓展可以包裹在原始功能的前后，类似于附加一个行为层。\n\n```C++\n#include <iostream>\n#include <string>\n\n// \"Component\"\nclass Shape {\npublic:\n    virtual void draw() const = 0;\n    virtual ~Shape() {}\n};\n\n// \"ConcreteComponent\"\nclass Circle : public Shape {\npublic:\n    void draw() const override {\n        std::cout << \"Shape: Circle\" << std::endl;\n    }\n};\n\nclass Rectangle : public Shape {\npublic:\n    void draw() const override {\n        std::cout << \"Shape: Rectangle\" << std::endl;\n    }\n};\n\n// \"Decorator\"\nclass ShapeDecorator : public Shape {\nprotected:\n    Shape* decoratedShape;\n\npublic:\n    ShapeDecorator(Shape* shape) : decoratedShape(shape) {}\n\n    void draw() const override {\n        decoratedShape->draw();\n    }\n\n    virtual ~ShapeDecorator() {\n        delete decoratedShape;\n    }\n};\n\n// \"ConcreteDecorator\"\nclass RedShapeDecorator : public ShapeDecorator {\npublic:\n    RedShapeDecorator(Shape* decoratedShape) : ShapeDecorator(decoratedShape) {}\n\n    void draw() const override {\n        ShapeDecorator::draw();\n        setRedBorder(decoratedShape);   // 附加的行为\n    }\n\nprivate:\n    void setRedBorder(Shape* decoratedShape) const {\n        std::cout << \"Border Color: Red\" << std::endl;\n    }\n};\n\nint main() {\n    Shape* circle = new Circle();\n    Shape* redCircle = new RedShapeDecorator(new Circle());\n    Shape* redRectangle = new RedShapeDecorator(new Rectangle());\n\n    std::cout << \"Circle with normal border:\" << std::endl;\n    circle->draw();\n\n    std::cout << \"\\nCircle of red border:\" << std::endl;\n    redCircle->draw();\n\n    std::cout << \"\\nRectangle of red border:\" << std::endl;\n    redRectangle->draw();\n\n    delete circle;\n    delete redCircle;\n    delete redRectangle;\n\n    return 0;\n}\n```\n\n## 五、享元模式\n\n> 享元模式主要用于减少创建对象的数量，用于减少内存占用和提高性能。享元模式会尝试重用现有的同类对象，如果我们找到了这个对象，那么就会对这个对象进行返回，如果未找这个对象，才会重新申请一个新的对象。主要目的是支持大量的细粒度对象，这些对象中有相当部分的状态可以共享。通过共享，可以在有限的内存资源下支持大规模的对象数量。\n\n![享元模式-01](design-model/享元模式_01.png)\n\n在我们的使用过程中，通常享元模式需要定义享元抽象类，抽象类中会有子类需要共享的方法和属性，并且通过子类继承抽象类，实现对应的抽象方法，我们的子类也会拥有属于子类的独有的属性和方法。\n\n同时，我们会定义一个享元工厂，享元工厂负责创建和管理享元对象，管理的方式通常使用`HashMap`哈希表的映射来完成，如果需要创建某一个对象的`key`已经存在，则说明这个对象已经存在在内存当中，可以作为享元对象直接返回，当在哈希表中找不到`key`时，才会新建一个新的对象。\n\n在我们的客户端只需要维护对享元对象的引用，并计算或存储享元对象的外部状态即可。外部状态指的是，客户端用于标识具体对象的一些标志。所以在使用的过程中，应该注意的是要明确区分内部状态和外部状态，实现状态分离，以免混淆。\n\n```C++\n#include <iostream>\n#include <map>\n#include <string>\n\n// 享元接口类\nclass Character {\npublic:\n    virtual ~Character() = default;\n    virtual void display() const = 0;\n};\n\n// 具体享元类\nclass ConcreteCharacter : public Character {\nprivate:\n    char glyph; // 内部状态：字符本身\n    \npublic:\n    ConcreteCharacter(char argGlyph) : glyph(argGlyph) {}\n    \n    void display() const override {\n        std::cout << \"Displaying character: \" << glyph << std::endl;\n    }\n};\n\n// 享元工厂类\nclass CharacterFactory {\nprivate:\n    std::map<char, Character*> characters; // 缓存已创建的享元对象\n    \npublic:\n    ~CharacterFactory() {\n        for (auto& pair : characters) {\n            delete pair.second;\n        }\n        characters.clear();\n    }\n    \n    Character* getCharacter(char key) {\n        if (characters.find(key) == characters.end()) {\n            // 如果字符不存在，则创建一个新的ConcreteCharacter并加入映射中\n            characters[key] = new ConcreteCharacter(key);\n        }\n        return characters[key];\n    }\n};\n\nint main() {\n    // 客户端代码\n    CharacterFactory factory;\n\n    // 创建几个字符对象\n    Character* characterA = factory.getCharacter('A');\n    Character* characterB = factory.getCharacter('B');\n    Character* characterA2 = factory.getCharacter('A'); // 再次请求'A'，应该得到相同的实例\n\n    // 显示字符\n    characterA->display();\n    characterB->display();\n    characterA2->display();\n\n    // 检查两个‘A’是否相同\n    std::cout << \"Are the two 'A' instances the same? \" << (characterA == characterA2 ? \"Yes\" : \"No\") << std::endl;\n\n    // 不需要手动删除字符对象，因为由CharacterFactory管理\n    return 0;\n}\n```\n\n## 六、责任链模式\n\n> 责任链模式为请求创建了一个接收者对象的链，它允许多个对象来处理一个请求，而无需发送者知道接收者的具体信息。请求在一系列接收者对象之间传递直到被处理，每一个接收者持有下一个接收者的引用，这样接收者就形成了一条链，并且每个链上的对象将决定自己能否处理请求或者应该将请求传递给链上的下一个对象。\n\n责任链模式主要解决的问题是解耦发送者和接收者，使得多个对象都有可能接收请求，而发送者不需要知道哪个对象会处理它。就好像我们的发送者只需要将需要处理的请求丢给`handle`责任链上，而无需在意最后的请求是谁处理的一样，这样可以简化对象之间的连接，达到解耦的目的。\n\n我们会定义一个抽象处理类，在这个处理类中会拥有一个指向下一个处理类的指针，并使用接口完成责任链的构建，我们责任链上的不同任务会通过传入的不同参数来进行标识。\n\n在我们的抽象处理类中，会有一个处理请求的抽象方法，这个方法是用于遍历责任链的，如果我们的子处理类无法处理当前的请求时，我们会调用下一个处理类来完成这个请求的处理。\n\n使用这样的责任链方式，我们可以减少请求方和具体实现方的耦合，我们可以发现这样的设计模式能够很好的满足设计模式中的依赖倒置原则，请求方和实现方都依赖的是抽象接口而不各自依赖。\n\n```C++\n#include <iostream>\n#include <memory>\n\n// 抽象处理器类\nclass Handler {\nprotected:\n    std::shared_ptr<Handler> next_handler;\npublic:\n    virtual ~Handler() = default;\n    \n    void setNext(std::shared_ptr<Handler> handler) {\n        next_handler = handler;\n    }\n    \n    virtual void handleRequest(int request) {\n        if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 具体处理器类A\nclass ConcreteHandlerA : public Handler {\npublic:\n    void handleRequest(int request) override {\n        if (request < 10) { // 可以处理小于10的请求\n            std::cout << \"Handler A is handling request: \" << request << std::endl;\n        } else if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 具体处理器类B\nclass ConcreteHandlerB : public Handler {\npublic:\n    void handleRequest(int request) override {\n        if (request >= 10) { // 可以处理大于等于10的请求\n            std::cout << \"Handler B is handling request: \" << request << std::endl;\n        } else if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 客户端代码\nint main() {\n    auto handlerA = std::make_shared<ConcreteHandlerA>();\n    auto handlerB = std::make_shared<ConcreteHandlerB>();\n    \n    handlerA->setNext(handlerB); // 设置责任链\n    \n    // 发出请求\n    handlerA->handleRequest(5);  // 将由HandlerA处理\n    handlerA->handleRequest(20); // 将由HandlerB处理\n\n    return 0;\n}\n```\n\n## 七、代理模式\n\n> 代理模式通过引入一个代理对象来控制原对象的访问。代理对象在客户端和目标对象之间充当中介，负责将客户端的请求转发给目标对象，同时可以在转发请求前后进行额外的处理，比如安全控制，延迟初始化，远程通信，记录日志等。\n\n代理模式实际上就是在客户端和实际服务对象之间建立一个中介层，用于在请求被送达给服务对象之前或之后执行某些操作\n\n在我们的代理类中，会继承于抽象类，并拥有一个具体类的实例，如果我们想要在真实类的某一个接口的前后添加譬如日志之类的额外处理，我们可以在代理类中实现抽象类中的接口，并在这个接口的前后添加对应的功能。\n\n* 问题一、代理模式和适配器模式的区别\n\n    代理模式，实现的是对另一个对象（原始被代理的对象）的控制访问，可以添加一些额外的功能，但是不应该改变原始对象的行为和功能。\n\n    适配器模式，适用于连接两个不兼容的接口，涉及到两类对象，通常会由适配器继承于一个对象，并拥有另一个对象的实例，在使用适配器进行适配的时候，通过修改所继承的接口方法来调用到被适配对象的行为，即把原接口适配成另一个客户想要的接口。\n\n* 问题二、代理模式和装饰器模式的区别\n\n    代理模式主要用于控制对资源的访问，通常只有一个代理类，而装饰器模式旨在不改变对象的接口的情况下，为对象添加行为，可以使用多个装饰器来增强对象的功能。\n\n    代理模式通常在编译时就确定了，它管理对象的生命周期并可以进行一些特定的任务，如懒加载、权限控制等；而装饰器可以在运行时递归地将装饰层嵌套起来，以此在不改变原始对象代码的基础上增强对象的行为。\n\n    代理模式关注于对对象的控制，例如为远程对象提供本地代理的过程中可能会处理网络通信、线程同步等问题；装饰器模式关注于增加对象的新功能，强调的是扩展对象的行为。\n\n```C++\n#include <iostream>\n#include <memory>\n\n// 抽象主题类\nclass Subject {\npublic:\n    virtual ~Subject() = default;\n    virtual void request() const = 0;\n};\n\n// 真实主题类\nclass RealSubject : public Subject {\npublic:\n    void request() const override {\n        std::cout << \"RealSubject: Handling request.\" << std::endl;\n    }\n};\n\n// 代理类\nclass Proxy : public Subject {\nprivate:\n    std::shared_ptr<RealSubject> real_subject;\n\n    bool checkAccess() const {\n        // 检查访问权限的逻辑\n        std::cout << \"Proxy: Checking access prior to firing a real request.\" << std::endl;\n        return true; // 假设访问权限得到了验证\n    }\n\n    void logAccess() const {\n        // 日志记录的逻辑\n        std::cout << \"Proxy: Logging the time of request.\" << std::endl;\n    }\n\npublic:\n    Proxy(std::shared_ptr<RealSubject> real_subject) : real_subject(real_subject) {}\n\n    void request() const override {\n        if (this->checkAccess()) {\n            this->real_subject->request(); // 调用真实主题的方法\n            this->logAccess(); // 记录请求日志\n        }\n    }\n};\n\n// 客户端代码\nint main() {\n    auto real_subject = std::make_shared<RealSubject>();\n    Proxy proxy(real_subject);\n    \n    proxy.request(); // 客户端使用代理完成工作\n\n    return 0;\n}\n```\n\n## 八、观察者模式\n\n> 观察者模式定义了一种一对多的依赖关系，当一个对象的状态发生改变时，其所有依赖者都会收到通知，并自动更新，主要用于分布式事件处理系统、消息发布/订阅机制，以及各种需要对象间解耦的场景。关键在于主题和观察者之间不直接进行通信，而是通过注册和通知机制进行交互。\n\n观察者模式通常包含几个核心角色\n\n* 主题：它是具有状态的对象，并维护这一个观察这列表。一般我们主题会提供添加、删除和通知观察者的方法\n* 观察者：观察者是接收主题通知的对象。观察者会实现一个更新方法，当我们收到主题的通知时，会调用该方法进行更新操作\n* 具体主题：具体主题时主题的具体实现类，会维护具体主题需要通知的观察者列表，并且在状态发生改变的时候通知观察者\n* 具体观察者：具体观察者是观察者的具体实现类。不同的观察者可能会实现各自的更新方法，方法中会定义收到主题通知时要执行的具体操作\n\n在我们使用的时候，基本逻辑就是，主题维护一个观察者列表，我们需要关注这个主题的观察者通过主题的实例对象来进行注册，注册到对应的主题当中，在我们的主题中会通过实现`notify`的方法，主动的调用观察者的更新函数。\n\n比较常见的场景就是`ros`的发布与订阅机制，订阅的节点通过订阅来将自己加入到具体的主题当中，当有主题到来的时候，就是状态触发的过程，就会通知各个订阅者进行相应的操作。\n\n```C++\n#include <iostream>\n#include <string>\n#include <list>\n#include <algorithm>\n\n// 前向声明\nclass Subject;\n\n// Observer接口\nclass Observer {\npublic:\n    virtual ~Observer() {}\n    virtual void update(Subject* subject) = 0;\n};\n\n// Subject接口\nclass Subject {\nprivate:\n    std::list<Observer*> observers; // 观察者列表\n\npublic:\n    virtual ~Subject() {}\n\n    // 注册观察者\n    void attach(Observer* obs) {\n        observers.push_back(obs);\n    }\n\n    // 注销观察者\n    void detach(Observer* obs) {\n        observers.remove(obs);\n    }\n\n    // 通知所有注册的观察者\n    void notify() {\n        for (auto& observer : observers) {\n            observer->update(this);\n        }\n    }\n\n    // 获取状态（必须由具体的主题实现）\n    virtual std::string getState() const = 0;\n};\n\n// 具体的Subject实现\nclass ConcreteSubject : public Subject {\nprivate:\n    std::string state;\n\npublic:\n    // 设置新状态并通知观察者\n    void setState(const std::string& newState) {\n        state = newState;\n        notify();\n    }\n\n    // 覆盖getState方法\n    std::string getState() const override {\n        return state;\n    }\n};\n\n// 具体的Observer实现\nclass ConcreteObserver : public Observer {\npublic:\n    void update(Subject* subject) override {\n        if (subject) {\n            std::cout << \"Observer received a new state: \" << subject->getState() << std::endl;\n        }\n    }\n};\n\nint main() {\n    // 创建主题和观察者\n    ConcreteSubject* concreteSubject = new ConcreteSubject();\n    Observer* observer1 = new ConcreteObserver();\n    Observer* observer2 = new ConcreteObserver();\n\n    // 注册观察者\n    concreteSubject->attach(observer1);\n    concreteSubject->attach(observer2);\n\n    // 改变状态并通知观察者\n    concreteSubject->setState(\"state1\");\n\n    // 注销一个观察者并再次改变状态\n    concreteSubject->detach(observer1);\n    concreteSubject->setState(\"state2\");\n\n    // 清理资源\n    delete observer1;\n    delete observer2;\n    delete concreteSubject;\n\n    return 0;\n}\n```\n\n## 九、策略模式\n\n策略模式可以定义一系列的算法行为，并且把它们封装起来，提供给客户一定的自由度，能够使它们进行互相替换，策略模式允许算法独立于使用它们的客户端的变化。\n\n![策略模式-01](design-model/策略模式_01.png)\n\n在C++中我们会定义一个抽象策略基类，不同的策略会继承于这个抽象类，并重写基类中需要进行策略呼唤的方法。\n\n在我们客户端需要使用策略的对象当中，会有一个抽象策略基类的指针，用于引用到子类的不同策略对象实例。通过不同的策略实例的调用就能够在我们客户端用到不同的方法了。\n\n```C++\n#include <iostream>\n#include <vector>\n#include <algorithm> // std::sort\n\n// Strategy Interface\nclass SortingStrategy {\npublic:\n    virtual void sort(std::vector<int>& dataset) = 0;\n    virtual ~SortingStrategy() {}\n};\n\n// Concrete Strategy A: Bubble Sort\nclass BubbleSort : public SortingStrategy {\npublic:\n    void sort(std::vector<int>& dataset) override {\n        bool swapped = true;\n        while (swapped) {\n            swapped = false;\n            for (size_t i = 1; i < dataset.size(); ++i) {\n                if (dataset[i - 1] > dataset[i]) {\n                    std::swap(dataset[i - 1], dataset[i]);\n                    swapped = true;\n                }\n            }\n        }\n    }\n};\n\n// Concrete Strategy B: Standard Library Sort\nclass StdSort : public SortingStrategy {\npublic:\n    void sort(std::vector<int>& dataset) override {\n        std::sort(dataset.begin(), dataset.end());\n    }\n};\n\n// Context\nclass SortedList {\nprivate:\n    std::vector<int> m_items;\n    SortingStrategy* m_strategy;\n\npublic:\n    SortedList(SortingStrategy* strategy) : m_strategy(strategy) {}\n\n    void set_strategy(SortingStrategy* strategy) {\n        m_strategy = strategy;\n    }\n\n    void add(int value) {\n        m_items.push_back(value);\n    }\n\n    void sort() {\n        m_strategy->sort(m_items);\n        for (int item : m_items) {\n            std::cout << item << \" \";\n        }\n        std::cout << std::endl;\n    }\n\n    ~SortedList() {\n        delete m_strategy;\n    }\n};\n\n// Client Code\nint main() {\n    std::vector<int> dataset = {5, 2, 9, 1, 5, 6};\n\n    // Use BubbleSort\n    SortedList* bubble_sorted_list = new SortedList(new BubbleSort());\n    for (int value : dataset) {\n        bubble_sorted_list->add(value);\n    }\n    std::cout << \"Bubble Sorted: \";\n    bubble_sorted_list->sort();\n    delete bubble_sorted_list;\n\n    // Use StdSort\n    SortedList* std_sorted_list = new SortedList(new StdSort());\n    for (int value : dataset) {\n        std_sorted_list->add(value);\n    }\n    std::cout << \"Std Sorted: \";\n    std_sorted_list->sort();\n    delete std_sorted_list;\n\n    return 0;\n}\n```\n\n参考链接：[菜鸟教程](https://www.runoob.com/design-pattern/design-pattern-tutorial.html)","source":"_posts/design-model.md","raw":"---\ntitle: 设计模式\ntags:\n  - 设计模式\n  - UML\n  - 软件工程\ncategories: 技术研究\ndate: 2024-06-26 14:19:26\ncover:\ntop_img:\n---\n### \n\n# 设计模式\n\n> 设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的代码编写经验。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。\n\n## 设计模式六大原则\n\n**1、开闭原则（Open Close Principle）**\n\n开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。\n\n**2、里氏代换原则（Liskov Substitution Principle）**\n\n里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n\n**3、依赖倒转原则（Dependence Inversion Principle）**\n\n这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。\n\n**4、接口隔离原则（Interface Segregation Principle）**\n\n这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。\n\n**5、迪米特法则，又称最少知道原则（Demeter Principle）**\n\n最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。\n\n**6、合成复用原则（Composite Reuse Principle）**\n\n合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。\n\n## 一、工厂模式\n\n> 工厂模式是一种创建对象的方式，类似于利用统一工厂类去创建不同的对象，这样就能够让创建对象的过程和使用对象的过程进行分离。\n\n![工厂模式_01](design-model/工厂模式_01.png)\n\n* 简单工厂模式\n\n    根据工厂类传入的参数来决定创建哪种类型的对象\n\n* 工厂方法模式\n\n    定义一个创建对象的接口，但由子类来决定实例化哪一个类，将对象的创建延迟到子类\n\n    不同的产品类继承于同一个抽象产品基类，同时为每一个产品类分配一个单独的创建类，创建类继承于创建基类，创建基类中有一个用于接收产品基类返回值的抽象方法，所有的创建类会重新这个方法，并在这个方法中，创建对应的产品对象，返回给产品基类接收。\n\n    在创建基类中，同时会定义一个接口方法，这个方法的实现会先通过抽象方法先创建出一个产品抽象类，并调用产品抽象类中的抽象方法，就能够达到统一调用子类方法的目的。\n\n    在实际使用中，用户只需要知道创建抽象类以及抽象类中的方法即可，当我们需要使用某一个产品的时候，我们只需要通过使用创建基类的指针指向一个某一个产品的创建子类的对象，通过调用创建基类中的方法就可以完成对应的功能。\n\n    ```C++\n    #include <iostream>\n    #include <memory>\n\n    // 产品基类\n    class Product {\n    public:\n        virtual ~Product() {}\n        virtual std::string Operation() const = 0;\n    };\n\n    // 具体产品A\n    class ConcreteProductA : public Product {\n    public:\n        std::string Operation() const override {\n            return \"Result of the ConcreteProductA\";\n        }\n    };\n\n    // 具体产品B\n    class ConcreteProductB : public Product {\n    public:\n        std::string Operation() const override {\n            return \"Result of the ConcreteProductB\";\n        }\n    };\n\n    // 创建者基类\n    class Creator {\n    public:\n        virtual ~Creator() {}\n        // 工厂方法，用于创建产品对象\n        virtual Product* FactoryMethod() const = 0;\n\n        // 创建者类的业务逻辑\n        std::string SomeOperation() const {\n            // 调用工厂方法来创建一个产品对象\n            std::unique_ptr<Product> product(this->FactoryMethod());\n            // 使用产品\n            std::string result = \"Creator: The same creator's code has just worked with \" + product->Operation();\n            return result;\n        }\n    };\n\n    // 具体创建者A\n    class ConcreteCreatorA : public Creator {\n    public:\n        Product* FactoryMethod() const override {\n            return new ConcreteProductA();\n        }\n    };\n\n    // 具体创建者B\n    class ConcreteCreatorB : public Creator {\n    public:\n        Product* FactoryMethod() const override {\n            return new ConcreteProductB();\n        }\n    };\n\n    void ClientCode(const Creator& creator) {\n        // ...\n        std::cout << \"Client: I'm not aware of the creator's class, but it still works.\\n\"\n                << creator.SomeOperation() << std::endl;\n        // ...\n    }\n\n    int main() {\n        std::unique_ptr<Creator> creator = std::make_unique<ConcreteCreatorA>();\n        ClientCode(*creator);\n\n        std::cout << std::endl;\n        \n        creator = std::make_unique<ConcreteCreatorB>();\n        ClientCode(*creator);\n        \n        return 0;\n    }\n    ```\n\n* 抽象工厂模式\n\n    ![工厂模式_02](design-model/工厂模式_02.png)\n\n    提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类\n\n    我们可以看出来工厂方法模式只关注某一类产品的构建，但是我们可以通过对抽象产品的继承来丰富这一类产品的类型。如果我们有多类产品的话，那就需要用到抽象工厂了。\n\n    因为我们有多类产品，所以我们会定义多个产品的抽象基类，这些产品基类会由多个产品子类来继承生成不同产品，在子类中会分别实现不同产品基类的抽象方法，如果我们需要在不同的产品类中进行通信的话，我们的抽象产品基类中应该还有一个能够将另一个产品基类作为形参传入的方法，在我们的具体产品中重写这一个方法。\n\n    同样我们会有一个抽象工厂，抽象工厂中会有创建不同产品的方法，这些方法都是以抽象产品基类指针作为返回值接收。抽象工厂子类会实现这些方法，它们可以选择性的去创建不同的产品子类，只需要实现对应的抽象产品方法即可，也就是说一个工厂是有可能可以创建多类产品的，尤其是当这些产品需要进行交互的时候。\n\n    下面的例子便是在具体工厂中实现多个产品的创建，当然我们只想让一个工厂对应某一类产品的话，我们只需要在对应的抽象方法中，返回`nullptr`就好了。\n\n    ```C++\n    #include <iostream>\n    #include <memory>\n\n    // 抽象产品A\n    class AbstractProductA {\n    public:\n        virtual ~AbstractProductA() {}\n        virtual std::string UsefulFunctionA() const = 0;\n    };\n\n    // 抽象产品B\n    class AbstractProductB {\n    public:\n        virtual ~AbstractProductB() {}\n        virtual std::string UsefulFunctionB() const = 0;\n        // 抽象方法，示例产品B能够与产品A进行交互\n        virtual std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const = 0;\n    };\n\n    // 具体产品A1\n    class ConcreteProductA1 : public AbstractProductA {\n    public:\n        std::string UsefulFunctionA() const override {\n            return \"The result of the product A1.\";\n        }\n    };\n\n    // 具体产品A2\n    class ConcreteProductA2 : public AbstractProductA {\n    public:\n        std::string UsefulFunctionA() const override {\n            return \"The result of the product A2.\";\n        }\n    };\n\n    // 具体产品B1\n    class ConcreteProductB1 : public AbstractProductB {\n    public:\n        std::string UsefulFunctionB() const override {\n            return \"The result of the product B1.\";\n        }\n        std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const override {\n            const std::string result = collaborator.UsefulFunctionA();\n            return \"The result of the B1 collaborating with ( \" + result + \" )\";\n        }\n    };\n\n    // 具体产品B2\n    class ConcreteProductB2 : public AbstractProductB {\n    public:\n        std::string UsefulFunctionB() const override {\n            return \"The result of the product B2.\";\n        }\n        std::string AnotherUsefulFunctionB(const AbstractProductA& collaborator) const override {\n            const std::string result = collaborator.UsefulFunctionA();\n            return \"The result of the B2 collaborating with ( \" + result + \" )\";\n        }\n    };\n\n    // 抽象工厂\n    class AbstractFactory {\n    public:\n        virtual ~AbstractFactory() {}\n        virtual std::unique_ptr<AbstractProductA> CreateProductA() const = 0;\n        virtual std::unique_ptr<AbstractProductB> CreateProductB() const = 0;\n    };\n\n    // 具体工厂1\n    class ConcreteFactory1 : public AbstractFactory {\n    public:\n        std::unique_ptr<AbstractProductA> CreateProductA() const override {\n            return std::make_unique<ConcreteProductA1>();\n        }\n        std::unique_ptr<AbstractProductB> CreateProductB() const override {\n            return std::make_unique<ConcreteProductB1>();\n        }\n    };\n\n    // 具体工厂2\n    class ConcreteFactory2 : public AbstractFactory {\n    public:\n        std::unique_ptr<AbstractProductA> CreateProductA() const override {\n            return std::make_unique<ConcreteProductA2>();\n        }\n        std::unique_ptr<AbstractProductB> CreateProductB() const override {\n            return std::make_unique<ConcreteProductB2>();\n        }\n    };\n\n    void ClientCode(const AbstractFactory& factory) {\n        auto product_a = factory.CreateProductA();\n        auto product_b = factory.CreateProductB();\n        std::cout << product_b->UsefulFunctionB() << \"\\n\";\n        std::cout << product_b->AnotherUsefulFunctionB(*product_a) << \"\\n\";\n    }\n\n    int main() {\n        std::cout << \"Client: Testing client code with the first factory type:\\n\";\n        ConcreteFactory1 f1;\n        ClientCode(f1);\n\n        std::cout << std::endl;\n\n        std::cout << \"Client: Testing the same client code with the second factory type:\\n\";\n        ConcreteFactory2 f2;\n        ClientCode(f2);\n        \n        return 0;\n    }\n    ```\n\n## 二、单例模式\n> 单例模式是一种比较常见的设计模式，在应用中十分广泛，在使用过程中用于确保一个对象中只有一个实例，并且会为这个实例提供一个全局访问点。在我们实际应用中，经常会用于一些控制资源共享的场景中，比如日志记录。因为只存在一个实例，所以需要考虑到这个实例在多线程的情况下资源竞争的问题。\n\n![单例模式_01](design-model/单例模式_01.png)\n\n在我们的单例模式实际应用中，通常会提供一个统一的静态全局访问方法，方法名一般叫做`getinstance()`，用于获取当前单例的实例对象，而我们会根据单例的创建时机将单例模式分为两种，懒汉式和饿汉式。\n\n* 懒汉式\n\n    懒汉式单例模式，指的是在我的当前工作进程中，不一定程序启动以后，单例跟着也同样进行实例化，而是只有当我们需要用到这一个单例的时候才会对这个单例进行实例化，具体的实现过程就是把单例的实例化代码写入到`getinstance()`函数中，当我们第一次调用到`getinstance()`的时候，我们会实例化这一个单例。\n\n    我们会把`instance`权限设置为私有，并且提供一个静态方法，用于创建并返回单例。\n\n    ```C++\n    private:\n        // 私有静态指针变量，用于持有类的唯一实例\n        static LazySingleton* instance;\n\n    protected:\n        // 受保护的构造函数，防止外部通过 new 创建实例\n        LazySingleton() {}\n\n        // 删除拷贝构造函数和赋值操作符\n        LazySingleton(const LazySingleton&) = delete;\n        LazySingleton& operator=(const LazySingleton&) = delete;\n\n\n    public:\n        // 在类中提供公共的静态方法来获取实例\n        static LazySingleton* GetInstance() {\n            if (instance == nullptr) { // 检查是否为空\n                instance = new LazySingleton();\n            }\n            return instance;\n        }\n    ```\n    \n    我们可以看到在单线程的情况下，这样的代码是没有问题的，但是如果是多线程的环境下，如果我们有多个线程同时到达`GetInstance`这个函数，那么就存在有多次创建这个单例的风险，违背了我们单例模式的初衷。\n    \n    很显然，我们可以通过加锁来完成不同线程创建多个单例的风险规避。\n\n    ```C++\n    class Singleton {\n    private:\n        static Singleton* instance;\n        static std::mutex mutex;\n\n    protected:\n        Singleton() {}\n\n    public:\n        static Singleton* GetInstance() {\n            std::lock_guard<std::mutex> lock(mutex); // 加锁\n            if (instance == nullptr) {\n                instance = new Singleton();\n            }\n            return instance;\n        }\n    };\n\n    Singleton* Singleton::instance = nullptr;\n    std::mutex Singleton::mutex;\n    ```\n\n    这样的实现方式我们可以很明显的看出来有一些小问题，就是需要处理多线程之间的同步问题，在上面的实现方式中，无论我的实例是否已经被创建，都需要获取到锁以后才能够进入到后面的代码当中，在实际应用中，我们只有在单例未被创建的时候完成同步就可以了，如果单例已经在进程当中，那我们直接返回这个单例就行。\n\n    所以，我们有了另一种实现方式\n    ```C++\n    class Singleton {\n    private:\n        static Singleton* instance;\n        static std::mutex mutex;\n\n    protected:\n        Singleton() {}\n\n    public:\n        static Singleton* GetInstance() {\n            if (instance == nullptr) { // 第一次检查，如果单例已经存在，不需要加锁直接返回单例\n                std::lock_guard<std::mutex> lock(mutex); // 加锁\n                if (instance == nullptr) { // 第二次检查，只有当单例不存在的时候，才会确保只有一个线程创建了单例\n                    instance = new Singleton();\n                }\n            }\n            return instance;\n        }\n    };\n\n    Singleton* Singleton::instance = nullptr;\n    std::mutex Singleton::mutex;\n    ```\n\n* 饿汉式\n\n    可以看到，我们的主进程在初始化这个单例的时候，我们不像之前一样，把单例初始化为`nullptr`，而是切切实实的创建了这一个单例，而在我们的`GetInstance()`方法中会直接返回这一个单例，因为我们的单例已经不可能为空了。\n\n    这样的方式能够避免多个单例的创建，因为创建指挥发生在主进程对类加载的时候，但是牺牲的代价是便是内存的耗费，并且我们不应该提供对这个单例销毁的方法，因为，我们销毁以后想要再次用到这个单例的话，就没有单例创建的入口了。\n\n    ```C++\n    class EagerSingleton {\n    private:\n        // 在定义变量的时候就初始化实例\n        static EagerSingleton instance;\n\n        // 私有构造函数，防止外部通过 new 创建实例\n        EagerSingleton() {}\n\n        // 删除拷贝构造函数和赋值操作符，防止拷贝和赋值\n        EagerSingleton(const EagerSingleton&) = delete;\n        EagerSingleton& operator=(const EagerSingleton&) = delete;\n\n    public:\n        // 提供公共的静态方法来获取实例的引用\n        static EagerSingleton& GetInstance() {\n            return instance;\n        }\n\n    };\n\n    // 类静态成员变量，在程序开始时即完成初始化\n    EagerSingleton EagerSingleton::instance;\n    ```\n\n## 三、适配器模式\n\n> 适配器可以充当两个不兼容接口之间的桥梁，通过一个中间件，将一个类的接口转换成客户期望的另一个接口，使得原本不能工作的类能够协同工作。\n\n![适配器模式-01](design-model/适配器模式_01.png)\n\n适配器模式一般有两种方式来实现，分别是对象适配器模式，和类适配器模式。在对象适配器模式中，适配器类会继承于目标类的接口，并拥有一个需要适配的类的引用，在适配器类中就能够通过引用来调用是需要适配的方法。类适配器模式则是用到的多继承思想，适配器类通过多继承的方式，同时拥有目标类和适配类的方法。\n\n* 对象适配器模式\n    ```C++\n    #include <iostream>\n\n    // 目标接口（Target），客户端期望的接口\n    class Target {\n    public:\n        virtual void Request() const {\n            std::cout << \"Target: Default behavior.\" << std::endl;\n        }\n    };\n\n    // 被适配的类（Adaptee），拥有一个特殊的请求方法\n    class Adaptee {\n    public:\n        void SpecificRequest() const {\n            std::cout << \"Adaptee: Specific request.\" << std::endl;\n        }\n    };\n\n    // 适配器类（Adapter），使 Adaptee 与 Target 接口兼容\n    class Adapter : public Target {\n    private:\n        Adaptee* adaptee;\n\n    public:\n        Adapter(Adaptee* a) : adaptee(a) {}\n\n        void Request() const override {\n            adaptee->SpecificRequest();\n        }\n    };\n\n    int main() {\n        Adaptee* adaptee = new Adaptee();\n        Target* target = new Adapter(adaptee);\n        \n        target->Request();\n\n        delete adaptee;\n        delete target;\n        \n        return 0;\n    }\n    ```\n\n## 四、装饰器模式\n\n![装饰器模式-01](design-model/装饰器模式_01.png)\n\n通常我们在需要在不改变某一个类的功能的前提下为这个类提供新的拓展功能和方法的时候，我们会考虑的一种方式是通过对象的继承，在子类中写一些新的方法，这样子就能够通过使用子类来达到拓展父类功能的目的。而使用继承的方式，我们通常在编译的时候就确定了子类的相关行为。与此同时，如果一个父类存在有多个可能的变化方向，那么我们就需要通过继承的方式实现每一种组合，这样子无疑会使得我们子类的数量呈指数型暴增。\n\n在这样的背景下，我们有了装饰器模式的产生。装饰器可以独立存在，更加灵活，能够动态地扩展对象的功能并且可以通过组合的方式将多个装饰应用在对象上。\n\n装饰器模式通常涉及以下几个角色：\n\n* Component：定义一个对象接口，可以给这些对象动态地添加职责。\n* ConcreteComponent：定义了一个具体的对象，也可以给这个对象添加一些额外的职责。\n* Decorator：持有一个组件（Component）对象的实例，并定义一个与组件接口一致的接口。\n* ConcreteDecorator：具体的装饰类，实现了在组件的接口中定义的操作，并添加新的操作，以给组件对象增加额外的职责。\n\n我们会使用一个装饰器类继承于抽象基类，并在这个装饰器类中持有一个基类的指针对象，在实现基类的方法的时候，通过这一个指针来调用其他具体子类实体的方法。同时我们会有另一个类继承于这一个装饰器类，我们可以叫做拓展装饰器类，在我们的拓展装饰器类中，我们可以拓展具体子类的新功能。这个功能的拓展可以包裹在原始功能的前后，类似于附加一个行为层。\n\n```C++\n#include <iostream>\n#include <string>\n\n// \"Component\"\nclass Shape {\npublic:\n    virtual void draw() const = 0;\n    virtual ~Shape() {}\n};\n\n// \"ConcreteComponent\"\nclass Circle : public Shape {\npublic:\n    void draw() const override {\n        std::cout << \"Shape: Circle\" << std::endl;\n    }\n};\n\nclass Rectangle : public Shape {\npublic:\n    void draw() const override {\n        std::cout << \"Shape: Rectangle\" << std::endl;\n    }\n};\n\n// \"Decorator\"\nclass ShapeDecorator : public Shape {\nprotected:\n    Shape* decoratedShape;\n\npublic:\n    ShapeDecorator(Shape* shape) : decoratedShape(shape) {}\n\n    void draw() const override {\n        decoratedShape->draw();\n    }\n\n    virtual ~ShapeDecorator() {\n        delete decoratedShape;\n    }\n};\n\n// \"ConcreteDecorator\"\nclass RedShapeDecorator : public ShapeDecorator {\npublic:\n    RedShapeDecorator(Shape* decoratedShape) : ShapeDecorator(decoratedShape) {}\n\n    void draw() const override {\n        ShapeDecorator::draw();\n        setRedBorder(decoratedShape);   // 附加的行为\n    }\n\nprivate:\n    void setRedBorder(Shape* decoratedShape) const {\n        std::cout << \"Border Color: Red\" << std::endl;\n    }\n};\n\nint main() {\n    Shape* circle = new Circle();\n    Shape* redCircle = new RedShapeDecorator(new Circle());\n    Shape* redRectangle = new RedShapeDecorator(new Rectangle());\n\n    std::cout << \"Circle with normal border:\" << std::endl;\n    circle->draw();\n\n    std::cout << \"\\nCircle of red border:\" << std::endl;\n    redCircle->draw();\n\n    std::cout << \"\\nRectangle of red border:\" << std::endl;\n    redRectangle->draw();\n\n    delete circle;\n    delete redCircle;\n    delete redRectangle;\n\n    return 0;\n}\n```\n\n## 五、享元模式\n\n> 享元模式主要用于减少创建对象的数量，用于减少内存占用和提高性能。享元模式会尝试重用现有的同类对象，如果我们找到了这个对象，那么就会对这个对象进行返回，如果未找这个对象，才会重新申请一个新的对象。主要目的是支持大量的细粒度对象，这些对象中有相当部分的状态可以共享。通过共享，可以在有限的内存资源下支持大规模的对象数量。\n\n![享元模式-01](design-model/享元模式_01.png)\n\n在我们的使用过程中，通常享元模式需要定义享元抽象类，抽象类中会有子类需要共享的方法和属性，并且通过子类继承抽象类，实现对应的抽象方法，我们的子类也会拥有属于子类的独有的属性和方法。\n\n同时，我们会定义一个享元工厂，享元工厂负责创建和管理享元对象，管理的方式通常使用`HashMap`哈希表的映射来完成，如果需要创建某一个对象的`key`已经存在，则说明这个对象已经存在在内存当中，可以作为享元对象直接返回，当在哈希表中找不到`key`时，才会新建一个新的对象。\n\n在我们的客户端只需要维护对享元对象的引用，并计算或存储享元对象的外部状态即可。外部状态指的是，客户端用于标识具体对象的一些标志。所以在使用的过程中，应该注意的是要明确区分内部状态和外部状态，实现状态分离，以免混淆。\n\n```C++\n#include <iostream>\n#include <map>\n#include <string>\n\n// 享元接口类\nclass Character {\npublic:\n    virtual ~Character() = default;\n    virtual void display() const = 0;\n};\n\n// 具体享元类\nclass ConcreteCharacter : public Character {\nprivate:\n    char glyph; // 内部状态：字符本身\n    \npublic:\n    ConcreteCharacter(char argGlyph) : glyph(argGlyph) {}\n    \n    void display() const override {\n        std::cout << \"Displaying character: \" << glyph << std::endl;\n    }\n};\n\n// 享元工厂类\nclass CharacterFactory {\nprivate:\n    std::map<char, Character*> characters; // 缓存已创建的享元对象\n    \npublic:\n    ~CharacterFactory() {\n        for (auto& pair : characters) {\n            delete pair.second;\n        }\n        characters.clear();\n    }\n    \n    Character* getCharacter(char key) {\n        if (characters.find(key) == characters.end()) {\n            // 如果字符不存在，则创建一个新的ConcreteCharacter并加入映射中\n            characters[key] = new ConcreteCharacter(key);\n        }\n        return characters[key];\n    }\n};\n\nint main() {\n    // 客户端代码\n    CharacterFactory factory;\n\n    // 创建几个字符对象\n    Character* characterA = factory.getCharacter('A');\n    Character* characterB = factory.getCharacter('B');\n    Character* characterA2 = factory.getCharacter('A'); // 再次请求'A'，应该得到相同的实例\n\n    // 显示字符\n    characterA->display();\n    characterB->display();\n    characterA2->display();\n\n    // 检查两个‘A’是否相同\n    std::cout << \"Are the two 'A' instances the same? \" << (characterA == characterA2 ? \"Yes\" : \"No\") << std::endl;\n\n    // 不需要手动删除字符对象，因为由CharacterFactory管理\n    return 0;\n}\n```\n\n## 六、责任链模式\n\n> 责任链模式为请求创建了一个接收者对象的链，它允许多个对象来处理一个请求，而无需发送者知道接收者的具体信息。请求在一系列接收者对象之间传递直到被处理，每一个接收者持有下一个接收者的引用，这样接收者就形成了一条链，并且每个链上的对象将决定自己能否处理请求或者应该将请求传递给链上的下一个对象。\n\n责任链模式主要解决的问题是解耦发送者和接收者，使得多个对象都有可能接收请求，而发送者不需要知道哪个对象会处理它。就好像我们的发送者只需要将需要处理的请求丢给`handle`责任链上，而无需在意最后的请求是谁处理的一样，这样可以简化对象之间的连接，达到解耦的目的。\n\n我们会定义一个抽象处理类，在这个处理类中会拥有一个指向下一个处理类的指针，并使用接口完成责任链的构建，我们责任链上的不同任务会通过传入的不同参数来进行标识。\n\n在我们的抽象处理类中，会有一个处理请求的抽象方法，这个方法是用于遍历责任链的，如果我们的子处理类无法处理当前的请求时，我们会调用下一个处理类来完成这个请求的处理。\n\n使用这样的责任链方式，我们可以减少请求方和具体实现方的耦合，我们可以发现这样的设计模式能够很好的满足设计模式中的依赖倒置原则，请求方和实现方都依赖的是抽象接口而不各自依赖。\n\n```C++\n#include <iostream>\n#include <memory>\n\n// 抽象处理器类\nclass Handler {\nprotected:\n    std::shared_ptr<Handler> next_handler;\npublic:\n    virtual ~Handler() = default;\n    \n    void setNext(std::shared_ptr<Handler> handler) {\n        next_handler = handler;\n    }\n    \n    virtual void handleRequest(int request) {\n        if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 具体处理器类A\nclass ConcreteHandlerA : public Handler {\npublic:\n    void handleRequest(int request) override {\n        if (request < 10) { // 可以处理小于10的请求\n            std::cout << \"Handler A is handling request: \" << request << std::endl;\n        } else if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 具体处理器类B\nclass ConcreteHandlerB : public Handler {\npublic:\n    void handleRequest(int request) override {\n        if (request >= 10) { // 可以处理大于等于10的请求\n            std::cout << \"Handler B is handling request: \" << request << std::endl;\n        } else if (next_handler) {\n            next_handler->handleRequest(request);\n        }\n    }\n};\n\n// 客户端代码\nint main() {\n    auto handlerA = std::make_shared<ConcreteHandlerA>();\n    auto handlerB = std::make_shared<ConcreteHandlerB>();\n    \n    handlerA->setNext(handlerB); // 设置责任链\n    \n    // 发出请求\n    handlerA->handleRequest(5);  // 将由HandlerA处理\n    handlerA->handleRequest(20); // 将由HandlerB处理\n\n    return 0;\n}\n```\n\n## 七、代理模式\n\n> 代理模式通过引入一个代理对象来控制原对象的访问。代理对象在客户端和目标对象之间充当中介，负责将客户端的请求转发给目标对象，同时可以在转发请求前后进行额外的处理，比如安全控制，延迟初始化，远程通信，记录日志等。\n\n代理模式实际上就是在客户端和实际服务对象之间建立一个中介层，用于在请求被送达给服务对象之前或之后执行某些操作\n\n在我们的代理类中，会继承于抽象类，并拥有一个具体类的实例，如果我们想要在真实类的某一个接口的前后添加譬如日志之类的额外处理，我们可以在代理类中实现抽象类中的接口，并在这个接口的前后添加对应的功能。\n\n* 问题一、代理模式和适配器模式的区别\n\n    代理模式，实现的是对另一个对象（原始被代理的对象）的控制访问，可以添加一些额外的功能，但是不应该改变原始对象的行为和功能。\n\n    适配器模式，适用于连接两个不兼容的接口，涉及到两类对象，通常会由适配器继承于一个对象，并拥有另一个对象的实例，在使用适配器进行适配的时候，通过修改所继承的接口方法来调用到被适配对象的行为，即把原接口适配成另一个客户想要的接口。\n\n* 问题二、代理模式和装饰器模式的区别\n\n    代理模式主要用于控制对资源的访问，通常只有一个代理类，而装饰器模式旨在不改变对象的接口的情况下，为对象添加行为，可以使用多个装饰器来增强对象的功能。\n\n    代理模式通常在编译时就确定了，它管理对象的生命周期并可以进行一些特定的任务，如懒加载、权限控制等；而装饰器可以在运行时递归地将装饰层嵌套起来，以此在不改变原始对象代码的基础上增强对象的行为。\n\n    代理模式关注于对对象的控制，例如为远程对象提供本地代理的过程中可能会处理网络通信、线程同步等问题；装饰器模式关注于增加对象的新功能，强调的是扩展对象的行为。\n\n```C++\n#include <iostream>\n#include <memory>\n\n// 抽象主题类\nclass Subject {\npublic:\n    virtual ~Subject() = default;\n    virtual void request() const = 0;\n};\n\n// 真实主题类\nclass RealSubject : public Subject {\npublic:\n    void request() const override {\n        std::cout << \"RealSubject: Handling request.\" << std::endl;\n    }\n};\n\n// 代理类\nclass Proxy : public Subject {\nprivate:\n    std::shared_ptr<RealSubject> real_subject;\n\n    bool checkAccess() const {\n        // 检查访问权限的逻辑\n        std::cout << \"Proxy: Checking access prior to firing a real request.\" << std::endl;\n        return true; // 假设访问权限得到了验证\n    }\n\n    void logAccess() const {\n        // 日志记录的逻辑\n        std::cout << \"Proxy: Logging the time of request.\" << std::endl;\n    }\n\npublic:\n    Proxy(std::shared_ptr<RealSubject> real_subject) : real_subject(real_subject) {}\n\n    void request() const override {\n        if (this->checkAccess()) {\n            this->real_subject->request(); // 调用真实主题的方法\n            this->logAccess(); // 记录请求日志\n        }\n    }\n};\n\n// 客户端代码\nint main() {\n    auto real_subject = std::make_shared<RealSubject>();\n    Proxy proxy(real_subject);\n    \n    proxy.request(); // 客户端使用代理完成工作\n\n    return 0;\n}\n```\n\n## 八、观察者模式\n\n> 观察者模式定义了一种一对多的依赖关系，当一个对象的状态发生改变时，其所有依赖者都会收到通知，并自动更新，主要用于分布式事件处理系统、消息发布/订阅机制，以及各种需要对象间解耦的场景。关键在于主题和观察者之间不直接进行通信，而是通过注册和通知机制进行交互。\n\n观察者模式通常包含几个核心角色\n\n* 主题：它是具有状态的对象，并维护这一个观察这列表。一般我们主题会提供添加、删除和通知观察者的方法\n* 观察者：观察者是接收主题通知的对象。观察者会实现一个更新方法，当我们收到主题的通知时，会调用该方法进行更新操作\n* 具体主题：具体主题时主题的具体实现类，会维护具体主题需要通知的观察者列表，并且在状态发生改变的时候通知观察者\n* 具体观察者：具体观察者是观察者的具体实现类。不同的观察者可能会实现各自的更新方法，方法中会定义收到主题通知时要执行的具体操作\n\n在我们使用的时候，基本逻辑就是，主题维护一个观察者列表，我们需要关注这个主题的观察者通过主题的实例对象来进行注册，注册到对应的主题当中，在我们的主题中会通过实现`notify`的方法，主动的调用观察者的更新函数。\n\n比较常见的场景就是`ros`的发布与订阅机制，订阅的节点通过订阅来将自己加入到具体的主题当中，当有主题到来的时候，就是状态触发的过程，就会通知各个订阅者进行相应的操作。\n\n```C++\n#include <iostream>\n#include <string>\n#include <list>\n#include <algorithm>\n\n// 前向声明\nclass Subject;\n\n// Observer接口\nclass Observer {\npublic:\n    virtual ~Observer() {}\n    virtual void update(Subject* subject) = 0;\n};\n\n// Subject接口\nclass Subject {\nprivate:\n    std::list<Observer*> observers; // 观察者列表\n\npublic:\n    virtual ~Subject() {}\n\n    // 注册观察者\n    void attach(Observer* obs) {\n        observers.push_back(obs);\n    }\n\n    // 注销观察者\n    void detach(Observer* obs) {\n        observers.remove(obs);\n    }\n\n    // 通知所有注册的观察者\n    void notify() {\n        for (auto& observer : observers) {\n            observer->update(this);\n        }\n    }\n\n    // 获取状态（必须由具体的主题实现）\n    virtual std::string getState() const = 0;\n};\n\n// 具体的Subject实现\nclass ConcreteSubject : public Subject {\nprivate:\n    std::string state;\n\npublic:\n    // 设置新状态并通知观察者\n    void setState(const std::string& newState) {\n        state = newState;\n        notify();\n    }\n\n    // 覆盖getState方法\n    std::string getState() const override {\n        return state;\n    }\n};\n\n// 具体的Observer实现\nclass ConcreteObserver : public Observer {\npublic:\n    void update(Subject* subject) override {\n        if (subject) {\n            std::cout << \"Observer received a new state: \" << subject->getState() << std::endl;\n        }\n    }\n};\n\nint main() {\n    // 创建主题和观察者\n    ConcreteSubject* concreteSubject = new ConcreteSubject();\n    Observer* observer1 = new ConcreteObserver();\n    Observer* observer2 = new ConcreteObserver();\n\n    // 注册观察者\n    concreteSubject->attach(observer1);\n    concreteSubject->attach(observer2);\n\n    // 改变状态并通知观察者\n    concreteSubject->setState(\"state1\");\n\n    // 注销一个观察者并再次改变状态\n    concreteSubject->detach(observer1);\n    concreteSubject->setState(\"state2\");\n\n    // 清理资源\n    delete observer1;\n    delete observer2;\n    delete concreteSubject;\n\n    return 0;\n}\n```\n\n## 九、策略模式\n\n策略模式可以定义一系列的算法行为，并且把它们封装起来，提供给客户一定的自由度，能够使它们进行互相替换，策略模式允许算法独立于使用它们的客户端的变化。\n\n![策略模式-01](design-model/策略模式_01.png)\n\n在C++中我们会定义一个抽象策略基类，不同的策略会继承于这个抽象类，并重写基类中需要进行策略呼唤的方法。\n\n在我们客户端需要使用策略的对象当中，会有一个抽象策略基类的指针，用于引用到子类的不同策略对象实例。通过不同的策略实例的调用就能够在我们客户端用到不同的方法了。\n\n```C++\n#include <iostream>\n#include <vector>\n#include <algorithm> // std::sort\n\n// Strategy Interface\nclass SortingStrategy {\npublic:\n    virtual void sort(std::vector<int>& dataset) = 0;\n    virtual ~SortingStrategy() {}\n};\n\n// Concrete Strategy A: Bubble Sort\nclass BubbleSort : public SortingStrategy {\npublic:\n    void sort(std::vector<int>& dataset) override {\n        bool swapped = true;\n        while (swapped) {\n            swapped = false;\n            for (size_t i = 1; i < dataset.size(); ++i) {\n                if (dataset[i - 1] > dataset[i]) {\n                    std::swap(dataset[i - 1], dataset[i]);\n                    swapped = true;\n                }\n            }\n        }\n    }\n};\n\n// Concrete Strategy B: Standard Library Sort\nclass StdSort : public SortingStrategy {\npublic:\n    void sort(std::vector<int>& dataset) override {\n        std::sort(dataset.begin(), dataset.end());\n    }\n};\n\n// Context\nclass SortedList {\nprivate:\n    std::vector<int> m_items;\n    SortingStrategy* m_strategy;\n\npublic:\n    SortedList(SortingStrategy* strategy) : m_strategy(strategy) {}\n\n    void set_strategy(SortingStrategy* strategy) {\n        m_strategy = strategy;\n    }\n\n    void add(int value) {\n        m_items.push_back(value);\n    }\n\n    void sort() {\n        m_strategy->sort(m_items);\n        for (int item : m_items) {\n            std::cout << item << \" \";\n        }\n        std::cout << std::endl;\n    }\n\n    ~SortedList() {\n        delete m_strategy;\n    }\n};\n\n// Client Code\nint main() {\n    std::vector<int> dataset = {5, 2, 9, 1, 5, 6};\n\n    // Use BubbleSort\n    SortedList* bubble_sorted_list = new SortedList(new BubbleSort());\n    for (int value : dataset) {\n        bubble_sorted_list->add(value);\n    }\n    std::cout << \"Bubble Sorted: \";\n    bubble_sorted_list->sort();\n    delete bubble_sorted_list;\n\n    // Use StdSort\n    SortedList* std_sorted_list = new SortedList(new StdSort());\n    for (int value : dataset) {\n        std_sorted_list->add(value);\n    }\n    std::cout << \"Std Sorted: \";\n    std_sorted_list->sort();\n    delete std_sorted_list;\n\n    return 0;\n}\n```\n\n参考链接：[菜鸟教程](https://www.runoob.com/design-pattern/design-pattern-tutorial.html)","slug":"design-model","published":1,"updated":"2024-07-03T10:02:33.800Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttt002108jvarze669h","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h1><blockquote>\n<p>设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的代码编写经验。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p>\n</blockquote>\n<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><p><strong>1、开闭原则（Open Close Principle）</strong></p>\n<p>开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。</p>\n<p><strong>2、里氏代换原则（Liskov Substitution Principle）</strong></p>\n<p>里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。</p>\n<p><strong>3、依赖倒转原则（Dependence Inversion Principle）</strong></p>\n<p>这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。</p>\n<p><strong>4、接口隔离原则（Interface Segregation Principle）</strong></p>\n<p>这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。</p>\n<p><strong>5、迪米特法则，又称最少知道原则（Demeter Principle）</strong></p>\n<p>最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。</p>\n<p><strong>6、合成复用原则（Composite Reuse Principle）</strong></p>\n<p>合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。</p>\n<h2 id=\"一、工厂模式\"><a href=\"#一、工厂模式\" class=\"headerlink\" title=\"一、工厂模式\"></a>一、工厂模式</h2><blockquote>\n<p>工厂模式是一种创建对象的方式，类似于利用统一工厂类去创建不同的对象，这样就能够让创建对象的过程和使用对象的过程进行分离。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"工厂模式_01\">\n<ul>\n<li><p>简单工厂模式</p>\n<p>  根据工厂类传入的参数来决定创建哪种类型的对象</p>\n</li>\n<li><p>工厂方法模式</p>\n<p>  定义一个创建对象的接口，但由子类来决定实例化哪一个类，将对象的创建延迟到子类</p>\n<p>  不同的产品类继承于同一个抽象产品基类，同时为每一个产品类分配一个单独的创建类，创建类继承于创建基类，创建基类中有一个用于接收产品基类返回值的抽象方法，所有的创建类会重新这个方法，并在这个方法中，创建对应的产品对象，返回给产品基类接收。</p>\n<p>  在创建基类中，同时会定义一个接口方法，这个方法的实现会先通过抽象方法先创建出一个产品抽象类，并调用产品抽象类中的抽象方法，就能够达到统一调用子类方法的目的。</p>\n<p>  在实际使用中，用户只需要知道创建抽象类以及抽象类中的方法即可，当我们需要使用某一个产品的时候，我们只需要通过使用创建基类的指针指向一个某一个产品的创建子类的对象，通过调用创建基类中的方法就可以完成对应的功能。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 产品基类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Product</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Product</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA</span> : <span class=\"hljs-keyword\">public</span> Product &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Result of the ConcreteProductA&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB</span> : <span class=\"hljs-keyword\">public</span> Product &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Result of the ConcreteProductB&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 创建者基类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Creator</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Creator</span>() &#123;&#125;<br>    <span class=\"hljs-comment\">// 工厂方法，用于创建产品对象</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-comment\">// 创建者类的业务逻辑</span><br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">SomeOperation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 调用工厂方法来创建一个产品对象</span><br>        <span class=\"hljs-function\">std::unique_ptr&lt;Product&gt; <span class=\"hljs-title\">product</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">this</span>-&gt;FactoryMethod())</span></span>;<br>        <span class=\"hljs-comment\">// 使用产品</span><br>        std::string result = <span class=\"hljs-string\">&quot;Creator: The same creator&#x27;s code has just worked with &quot;</span> + product-&gt;<span class=\"hljs-built_in\">Operation</span>();<br>        <span class=\"hljs-keyword\">return</span> result;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体创建者A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCreatorA</span> : <span class=\"hljs-keyword\">public</span> Creator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteProductA</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体创建者B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCreatorB</span> : <span class=\"hljs-keyword\">public</span> Creator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteProductB</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">ClientCode</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> Creator&amp; creator)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// ...</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: I&#x27;m not aware of the creator&#x27;s class, but it still works.\\n&quot;</span><br>            &lt;&lt; creator.<span class=\"hljs-built_in\">SomeOperation</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-comment\">// ...</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::unique_ptr&lt;Creator&gt; creator = std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteCreatorA&gt;();<br>    <span class=\"hljs-built_in\">ClientCode</span>(*creator);<br><br>    std::cout &lt;&lt; std::endl;<br>    <br>    creator = std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteCreatorB&gt;();<br>    <span class=\"hljs-built_in\">ClientCode</span>(*creator);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>抽象工厂模式</p>\n  <img src=\"/2024/06/26/design-model/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F_02.png\" class=\"\" title=\"工厂模式_02\">\n<p>  提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类</p>\n<p>  我们可以看出来工厂方法模式只关注某一类产品的构建，但是我们可以通过对抽象产品的继承来丰富这一类产品的类型。如果我们有多类产品的话，那就需要用到抽象工厂了。</p>\n<p>  因为我们有多类产品，所以我们会定义多个产品的抽象基类，这些产品基类会由多个产品子类来继承生成不同产品，在子类中会分别实现不同产品基类的抽象方法，如果我们需要在不同的产品类中进行通信的话，我们的抽象产品基类中应该还有一个能够将另一个产品基类作为形参传入的方法，在我们的具体产品中重写这一个方法。</p>\n<p>  同样我们会有一个抽象工厂，抽象工厂中会有创建不同产品的方法，这些方法都是以抽象产品基类指针作为返回值接收。抽象工厂子类会实现这些方法，它们可以选择性的去创建不同的产品子类，只需要实现对应的抽象产品方法即可，也就是说一个工厂是有可能可以创建多类产品的，尤其是当这些产品需要进行交互的时候。</p>\n<p>  下面的例子便是在具体工厂中实现多个产品的创建，当然我们只想让一个工厂对应某一类产品的话，我们只需要在对应的抽象方法中，返回<code>nullptr</code>就好了。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象产品A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractProductA</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractProductA</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 抽象产品B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractProductB</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractProductB</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-comment\">// 抽象方法，示例产品B能够与产品A进行交互</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA1</span> : <span class=\"hljs-keyword\">public</span> AbstractProductA &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product A1.&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA2</span> : <span class=\"hljs-keyword\">public</span> AbstractProductA &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product A2.&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB1</span> : <span class=\"hljs-keyword\">public</span> AbstractProductB &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product B1.&quot;</span>;<br>    &#125;<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">const</span> std::string result = collaborator.<span class=\"hljs-built_in\">UsefulFunctionA</span>();<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the B1 collaborating with ( &quot;</span> + result + <span class=\"hljs-string\">&quot; )&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB2</span> : <span class=\"hljs-keyword\">public</span> AbstractProductB &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product B2.&quot;</span>;<br>    &#125;<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">const</span> std::string result = collaborator.<span class=\"hljs-built_in\">UsefulFunctionA</span>();<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the B2 collaborating with ( &quot;</span> + result + <span class=\"hljs-string\">&quot; )&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 抽象工厂</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractFactory</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractFactory</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体工厂1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteFactory1</span> : <span class=\"hljs-keyword\">public</span> AbstractFactory &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductA1&gt;();<br>    &#125;<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductB1&gt;();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体工厂2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteFactory2</span> : <span class=\"hljs-keyword\">public</span> AbstractFactory &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductA2&gt;();<br>    &#125;<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductB2&gt;();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">ClientCode</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractFactory&amp; factory)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> product_a = factory.<span class=\"hljs-built_in\">CreateProductA</span>();<br>    <span class=\"hljs-keyword\">auto</span> product_b = factory.<span class=\"hljs-built_in\">CreateProductB</span>();<br>    std::cout &lt;&lt; product_b-&gt;<span class=\"hljs-built_in\">UsefulFunctionB</span>() &lt;&lt; <span class=\"hljs-string\">&quot;\\n&quot;</span>;<br>    std::cout &lt;&lt; product_b-&gt;<span class=\"hljs-built_in\">AnotherUsefulFunctionB</span>(*product_a) &lt;&lt; <span class=\"hljs-string\">&quot;\\n&quot;</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: Testing client code with the first factory type:\\n&quot;</span>;<br>    ConcreteFactory1 f1;<br>    <span class=\"hljs-built_in\">ClientCode</span>(f1);<br><br>    std::cout &lt;&lt; std::endl;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: Testing the same client code with the second factory type:\\n&quot;</span>;<br>    ConcreteFactory2 f2;<br>    <span class=\"hljs-built_in\">ClientCode</span>(f2);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"二、单例模式\"><a href=\"#二、单例模式\" class=\"headerlink\" title=\"二、单例模式\"></a>二、单例模式</h2><blockquote>\n<p>单例模式是一种比较常见的设计模式，在应用中十分广泛，在使用过程中用于确保一个对象中只有一个实例，并且会为这个实例提供一个全局访问点。在我们实际应用中，经常会用于一些控制资源共享的场景中，比如日志记录。因为只存在一个实例，所以需要考虑到这个实例在多线程的情况下资源竞争的问题。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"单例模式_01\">\n<p>在我们的单例模式实际应用中，通常会提供一个统一的静态全局访问方法，方法名一般叫做<code>getinstance()</code>，用于获取当前单例的实例对象，而我们会根据单例的创建时机将单例模式分为两种，懒汉式和饿汉式。</p>\n<ul>\n<li><p>懒汉式</p>\n<p>  懒汉式单例模式，指的是在我的当前工作进程中，不一定程序启动以后，单例跟着也同样进行实例化，而是只有当我们需要用到这一个单例的时候才会对这个单例进行实例化，具体的实现过程就是把单例的实例化代码写入到<code>getinstance()</code>函数中，当我们第一次调用到<code>getinstance()</code>的时候，我们会实例化这一个单例。</p>\n<p>  我们会把<code>instance</code>权限设置为私有，并且提供一个静态方法，用于创建并返回单例。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-comment\">// 私有静态指针变量，用于持有类的唯一实例</span><br>    <span class=\"hljs-type\">static</span> LazySingleton* instance;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-comment\">// 受保护的构造函数，防止外部通过 new 创建实例</span><br>    <span class=\"hljs-built_in\">LazySingleton</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 删除拷贝构造函数和赋值操作符</span><br>    <span class=\"hljs-built_in\">LazySingleton</span>(<span class=\"hljs-type\">const</span> LazySingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br>    LazySingleton&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> LazySingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br><br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 在类中提供公共的静态方法来获取实例</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> LazySingleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 检查是否为空</span><br>            instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">LazySingleton</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br></code></pre></td></tr></table></figure>\n<p>  我们可以看到在单线程的情况下，这样的代码是没有问题的，但是如果是多线程的环境下，如果我们有多个线程同时到达<code>GetInstance</code>这个函数，那么就存在有多次创建这个单例的风险，违背了我们单例模式的初衷。</p>\n<p>  很显然，我们可以通过加锁来完成不同线程创建多个单例的风险规避。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Singleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">static</span> Singleton* instance;<br>    <span class=\"hljs-type\">static</span> std::mutex mutex;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-built_in\">Singleton</span>() &#123;&#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Singleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lock</span><span class=\"hljs-params\">(mutex)</span></span>; <span class=\"hljs-comment\">// 加锁</span><br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123;<br>            instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Singleton</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br>&#125;;<br><br>Singleton* Singleton::instance = <span class=\"hljs-literal\">nullptr</span>;<br>std::mutex Singleton::mutex;<br></code></pre></td></tr></table></figure>\n<p>  这样的实现方式我们可以很明显的看出来有一些小问题，就是需要处理多线程之间的同步问题，在上面的实现方式中，无论我的实例是否已经被创建，都需要获取到锁以后才能够进入到后面的代码当中，在实际应用中，我们只有在单例未被创建的时候完成同步就可以了，如果单例已经在进程当中，那我们直接返回这个单例就行。</p>\n<p>  所以，我们有了另一种实现方式</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Singleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">static</span> Singleton* instance;<br>    <span class=\"hljs-type\">static</span> std::mutex mutex;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-built_in\">Singleton</span>() &#123;&#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Singleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 第一次检查，如果单例已经存在，不需要加锁直接返回单例</span><br>            <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lock</span><span class=\"hljs-params\">(mutex)</span></span>; <span class=\"hljs-comment\">// 加锁</span><br>            <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 第二次检查，只有当单例不存在的时候，才会确保只有一个线程创建了单例</span><br>                instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Singleton</span>();<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br>&#125;;<br><br>Singleton* Singleton::instance = <span class=\"hljs-literal\">nullptr</span>;<br>std::mutex Singleton::mutex;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>饿汉式</p>\n<p>  可以看到，我们的主进程在初始化这个单例的时候，我们不像之前一样，把单例初始化为<code>nullptr</code>，而是切切实实的创建了这一个单例，而在我们的<code>GetInstance()</code>方法中会直接返回这一个单例，因为我们的单例已经不可能为空了。</p>\n<p>  这样的方式能够避免多个单例的创建，因为创建指挥发生在主进程对类加载的时候，但是牺牲的代价是便是内存的耗费，并且我们不应该提供对这个单例销毁的方法，因为，我们销毁以后想要再次用到这个单例的话，就没有单例创建的入口了。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">EagerSingleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-comment\">// 在定义变量的时候就初始化实例</span><br>    <span class=\"hljs-type\">static</span> EagerSingleton instance;<br><br>    <span class=\"hljs-comment\">// 私有构造函数，防止外部通过 new 创建实例</span><br>    <span class=\"hljs-built_in\">EagerSingleton</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 删除拷贝构造函数和赋值操作符，防止拷贝和赋值</span><br>    <span class=\"hljs-built_in\">EagerSingleton</span>(<span class=\"hljs-type\">const</span> EagerSingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br>    EagerSingleton&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> EagerSingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 提供公共的静态方法来获取实例的引用</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> EagerSingleton&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br><br>&#125;;<br><br><span class=\"hljs-comment\">// 类静态成员变量，在程序开始时即完成初始化</span><br>EagerSingleton EagerSingleton::instance;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"三、适配器模式\"><a href=\"#三、适配器模式\" class=\"headerlink\" title=\"三、适配器模式\"></a>三、适配器模式</h2><blockquote>\n<p>适配器可以充当两个不兼容接口之间的桥梁，通过一个中间件，将一个类的接口转换成客户期望的另一个接口，使得原本不能工作的类能够协同工作。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"适配器模式-01\">\n<p>适配器模式一般有两种方式来实现，分别是对象适配器模式，和类适配器模式。在对象适配器模式中，适配器类会继承于目标类的接口，并拥有一个需要适配的类的引用，在适配器类中就能够通过引用来调用是需要适配的方法。类适配器模式则是用到的多继承思想，适配器类通过多继承的方式，同时拥有目标类和适配类的方法。</p>\n<ul>\n<li>对象适配器模式  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 目标接口（Target），客户端期望的接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Target</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Target: Default behavior.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 被适配的类（Adaptee），拥有一个特殊的请求方法</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Adaptee</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">SpecificRequest</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Adaptee: Specific request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 适配器类（Adapter），使 Adaptee 与 Target 接口兼容</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Adapter</span> : <span class=\"hljs-keyword\">public</span> Target &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    Adaptee* adaptee;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Adapter</span>(Adaptee* a) : <span class=\"hljs-built_in\">adaptee</span>(a) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        adaptee-&gt;<span class=\"hljs-built_in\">SpecificRequest</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    Adaptee* adaptee = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Adaptee</span>();<br>    Target* target = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Adapter</span>(adaptee);<br>    <br>    target-&gt;<span class=\"hljs-built_in\">Request</span>();<br><br>    <span class=\"hljs-keyword\">delete</span> adaptee;<br>    <span class=\"hljs-keyword\">delete</span> target;<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"四、装饰器模式\"><a href=\"#四、装饰器模式\" class=\"headerlink\" title=\"四、装饰器模式\"></a>四、装饰器模式</h2><img src=\"/2024/06/26/design-model/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"装饰器模式-01\">\n<p>通常我们在需要在不改变某一个类的功能的前提下为这个类提供新的拓展功能和方法的时候，我们会考虑的一种方式是通过对象的继承，在子类中写一些新的方法，这样子就能够通过使用子类来达到拓展父类功能的目的。而使用继承的方式，我们通常在编译的时候就确定了子类的相关行为。与此同时，如果一个父类存在有多个可能的变化方向，那么我们就需要通过继承的方式实现每一种组合，这样子无疑会使得我们子类的数量呈指数型暴增。</p>\n<p>在这样的背景下，我们有了装饰器模式的产生。装饰器可以独立存在，更加灵活，能够动态地扩展对象的功能并且可以通过组合的方式将多个装饰应用在对象上。</p>\n<p>装饰器模式通常涉及以下几个角色：</p>\n<ul>\n<li>Component：定义一个对象接口，可以给这些对象动态地添加职责。</li>\n<li>ConcreteComponent：定义了一个具体的对象，也可以给这个对象添加一些额外的职责。</li>\n<li>Decorator：持有一个组件（Component）对象的实例，并定义一个与组件接口一致的接口。</li>\n<li>ConcreteDecorator：具体的装饰类，实现了在组件的接口中定义的操作，并添加新的操作，以给组件对象增加额外的职责。</li>\n</ul>\n<p>我们会使用一个装饰器类继承于抽象基类，并在这个装饰器类中持有一个基类的指针对象，在实现基类的方法的时候，通过这一个指针来调用其他具体子类实体的方法。同时我们会有另一个类继承于这一个装饰器类，我们可以叫做拓展装饰器类，在我们的拓展装饰器类中，我们可以拓展具体子类的新功能。这个功能的拓展可以包裹在原始功能的前后，类似于附加一个行为层。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><br><span class=\"hljs-comment\">// &quot;Component&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Shape</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Shape</span>() &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;ConcreteComponent&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Circle</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Shape: Circle&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Rectangle</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Shape: Rectangle&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;Decorator&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ShapeDecorator</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">protected</span>:<br>    Shape* decoratedShape;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ShapeDecorator</span>(Shape* shape) : <span class=\"hljs-built_in\">decoratedShape</span>(shape) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        decoratedShape-&gt;<span class=\"hljs-built_in\">draw</span>();<br>    &#125;<br><br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">ShapeDecorator</span>() &#123;<br>        <span class=\"hljs-keyword\">delete</span> decoratedShape;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;ConcreteDecorator&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RedShapeDecorator</span> : <span class=\"hljs-keyword\">public</span> ShapeDecorator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">RedShapeDecorator</span>(Shape* decoratedShape) : <span class=\"hljs-built_in\">ShapeDecorator</span>(decoratedShape) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        ShapeDecorator::<span class=\"hljs-built_in\">draw</span>();<br>        <span class=\"hljs-built_in\">setRedBorder</span>(decoratedShape);   <span class=\"hljs-comment\">// 附加的行为</span><br>    &#125;<br><br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setRedBorder</span><span class=\"hljs-params\">(Shape* decoratedShape)</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Border Color: Red&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    Shape* circle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Circle</span>();<br>    Shape* redCircle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">RedShapeDecorator</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Circle</span>());<br>    Shape* redRectangle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">RedShapeDecorator</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Rectangle</span>());<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Circle with normal border:&quot;</span> &lt;&lt; std::endl;<br>    circle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\nCircle of red border:&quot;</span> &lt;&lt; std::endl;<br>    redCircle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\nRectangle of red border:&quot;</span> &lt;&lt; std::endl;<br>    redRectangle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    <span class=\"hljs-keyword\">delete</span> circle;<br>    <span class=\"hljs-keyword\">delete</span> redCircle;<br>    <span class=\"hljs-keyword\">delete</span> redRectangle;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"五、享元模式\"><a href=\"#五、享元模式\" class=\"headerlink\" title=\"五、享元模式\"></a>五、享元模式</h2><blockquote>\n<p>享元模式主要用于减少创建对象的数量，用于减少内存占用和提高性能。享元模式会尝试重用现有的同类对象，如果我们找到了这个对象，那么就会对这个对象进行返回，如果未找这个对象，才会重新申请一个新的对象。主要目的是支持大量的细粒度对象，这些对象中有相当部分的状态可以共享。通过共享，可以在有限的内存资源下支持大规模的对象数量。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"享元模式-01\">\n<p>在我们的使用过程中，通常享元模式需要定义享元抽象类，抽象类中会有子类需要共享的方法和属性，并且通过子类继承抽象类，实现对应的抽象方法，我们的子类也会拥有属于子类的独有的属性和方法。</p>\n<p>同时，我们会定义一个享元工厂，享元工厂负责创建和管理享元对象，管理的方式通常使用<code>HashMap</code>哈希表的映射来完成，如果需要创建某一个对象的<code>key</code>已经存在，则说明这个对象已经存在在内存当中，可以作为享元对象直接返回，当在哈希表中找不到<code>key</code>时，才会新建一个新的对象。</p>\n<p>在我们的客户端只需要维护对享元对象的引用，并计算或存储享元对象的外部状态即可。外部状态指的是，客户端用于标识具体对象的一些标志。所以在使用的过程中，应该注意的是要明确区分内部状态和外部状态，实现状态分离，以免混淆。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;map&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><br><span class=\"hljs-comment\">// 享元接口类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Character</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Character</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">display</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体享元类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCharacter</span> : <span class=\"hljs-keyword\">public</span> Character &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">char</span> glyph; <span class=\"hljs-comment\">// 内部状态：字符本身</span><br>    <br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ConcreteCharacter</span>(<span class=\"hljs-type\">char</span> argGlyph) : <span class=\"hljs-built_in\">glyph</span>(argGlyph) &#123;&#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">display</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Displaying character: &quot;</span> &lt;&lt; glyph &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 享元工厂类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CharacterFactory</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::map&lt;<span class=\"hljs-type\">char</span>, Character*&gt; characters; <span class=\"hljs-comment\">// 缓存已创建的享元对象</span><br>    <br><span class=\"hljs-keyword\">public</span>:<br>    ~<span class=\"hljs-built_in\">CharacterFactory</span>() &#123;<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">auto</span>&amp; pair : characters) &#123;<br>            <span class=\"hljs-keyword\">delete</span> pair.second;<br>        &#125;<br>        characters.<span class=\"hljs-built_in\">clear</span>();<br>    &#125;<br>    <br>    <span class=\"hljs-function\">Character* <span class=\"hljs-title\">getCharacter</span><span class=\"hljs-params\">(<span class=\"hljs-type\">char</span> key)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (characters.<span class=\"hljs-built_in\">find</span>(key) == characters.<span class=\"hljs-built_in\">end</span>()) &#123;<br>            <span class=\"hljs-comment\">// 如果字符不存在，则创建一个新的ConcreteCharacter并加入映射中</span><br>            characters[key] = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteCharacter</span>(key);<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> characters[key];<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 客户端代码</span><br>    CharacterFactory factory;<br><br>    <span class=\"hljs-comment\">// 创建几个字符对象</span><br>    Character* characterA = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;A&#x27;</span>);<br>    Character* characterB = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;B&#x27;</span>);<br>    Character* characterA2 = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;A&#x27;</span>); <span class=\"hljs-comment\">// 再次请求&#x27;A&#x27;，应该得到相同的实例</span><br><br>    <span class=\"hljs-comment\">// 显示字符</span><br>    characterA-&gt;<span class=\"hljs-built_in\">display</span>();<br>    characterB-&gt;<span class=\"hljs-built_in\">display</span>();<br>    characterA2-&gt;<span class=\"hljs-built_in\">display</span>();<br><br>    <span class=\"hljs-comment\">// 检查两个‘A’是否相同</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Are the two &#x27;A&#x27; instances the same? &quot;</span> &lt;&lt; (characterA == characterA2 ? <span class=\"hljs-string\">&quot;Yes&quot;</span> : <span class=\"hljs-string\">&quot;No&quot;</span>) &lt;&lt; std::endl;<br><br>    <span class=\"hljs-comment\">// 不需要手动删除字符对象，因为由CharacterFactory管理</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、责任链模式\"><a href=\"#六、责任链模式\" class=\"headerlink\" title=\"六、责任链模式\"></a>六、责任链模式</h2><blockquote>\n<p>责任链模式为请求创建了一个接收者对象的链，它允许多个对象来处理一个请求，而无需发送者知道接收者的具体信息。请求在一系列接收者对象之间传递直到被处理，每一个接收者持有下一个接收者的引用，这样接收者就形成了一条链，并且每个链上的对象将决定自己能否处理请求或者应该将请求传递给链上的下一个对象。</p>\n</blockquote>\n<p>责任链模式主要解决的问题是解耦发送者和接收者，使得多个对象都有可能接收请求，而发送者不需要知道哪个对象会处理它。就好像我们的发送者只需要将需要处理的请求丢给<code>handle</code>责任链上，而无需在意最后的请求是谁处理的一样，这样可以简化对象之间的连接，达到解耦的目的。</p>\n<p>我们会定义一个抽象处理类，在这个处理类中会拥有一个指向下一个处理类的指针，并使用接口完成责任链的构建，我们责任链上的不同任务会通过传入的不同参数来进行标识。</p>\n<p>在我们的抽象处理类中，会有一个处理请求的抽象方法，这个方法是用于遍历责任链的，如果我们的子处理类无法处理当前的请求时，我们会调用下一个处理类来完成这个请求的处理。</p>\n<p>使用这样的责任链方式，我们可以减少请求方和具体实现方的耦合，我们可以发现这样的设计模式能够很好的满足设计模式中的依赖倒置原则，请求方和实现方都依赖的是抽象接口而不各自依赖。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象处理器类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Handler</span> &#123;<br><span class=\"hljs-keyword\">protected</span>:<br>    std::shared_ptr&lt;Handler&gt; next_handler;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Handler</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setNext</span><span class=\"hljs-params\">(std::shared_ptr&lt;Handler&gt; handler)</span> </span>&#123;<br>        next_handler = handler;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体处理器类A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteHandlerA</span> : <span class=\"hljs-keyword\">public</span> Handler &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (request &lt; <span class=\"hljs-number\">10</span>) &#123; <span class=\"hljs-comment\">// 可以处理小于10的请求</span><br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Handler A is handling request: &quot;</span> &lt;&lt; request &lt;&lt; std::endl;<br>        &#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体处理器类B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteHandlerB</span> : <span class=\"hljs-keyword\">public</span> Handler &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (request &gt;= <span class=\"hljs-number\">10</span>) &#123; <span class=\"hljs-comment\">// 可以处理大于等于10的请求</span><br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Handler B is handling request: &quot;</span> &lt;&lt; request &lt;&lt; std::endl;<br>        &#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 客户端代码</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> handlerA = std::<span class=\"hljs-built_in\">make_shared</span>&lt;ConcreteHandlerA&gt;();<br>    <span class=\"hljs-keyword\">auto</span> handlerB = std::<span class=\"hljs-built_in\">make_shared</span>&lt;ConcreteHandlerB&gt;();<br>    <br>    handlerA-&gt;<span class=\"hljs-built_in\">setNext</span>(handlerB); <span class=\"hljs-comment\">// 设置责任链</span><br>    <br>    <span class=\"hljs-comment\">// 发出请求</span><br>    handlerA-&gt;<span class=\"hljs-built_in\">handleRequest</span>(<span class=\"hljs-number\">5</span>);  <span class=\"hljs-comment\">// 将由HandlerA处理</span><br>    handlerA-&gt;<span class=\"hljs-built_in\">handleRequest</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 将由HandlerB处理</span><br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、代理模式\"><a href=\"#七、代理模式\" class=\"headerlink\" title=\"七、代理模式\"></a>七、代理模式</h2><blockquote>\n<p>代理模式通过引入一个代理对象来控制原对象的访问。代理对象在客户端和目标对象之间充当中介，负责将客户端的请求转发给目标对象，同时可以在转发请求前后进行额外的处理，比如安全控制，延迟初始化，远程通信，记录日志等。</p>\n</blockquote>\n<p>代理模式实际上就是在客户端和实际服务对象之间建立一个中介层，用于在请求被送达给服务对象之前或之后执行某些操作</p>\n<p>在我们的代理类中，会继承于抽象类，并拥有一个具体类的实例，如果我们想要在真实类的某一个接口的前后添加譬如日志之类的额外处理，我们可以在代理类中实现抽象类中的接口，并在这个接口的前后添加对应的功能。</p>\n<ul>\n<li><p>问题一、代理模式和适配器模式的区别</p>\n<p>  代理模式，实现的是对另一个对象（原始被代理的对象）的控制访问，可以添加一些额外的功能，但是不应该改变原始对象的行为和功能。</p>\n<p>  适配器模式，适用于连接两个不兼容的接口，涉及到两类对象，通常会由适配器继承于一个对象，并拥有另一个对象的实例，在使用适配器进行适配的时候，通过修改所继承的接口方法来调用到被适配对象的行为，即把原接口适配成另一个客户想要的接口。</p>\n</li>\n<li><p>问题二、代理模式和装饰器模式的区别</p>\n<p>  代理模式主要用于控制对资源的访问，通常只有一个代理类，而装饰器模式旨在不改变对象的接口的情况下，为对象添加行为，可以使用多个装饰器来增强对象的功能。</p>\n<p>  代理模式通常在编译时就确定了，它管理对象的生命周期并可以进行一些特定的任务，如懒加载、权限控制等；而装饰器可以在运行时递归地将装饰层嵌套起来，以此在不改变原始对象代码的基础上增强对象的行为。</p>\n<p>  代理模式关注于对对象的控制，例如为远程对象提供本地代理的过程中可能会处理网络通信、线程同步等问题；装饰器模式关注于增加对象的新功能，强调的是扩展对象的行为。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象主题类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Subject</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 真实主题类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RealSubject</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;RealSubject: Handling request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 代理类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Proxy</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::shared_ptr&lt;RealSubject&gt; real_subject;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">checkAccess</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 检查访问权限的逻辑</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Proxy: Checking access prior to firing a real request.&quot;</span> &lt;&lt; std::endl;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>; <span class=\"hljs-comment\">// 假设访问权限得到了验证</span><br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">logAccess</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 日志记录的逻辑</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Proxy: Logging the time of request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Proxy</span>(std::shared_ptr&lt;RealSubject&gt; real_subject) : <span class=\"hljs-built_in\">real_subject</span>(real_subject) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">checkAccess</span>()) &#123;<br>            <span class=\"hljs-keyword\">this</span>-&gt;real_subject-&gt;<span class=\"hljs-built_in\">request</span>(); <span class=\"hljs-comment\">// 调用真实主题的方法</span><br>            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">logAccess</span>(); <span class=\"hljs-comment\">// 记录请求日志</span><br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 客户端代码</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> real_subject = std::<span class=\"hljs-built_in\">make_shared</span>&lt;RealSubject&gt;();<br>    <span class=\"hljs-function\">Proxy <span class=\"hljs-title\">proxy</span><span class=\"hljs-params\">(real_subject)</span></span>;<br>    <br>    proxy.<span class=\"hljs-built_in\">request</span>(); <span class=\"hljs-comment\">// 客户端使用代理完成工作</span><br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"八、观察者模式\"><a href=\"#八、观察者模式\" class=\"headerlink\" title=\"八、观察者模式\"></a>八、观察者模式</h2><blockquote>\n<p>观察者模式定义了一种一对多的依赖关系，当一个对象的状态发生改变时，其所有依赖者都会收到通知，并自动更新，主要用于分布式事件处理系统、消息发布/订阅机制，以及各种需要对象间解耦的场景。关键在于主题和观察者之间不直接进行通信，而是通过注册和通知机制进行交互。</p>\n</blockquote>\n<p>观察者模式通常包含几个核心角色</p>\n<ul>\n<li>主题：它是具有状态的对象，并维护这一个观察这列表。一般我们主题会提供添加、删除和通知观察者的方法</li>\n<li>观察者：观察者是接收主题通知的对象。观察者会实现一个更新方法，当我们收到主题的通知时，会调用该方法进行更新操作</li>\n<li>具体主题：具体主题时主题的具体实现类，会维护具体主题需要通知的观察者列表，并且在状态发生改变的时候通知观察者</li>\n<li>具体观察者：具体观察者是观察者的具体实现类。不同的观察者可能会实现各自的更新方法，方法中会定义收到主题通知时要执行的具体操作</li>\n</ul>\n<p>在我们使用的时候，基本逻辑就是，主题维护一个观察者列表，我们需要关注这个主题的观察者通过主题的实例对象来进行注册，注册到对应的主题当中，在我们的主题中会通过实现<code>notify</code>的方法，主动的调用观察者的更新函数。</p>\n<p>比较常见的场景就是<code>ros</code>的发布与订阅机制，订阅的节点通过订阅来将自己加入到具体的主题当中，当有主题到来的时候，就是状态触发的过程，就会通知各个订阅者进行相应的操作。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;list&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span></span><br><br><span class=\"hljs-comment\">// 前向声明</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span>;<br><br><span class=\"hljs-comment\">// Observer接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Observer</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Observer</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(Subject* subject)</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// Subject接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::list&lt;Observer*&gt; observers; <span class=\"hljs-comment\">// 观察者列表</span><br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Subject</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 注册观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">attach</span><span class=\"hljs-params\">(Observer* obs)</span> </span>&#123;<br>        observers.<span class=\"hljs-built_in\">push_back</span>(obs);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 注销观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">detach</span><span class=\"hljs-params\">(Observer* obs)</span> </span>&#123;<br>        observers.<span class=\"hljs-built_in\">remove</span>(obs);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 通知所有注册的观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">notify</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">auto</span>&amp; observer : observers) &#123;<br>            observer-&gt;<span class=\"hljs-built_in\">update</span>(<span class=\"hljs-keyword\">this</span>);<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 获取状态（必须由具体的主题实现）</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">getState</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体的Subject实现</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteSubject</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::string state;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 设置新状态并通知观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setState</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string&amp; newState)</span> </span>&#123;<br>        state = newState;<br>        <span class=\"hljs-built_in\">notify</span>();<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 覆盖getState方法</span><br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">getState</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> state;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体的Observer实现</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteObserver</span> : <span class=\"hljs-keyword\">public</span> Observer &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(Subject* subject)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (subject) &#123;<br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Observer received a new state: &quot;</span> &lt;&lt; subject-&gt;<span class=\"hljs-built_in\">getState</span>() &lt;&lt; std::endl;<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 创建主题和观察者</span><br>    ConcreteSubject* concreteSubject = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteSubject</span>();<br>    Observer* observer1 = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteObserver</span>();<br>    Observer* observer2 = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteObserver</span>();<br><br>    <span class=\"hljs-comment\">// 注册观察者</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">attach</span>(observer1);<br>    concreteSubject-&gt;<span class=\"hljs-built_in\">attach</span>(observer2);<br><br>    <span class=\"hljs-comment\">// 改变状态并通知观察者</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">setState</span>(<span class=\"hljs-string\">&quot;state1&quot;</span>);<br><br>    <span class=\"hljs-comment\">// 注销一个观察者并再次改变状态</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">detach</span>(observer1);<br>    concreteSubject-&gt;<span class=\"hljs-built_in\">setState</span>(<span class=\"hljs-string\">&quot;state2&quot;</span>);<br><br>    <span class=\"hljs-comment\">// 清理资源</span><br>    <span class=\"hljs-keyword\">delete</span> observer1;<br>    <span class=\"hljs-keyword\">delete</span> observer2;<br>    <span class=\"hljs-keyword\">delete</span> concreteSubject;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"九、策略模式\"><a href=\"#九、策略模式\" class=\"headerlink\" title=\"九、策略模式\"></a>九、策略模式</h2><p>策略模式可以定义一系列的算法行为，并且把它们封装起来，提供给客户一定的自由度，能够使它们进行互相替换，策略模式允许算法独立于使用它们的客户端的变化。</p>\n<img src=\"/2024/06/26/design-model/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"策略模式-01\">\n<p>在C++中我们会定义一个抽象策略基类，不同的策略会继承于这个抽象类，并重写基类中需要进行策略呼唤的方法。</p>\n<p>在我们客户端需要使用策略的对象当中，会有一个抽象策略基类的指针，用于引用到子类的不同策略对象实例。通过不同的策略实例的调用就能够在我们客户端用到不同的方法了。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span> <span class=\"hljs-comment\">// std::sort</span></span><br><br><span class=\"hljs-comment\">// Strategy Interface</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SortingStrategy</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">SortingStrategy</span>() &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Concrete Strategy A: Bubble Sort</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BubbleSort</span> : <span class=\"hljs-keyword\">public</span> SortingStrategy &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">bool</span> swapped = <span class=\"hljs-literal\">true</span>;<br>        <span class=\"hljs-keyword\">while</span> (swapped) &#123;<br>            swapped = <span class=\"hljs-literal\">false</span>;<br>            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt; dataset.<span class=\"hljs-built_in\">size</span>(); ++i) &#123;<br>                <span class=\"hljs-keyword\">if</span> (dataset[i - <span class=\"hljs-number\">1</span>] &gt; dataset[i]) &#123;<br>                    std::<span class=\"hljs-built_in\">swap</span>(dataset[i - <span class=\"hljs-number\">1</span>], dataset[i]);<br>                    swapped = <span class=\"hljs-literal\">true</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Concrete Strategy B: Standard Library Sort</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">StdSort</span> : <span class=\"hljs-keyword\">public</span> SortingStrategy &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::<span class=\"hljs-built_in\">sort</span>(dataset.<span class=\"hljs-built_in\">begin</span>(), dataset.<span class=\"hljs-built_in\">end</span>());<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Context</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SortedList</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; m_items;<br>    SortingStrategy* m_strategy;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">SortedList</span>(SortingStrategy* strategy) : <span class=\"hljs-built_in\">m_strategy</span>(strategy) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_strategy</span><span class=\"hljs-params\">(SortingStrategy* strategy)</span> </span>&#123;<br>        m_strategy = strategy;<br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> value)</span> </span>&#123;<br>        m_items.<span class=\"hljs-built_in\">push_back</span>(value);<br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        m_strategy-&gt;<span class=\"hljs-built_in\">sort</span>(m_items);<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> item : m_items) &#123;<br>            std::cout &lt;&lt; item &lt;&lt; <span class=\"hljs-string\">&quot; &quot;</span>;<br>        &#125;<br>        std::cout &lt;&lt; std::endl;<br>    &#125;<br><br>    ~<span class=\"hljs-built_in\">SortedList</span>() &#123;<br>        <span class=\"hljs-keyword\">delete</span> m_strategy;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Client Code</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; dataset = &#123;<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>&#125;;<br><br>    <span class=\"hljs-comment\">// Use BubbleSort</span><br>    SortedList* bubble_sorted_list = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">SortedList</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">BubbleSort</span>());<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> value : dataset) &#123;<br>        bubble_sorted_list-&gt;<span class=\"hljs-built_in\">add</span>(value);<br>    &#125;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Bubble Sorted: &quot;</span>;<br>    bubble_sorted_list-&gt;<span class=\"hljs-built_in\">sort</span>();<br>    <span class=\"hljs-keyword\">delete</span> bubble_sorted_list;<br><br>    <span class=\"hljs-comment\">// Use StdSort</span><br>    SortedList* std_sorted_list = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">SortedList</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">StdSort</span>());<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> value : dataset) &#123;<br>        std_sorted_list-&gt;<span class=\"hljs-built_in\">add</span>(value);<br>    &#125;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Std Sorted: &quot;</span>;<br>    std_sorted_list-&gt;<span class=\"hljs-built_in\">sort</span>();<br>    <span class=\"hljs-keyword\">delete</span> std_sorted_list;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>参考链接：<a href=\"https://www.runoob.com/design-pattern/design-pattern-tutorial.html\">菜鸟教程</a></p>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h1><blockquote>\n<p>设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的代码编写经验。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p>\n</blockquote>\n<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><p><strong>1、开闭原则（Open Close Principle）</strong></p>\n<p>开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。</p>\n<p><strong>2、里氏代换原则（Liskov Substitution Principle）</strong></p>\n<p>里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。</p>\n<p><strong>3、依赖倒转原则（Dependence Inversion Principle）</strong></p>\n<p>这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。</p>\n<p><strong>4、接口隔离原则（Interface Segregation Principle）</strong></p>\n<p>这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。</p>\n<p><strong>5、迪米特法则，又称最少知道原则（Demeter Principle）</strong></p>\n<p>最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。</p>\n<p><strong>6、合成复用原则（Composite Reuse Principle）</strong></p>\n<p>合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。</p>\n<h2 id=\"一、工厂模式\"><a href=\"#一、工厂模式\" class=\"headerlink\" title=\"一、工厂模式\"></a>一、工厂模式</h2><blockquote>\n<p>工厂模式是一种创建对象的方式，类似于利用统一工厂类去创建不同的对象，这样就能够让创建对象的过程和使用对象的过程进行分离。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"工厂模式_01\">\n<ul>\n<li><p>简单工厂模式</p>\n<p>  根据工厂类传入的参数来决定创建哪种类型的对象</p>\n</li>\n<li><p>工厂方法模式</p>\n<p>  定义一个创建对象的接口，但由子类来决定实例化哪一个类，将对象的创建延迟到子类</p>\n<p>  不同的产品类继承于同一个抽象产品基类，同时为每一个产品类分配一个单独的创建类，创建类继承于创建基类，创建基类中有一个用于接收产品基类返回值的抽象方法，所有的创建类会重新这个方法，并在这个方法中，创建对应的产品对象，返回给产品基类接收。</p>\n<p>  在创建基类中，同时会定义一个接口方法，这个方法的实现会先通过抽象方法先创建出一个产品抽象类，并调用产品抽象类中的抽象方法，就能够达到统一调用子类方法的目的。</p>\n<p>  在实际使用中，用户只需要知道创建抽象类以及抽象类中的方法即可，当我们需要使用某一个产品的时候，我们只需要通过使用创建基类的指针指向一个某一个产品的创建子类的对象，通过调用创建基类中的方法就可以完成对应的功能。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 产品基类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Product</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Product</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA</span> : <span class=\"hljs-keyword\">public</span> Product &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Result of the ConcreteProductA&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB</span> : <span class=\"hljs-keyword\">public</span> Product &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">Operation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;Result of the ConcreteProductB&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 创建者基类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Creator</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Creator</span>() &#123;&#125;<br>    <span class=\"hljs-comment\">// 工厂方法，用于创建产品对象</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-comment\">// 创建者类的业务逻辑</span><br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">SomeOperation</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 调用工厂方法来创建一个产品对象</span><br>        <span class=\"hljs-function\">std::unique_ptr&lt;Product&gt; <span class=\"hljs-title\">product</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">this</span>-&gt;FactoryMethod())</span></span>;<br>        <span class=\"hljs-comment\">// 使用产品</span><br>        std::string result = <span class=\"hljs-string\">&quot;Creator: The same creator&#x27;s code has just worked with &quot;</span> + product-&gt;<span class=\"hljs-built_in\">Operation</span>();<br>        <span class=\"hljs-keyword\">return</span> result;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体创建者A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCreatorA</span> : <span class=\"hljs-keyword\">public</span> Creator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteProductA</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体创建者B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCreatorB</span> : <span class=\"hljs-keyword\">public</span> Creator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">Product* <span class=\"hljs-title\">FactoryMethod</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteProductB</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">ClientCode</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> Creator&amp; creator)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// ...</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: I&#x27;m not aware of the creator&#x27;s class, but it still works.\\n&quot;</span><br>            &lt;&lt; creator.<span class=\"hljs-built_in\">SomeOperation</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-comment\">// ...</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::unique_ptr&lt;Creator&gt; creator = std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteCreatorA&gt;();<br>    <span class=\"hljs-built_in\">ClientCode</span>(*creator);<br><br>    std::cout &lt;&lt; std::endl;<br>    <br>    creator = std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteCreatorB&gt;();<br>    <span class=\"hljs-built_in\">ClientCode</span>(*creator);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>抽象工厂模式</p>\n  <img src=\"/2024/06/26/design-model/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F_02.png\" class=\"\" title=\"工厂模式_02\">\n<p>  提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类</p>\n<p>  我们可以看出来工厂方法模式只关注某一类产品的构建，但是我们可以通过对抽象产品的继承来丰富这一类产品的类型。如果我们有多类产品的话，那就需要用到抽象工厂了。</p>\n<p>  因为我们有多类产品，所以我们会定义多个产品的抽象基类，这些产品基类会由多个产品子类来继承生成不同产品，在子类中会分别实现不同产品基类的抽象方法，如果我们需要在不同的产品类中进行通信的话，我们的抽象产品基类中应该还有一个能够将另一个产品基类作为形参传入的方法，在我们的具体产品中重写这一个方法。</p>\n<p>  同样我们会有一个抽象工厂，抽象工厂中会有创建不同产品的方法，这些方法都是以抽象产品基类指针作为返回值接收。抽象工厂子类会实现这些方法，它们可以选择性的去创建不同的产品子类，只需要实现对应的抽象产品方法即可，也就是说一个工厂是有可能可以创建多类产品的，尤其是当这些产品需要进行交互的时候。</p>\n<p>  下面的例子便是在具体工厂中实现多个产品的创建，当然我们只想让一个工厂对应某一类产品的话，我们只需要在对应的抽象方法中，返回<code>nullptr</code>就好了。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象产品A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractProductA</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractProductA</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 抽象产品B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractProductB</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractProductB</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-comment\">// 抽象方法，示例产品B能够与产品A进行交互</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA1</span> : <span class=\"hljs-keyword\">public</span> AbstractProductA &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product A1.&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品A2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductA2</span> : <span class=\"hljs-keyword\">public</span> AbstractProductA &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product A2.&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB1</span> : <span class=\"hljs-keyword\">public</span> AbstractProductB &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product B1.&quot;</span>;<br>    &#125;<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">const</span> std::string result = collaborator.<span class=\"hljs-built_in\">UsefulFunctionA</span>();<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the B1 collaborating with ( &quot;</span> + result + <span class=\"hljs-string\">&quot; )&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体产品B2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteProductB2</span> : <span class=\"hljs-keyword\">public</span> AbstractProductB &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">UsefulFunctionB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the product B2.&quot;</span>;<br>    &#125;<br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">AnotherUsefulFunctionB</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractProductA&amp; collaborator)</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">const</span> std::string result = collaborator.<span class=\"hljs-built_in\">UsefulFunctionA</span>();<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;The result of the B2 collaborating with ( &quot;</span> + result + <span class=\"hljs-string\">&quot; )&quot;</span>;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 抽象工厂</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AbstractFactory</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">AbstractFactory</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体工厂1</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteFactory1</span> : <span class=\"hljs-keyword\">public</span> AbstractFactory &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductA1&gt;();<br>    &#125;<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductB1&gt;();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体工厂2</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteFactory2</span> : <span class=\"hljs-keyword\">public</span> AbstractFactory &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductA&gt; <span class=\"hljs-title\">CreateProductA</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductA2&gt;();<br>    &#125;<br>    <span class=\"hljs-function\">std::unique_ptr&lt;AbstractProductB&gt; <span class=\"hljs-title\">CreateProductB</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">make_unique</span>&lt;ConcreteProductB2&gt;();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">ClientCode</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> AbstractFactory&amp; factory)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> product_a = factory.<span class=\"hljs-built_in\">CreateProductA</span>();<br>    <span class=\"hljs-keyword\">auto</span> product_b = factory.<span class=\"hljs-built_in\">CreateProductB</span>();<br>    std::cout &lt;&lt; product_b-&gt;<span class=\"hljs-built_in\">UsefulFunctionB</span>() &lt;&lt; <span class=\"hljs-string\">&quot;\\n&quot;</span>;<br>    std::cout &lt;&lt; product_b-&gt;<span class=\"hljs-built_in\">AnotherUsefulFunctionB</span>(*product_a) &lt;&lt; <span class=\"hljs-string\">&quot;\\n&quot;</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: Testing client code with the first factory type:\\n&quot;</span>;<br>    ConcreteFactory1 f1;<br>    <span class=\"hljs-built_in\">ClientCode</span>(f1);<br><br>    std::cout &lt;&lt; std::endl;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Client: Testing the same client code with the second factory type:\\n&quot;</span>;<br>    ConcreteFactory2 f2;<br>    <span class=\"hljs-built_in\">ClientCode</span>(f2);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"二、单例模式\"><a href=\"#二、单例模式\" class=\"headerlink\" title=\"二、单例模式\"></a>二、单例模式</h2><blockquote>\n<p>单例模式是一种比较常见的设计模式，在应用中十分广泛，在使用过程中用于确保一个对象中只有一个实例，并且会为这个实例提供一个全局访问点。在我们实际应用中，经常会用于一些控制资源共享的场景中，比如日志记录。因为只存在一个实例，所以需要考虑到这个实例在多线程的情况下资源竞争的问题。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"单例模式_01\">\n<p>在我们的单例模式实际应用中，通常会提供一个统一的静态全局访问方法，方法名一般叫做<code>getinstance()</code>，用于获取当前单例的实例对象，而我们会根据单例的创建时机将单例模式分为两种，懒汉式和饿汉式。</p>\n<ul>\n<li><p>懒汉式</p>\n<p>  懒汉式单例模式，指的是在我的当前工作进程中，不一定程序启动以后，单例跟着也同样进行实例化，而是只有当我们需要用到这一个单例的时候才会对这个单例进行实例化，具体的实现过程就是把单例的实例化代码写入到<code>getinstance()</code>函数中，当我们第一次调用到<code>getinstance()</code>的时候，我们会实例化这一个单例。</p>\n<p>  我们会把<code>instance</code>权限设置为私有，并且提供一个静态方法，用于创建并返回单例。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-comment\">// 私有静态指针变量，用于持有类的唯一实例</span><br>    <span class=\"hljs-type\">static</span> LazySingleton* instance;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-comment\">// 受保护的构造函数，防止外部通过 new 创建实例</span><br>    <span class=\"hljs-built_in\">LazySingleton</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 删除拷贝构造函数和赋值操作符</span><br>    <span class=\"hljs-built_in\">LazySingleton</span>(<span class=\"hljs-type\">const</span> LazySingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br>    LazySingleton&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> LazySingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br><br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 在类中提供公共的静态方法来获取实例</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> LazySingleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 检查是否为空</span><br>            instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">LazySingleton</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br></code></pre></td></tr></table></figure>\n<p>  我们可以看到在单线程的情况下，这样的代码是没有问题的，但是如果是多线程的环境下，如果我们有多个线程同时到达<code>GetInstance</code>这个函数，那么就存在有多次创建这个单例的风险，违背了我们单例模式的初衷。</p>\n<p>  很显然，我们可以通过加锁来完成不同线程创建多个单例的风险规避。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Singleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">static</span> Singleton* instance;<br>    <span class=\"hljs-type\">static</span> std::mutex mutex;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-built_in\">Singleton</span>() &#123;&#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Singleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lock</span><span class=\"hljs-params\">(mutex)</span></span>; <span class=\"hljs-comment\">// 加锁</span><br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123;<br>            instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Singleton</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br>&#125;;<br><br>Singleton* Singleton::instance = <span class=\"hljs-literal\">nullptr</span>;<br>std::mutex Singleton::mutex;<br></code></pre></td></tr></table></figure>\n<p>  这样的实现方式我们可以很明显的看出来有一些小问题，就是需要处理多线程之间的同步问题，在上面的实现方式中，无论我的实例是否已经被创建，都需要获取到锁以后才能够进入到后面的代码当中，在实际应用中，我们只有在单例未被创建的时候完成同步就可以了，如果单例已经在进程当中，那我们直接返回这个单例就行。</p>\n<p>  所以，我们有了另一种实现方式</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Singleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">static</span> Singleton* instance;<br>    <span class=\"hljs-type\">static</span> std::mutex mutex;<br><br><span class=\"hljs-keyword\">protected</span>:<br>    <span class=\"hljs-built_in\">Singleton</span>() &#123;&#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Singleton* <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 第一次检查，如果单例已经存在，不需要加锁直接返回单例</span><br>            <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lock</span><span class=\"hljs-params\">(mutex)</span></span>; <span class=\"hljs-comment\">// 加锁</span><br>            <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-literal\">nullptr</span>) &#123; <span class=\"hljs-comment\">// 第二次检查，只有当单例不存在的时候，才会确保只有一个线程创建了单例</span><br>                instance = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Singleton</span>();<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br>&#125;;<br><br>Singleton* Singleton::instance = <span class=\"hljs-literal\">nullptr</span>;<br>std::mutex Singleton::mutex;<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>饿汉式</p>\n<p>  可以看到，我们的主进程在初始化这个单例的时候，我们不像之前一样，把单例初始化为<code>nullptr</code>，而是切切实实的创建了这一个单例，而在我们的<code>GetInstance()</code>方法中会直接返回这一个单例，因为我们的单例已经不可能为空了。</p>\n<p>  这样的方式能够避免多个单例的创建，因为创建指挥发生在主进程对类加载的时候，但是牺牲的代价是便是内存的耗费，并且我们不应该提供对这个单例销毁的方法，因为，我们销毁以后想要再次用到这个单例的话，就没有单例创建的入口了。</p>\n  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">EagerSingleton</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-comment\">// 在定义变量的时候就初始化实例</span><br>    <span class=\"hljs-type\">static</span> EagerSingleton instance;<br><br>    <span class=\"hljs-comment\">// 私有构造函数，防止外部通过 new 创建实例</span><br>    <span class=\"hljs-built_in\">EagerSingleton</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 删除拷贝构造函数和赋值操作符，防止拷贝和赋值</span><br>    <span class=\"hljs-built_in\">EagerSingleton</span>(<span class=\"hljs-type\">const</span> EagerSingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br>    EagerSingleton&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> EagerSingleton&amp;) = <span class=\"hljs-keyword\">delete</span>;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 提供公共的静态方法来获取实例的引用</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> EagerSingleton&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> instance;<br>    &#125;<br><br>&#125;;<br><br><span class=\"hljs-comment\">// 类静态成员变量，在程序开始时即完成初始化</span><br>EagerSingleton EagerSingleton::instance;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"三、适配器模式\"><a href=\"#三、适配器模式\" class=\"headerlink\" title=\"三、适配器模式\"></a>三、适配器模式</h2><blockquote>\n<p>适配器可以充当两个不兼容接口之间的桥梁，通过一个中间件，将一个类的接口转换成客户期望的另一个接口，使得原本不能工作的类能够协同工作。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"适配器模式-01\">\n<p>适配器模式一般有两种方式来实现，分别是对象适配器模式，和类适配器模式。在对象适配器模式中，适配器类会继承于目标类的接口，并拥有一个需要适配的类的引用，在适配器类中就能够通过引用来调用是需要适配的方法。类适配器模式则是用到的多继承思想，适配器类通过多继承的方式，同时拥有目标类和适配类的方法。</p>\n<ul>\n<li>对象适配器模式  <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 目标接口（Target），客户端期望的接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Target</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Target: Default behavior.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 被适配的类（Adaptee），拥有一个特殊的请求方法</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Adaptee</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">SpecificRequest</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Adaptee: Specific request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 适配器类（Adapter），使 Adaptee 与 Target 接口兼容</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Adapter</span> : <span class=\"hljs-keyword\">public</span> Target &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    Adaptee* adaptee;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Adapter</span>(Adaptee* a) : <span class=\"hljs-built_in\">adaptee</span>(a) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        adaptee-&gt;<span class=\"hljs-built_in\">SpecificRequest</span>();<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    Adaptee* adaptee = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Adaptee</span>();<br>    Target* target = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Adapter</span>(adaptee);<br>    <br>    target-&gt;<span class=\"hljs-built_in\">Request</span>();<br><br>    <span class=\"hljs-keyword\">delete</span> adaptee;<br>    <span class=\"hljs-keyword\">delete</span> target;<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"四、装饰器模式\"><a href=\"#四、装饰器模式\" class=\"headerlink\" title=\"四、装饰器模式\"></a>四、装饰器模式</h2><img src=\"/2024/06/26/design-model/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"装饰器模式-01\">\n<p>通常我们在需要在不改变某一个类的功能的前提下为这个类提供新的拓展功能和方法的时候，我们会考虑的一种方式是通过对象的继承，在子类中写一些新的方法，这样子就能够通过使用子类来达到拓展父类功能的目的。而使用继承的方式，我们通常在编译的时候就确定了子类的相关行为。与此同时，如果一个父类存在有多个可能的变化方向，那么我们就需要通过继承的方式实现每一种组合，这样子无疑会使得我们子类的数量呈指数型暴增。</p>\n<p>在这样的背景下，我们有了装饰器模式的产生。装饰器可以独立存在，更加灵活，能够动态地扩展对象的功能并且可以通过组合的方式将多个装饰应用在对象上。</p>\n<p>装饰器模式通常涉及以下几个角色：</p>\n<ul>\n<li>Component：定义一个对象接口，可以给这些对象动态地添加职责。</li>\n<li>ConcreteComponent：定义了一个具体的对象，也可以给这个对象添加一些额外的职责。</li>\n<li>Decorator：持有一个组件（Component）对象的实例，并定义一个与组件接口一致的接口。</li>\n<li>ConcreteDecorator：具体的装饰类，实现了在组件的接口中定义的操作，并添加新的操作，以给组件对象增加额外的职责。</li>\n</ul>\n<p>我们会使用一个装饰器类继承于抽象基类，并在这个装饰器类中持有一个基类的指针对象，在实现基类的方法的时候，通过这一个指针来调用其他具体子类实体的方法。同时我们会有另一个类继承于这一个装饰器类，我们可以叫做拓展装饰器类，在我们的拓展装饰器类中，我们可以拓展具体子类的新功能。这个功能的拓展可以包裹在原始功能的前后，类似于附加一个行为层。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><br><span class=\"hljs-comment\">// &quot;Component&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Shape</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Shape</span>() &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;ConcreteComponent&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Circle</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Shape: Circle&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Rectangle</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Shape: Rectangle&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;Decorator&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ShapeDecorator</span> : <span class=\"hljs-keyword\">public</span> Shape &#123;<br><span class=\"hljs-keyword\">protected</span>:<br>    Shape* decoratedShape;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ShapeDecorator</span>(Shape* shape) : <span class=\"hljs-built_in\">decoratedShape</span>(shape) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        decoratedShape-&gt;<span class=\"hljs-built_in\">draw</span>();<br>    &#125;<br><br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">ShapeDecorator</span>() &#123;<br>        <span class=\"hljs-keyword\">delete</span> decoratedShape;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// &quot;ConcreteDecorator&quot;</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RedShapeDecorator</span> : <span class=\"hljs-keyword\">public</span> ShapeDecorator &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">RedShapeDecorator</span>(Shape* decoratedShape) : <span class=\"hljs-built_in\">ShapeDecorator</span>(decoratedShape) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">draw</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        ShapeDecorator::<span class=\"hljs-built_in\">draw</span>();<br>        <span class=\"hljs-built_in\">setRedBorder</span>(decoratedShape);   <span class=\"hljs-comment\">// 附加的行为</span><br>    &#125;<br><br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setRedBorder</span><span class=\"hljs-params\">(Shape* decoratedShape)</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Border Color: Red&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    Shape* circle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Circle</span>();<br>    Shape* redCircle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">RedShapeDecorator</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Circle</span>());<br>    Shape* redRectangle = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">RedShapeDecorator</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Rectangle</span>());<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Circle with normal border:&quot;</span> &lt;&lt; std::endl;<br>    circle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\nCircle of red border:&quot;</span> &lt;&lt; std::endl;<br>    redCircle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\nRectangle of red border:&quot;</span> &lt;&lt; std::endl;<br>    redRectangle-&gt;<span class=\"hljs-built_in\">draw</span>();<br><br>    <span class=\"hljs-keyword\">delete</span> circle;<br>    <span class=\"hljs-keyword\">delete</span> redCircle;<br>    <span class=\"hljs-keyword\">delete</span> redRectangle;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"五、享元模式\"><a href=\"#五、享元模式\" class=\"headerlink\" title=\"五、享元模式\"></a>五、享元模式</h2><blockquote>\n<p>享元模式主要用于减少创建对象的数量，用于减少内存占用和提高性能。享元模式会尝试重用现有的同类对象，如果我们找到了这个对象，那么就会对这个对象进行返回，如果未找这个对象，才会重新申请一个新的对象。主要目的是支持大量的细粒度对象，这些对象中有相当部分的状态可以共享。通过共享，可以在有限的内存资源下支持大规模的对象数量。</p>\n</blockquote>\n<img src=\"/2024/06/26/design-model/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"享元模式-01\">\n<p>在我们的使用过程中，通常享元模式需要定义享元抽象类，抽象类中会有子类需要共享的方法和属性，并且通过子类继承抽象类，实现对应的抽象方法，我们的子类也会拥有属于子类的独有的属性和方法。</p>\n<p>同时，我们会定义一个享元工厂，享元工厂负责创建和管理享元对象，管理的方式通常使用<code>HashMap</code>哈希表的映射来完成，如果需要创建某一个对象的<code>key</code>已经存在，则说明这个对象已经存在在内存当中，可以作为享元对象直接返回，当在哈希表中找不到<code>key</code>时，才会新建一个新的对象。</p>\n<p>在我们的客户端只需要维护对享元对象的引用，并计算或存储享元对象的外部状态即可。外部状态指的是，客户端用于标识具体对象的一些标志。所以在使用的过程中，应该注意的是要明确区分内部状态和外部状态，实现状态分离，以免混淆。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;map&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><br><span class=\"hljs-comment\">// 享元接口类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Character</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Character</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">display</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体享元类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteCharacter</span> : <span class=\"hljs-keyword\">public</span> Character &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-type\">char</span> glyph; <span class=\"hljs-comment\">// 内部状态：字符本身</span><br>    <br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">ConcreteCharacter</span>(<span class=\"hljs-type\">char</span> argGlyph) : <span class=\"hljs-built_in\">glyph</span>(argGlyph) &#123;&#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">display</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Displaying character: &quot;</span> &lt;&lt; glyph &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 享元工厂类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CharacterFactory</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::map&lt;<span class=\"hljs-type\">char</span>, Character*&gt; characters; <span class=\"hljs-comment\">// 缓存已创建的享元对象</span><br>    <br><span class=\"hljs-keyword\">public</span>:<br>    ~<span class=\"hljs-built_in\">CharacterFactory</span>() &#123;<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">auto</span>&amp; pair : characters) &#123;<br>            <span class=\"hljs-keyword\">delete</span> pair.second;<br>        &#125;<br>        characters.<span class=\"hljs-built_in\">clear</span>();<br>    &#125;<br>    <br>    <span class=\"hljs-function\">Character* <span class=\"hljs-title\">getCharacter</span><span class=\"hljs-params\">(<span class=\"hljs-type\">char</span> key)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (characters.<span class=\"hljs-built_in\">find</span>(key) == characters.<span class=\"hljs-built_in\">end</span>()) &#123;<br>            <span class=\"hljs-comment\">// 如果字符不存在，则创建一个新的ConcreteCharacter并加入映射中</span><br>            characters[key] = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteCharacter</span>(key);<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> characters[key];<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 客户端代码</span><br>    CharacterFactory factory;<br><br>    <span class=\"hljs-comment\">// 创建几个字符对象</span><br>    Character* characterA = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;A&#x27;</span>);<br>    Character* characterB = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;B&#x27;</span>);<br>    Character* characterA2 = factory.<span class=\"hljs-built_in\">getCharacter</span>(<span class=\"hljs-string\">&#x27;A&#x27;</span>); <span class=\"hljs-comment\">// 再次请求&#x27;A&#x27;，应该得到相同的实例</span><br><br>    <span class=\"hljs-comment\">// 显示字符</span><br>    characterA-&gt;<span class=\"hljs-built_in\">display</span>();<br>    characterB-&gt;<span class=\"hljs-built_in\">display</span>();<br>    characterA2-&gt;<span class=\"hljs-built_in\">display</span>();<br><br>    <span class=\"hljs-comment\">// 检查两个‘A’是否相同</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Are the two &#x27;A&#x27; instances the same? &quot;</span> &lt;&lt; (characterA == characterA2 ? <span class=\"hljs-string\">&quot;Yes&quot;</span> : <span class=\"hljs-string\">&quot;No&quot;</span>) &lt;&lt; std::endl;<br><br>    <span class=\"hljs-comment\">// 不需要手动删除字符对象，因为由CharacterFactory管理</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"六、责任链模式\"><a href=\"#六、责任链模式\" class=\"headerlink\" title=\"六、责任链模式\"></a>六、责任链模式</h2><blockquote>\n<p>责任链模式为请求创建了一个接收者对象的链，它允许多个对象来处理一个请求，而无需发送者知道接收者的具体信息。请求在一系列接收者对象之间传递直到被处理，每一个接收者持有下一个接收者的引用，这样接收者就形成了一条链，并且每个链上的对象将决定自己能否处理请求或者应该将请求传递给链上的下一个对象。</p>\n</blockquote>\n<p>责任链模式主要解决的问题是解耦发送者和接收者，使得多个对象都有可能接收请求，而发送者不需要知道哪个对象会处理它。就好像我们的发送者只需要将需要处理的请求丢给<code>handle</code>责任链上，而无需在意最后的请求是谁处理的一样，这样可以简化对象之间的连接，达到解耦的目的。</p>\n<p>我们会定义一个抽象处理类，在这个处理类中会拥有一个指向下一个处理类的指针，并使用接口完成责任链的构建，我们责任链上的不同任务会通过传入的不同参数来进行标识。</p>\n<p>在我们的抽象处理类中，会有一个处理请求的抽象方法，这个方法是用于遍历责任链的，如果我们的子处理类无法处理当前的请求时，我们会调用下一个处理类来完成这个请求的处理。</p>\n<p>使用这样的责任链方式，我们可以减少请求方和具体实现方的耦合，我们可以发现这样的设计模式能够很好的满足设计模式中的依赖倒置原则，请求方和实现方都依赖的是抽象接口而不各自依赖。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象处理器类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Handler</span> &#123;<br><span class=\"hljs-keyword\">protected</span>:<br>    std::shared_ptr&lt;Handler&gt; next_handler;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Handler</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setNext</span><span class=\"hljs-params\">(std::shared_ptr&lt;Handler&gt; handler)</span> </span>&#123;<br>        next_handler = handler;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体处理器类A</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteHandlerA</span> : <span class=\"hljs-keyword\">public</span> Handler &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (request &lt; <span class=\"hljs-number\">10</span>) &#123; <span class=\"hljs-comment\">// 可以处理小于10的请求</span><br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Handler A is handling request: &quot;</span> &lt;&lt; request &lt;&lt; std::endl;<br>        &#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体处理器类B</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteHandlerB</span> : <span class=\"hljs-keyword\">public</span> Handler &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">handleRequest</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> request)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (request &gt;= <span class=\"hljs-number\">10</span>) &#123; <span class=\"hljs-comment\">// 可以处理大于等于10的请求</span><br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Handler B is handling request: &quot;</span> &lt;&lt; request &lt;&lt; std::endl;<br>        &#125; <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (next_handler) &#123;<br>            next_handler-&gt;<span class=\"hljs-built_in\">handleRequest</span>(request);<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 客户端代码</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> handlerA = std::<span class=\"hljs-built_in\">make_shared</span>&lt;ConcreteHandlerA&gt;();<br>    <span class=\"hljs-keyword\">auto</span> handlerB = std::<span class=\"hljs-built_in\">make_shared</span>&lt;ConcreteHandlerB&gt;();<br>    <br>    handlerA-&gt;<span class=\"hljs-built_in\">setNext</span>(handlerB); <span class=\"hljs-comment\">// 设置责任链</span><br>    <br>    <span class=\"hljs-comment\">// 发出请求</span><br>    handlerA-&gt;<span class=\"hljs-built_in\">handleRequest</span>(<span class=\"hljs-number\">5</span>);  <span class=\"hljs-comment\">// 将由HandlerA处理</span><br>    handlerA-&gt;<span class=\"hljs-built_in\">handleRequest</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 将由HandlerB处理</span><br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"七、代理模式\"><a href=\"#七、代理模式\" class=\"headerlink\" title=\"七、代理模式\"></a>七、代理模式</h2><blockquote>\n<p>代理模式通过引入一个代理对象来控制原对象的访问。代理对象在客户端和目标对象之间充当中介，负责将客户端的请求转发给目标对象，同时可以在转发请求前后进行额外的处理，比如安全控制，延迟初始化，远程通信，记录日志等。</p>\n</blockquote>\n<p>代理模式实际上就是在客户端和实际服务对象之间建立一个中介层，用于在请求被送达给服务对象之前或之后执行某些操作</p>\n<p>在我们的代理类中，会继承于抽象类，并拥有一个具体类的实例，如果我们想要在真实类的某一个接口的前后添加譬如日志之类的额外处理，我们可以在代理类中实现抽象类中的接口，并在这个接口的前后添加对应的功能。</p>\n<ul>\n<li><p>问题一、代理模式和适配器模式的区别</p>\n<p>  代理模式，实现的是对另一个对象（原始被代理的对象）的控制访问，可以添加一些额外的功能，但是不应该改变原始对象的行为和功能。</p>\n<p>  适配器模式，适用于连接两个不兼容的接口，涉及到两类对象，通常会由适配器继承于一个对象，并拥有另一个对象的实例，在使用适配器进行适配的时候，通过修改所继承的接口方法来调用到被适配对象的行为，即把原接口适配成另一个客户想要的接口。</p>\n</li>\n<li><p>问题二、代理模式和装饰器模式的区别</p>\n<p>  代理模式主要用于控制对资源的访问，通常只有一个代理类，而装饰器模式旨在不改变对象的接口的情况下，为对象添加行为，可以使用多个装饰器来增强对象的功能。</p>\n<p>  代理模式通常在编译时就确定了，它管理对象的生命周期并可以进行一些特定的任务，如懒加载、权限控制等；而装饰器可以在运行时递归地将装饰层嵌套起来，以此在不改变原始对象代码的基础上增强对象的行为。</p>\n<p>  代理模式关注于对对象的控制，例如为远程对象提供本地代理的过程中可能会处理网络通信、线程同步等问题；装饰器模式关注于增加对象的新功能，强调的是扩展对象的行为。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-comment\">// 抽象主题类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Subject</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 真实主题类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RealSubject</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;RealSubject: Handling request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 代理类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Proxy</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::shared_ptr&lt;RealSubject&gt; real_subject;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title\">checkAccess</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 检查访问权限的逻辑</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Proxy: Checking access prior to firing a real request.&quot;</span> &lt;&lt; std::endl;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>; <span class=\"hljs-comment\">// 假设访问权限得到了验证</span><br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">logAccess</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>&#123;<br>        <span class=\"hljs-comment\">// 日志记录的逻辑</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Proxy: Logging the time of request.&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Proxy</span>(std::shared_ptr&lt;RealSubject&gt; real_subject) : <span class=\"hljs-built_in\">real_subject</span>(real_subject) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">request</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">checkAccess</span>()) &#123;<br>            <span class=\"hljs-keyword\">this</span>-&gt;real_subject-&gt;<span class=\"hljs-built_in\">request</span>(); <span class=\"hljs-comment\">// 调用真实主题的方法</span><br>            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">logAccess</span>(); <span class=\"hljs-comment\">// 记录请求日志</span><br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 客户端代码</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">auto</span> real_subject = std::<span class=\"hljs-built_in\">make_shared</span>&lt;RealSubject&gt;();<br>    <span class=\"hljs-function\">Proxy <span class=\"hljs-title\">proxy</span><span class=\"hljs-params\">(real_subject)</span></span>;<br>    <br>    proxy.<span class=\"hljs-built_in\">request</span>(); <span class=\"hljs-comment\">// 客户端使用代理完成工作</span><br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"八、观察者模式\"><a href=\"#八、观察者模式\" class=\"headerlink\" title=\"八、观察者模式\"></a>八、观察者模式</h2><blockquote>\n<p>观察者模式定义了一种一对多的依赖关系，当一个对象的状态发生改变时，其所有依赖者都会收到通知，并自动更新，主要用于分布式事件处理系统、消息发布/订阅机制，以及各种需要对象间解耦的场景。关键在于主题和观察者之间不直接进行通信，而是通过注册和通知机制进行交互。</p>\n</blockquote>\n<p>观察者模式通常包含几个核心角色</p>\n<ul>\n<li>主题：它是具有状态的对象，并维护这一个观察这列表。一般我们主题会提供添加、删除和通知观察者的方法</li>\n<li>观察者：观察者是接收主题通知的对象。观察者会实现一个更新方法，当我们收到主题的通知时，会调用该方法进行更新操作</li>\n<li>具体主题：具体主题时主题的具体实现类，会维护具体主题需要通知的观察者列表，并且在状态发生改变的时候通知观察者</li>\n<li>具体观察者：具体观察者是观察者的具体实现类。不同的观察者可能会实现各自的更新方法，方法中会定义收到主题通知时要执行的具体操作</li>\n</ul>\n<p>在我们使用的时候，基本逻辑就是，主题维护一个观察者列表，我们需要关注这个主题的观察者通过主题的实例对象来进行注册，注册到对应的主题当中，在我们的主题中会通过实现<code>notify</code>的方法，主动的调用观察者的更新函数。</p>\n<p>比较常见的场景就是<code>ros</code>的发布与订阅机制，订阅的节点通过订阅来将自己加入到具体的主题当中，当有主题到来的时候，就是状态触发的过程，就会通知各个订阅者进行相应的操作。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;list&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span></span><br><br><span class=\"hljs-comment\">// 前向声明</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span>;<br><br><span class=\"hljs-comment\">// Observer接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Observer</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Observer</span>() &#123;&#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(Subject* subject)</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// Subject接口</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Subject</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::list&lt;Observer*&gt; observers; <span class=\"hljs-comment\">// 观察者列表</span><br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">Subject</span>() &#123;&#125;<br><br>    <span class=\"hljs-comment\">// 注册观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">attach</span><span class=\"hljs-params\">(Observer* obs)</span> </span>&#123;<br>        observers.<span class=\"hljs-built_in\">push_back</span>(obs);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 注销观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">detach</span><span class=\"hljs-params\">(Observer* obs)</span> </span>&#123;<br>        observers.<span class=\"hljs-built_in\">remove</span>(obs);<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 通知所有注册的观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">notify</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">auto</span>&amp; observer : observers) &#123;<br>            observer-&gt;<span class=\"hljs-built_in\">update</span>(<span class=\"hljs-keyword\">this</span>);<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 获取状态（必须由具体的主题实现）</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> std::string <span class=\"hljs-title\">getState</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> </span>= <span class=\"hljs-number\">0</span>;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体的Subject实现</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteSubject</span> : <span class=\"hljs-keyword\">public</span> Subject &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::string state;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 设置新状态并通知观察者</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">setState</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string&amp; newState)</span> </span>&#123;<br>        state = newState;<br>        <span class=\"hljs-built_in\">notify</span>();<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 覆盖getState方法</span><br>    <span class=\"hljs-function\">std::string <span class=\"hljs-title\">getState</span><span class=\"hljs-params\">()</span> <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> state;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// 具体的Observer实现</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ConcreteObserver</span> : <span class=\"hljs-keyword\">public</span> Observer &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(Subject* subject)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span> (subject) &#123;<br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Observer received a new state: &quot;</span> &lt;&lt; subject-&gt;<span class=\"hljs-built_in\">getState</span>() &lt;&lt; std::endl;<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 创建主题和观察者</span><br>    ConcreteSubject* concreteSubject = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteSubject</span>();<br>    Observer* observer1 = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteObserver</span>();<br>    Observer* observer2 = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">ConcreteObserver</span>();<br><br>    <span class=\"hljs-comment\">// 注册观察者</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">attach</span>(observer1);<br>    concreteSubject-&gt;<span class=\"hljs-built_in\">attach</span>(observer2);<br><br>    <span class=\"hljs-comment\">// 改变状态并通知观察者</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">setState</span>(<span class=\"hljs-string\">&quot;state1&quot;</span>);<br><br>    <span class=\"hljs-comment\">// 注销一个观察者并再次改变状态</span><br>    concreteSubject-&gt;<span class=\"hljs-built_in\">detach</span>(observer1);<br>    concreteSubject-&gt;<span class=\"hljs-built_in\">setState</span>(<span class=\"hljs-string\">&quot;state2&quot;</span>);<br><br>    <span class=\"hljs-comment\">// 清理资源</span><br>    <span class=\"hljs-keyword\">delete</span> observer1;<br>    <span class=\"hljs-keyword\">delete</span> observer2;<br>    <span class=\"hljs-keyword\">delete</span> concreteSubject;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"九、策略模式\"><a href=\"#九、策略模式\" class=\"headerlink\" title=\"九、策略模式\"></a>九、策略模式</h2><p>策略模式可以定义一系列的算法行为，并且把它们封装起来，提供给客户一定的自由度，能够使它们进行互相替换，策略模式允许算法独立于使用它们的客户端的变化。</p>\n<img src=\"/2024/06/26/design-model/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F_01.png\" class=\"\" title=\"策略模式-01\">\n<p>在C++中我们会定义一个抽象策略基类，不同的策略会继承于这个抽象类，并重写基类中需要进行策略呼唤的方法。</p>\n<p>在我们客户端需要使用策略的对象当中，会有一个抽象策略基类的指针，用于引用到子类的不同策略对象实例。通过不同的策略实例的调用就能够在我们客户端用到不同的方法了。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span> <span class=\"hljs-comment\">// std::sort</span></span><br><br><span class=\"hljs-comment\">// Strategy Interface</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SortingStrategy</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> </span>= <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">virtual</span> ~<span class=\"hljs-built_in\">SortingStrategy</span>() &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Concrete Strategy A: Bubble Sort</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BubbleSort</span> : <span class=\"hljs-keyword\">public</span> SortingStrategy &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        <span class=\"hljs-type\">bool</span> swapped = <span class=\"hljs-literal\">true</span>;<br>        <span class=\"hljs-keyword\">while</span> (swapped) &#123;<br>            swapped = <span class=\"hljs-literal\">false</span>;<br>            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt; dataset.<span class=\"hljs-built_in\">size</span>(); ++i) &#123;<br>                <span class=\"hljs-keyword\">if</span> (dataset[i - <span class=\"hljs-number\">1</span>] &gt; dataset[i]) &#123;<br>                    std::<span class=\"hljs-built_in\">swap</span>(dataset[i - <span class=\"hljs-number\">1</span>], dataset[i]);<br>                    swapped = <span class=\"hljs-literal\">true</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Concrete Strategy B: Standard Library Sort</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">StdSort</span> : <span class=\"hljs-keyword\">public</span> SortingStrategy &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; dataset)</span> <span class=\"hljs-keyword\">override</span> </span>&#123;<br>        std::<span class=\"hljs-built_in\">sort</span>(dataset.<span class=\"hljs-built_in\">begin</span>(), dataset.<span class=\"hljs-built_in\">end</span>());<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Context</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SortedList</span> &#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; m_items;<br>    SortingStrategy* m_strategy;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">SortedList</span>(SortingStrategy* strategy) : <span class=\"hljs-built_in\">m_strategy</span>(strategy) &#123;&#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">set_strategy</span><span class=\"hljs-params\">(SortingStrategy* strategy)</span> </span>&#123;<br>        m_strategy = strategy;<br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">add</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> value)</span> </span>&#123;<br>        m_items.<span class=\"hljs-built_in\">push_back</span>(value);<br>    &#125;<br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sort</span><span class=\"hljs-params\">()</span> </span>&#123;<br>        m_strategy-&gt;<span class=\"hljs-built_in\">sort</span>(m_items);<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> item : m_items) &#123;<br>            std::cout &lt;&lt; item &lt;&lt; <span class=\"hljs-string\">&quot; &quot;</span>;<br>        &#125;<br>        std::cout &lt;&lt; std::endl;<br>    &#125;<br><br>    ~<span class=\"hljs-built_in\">SortedList</span>() &#123;<br>        <span class=\"hljs-keyword\">delete</span> m_strategy;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-comment\">// Client Code</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; dataset = &#123;<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>&#125;;<br><br>    <span class=\"hljs-comment\">// Use BubbleSort</span><br>    SortedList* bubble_sorted_list = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">SortedList</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">BubbleSort</span>());<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> value : dataset) &#123;<br>        bubble_sorted_list-&gt;<span class=\"hljs-built_in\">add</span>(value);<br>    &#125;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Bubble Sorted: &quot;</span>;<br>    bubble_sorted_list-&gt;<span class=\"hljs-built_in\">sort</span>();<br>    <span class=\"hljs-keyword\">delete</span> bubble_sorted_list;<br><br>    <span class=\"hljs-comment\">// Use StdSort</span><br>    SortedList* std_sorted_list = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">SortedList</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">StdSort</span>());<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> value : dataset) &#123;<br>        std_sorted_list-&gt;<span class=\"hljs-built_in\">add</span>(value);<br>    &#125;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Std Sorted: &quot;</span>;<br>    std_sorted_list-&gt;<span class=\"hljs-built_in\">sort</span>();<br>    <span class=\"hljs-keyword\">delete</span> std_sorted_list;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>参考链接：<a href=\"https://www.runoob.com/design-pattern/design-pattern-tutorial.html\">菜鸟教程</a></p>\n"},{"title":"数字图像处理实验-空域滤波","date":"2022-10-02T10:32:15.000Z","cover":"/img/default_cover07.jpg","top_img":null,"_content":"### 1、利用均值模板平滑灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3*3、5*5 和 9*9 尺寸的均值模板平滑灰度图像。\n\n完成程度：对原图像进行边缘填充，用周围的像素点灰度值代替图像边缘的值，构造了3*3、5*5、7*7的均值模板，对灰度图像进行均值计算操作，将得到的均值赋值给对应的新矩阵。\n\n```C++\n// 辅助函数1、对原始灰度图像进行边缘填充操作\nMat fill_zero(Mat image, int size) {\n\t// 将边缘的填充为与它最近的像素灰度\n\tint fill_size = int(size / 2);\n\tint row = image.rows;\n\tint col = image.cols;\n\n\tMat first_row = image.rowRange(0, 1);\n\tMat last_row = image.rowRange(row - 1, row);\n\t\n\t// 垂直填充\n\tfor (int i = 0; i < fill_size; ++i) {\n\t\tcv::vconcat(first_row, image, image);\n\t\tcv::vconcat(image, last_row, image);\n\t}\n\n\t// 水平填充\n\tMat left_col = image.colRange(0, 1);\n\tMat right_col = image.colRange(col - 1, col);\n\n\tfor (int i = 0; i < fill_size; ++i) {\n\t\tcv::hconcat(left_col, image, image);\n\t\tcv::hconcat(image, right_col, image);\n\t}\n\n\t// imshow(\"填充后\", image);\n\treturn image;\n\n}\n\n// 1、利用均值模板平滑灰度图像\nMat average_filter(Mat image, int size) {\n\t// 构建均值滤波模板\n\timage.convertTo(image, CV_8U);\n\tMat meta = Mat::ones(size, size, CV_8U);\n\n\tint count_size = size * size;\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row-size+1, col-size+1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_ += image.at<uchar>(i+s, j+t) * meta.at<uchar>(s, t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = sum_/count_size;\n\t\t}\n\t}\n\timshow(\"均值滤波：\"+ to_string(size) + '*' + to_string(size), res);\n\t\n\treturn res;\n\n}\n```\n\n![image-20240302184920811](digital-image-test03/image-20240302184920811.png)\n\n### 2、利用高斯模板平滑灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3*3、5*5 和 9*9 尺寸的高斯模板平滑灰度图像。 \n\n完成程度：通过高斯函数自定义构造3*3、5*5、7*7的高斯模板，编写卷积运算的函数，并将原灰度图与所构造的高斯模板进行卷积操作，得到平滑后的图像并输出。\n\n```c++\n// 辅助函数2、完成卷积操作\nMat juanji(Mat image, vector<vector<int> > meta, int size_) {\n\n\tdouble sum = 0.0;\n\t// 求meta元素的和\n\t//for (int i = 0; i < size; ++i) {\n\t//\tfor (int j = 0; j < size; ++j) {\n\t//\t\tsum += meta[i][j];\n\t//\t}\n\t//}\n\tint size = size_ % 2 == 0 ? size_ + 1 : size_;\n\tint row = image.rows;\n\tint col = image.cols;\n\tMat res = Mat::zeros(row - size + 1, col - size + 1, CV_8U);\n\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\tdouble sum_1 = 0.0;\n\t\t\tfor (int s = 0; s < size_; ++s) {\n\t\t\t\tfor (int t = 0; t < size_; ++t) {\n\t\t\t\t\tsum_1 += image.at<uchar>(i + s, j + t) * meta[s][t];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (sum_1 > 0) {\n\t\t\t\tres.at<uchar>(i, j) = int(sum_1);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tres.at<uchar>(i, j) = 0;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}\n\n// 2、利用高斯模板平滑灰度图像\nMat gaussion_filter(Mat image, int size, double sigma) {\n\t// 高斯方程为，h(x,y) = e**-{([(x-x0))**2+(y-y0)**2]/(2*σ**2)]}\n\t// 其中x0，y0为中心坐标\n\t// 构造高斯滤波器模板\n\tvector<vector<double> >gaussion_module(size, vector<double>(size));\n\tint x0 = (size - 1) / 2;\n\tint y0 = (size - 1) / 2;\n\t// 求和\n\tdouble sum_ = 0.0;\n\tfor (int x = 0; x < size; ++x) {\n\t\tfor (int y = 0; y < size; ++y) {\n\t\t\tgaussion_module[x][y] = exp(-(pow((x - x0), 2) + pow((y - y0), 2)) / (2 * sigma * sigma));\n\t\t\tsum_ += gaussion_module[x][y];\n\t\t}\n\t}\n\t\n\t// 填充\n\timage = fill_zero(image, size);\n\n\t// Mat res = juanji(image, gaussion_module, size);\n\n\tint row = image.rows;\n\tint col = image.cols;\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\n\t// 使用高斯滤波进行卷积操作\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\t// 卷积和\n\t\t\tdouble sum_mul = 0.0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_mul += image.at<uchar>(i + s, j + t) * gaussion_module[s][t];\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = int(sum_mul / sum_);\n\t\t}\n\t}\n\n\timshow(\"高斯模板尺寸：\" + to_string(size) + '*' + to_string(size), res);\n\n\treturn res;\n}\n```\n\n![image-20240302184935209](digital-image-test03/image-20240302184935209.png)\n\n![image-20240302184940449](digital-image-test03/image-20240302184940449.png)\n\n### 3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化灰度图像。 \n\n完成程度：分别构造Laplacian、Robert、Sobel模板，用这三个模板分别原始图像进行卷积操作，得到结果后输出\n\n```c++\n// 3、利用Laplacian、Robert、Sobel模板锐化灰度图像\nvector<Mat> sharpen(Mat image1) {\n\n\timshow(\"原图\", image1);\n\t// 对原图进行填充\n\tMat image = image1;\n\n\t//image = average_filter(image, 3);\n\timage = fill_zero(image, 3);\n\t// 拉普拉斯模板{0，1，0，1，-4，1，0，1，0}\n\tvector<vector<int> >laplacian_model = { {0,1,0},{1,-4,1},{0,1,0} };\n\tvector<vector<int> >laplacian_model2 = { {1,1,1},{1,-8,1},{1,1,1} };\n\t\n\tMat res_laplacian = juanji(image, laplacian_model, 3);\n\n\timshow(\"Laplacian\", res_laplacian);\n\tsubtract(image1, res_laplacian, res_laplacian);\n\timshow(\"Laplacian处理过后的图像\", res_laplacian);\n\n\t// Robert算子\n\tvector<vector<int> >robert_model = { {-1,0},{0, 1} };\n\tMat image_robert = image1;\n\timage_robert = fill_zero(image_robert, 2);\n\tMat res_robert = juanji(image_robert, robert_model, 2);\n\n\timshow(\"robert\", res_robert);\n\tadd(image1, res_robert, res_robert);\n\timshow(\"Rebort处理过后的图像\", res_robert);\n\t// cout << res_rebort.cols << \"sadas\" << endl;\n\n\t// Sobel算子\n\tvector<vector<int> >sobel_model = { {-1,-2,-1},{0,0,0},{1,2,1} };\n\tMat image_sobel = image1;\n\timage_sobel = fill_zero(image_sobel, 3);\n\tMat res_sobel = juanji(image_sobel, sobel_model, 3);\n\n\timshow(\"sobel\", res_sobel);\n\tsubtract(image1, res_sobel, res_sobel);\n\timshow(\"Sobel处理过后的图像\", res_sobel);\n\n\tvector<Mat> res = { res_laplacian, res_robert, res_sobel };\n\tMat s;\n\tmerge(res, s);\n\timshow(\"get\", s);\n\n\treturn res;\n\n}\n```\n\nLaplacian\n\n![image-20240302184950081](digital-image-test03/image-20240302184950081.png)\n\nRobert\n\n![image-20240302184959151](digital-image-test03/image-20240302184959151.png)\n\nSobel\n\n![image-20240302185003442](digital-image-test03/image-20240302185003442.png)\n\n### 4、利用高提升滤波算法增强灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，设计高提升滤波算法增强图像。 \n\n完成程度：使用高斯滤波平滑原始图像，将原始图像减去平滑后的图像，得到高斯滤波过滤掉的细节图像，给细节图像乘上一定的倍数（本实验所用的倍数是2），再加到原始图像中，输出图像。\n\n```C++\n// 4、利用高提升滤波算法增强灰度图像\nvoid enhance_image(Mat image) {\n\t// 先对原始图像进行平滑处理\n\tMat filt_image = gaussion_filter(image, 3, 1);\n\tMat sub_image;\n\tsubtract(image, filt_image, sub_image);\n\n\timshow(\"dada\", sub_image*2);\n\tMat res;\n\tadd(image, sub_image, res);\n\timshow(\"高提升后的图像\", res);\n}\n```\n\n![image-20240302185107213](digital-image-test03/image-20240302185107213.png)\n\n### 5、利用均值模板平滑彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，利用 3*3、5*5 和 9*9 尺寸的均值模板平滑彩色图像。\n\n完成程度：在完成了均值滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。\n\n```c++\n// 5、利用均值模板平滑彩色图像\nvoid average_filter_color(Mat image, int size) {\n\n\t// 分别对三个通道进行处理\n\tvector<Mat> channels;\n\tcv::split(image, channels);\n\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = average_filter(channels[i], size);\n\t}\n\t\n\tcv::merge(channels, image);\n\n\timshow(\"彩图\", image);\n\n}\n```\n\n![image-20240302185113358](digital-image-test03/image-20240302185113358.png)\n\n![image-20240302185116864](digital-image-test03/image-20240302185116864.png)\n\n### 6、利用高斯模板平滑彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 3*3、5*5 和 9*9 尺寸的高斯模板平滑彩色图像。\n\n完成程度：在完成了高斯滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。\n\n```c++\n// 6、利用高斯模板平滑彩色图像\nvoid gaussion_filter_color(Mat image, int size) {\n\n\t// 分别对三个通道进行处理\n\tvector<Mat> channels;\n\tcv::split(image, channels);\n\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = gaussion_filter(channels[i], size, 1);\n\t}\n\n\tcv::merge(channels, image);\n\n\timshow(\"彩图\", image);\n}\n```\n\n![image-20240302185124222](digital-image-test03/image-20240302185124222.png)\n\n![image-20240302185128004](digital-image-test03/image-20240302185128004.png)\n\n### 7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化彩色图像。\n\n完成程度：构造Laplacian、Robert、Sobel算子，分别对彩色图像的三个通道进行卷积操作，完成以后进行通道合并，并输出合并后的彩色图像。\n\n```c++\n// 7、利用Laplacian、Robert、Sobel模板锐化彩色图像\nvoid sharpen_color(Mat image) {\n\n\tvector<Mat> channels;\n\tsplit(image, channels);\n\n\t// Laplacian\n\tvector<Mat> laplacian_channels = channels;\n\tvector<Mat> laplacian_channels_color = channels;\n\n\tvector<Mat> robert_channels = channels;\n\tvector<Mat> robert_channels_color = channels;\n\n\tvector<Mat> sobel_channels = channels;\n\tvector<Mat> sobel_channels_color = channels;\n\n\tMat res_laplacian;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >laplacian_model = { {0,1,0},{1,-4,1},{0,1,0} };\n\t\tvector<vector<int> >laplacian_model2 = { {1,1,1},{1,-8,1},{1,1,1} };\n\n\t\tlaplacian_channels[i] = fill_zero(laplacian_channels[i], 3);\n\t\tlaplacian_channels[i] = juanji(laplacian_channels[i], laplacian_model, 3);\n\n\t\tsubtract(channels[i], laplacian_channels[i], laplacian_channels_color[i]);\n\t}\n\tmerge(laplacian_channels, res_laplacian);\n\timshow(\"Laplacian锐化\", res_laplacian);\n\tmerge(laplacian_channels_color, res_laplacian);\n\timshow(\"Laplacian锐化处理后图片\", res_laplacian);\n\t\n\t// Robert\n\n\tsplit(image, channels);\n\tMat res_robert;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >robert_model = { {-1,0},{0, 1} };\n\n\t\trobert_channels[i] = fill_zero(robert_channels[i], 2);\n\t\trobert_channels[i] = juanji(robert_channels[i], robert_model, 2);\n\n\t\tadd(channels[i], robert_channels[i], robert_channels_color[i]);\n\t}\n\tmerge(robert_channels, res_robert);\n\timshow(\"Robert锐化\", res_robert);\n\tmerge(robert_channels_color, res_robert);\n\timshow(\"Robert锐化处理后图片\", res_robert);\n\n\t// Sobel\n\n\tsplit(image, channels);\n\tMat res_sobel;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >sobel_model = { {-1,-2,-1},{0,0,0},{1,2,1} };\n\n\t\tsobel_channels[i] = fill_zero(sobel_channels[i], 3);\n\t\tsobel_channels[i] = juanji(sobel_channels[i], sobel_model, 3);\n\n\t\tsubtract(channels[i], sobel_channels[i], sobel_channels_color[i]);\n\t}\n\tmerge(sobel_channels, res_sobel);\n\timshow(\"Sobel锐化\", res_sobel);\n\tmerge(sobel_channels_color, res_sobel);\n\timshow(\"Sobel锐化处理后图片\", res_sobel);\n}\n```\n\nLaplacian\n\n![image-20240302185142206](digital-image-test03/image-20240302185142206.png)\n\nRobert\n\n![image-20240302185150777](digital-image-test03/image-20240302185150777.png)\n\nSobel\n\n![image-20240302185159151](digital-image-test03/image-20240302185159151.png)","source":"_posts/digital-image-test03.md","raw":"---\ntitle: 数字图像处理实验-空域滤波\ncategories: 算法实践\ndate: 2022-10-02 18:32:15\ntags: [数字图像, OpenCV]\ncover:\ntop_img:\n---\n### 1、利用均值模板平滑灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3*3、5*5 和 9*9 尺寸的均值模板平滑灰度图像。\n\n完成程度：对原图像进行边缘填充，用周围的像素点灰度值代替图像边缘的值，构造了3*3、5*5、7*7的均值模板，对灰度图像进行均值计算操作，将得到的均值赋值给对应的新矩阵。\n\n```C++\n// 辅助函数1、对原始灰度图像进行边缘填充操作\nMat fill_zero(Mat image, int size) {\n\t// 将边缘的填充为与它最近的像素灰度\n\tint fill_size = int(size / 2);\n\tint row = image.rows;\n\tint col = image.cols;\n\n\tMat first_row = image.rowRange(0, 1);\n\tMat last_row = image.rowRange(row - 1, row);\n\t\n\t// 垂直填充\n\tfor (int i = 0; i < fill_size; ++i) {\n\t\tcv::vconcat(first_row, image, image);\n\t\tcv::vconcat(image, last_row, image);\n\t}\n\n\t// 水平填充\n\tMat left_col = image.colRange(0, 1);\n\tMat right_col = image.colRange(col - 1, col);\n\n\tfor (int i = 0; i < fill_size; ++i) {\n\t\tcv::hconcat(left_col, image, image);\n\t\tcv::hconcat(image, right_col, image);\n\t}\n\n\t// imshow(\"填充后\", image);\n\treturn image;\n\n}\n\n// 1、利用均值模板平滑灰度图像\nMat average_filter(Mat image, int size) {\n\t// 构建均值滤波模板\n\timage.convertTo(image, CV_8U);\n\tMat meta = Mat::ones(size, size, CV_8U);\n\n\tint count_size = size * size;\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row-size+1, col-size+1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_ += image.at<uchar>(i+s, j+t) * meta.at<uchar>(s, t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = sum_/count_size;\n\t\t}\n\t}\n\timshow(\"均值滤波：\"+ to_string(size) + '*' + to_string(size), res);\n\t\n\treturn res;\n\n}\n```\n\n![image-20240302184920811](digital-image-test03/image-20240302184920811.png)\n\n### 2、利用高斯模板平滑灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3*3、5*5 和 9*9 尺寸的高斯模板平滑灰度图像。 \n\n完成程度：通过高斯函数自定义构造3*3、5*5、7*7的高斯模板，编写卷积运算的函数，并将原灰度图与所构造的高斯模板进行卷积操作，得到平滑后的图像并输出。\n\n```c++\n// 辅助函数2、完成卷积操作\nMat juanji(Mat image, vector<vector<int> > meta, int size_) {\n\n\tdouble sum = 0.0;\n\t// 求meta元素的和\n\t//for (int i = 0; i < size; ++i) {\n\t//\tfor (int j = 0; j < size; ++j) {\n\t//\t\tsum += meta[i][j];\n\t//\t}\n\t//}\n\tint size = size_ % 2 == 0 ? size_ + 1 : size_;\n\tint row = image.rows;\n\tint col = image.cols;\n\tMat res = Mat::zeros(row - size + 1, col - size + 1, CV_8U);\n\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\tdouble sum_1 = 0.0;\n\t\t\tfor (int s = 0; s < size_; ++s) {\n\t\t\t\tfor (int t = 0; t < size_; ++t) {\n\t\t\t\t\tsum_1 += image.at<uchar>(i + s, j + t) * meta[s][t];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (sum_1 > 0) {\n\t\t\t\tres.at<uchar>(i, j) = int(sum_1);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tres.at<uchar>(i, j) = 0;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}\n\n// 2、利用高斯模板平滑灰度图像\nMat gaussion_filter(Mat image, int size, double sigma) {\n\t// 高斯方程为，h(x,y) = e**-{([(x-x0))**2+(y-y0)**2]/(2*σ**2)]}\n\t// 其中x0，y0为中心坐标\n\t// 构造高斯滤波器模板\n\tvector<vector<double> >gaussion_module(size, vector<double>(size));\n\tint x0 = (size - 1) / 2;\n\tint y0 = (size - 1) / 2;\n\t// 求和\n\tdouble sum_ = 0.0;\n\tfor (int x = 0; x < size; ++x) {\n\t\tfor (int y = 0; y < size; ++y) {\n\t\t\tgaussion_module[x][y] = exp(-(pow((x - x0), 2) + pow((y - y0), 2)) / (2 * sigma * sigma));\n\t\t\tsum_ += gaussion_module[x][y];\n\t\t}\n\t}\n\t\n\t// 填充\n\timage = fill_zero(image, size);\n\n\t// Mat res = juanji(image, gaussion_module, size);\n\n\tint row = image.rows;\n\tint col = image.cols;\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\n\t// 使用高斯滤波进行卷积操作\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\t// 卷积和\n\t\t\tdouble sum_mul = 0.0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_mul += image.at<uchar>(i + s, j + t) * gaussion_module[s][t];\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = int(sum_mul / sum_);\n\t\t}\n\t}\n\n\timshow(\"高斯模板尺寸：\" + to_string(size) + '*' + to_string(size), res);\n\n\treturn res;\n}\n```\n\n![image-20240302184935209](digital-image-test03/image-20240302184935209.png)\n\n![image-20240302184940449](digital-image-test03/image-20240302184940449.png)\n\n### 3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化灰度图像。 \n\n完成程度：分别构造Laplacian、Robert、Sobel模板，用这三个模板分别原始图像进行卷积操作，得到结果后输出\n\n```c++\n// 3、利用Laplacian、Robert、Sobel模板锐化灰度图像\nvector<Mat> sharpen(Mat image1) {\n\n\timshow(\"原图\", image1);\n\t// 对原图进行填充\n\tMat image = image1;\n\n\t//image = average_filter(image, 3);\n\timage = fill_zero(image, 3);\n\t// 拉普拉斯模板{0，1，0，1，-4，1，0，1，0}\n\tvector<vector<int> >laplacian_model = { {0,1,0},{1,-4,1},{0,1,0} };\n\tvector<vector<int> >laplacian_model2 = { {1,1,1},{1,-8,1},{1,1,1} };\n\t\n\tMat res_laplacian = juanji(image, laplacian_model, 3);\n\n\timshow(\"Laplacian\", res_laplacian);\n\tsubtract(image1, res_laplacian, res_laplacian);\n\timshow(\"Laplacian处理过后的图像\", res_laplacian);\n\n\t// Robert算子\n\tvector<vector<int> >robert_model = { {-1,0},{0, 1} };\n\tMat image_robert = image1;\n\timage_robert = fill_zero(image_robert, 2);\n\tMat res_robert = juanji(image_robert, robert_model, 2);\n\n\timshow(\"robert\", res_robert);\n\tadd(image1, res_robert, res_robert);\n\timshow(\"Rebort处理过后的图像\", res_robert);\n\t// cout << res_rebort.cols << \"sadas\" << endl;\n\n\t// Sobel算子\n\tvector<vector<int> >sobel_model = { {-1,-2,-1},{0,0,0},{1,2,1} };\n\tMat image_sobel = image1;\n\timage_sobel = fill_zero(image_sobel, 3);\n\tMat res_sobel = juanji(image_sobel, sobel_model, 3);\n\n\timshow(\"sobel\", res_sobel);\n\tsubtract(image1, res_sobel, res_sobel);\n\timshow(\"Sobel处理过后的图像\", res_sobel);\n\n\tvector<Mat> res = { res_laplacian, res_robert, res_sobel };\n\tMat s;\n\tmerge(res, s);\n\timshow(\"get\", s);\n\n\treturn res;\n\n}\n```\n\nLaplacian\n\n![image-20240302184950081](digital-image-test03/image-20240302184950081.png)\n\nRobert\n\n![image-20240302184959151](digital-image-test03/image-20240302184959151.png)\n\nSobel\n\n![image-20240302185003442](digital-image-test03/image-20240302185003442.png)\n\n### 4、利用高提升滤波算法增强灰度图像\n\n具体内容: 利用 OpenCV 对图像像素进行操作，设计高提升滤波算法增强图像。 \n\n完成程度：使用高斯滤波平滑原始图像，将原始图像减去平滑后的图像，得到高斯滤波过滤掉的细节图像，给细节图像乘上一定的倍数（本实验所用的倍数是2），再加到原始图像中，输出图像。\n\n```C++\n// 4、利用高提升滤波算法增强灰度图像\nvoid enhance_image(Mat image) {\n\t// 先对原始图像进行平滑处理\n\tMat filt_image = gaussion_filter(image, 3, 1);\n\tMat sub_image;\n\tsubtract(image, filt_image, sub_image);\n\n\timshow(\"dada\", sub_image*2);\n\tMat res;\n\tadd(image, sub_image, res);\n\timshow(\"高提升后的图像\", res);\n}\n```\n\n![image-20240302185107213](digital-image-test03/image-20240302185107213.png)\n\n### 5、利用均值模板平滑彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，利用 3*3、5*5 和 9*9 尺寸的均值模板平滑彩色图像。\n\n完成程度：在完成了均值滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。\n\n```c++\n// 5、利用均值模板平滑彩色图像\nvoid average_filter_color(Mat image, int size) {\n\n\t// 分别对三个通道进行处理\n\tvector<Mat> channels;\n\tcv::split(image, channels);\n\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = average_filter(channels[i], size);\n\t}\n\t\n\tcv::merge(channels, image);\n\n\timshow(\"彩图\", image);\n\n}\n```\n\n![image-20240302185113358](digital-image-test03/image-20240302185113358.png)\n\n![image-20240302185116864](digital-image-test03/image-20240302185116864.png)\n\n### 6、利用高斯模板平滑彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 3*3、5*5 和 9*9 尺寸的高斯模板平滑彩色图像。\n\n完成程度：在完成了高斯滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。\n\n```c++\n// 6、利用高斯模板平滑彩色图像\nvoid gaussion_filter_color(Mat image, int size) {\n\n\t// 分别对三个通道进行处理\n\tvector<Mat> channels;\n\tcv::split(image, channels);\n\n\tfor (int i = 0; i < 3; i++) {\n\t\tchannels[i] = gaussion_filter(channels[i], size, 1);\n\t}\n\n\tcv::merge(channels, image);\n\n\timshow(\"彩图\", image);\n}\n```\n\n![image-20240302185124222](digital-image-test03/image-20240302185124222.png)\n\n![image-20240302185128004](digital-image-test03/image-20240302185128004.png)\n\n### 7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像\n\n具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化彩色图像。\n\n完成程度：构造Laplacian、Robert、Sobel算子，分别对彩色图像的三个通道进行卷积操作，完成以后进行通道合并，并输出合并后的彩色图像。\n\n```c++\n// 7、利用Laplacian、Robert、Sobel模板锐化彩色图像\nvoid sharpen_color(Mat image) {\n\n\tvector<Mat> channels;\n\tsplit(image, channels);\n\n\t// Laplacian\n\tvector<Mat> laplacian_channels = channels;\n\tvector<Mat> laplacian_channels_color = channels;\n\n\tvector<Mat> robert_channels = channels;\n\tvector<Mat> robert_channels_color = channels;\n\n\tvector<Mat> sobel_channels = channels;\n\tvector<Mat> sobel_channels_color = channels;\n\n\tMat res_laplacian;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >laplacian_model = { {0,1,0},{1,-4,1},{0,1,0} };\n\t\tvector<vector<int> >laplacian_model2 = { {1,1,1},{1,-8,1},{1,1,1} };\n\n\t\tlaplacian_channels[i] = fill_zero(laplacian_channels[i], 3);\n\t\tlaplacian_channels[i] = juanji(laplacian_channels[i], laplacian_model, 3);\n\n\t\tsubtract(channels[i], laplacian_channels[i], laplacian_channels_color[i]);\n\t}\n\tmerge(laplacian_channels, res_laplacian);\n\timshow(\"Laplacian锐化\", res_laplacian);\n\tmerge(laplacian_channels_color, res_laplacian);\n\timshow(\"Laplacian锐化处理后图片\", res_laplacian);\n\t\n\t// Robert\n\n\tsplit(image, channels);\n\tMat res_robert;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >robert_model = { {-1,0},{0, 1} };\n\n\t\trobert_channels[i] = fill_zero(robert_channels[i], 2);\n\t\trobert_channels[i] = juanji(robert_channels[i], robert_model, 2);\n\n\t\tadd(channels[i], robert_channels[i], robert_channels_color[i]);\n\t}\n\tmerge(robert_channels, res_robert);\n\timshow(\"Robert锐化\", res_robert);\n\tmerge(robert_channels_color, res_robert);\n\timshow(\"Robert锐化处理后图片\", res_robert);\n\n\t// Sobel\n\n\tsplit(image, channels);\n\tMat res_sobel;\n\tfor (int i = 0; i < 3; ++i) {\n\t\tvector<vector<int> >sobel_model = { {-1,-2,-1},{0,0,0},{1,2,1} };\n\n\t\tsobel_channels[i] = fill_zero(sobel_channels[i], 3);\n\t\tsobel_channels[i] = juanji(sobel_channels[i], sobel_model, 3);\n\n\t\tsubtract(channels[i], sobel_channels[i], sobel_channels_color[i]);\n\t}\n\tmerge(sobel_channels, res_sobel);\n\timshow(\"Sobel锐化\", res_sobel);\n\tmerge(sobel_channels_color, res_sobel);\n\timshow(\"Sobel锐化处理后图片\", res_sobel);\n}\n```\n\nLaplacian\n\n![image-20240302185142206](digital-image-test03/image-20240302185142206.png)\n\nRobert\n\n![image-20240302185150777](digital-image-test03/image-20240302185150777.png)\n\nSobel\n\n![image-20240302185159151](digital-image-test03/image-20240302185159151.png)","slug":"digital-image-test03","published":1,"updated":"2024-06-05T09:03:03.713Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttu002508jv5ht5edwo","content":"<h3 id=\"1、利用均值模板平滑灰度图像\"><a href=\"#1、利用均值模板平滑灰度图像\" class=\"headerlink\" title=\"1、利用均值模板平滑灰度图像\"></a>1、利用均值模板平滑灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的均值模板平滑灰度图像。</p>\n<p>完成程度：对原图像进行边缘填充，用周围的像素点灰度值代替图像边缘的值，构造了3<em>3、5</em>5、7*7的均值模板，对灰度图像进行均值计算操作，将得到的均值赋值给对应的新矩阵。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 辅助函数1、对原始灰度图像进行边缘填充操作</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">fill_zero</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 将边缘的填充为与它最近的像素灰度</span><br>\t<span class=\"hljs-type\">int</span> fill_size = <span class=\"hljs-built_in\">int</span>(size / <span class=\"hljs-number\">2</span>);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br><br>\tMat first_row = image.<span class=\"hljs-built_in\">rowRange</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>);<br>\tMat last_row = image.<span class=\"hljs-built_in\">rowRange</span>(row - <span class=\"hljs-number\">1</span>, row);<br>\t<br>\t<span class=\"hljs-comment\">// 垂直填充</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; fill_size; ++i) &#123;<br>\t\tcv::<span class=\"hljs-built_in\">vconcat</span>(first_row, image, image);<br>\t\tcv::<span class=\"hljs-built_in\">vconcat</span>(image, last_row, image);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 水平填充</span><br>\tMat left_col = image.<span class=\"hljs-built_in\">colRange</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>);<br>\tMat right_col = image.<span class=\"hljs-built_in\">colRange</span>(col - <span class=\"hljs-number\">1</span>, col);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; fill_size; ++i) &#123;<br>\t\tcv::<span class=\"hljs-built_in\">hconcat</span>(left_col, image, image);<br>\t\tcv::<span class=\"hljs-built_in\">hconcat</span>(image, right_col, image);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// imshow(&quot;填充后&quot;, image);</span><br>\t<span class=\"hljs-keyword\">return</span> image;<br><br>&#125;<br><br><span class=\"hljs-comment\">// 1、利用均值模板平滑灰度图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br>\tMat meta = Mat::<span class=\"hljs-built_in\">ones</span>(size, size, CV_8U);<br><br>\t<span class=\"hljs-type\">int</span> count_size = size * size;<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row-size+<span class=\"hljs-number\">1</span>, col-size+<span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br><br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_ += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i+s, j+t) * meta.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(s, t);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = sum_/count_size;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;均值滤波：&quot;</span>+ <span class=\"hljs-built_in\">to_string</span>(size) + <span class=\"hljs-string\">&#x27;*&#x27;</span> + <span class=\"hljs-built_in\">to_string</span>(size), res);<br>\t<br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184920811.png\" class=\"\" title=\"image-20240302184920811\">\n<h3 id=\"2、利用高斯模板平滑灰度图像\"><a href=\"#2、利用高斯模板平滑灰度图像\" class=\"headerlink\" title=\"2、利用高斯模板平滑灰度图像\"></a>2、利用高斯模板平滑灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的高斯模板平滑灰度图像。 </p>\n<p>完成程度：通过高斯函数自定义构造3<em>3、5</em>5、7*7的高斯模板，编写卷积运算的函数，并将原灰度图与所构造的高斯模板进行卷积操作，得到平滑后的图像并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 辅助函数2、完成卷积操作</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">juanji</span><span class=\"hljs-params\">(Mat image, vector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt; meta, <span class=\"hljs-type\">int</span> size_)</span> </span>&#123;<br><br>\t<span class=\"hljs-type\">double</span> sum = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-comment\">// 求meta元素的和</span><br>\t<span class=\"hljs-comment\">//for (int i = 0; i &lt; size; ++i) &#123;</span><br>\t<span class=\"hljs-comment\">//\tfor (int j = 0; j &lt; size; ++j) &#123;</span><br>\t<span class=\"hljs-comment\">//\t\tsum += meta[i][j];</span><br>\t<span class=\"hljs-comment\">//\t&#125;</span><br>\t<span class=\"hljs-comment\">//&#125;</span><br>\t<span class=\"hljs-type\">int</span> size = size_ % <span class=\"hljs-number\">2</span> == <span class=\"hljs-number\">0</span> ? size_ + <span class=\"hljs-number\">1</span> : size_;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\tMat res = Mat::<span class=\"hljs-built_in\">zeros</span>(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\t<span class=\"hljs-type\">double</span> sum_1 = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size_; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size_; ++t) &#123;<br>\t\t\t\t\tsum_1 += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * meta[s][t];<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (sum_1 &gt; <span class=\"hljs-number\">0</span>) &#123;<br>\t\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-built_in\">int</span>(sum_1);<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">else</span> &#123;<br>\t\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-number\">0</span>;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> res;<br>&#125;<br><br><span class=\"hljs-comment\">// 2、利用高斯模板平滑灰度图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">gaussion_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size, <span class=\"hljs-type\">double</span> sigma)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 高斯方程为，h(x,y) = e**-&#123;([(x-x0))**2+(y-y0)**2]/(2*σ**2)]&#125;</span><br>\t<span class=\"hljs-comment\">// 其中x0，y0为中心坐标</span><br>\t<span class=\"hljs-comment\">// 构造高斯滤波器模板</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">double</span>&gt; &gt;<span class=\"hljs-built_in\">gaussion_module</span>(size, <span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-type\">double</span>&gt;(size));<br>\t<span class=\"hljs-type\">int</span> x0 = (size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-type\">int</span> y0 = (size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-comment\">// 求和</span><br>\t<span class=\"hljs-type\">double</span> sum_ = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">0</span>; x &lt; size; ++x) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> y = <span class=\"hljs-number\">0</span>; y &lt; size; ++y) &#123;<br>\t\t\tgaussion_module[x][y] = <span class=\"hljs-built_in\">exp</span>(-(<span class=\"hljs-built_in\">pow</span>((x - x0), <span class=\"hljs-number\">2</span>) + <span class=\"hljs-built_in\">pow</span>((y - y0), <span class=\"hljs-number\">2</span>)) / (<span class=\"hljs-number\">2</span> * sigma * sigma));<br>\t\t\tsum_ += gaussion_module[x][y];<br>\t\t&#125;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-comment\">// 填充</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br><br>\t<span class=\"hljs-comment\">// Mat res = juanji(image, gaussion_module, size);</span><br><br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br><br>\t<span class=\"hljs-comment\">// 使用高斯滤波进行卷积操作</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\t<span class=\"hljs-comment\">// 卷积和</span><br>\t\t\t<span class=\"hljs-type\">double</span> sum_mul = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_mul += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * gaussion_module[s][t];<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-built_in\">int</span>(sum_mul / sum_);<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;高斯模板尺寸：&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(size) + <span class=\"hljs-string\">&#x27;*&#x27;</span> + <span class=\"hljs-built_in\">to_string</span>(size), res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184935209.png\" class=\"\" title=\"image-20240302184935209\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184940449.png\" class=\"\" title=\"image-20240302184940449\">\n<h3 id=\"3、利用-Laplacian、Robert、Sobel-模板锐化灰度图像\"><a href=\"#3、利用-Laplacian、Robert、Sobel-模板锐化灰度图像\" class=\"headerlink\" title=\"3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像\"></a>3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化灰度图像。 </p>\n<p>完成程度：分别构造Laplacian、Robert、Sobel模板，用这三个模板分别原始图像进行卷积操作，得到结果后输出</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、利用Laplacian、Robert、Sobel模板锐化灰度图像</span><br><span class=\"hljs-function\">vector&lt;Mat&gt; <span class=\"hljs-title\">sharpen</span><span class=\"hljs-params\">(Mat image1)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image1);<br>\t<span class=\"hljs-comment\">// 对原图进行填充</span><br>\tMat image = image1;<br><br>\t<span class=\"hljs-comment\">//image = average_filter(image, 3);</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, <span class=\"hljs-number\">3</span>);<br>\t<span class=\"hljs-comment\">// 拉普拉斯模板&#123;0，1，0，1，-4，1，0，1，0&#125;</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model = &#123; &#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-4</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125; &#125;;<br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model2 = &#123; &#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-8</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br>\t<br>\tMat res_laplacian = <span class=\"hljs-built_in\">juanji</span>(image, laplacian_model, <span class=\"hljs-number\">3</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian&quot;</span>, res_laplacian);<br>\t<span class=\"hljs-built_in\">subtract</span>(image1, res_laplacian, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian处理过后的图像&quot;</span>, res_laplacian);<br><br>\t<span class=\"hljs-comment\">// Robert算子</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;robert_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>&#125; &#125;;<br>\tMat image_robert = image1;<br>\timage_robert = <span class=\"hljs-built_in\">fill_zero</span>(image_robert, <span class=\"hljs-number\">2</span>);<br>\tMat res_robert = <span class=\"hljs-built_in\">juanji</span>(image_robert, robert_model, <span class=\"hljs-number\">2</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;robert&quot;</span>, res_robert);<br>\t<span class=\"hljs-built_in\">add</span>(image1, res_robert, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Rebort处理过后的图像&quot;</span>, res_robert);<br>\t<span class=\"hljs-comment\">// cout &lt;&lt; res_rebort.cols &lt;&lt; &quot;sadas&quot; &lt;&lt; endl;</span><br><br>\t<span class=\"hljs-comment\">// Sobel算子</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;sobel_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">-2</span>,<span class=\"hljs-number\">-1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br>\tMat image_sobel = image1;<br>\timage_sobel = <span class=\"hljs-built_in\">fill_zero</span>(image_sobel, <span class=\"hljs-number\">3</span>);<br>\tMat res_sobel = <span class=\"hljs-built_in\">juanji</span>(image_sobel, sobel_model, <span class=\"hljs-number\">3</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;sobel&quot;</span>, res_sobel);<br>\t<span class=\"hljs-built_in\">subtract</span>(image1, res_sobel, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel处理过后的图像&quot;</span>, res_sobel);<br><br>\tvector&lt;Mat&gt; res = &#123; res_laplacian, res_robert, res_sobel &#125;;<br>\tMat s;<br>\t<span class=\"hljs-built_in\">merge</span>(res, s);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;get&quot;</span>, s);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>Laplacian</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184950081.png\" class=\"\" title=\"image-20240302184950081\">\n<p>Robert</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184959151.png\" class=\"\" title=\"image-20240302184959151\">\n<p>Sobel</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185003442.png\" class=\"\" title=\"image-20240302185003442\">\n<h3 id=\"4、利用高提升滤波算法增强灰度图像\"><a href=\"#4、利用高提升滤波算法增强灰度图像\" class=\"headerlink\" title=\"4、利用高提升滤波算法增强灰度图像\"></a>4、利用高提升滤波算法增强灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，设计高提升滤波算法增强图像。 </p>\n<p>完成程度：使用高斯滤波平滑原始图像，将原始图像减去平滑后的图像，得到高斯滤波过滤掉的细节图像，给细节图像乘上一定的倍数（本实验所用的倍数是2），再加到原始图像中，输出图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 4、利用高提升滤波算法增强灰度图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">enhance_image</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 先对原始图像进行平滑处理</span><br>\tMat filt_image = <span class=\"hljs-built_in\">gaussion_filter</span>(image, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>);<br>\tMat sub_image;<br>\t<span class=\"hljs-built_in\">subtract</span>(image, filt_image, sub_image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;dada&quot;</span>, sub_image*<span class=\"hljs-number\">2</span>);<br>\tMat res;<br>\t<span class=\"hljs-built_in\">add</span>(image, sub_image, res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;高提升后的图像&quot;</span>, res);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185107213.png\" class=\"\" title=\"image-20240302185107213\">\n<h3 id=\"5、利用均值模板平滑彩色图像\"><a href=\"#5、利用均值模板平滑彩色图像\" class=\"headerlink\" title=\"5、利用均值模板平滑彩色图像\"></a>5、利用均值模板平滑彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，利用 3<em>3、5</em>5 和 9*9 尺寸的均值模板平滑彩色图像。</p>\n<p>完成程度：在完成了均值滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 5、利用均值模板平滑彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">average_filter_color</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\t<span class=\"hljs-comment\">// 分别对三个通道进行处理</span><br>\tvector&lt;Mat&gt; channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">average_filter</span>(channels[i], size);<br>\t&#125;<br>\t<br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩图&quot;</span>, image);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185113358.png\" class=\"\" title=\"image-20240302185113358\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185116864.png\" class=\"\" title=\"image-20240302185116864\">\n<h3 id=\"6、利用高斯模板平滑彩色图像\"><a href=\"#6、利用高斯模板平滑彩色图像\" class=\"headerlink\" title=\"6、利用高斯模板平滑彩色图像\"></a>6、利用高斯模板平滑彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的高斯模板平滑彩色图像。</p>\n<p>完成程度：在完成了高斯滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 6、利用高斯模板平滑彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">gaussion_filter_color</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\t<span class=\"hljs-comment\">// 分别对三个通道进行处理</span><br>\tvector&lt;Mat&gt; channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">gaussion_filter</span>(channels[i], size, <span class=\"hljs-number\">1</span>);<br>\t&#125;<br><br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩图&quot;</span>, image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185124222.png\" class=\"\" title=\"image-20240302185124222\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185128004.png\" class=\"\" title=\"image-20240302185128004\">\n<h3 id=\"7、利用-Laplacian、Robert、Sobel-模板锐化彩色图像\"><a href=\"#7、利用-Laplacian、Robert、Sobel-模板锐化彩色图像\" class=\"headerlink\" title=\"7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像\"></a>7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化彩色图像。</p>\n<p>完成程度：构造Laplacian、Robert、Sobel算子，分别对彩色图像的三个通道进行卷积操作，完成以后进行通道合并，并输出合并后的彩色图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 7、利用Laplacian、Robert、Sobel模板锐化彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sharpen_color</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\tvector&lt;Mat&gt; channels;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-comment\">// Laplacian</span><br>\tvector&lt;Mat&gt; laplacian_channels = channels;<br>\tvector&lt;Mat&gt; laplacian_channels_color = channels;<br><br>\tvector&lt;Mat&gt; robert_channels = channels;<br>\tvector&lt;Mat&gt; robert_channels_color = channels;<br><br>\tvector&lt;Mat&gt; sobel_channels = channels;<br>\tvector&lt;Mat&gt; sobel_channels_color = channels;<br><br>\tMat res_laplacian;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model = &#123; &#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-4</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125; &#125;;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model2 = &#123; &#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-8</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\tlaplacian_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(laplacian_channels[i], <span class=\"hljs-number\">3</span>);<br>\t\tlaplacian_channels[i] = <span class=\"hljs-built_in\">juanji</span>(laplacian_channels[i], laplacian_model, <span class=\"hljs-number\">3</span>);<br><br>\t\t<span class=\"hljs-built_in\">subtract</span>(channels[i], laplacian_channels[i], laplacian_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(laplacian_channels, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian锐化&quot;</span>, res_laplacian);<br>\t<span class=\"hljs-built_in\">merge</span>(laplacian_channels_color, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian锐化处理后图片&quot;</span>, res_laplacian);<br>\t<br>\t<span class=\"hljs-comment\">// Robert</span><br><br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tMat res_robert;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;robert_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\trobert_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(robert_channels[i], <span class=\"hljs-number\">2</span>);<br>\t\trobert_channels[i] = <span class=\"hljs-built_in\">juanji</span>(robert_channels[i], robert_model, <span class=\"hljs-number\">2</span>);<br><br>\t\t<span class=\"hljs-built_in\">add</span>(channels[i], robert_channels[i], robert_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(robert_channels, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Robert锐化&quot;</span>, res_robert);<br>\t<span class=\"hljs-built_in\">merge</span>(robert_channels_color, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Robert锐化处理后图片&quot;</span>, res_robert);<br><br>\t<span class=\"hljs-comment\">// Sobel</span><br><br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tMat res_sobel;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;sobel_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">-2</span>,<span class=\"hljs-number\">-1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\tsobel_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(sobel_channels[i], <span class=\"hljs-number\">3</span>);<br>\t\tsobel_channels[i] = <span class=\"hljs-built_in\">juanji</span>(sobel_channels[i], sobel_model, <span class=\"hljs-number\">3</span>);<br><br>\t\t<span class=\"hljs-built_in\">subtract</span>(channels[i], sobel_channels[i], sobel_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(sobel_channels, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel锐化&quot;</span>, res_sobel);<br>\t<span class=\"hljs-built_in\">merge</span>(sobel_channels_color, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel锐化处理后图片&quot;</span>, res_sobel);<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>Laplacian</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185142206.png\" class=\"\" title=\"image-20240302185142206\">\n<p>Robert</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185150777.png\" class=\"\" title=\"image-20240302185150777\">\n<p>Sobel</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185159151.png\" class=\"\" title=\"image-20240302185159151\">","cover_type":"img","excerpt":"","more":"<h3 id=\"1、利用均值模板平滑灰度图像\"><a href=\"#1、利用均值模板平滑灰度图像\" class=\"headerlink\" title=\"1、利用均值模板平滑灰度图像\"></a>1、利用均值模板平滑灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的均值模板平滑灰度图像。</p>\n<p>完成程度：对原图像进行边缘填充，用周围的像素点灰度值代替图像边缘的值，构造了3<em>3、5</em>5、7*7的均值模板，对灰度图像进行均值计算操作，将得到的均值赋值给对应的新矩阵。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 辅助函数1、对原始灰度图像进行边缘填充操作</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">fill_zero</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 将边缘的填充为与它最近的像素灰度</span><br>\t<span class=\"hljs-type\">int</span> fill_size = <span class=\"hljs-built_in\">int</span>(size / <span class=\"hljs-number\">2</span>);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br><br>\tMat first_row = image.<span class=\"hljs-built_in\">rowRange</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>);<br>\tMat last_row = image.<span class=\"hljs-built_in\">rowRange</span>(row - <span class=\"hljs-number\">1</span>, row);<br>\t<br>\t<span class=\"hljs-comment\">// 垂直填充</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; fill_size; ++i) &#123;<br>\t\tcv::<span class=\"hljs-built_in\">vconcat</span>(first_row, image, image);<br>\t\tcv::<span class=\"hljs-built_in\">vconcat</span>(image, last_row, image);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 水平填充</span><br>\tMat left_col = image.<span class=\"hljs-built_in\">colRange</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>);<br>\tMat right_col = image.<span class=\"hljs-built_in\">colRange</span>(col - <span class=\"hljs-number\">1</span>, col);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; fill_size; ++i) &#123;<br>\t\tcv::<span class=\"hljs-built_in\">hconcat</span>(left_col, image, image);<br>\t\tcv::<span class=\"hljs-built_in\">hconcat</span>(image, right_col, image);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// imshow(&quot;填充后&quot;, image);</span><br>\t<span class=\"hljs-keyword\">return</span> image;<br><br>&#125;<br><br><span class=\"hljs-comment\">// 1、利用均值模板平滑灰度图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br>\tMat meta = Mat::<span class=\"hljs-built_in\">ones</span>(size, size, CV_8U);<br><br>\t<span class=\"hljs-type\">int</span> count_size = size * size;<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row-size+<span class=\"hljs-number\">1</span>, col-size+<span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br><br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_ += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i+s, j+t) * meta.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(s, t);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = sum_/count_size;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;均值滤波：&quot;</span>+ <span class=\"hljs-built_in\">to_string</span>(size) + <span class=\"hljs-string\">&#x27;*&#x27;</span> + <span class=\"hljs-built_in\">to_string</span>(size), res);<br>\t<br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184920811.png\" class=\"\" title=\"image-20240302184920811\">\n<h3 id=\"2、利用高斯模板平滑灰度图像\"><a href=\"#2、利用高斯模板平滑灰度图像\" class=\"headerlink\" title=\"2、利用高斯模板平滑灰度图像\"></a>2、利用高斯模板平滑灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的高斯模板平滑灰度图像。 </p>\n<p>完成程度：通过高斯函数自定义构造3<em>3、5</em>5、7*7的高斯模板，编写卷积运算的函数，并将原灰度图与所构造的高斯模板进行卷积操作，得到平滑后的图像并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 辅助函数2、完成卷积操作</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">juanji</span><span class=\"hljs-params\">(Mat image, vector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt; meta, <span class=\"hljs-type\">int</span> size_)</span> </span>&#123;<br><br>\t<span class=\"hljs-type\">double</span> sum = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-comment\">// 求meta元素的和</span><br>\t<span class=\"hljs-comment\">//for (int i = 0; i &lt; size; ++i) &#123;</span><br>\t<span class=\"hljs-comment\">//\tfor (int j = 0; j &lt; size; ++j) &#123;</span><br>\t<span class=\"hljs-comment\">//\t\tsum += meta[i][j];</span><br>\t<span class=\"hljs-comment\">//\t&#125;</span><br>\t<span class=\"hljs-comment\">//&#125;</span><br>\t<span class=\"hljs-type\">int</span> size = size_ % <span class=\"hljs-number\">2</span> == <span class=\"hljs-number\">0</span> ? size_ + <span class=\"hljs-number\">1</span> : size_;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\tMat res = Mat::<span class=\"hljs-built_in\">zeros</span>(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\t<span class=\"hljs-type\">double</span> sum_1 = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size_; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size_; ++t) &#123;<br>\t\t\t\t\tsum_1 += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * meta[s][t];<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (sum_1 &gt; <span class=\"hljs-number\">0</span>) &#123;<br>\t\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-built_in\">int</span>(sum_1);<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">else</span> &#123;<br>\t\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-number\">0</span>;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> res;<br>&#125;<br><br><span class=\"hljs-comment\">// 2、利用高斯模板平滑灰度图像</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">gaussion_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size, <span class=\"hljs-type\">double</span> sigma)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 高斯方程为，h(x,y) = e**-&#123;([(x-x0))**2+(y-y0)**2]/(2*σ**2)]&#125;</span><br>\t<span class=\"hljs-comment\">// 其中x0，y0为中心坐标</span><br>\t<span class=\"hljs-comment\">// 构造高斯滤波器模板</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">double</span>&gt; &gt;<span class=\"hljs-built_in\">gaussion_module</span>(size, <span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-type\">double</span>&gt;(size));<br>\t<span class=\"hljs-type\">int</span> x0 = (size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-type\">int</span> y0 = (size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-comment\">// 求和</span><br>\t<span class=\"hljs-type\">double</span> sum_ = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">0</span>; x &lt; size; ++x) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> y = <span class=\"hljs-number\">0</span>; y &lt; size; ++y) &#123;<br>\t\t\tgaussion_module[x][y] = <span class=\"hljs-built_in\">exp</span>(-(<span class=\"hljs-built_in\">pow</span>((x - x0), <span class=\"hljs-number\">2</span>) + <span class=\"hljs-built_in\">pow</span>((y - y0), <span class=\"hljs-number\">2</span>)) / (<span class=\"hljs-number\">2</span> * sigma * sigma));<br>\t\t\tsum_ += gaussion_module[x][y];<br>\t\t&#125;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-comment\">// 填充</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br><br>\t<span class=\"hljs-comment\">// Mat res = juanji(image, gaussion_module, size);</span><br><br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br><br>\t<span class=\"hljs-comment\">// 使用高斯滤波进行卷积操作</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\t<span class=\"hljs-comment\">// 卷积和</span><br>\t\t\t<span class=\"hljs-type\">double</span> sum_mul = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_mul += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * gaussion_module[s][t];<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = <span class=\"hljs-built_in\">int</span>(sum_mul / sum_);<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;高斯模板尺寸：&quot;</span> + <span class=\"hljs-built_in\">to_string</span>(size) + <span class=\"hljs-string\">&#x27;*&#x27;</span> + <span class=\"hljs-built_in\">to_string</span>(size), res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184935209.png\" class=\"\" title=\"image-20240302184935209\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184940449.png\" class=\"\" title=\"image-20240302184940449\">\n<h3 id=\"3、利用-Laplacian、Robert、Sobel-模板锐化灰度图像\"><a href=\"#3、利用-Laplacian、Robert、Sobel-模板锐化灰度图像\" class=\"headerlink\" title=\"3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像\"></a>3、利用 Laplacian、Robert、Sobel 模板锐化灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化灰度图像。 </p>\n<p>完成程度：分别构造Laplacian、Robert、Sobel模板，用这三个模板分别原始图像进行卷积操作，得到结果后输出</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、利用Laplacian、Robert、Sobel模板锐化灰度图像</span><br><span class=\"hljs-function\">vector&lt;Mat&gt; <span class=\"hljs-title\">sharpen</span><span class=\"hljs-params\">(Mat image1)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image1);<br>\t<span class=\"hljs-comment\">// 对原图进行填充</span><br>\tMat image = image1;<br><br>\t<span class=\"hljs-comment\">//image = average_filter(image, 3);</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, <span class=\"hljs-number\">3</span>);<br>\t<span class=\"hljs-comment\">// 拉普拉斯模板&#123;0，1，0，1，-4，1，0，1，0&#125;</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model = &#123; &#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-4</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125; &#125;;<br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model2 = &#123; &#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-8</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br>\t<br>\tMat res_laplacian = <span class=\"hljs-built_in\">juanji</span>(image, laplacian_model, <span class=\"hljs-number\">3</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian&quot;</span>, res_laplacian);<br>\t<span class=\"hljs-built_in\">subtract</span>(image1, res_laplacian, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian处理过后的图像&quot;</span>, res_laplacian);<br><br>\t<span class=\"hljs-comment\">// Robert算子</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;robert_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>&#125; &#125;;<br>\tMat image_robert = image1;<br>\timage_robert = <span class=\"hljs-built_in\">fill_zero</span>(image_robert, <span class=\"hljs-number\">2</span>);<br>\tMat res_robert = <span class=\"hljs-built_in\">juanji</span>(image_robert, robert_model, <span class=\"hljs-number\">2</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;robert&quot;</span>, res_robert);<br>\t<span class=\"hljs-built_in\">add</span>(image1, res_robert, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Rebort处理过后的图像&quot;</span>, res_robert);<br>\t<span class=\"hljs-comment\">// cout &lt;&lt; res_rebort.cols &lt;&lt; &quot;sadas&quot; &lt;&lt; endl;</span><br><br>\t<span class=\"hljs-comment\">// Sobel算子</span><br>\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;sobel_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">-2</span>,<span class=\"hljs-number\">-1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br>\tMat image_sobel = image1;<br>\timage_sobel = <span class=\"hljs-built_in\">fill_zero</span>(image_sobel, <span class=\"hljs-number\">3</span>);<br>\tMat res_sobel = <span class=\"hljs-built_in\">juanji</span>(image_sobel, sobel_model, <span class=\"hljs-number\">3</span>);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;sobel&quot;</span>, res_sobel);<br>\t<span class=\"hljs-built_in\">subtract</span>(image1, res_sobel, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel处理过后的图像&quot;</span>, res_sobel);<br><br>\tvector&lt;Mat&gt; res = &#123; res_laplacian, res_robert, res_sobel &#125;;<br>\tMat s;<br>\t<span class=\"hljs-built_in\">merge</span>(res, s);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;get&quot;</span>, s);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>Laplacian</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184950081.png\" class=\"\" title=\"image-20240302184950081\">\n<p>Robert</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302184959151.png\" class=\"\" title=\"image-20240302184959151\">\n<p>Sobel</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185003442.png\" class=\"\" title=\"image-20240302185003442\">\n<h3 id=\"4、利用高提升滤波算法增强灰度图像\"><a href=\"#4、利用高提升滤波算法增强灰度图像\" class=\"headerlink\" title=\"4、利用高提升滤波算法增强灰度图像\"></a>4、利用高提升滤波算法增强灰度图像</h3><p>具体内容: 利用 OpenCV 对图像像素进行操作，设计高提升滤波算法增强图像。 </p>\n<p>完成程度：使用高斯滤波平滑原始图像，将原始图像减去平滑后的图像，得到高斯滤波过滤掉的细节图像，给细节图像乘上一定的倍数（本实验所用的倍数是2），再加到原始图像中，输出图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 4、利用高提升滤波算法增强灰度图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">enhance_image</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 先对原始图像进行平滑处理</span><br>\tMat filt_image = <span class=\"hljs-built_in\">gaussion_filter</span>(image, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>);<br>\tMat sub_image;<br>\t<span class=\"hljs-built_in\">subtract</span>(image, filt_image, sub_image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;dada&quot;</span>, sub_image*<span class=\"hljs-number\">2</span>);<br>\tMat res;<br>\t<span class=\"hljs-built_in\">add</span>(image, sub_image, res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;高提升后的图像&quot;</span>, res);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185107213.png\" class=\"\" title=\"image-20240302185107213\">\n<h3 id=\"5、利用均值模板平滑彩色图像\"><a href=\"#5、利用均值模板平滑彩色图像\" class=\"headerlink\" title=\"5、利用均值模板平滑彩色图像\"></a>5、利用均值模板平滑彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，利用 3<em>3、5</em>5 和 9*9 尺寸的均值模板平滑彩色图像。</p>\n<p>完成程度：在完成了均值滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 5、利用均值模板平滑彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">average_filter_color</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\t<span class=\"hljs-comment\">// 分别对三个通道进行处理</span><br>\tvector&lt;Mat&gt; channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">average_filter</span>(channels[i], size);<br>\t&#125;<br>\t<br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩图&quot;</span>, image);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185113358.png\" class=\"\" title=\"image-20240302185113358\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185116864.png\" class=\"\" title=\"image-20240302185116864\">\n<h3 id=\"6、利用高斯模板平滑彩色图像\"><a href=\"#6、利用高斯模板平滑彩色图像\" class=\"headerlink\" title=\"6、利用高斯模板平滑彩色图像\"></a>6、利用高斯模板平滑彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 3<em>3、5</em>5 和 9*9 尺寸的高斯模板平滑彩色图像。</p>\n<p>完成程度：在完成了高斯滤波平滑灰度图像的基础上，分离彩色图像的三个通道，分别对其三个通道进行平滑处理，完成以后再合并输出。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 6、利用高斯模板平滑彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">gaussion_filter_color</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\t<span class=\"hljs-comment\">// 分别对三个通道进行处理</span><br>\tvector&lt;Mat&gt; channels;<br>\tcv::<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; i++) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">gaussion_filter</span>(channels[i], size, <span class=\"hljs-number\">1</span>);<br>\t&#125;<br><br>\tcv::<span class=\"hljs-built_in\">merge</span>(channels, image);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩图&quot;</span>, image);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185124222.png\" class=\"\" title=\"image-20240302185124222\">\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185128004.png\" class=\"\" title=\"image-20240302185128004\">\n<h3 id=\"7、利用-Laplacian、Robert、Sobel-模板锐化彩色图像\"><a href=\"#7、利用-Laplacian、Robert、Sobel-模板锐化彩色图像\" class=\"headerlink\" title=\"7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像\"></a>7、利用 Laplacian、Robert、Sobel 模板锐化彩色图像</h3><p>具体内容：利用 OpenCV 分别对图像像素的 RGB 三个通道进行操作，分别利用 Laplacian、Robert、Sobel 模板锐化彩色图像。</p>\n<p>完成程度：构造Laplacian、Robert、Sobel算子，分别对彩色图像的三个通道进行卷积操作，完成以后进行通道合并，并输出合并后的彩色图像。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 7、利用Laplacian、Robert、Sobel模板锐化彩色图像</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">sharpen_color</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\tvector&lt;Mat&gt; channels;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br><br>\t<span class=\"hljs-comment\">// Laplacian</span><br>\tvector&lt;Mat&gt; laplacian_channels = channels;<br>\tvector&lt;Mat&gt; laplacian_channels_color = channels;<br><br>\tvector&lt;Mat&gt; robert_channels = channels;<br>\tvector&lt;Mat&gt; robert_channels_color = channels;<br><br>\tvector&lt;Mat&gt; sobel_channels = channels;<br>\tvector&lt;Mat&gt; sobel_channels_color = channels;<br><br>\tMat res_laplacian;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model = &#123; &#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-4</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>&#125; &#125;;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;laplacian_model2 = &#123; &#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">-8</span>,<span class=\"hljs-number\">1</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\tlaplacian_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(laplacian_channels[i], <span class=\"hljs-number\">3</span>);<br>\t\tlaplacian_channels[i] = <span class=\"hljs-built_in\">juanji</span>(laplacian_channels[i], laplacian_model, <span class=\"hljs-number\">3</span>);<br><br>\t\t<span class=\"hljs-built_in\">subtract</span>(channels[i], laplacian_channels[i], laplacian_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(laplacian_channels, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian锐化&quot;</span>, res_laplacian);<br>\t<span class=\"hljs-built_in\">merge</span>(laplacian_channels_color, res_laplacian);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Laplacian锐化处理后图片&quot;</span>, res_laplacian);<br>\t<br>\t<span class=\"hljs-comment\">// Robert</span><br><br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tMat res_robert;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;robert_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\trobert_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(robert_channels[i], <span class=\"hljs-number\">2</span>);<br>\t\trobert_channels[i] = <span class=\"hljs-built_in\">juanji</span>(robert_channels[i], robert_model, <span class=\"hljs-number\">2</span>);<br><br>\t\t<span class=\"hljs-built_in\">add</span>(channels[i], robert_channels[i], robert_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(robert_channels, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Robert锐化&quot;</span>, res_robert);<br>\t<span class=\"hljs-built_in\">merge</span>(robert_channels_color, res_robert);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Robert锐化处理后图片&quot;</span>, res_robert);<br><br>\t<span class=\"hljs-comment\">// Sobel</span><br><br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tMat res_sobel;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tvector&lt;vector&lt;<span class=\"hljs-type\">int</span>&gt; &gt;sobel_model = &#123; &#123;<span class=\"hljs-number\">-1</span>,<span class=\"hljs-number\">-2</span>,<span class=\"hljs-number\">-1</span>&#125;,&#123;<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>&#125;,&#123;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>&#125; &#125;;<br><br>\t\tsobel_channels[i] = <span class=\"hljs-built_in\">fill_zero</span>(sobel_channels[i], <span class=\"hljs-number\">3</span>);<br>\t\tsobel_channels[i] = <span class=\"hljs-built_in\">juanji</span>(sobel_channels[i], sobel_model, <span class=\"hljs-number\">3</span>);<br><br>\t\t<span class=\"hljs-built_in\">subtract</span>(channels[i], sobel_channels[i], sobel_channels_color[i]);<br>\t&#125;<br>\t<span class=\"hljs-built_in\">merge</span>(sobel_channels, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel锐化&quot;</span>, res_sobel);<br>\t<span class=\"hljs-built_in\">merge</span>(sobel_channels_color, res_sobel);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;Sobel锐化处理后图片&quot;</span>, res_sobel);<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>Laplacian</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185142206.png\" class=\"\" title=\"image-20240302185142206\">\n<p>Robert</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185150777.png\" class=\"\" title=\"image-20240302185150777\">\n<p>Sobel</p>\n<img src=\"/2022/10/02/digital-image-test03/image-20240302185159151.png\" class=\"\" title=\"image-20240302185159151\">"},{"title":"数字图像处理实验-图像去噪","date":"2022-10-19T10:32:15.000Z","cover":"/img/default_cover05.jpg","top_img":null,"_content":"### 1、均值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用算术均值滤波器、几何均值滤波器、谐波和逆谐波均值滤波器进行图像去噪。模板大小为5*5。（注：请分别为图像添加高斯噪声、胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果）\n\n完成程度：读入灰度图像，分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是用模板中的像素取平均值后赋值给中心像素，最终得到处理结果。\n\n```c++\n// 1、均值滤波\nMat average_filter(Mat image1, string s) {\n\t// 构建均值滤波模板\n\n\tMat image = image1.clone();\n\tint size = 5;\n\timage.convertTo(image, CV_8U);\n\tMat meta = Mat::ones(size, size, CV_8U);\n\n\tint count_size = size * size;\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_ += image.at<uchar>(i + s, j + t) * meta.at<uchar>(s, t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = sum_ / count_size;\n\t\t}\n\t}\n\n\n\n\timshow(\"均值滤波处理\" + s, res);\n\n\treturn res;\n\n}\nvoid junzhi_quzao(Mat image) {\n\n\timshow(\"原图\", image);\n\n\taverage_filter(guassion(image), \"高斯噪声\");\n\taverage_filter(jiao_salty(image), \"椒盐噪声\");\n\taverage_filter(salty(image), \"盐噪声\");\n\taverage_filter(jiao(image), \"椒噪声\");\n\n}\n```\n\n添加噪声\n\n![image-20240302185557410](digital-image-test04/image-20240302185557410.png)\n\n![image-20240302185602980](digital-image-test04/image-20240302185602980.png)\n\n![image-20240302185608155](digital-image-test04/image-20240302185608155.png)\n\n均值滤波\n\n![image-20240302185735104](digital-image-test04/image-20240302185735104.png)\n\n![image-20240302185739084](digital-image-test04/image-20240302185739084.png)\n\n### 2、中值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用 5*5 和 9*9尺寸的模板对图像进行中值滤波。（注：请分别为图像添加胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果） \n\n完成程度：分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是，将模板内的像素灰度进行排序，取排序后的中间灰度值作为模板中心像素的灰度值，最终得到处理结果。\n\n```c++\n// 2、中值滤波\n// 将窗口中的点按照从小到大的排序，取中间的值作为窗口中心的值\nMat median_filter(Mat image1, int size, string s1) {\n\t// 构建均值滤波模板\n\tMat image = image1.clone();\n\timage.convertTo(image, CV_8U);\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\tvector<int> num;\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tint k = image.at<uchar>(i + s, j + t);\n\t\t\t\t\tnum.push_back(k);\n\t\t\t\t}\n\t\t\t}\n\t\t\tsort(num.begin(), num.end());\n\t\t\tres.at<uchar>(i, j) = num[int(num.size() / 2)];\n\t\t}\n\t}\n\timshow(\"中值滤波处理\" + s1, res);\n\n\treturn res;\n\n}\nvoid zhongzhi_quzao(Mat image) {\n\n\timshow(\"原图\", image);\n\n\tmedian_filter(guassion(image), 5, \"高斯噪声\");\n\tmedian_filter(jiao_salty(image), 5, \"椒盐噪声\");\n\tmedian_filter(salty(image), 5, \"盐噪声\");\n\tmedian_filter(jiao(image), 5, \"椒噪声\");\n\n}\n```\n\n![image-20240302185751435](digital-image-test04/image-20240302185751435.png)\n\n![image-20240302185800747](digital-image-test04/image-20240302185800747.png)\n\n### 3、自适应均值滤波\n\n具体内容:利用 OpenCV 对灰度图像像素进行操作，设计自适应局部降低噪声滤波器去噪算法。模板大小 7*7（对比该算法的效果和均值滤波器的效果） \n\n完成程度：自适应的均值滤波，可以通过局部的均值方差，以及噪声的均值方差之间的关系，来自动的调整对噪声处理强的大小，将原始图片的方差作为分子，将局部图片的方差作为分母，用7*7的模板对加入高斯噪声的图像进行了处理。\n\n```c++\n// 3、自适应均值滤波\n// 计算图像全局的方差\ndouble quare_sub(Mat image) {\n\t// 统计不同灰度的概率密度\n\tdouble midu[256] = { 0 };\n\n\tint col = image.cols;\n\tint row = image.rows;\n\n\tfor (int i = 0; i < row; ++i) {\n\t\tfor (int j = 0; j < col; ++j) {\n\t\t\tmidu[image.at<uchar>(i, j)] += 1;\n\t\t}\n\t}\n\n\tint size = col * row;\n\n\t// 计算均值\n\tdouble med = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tmed += i * (midu[i] / size);\n\t}\n\n\t// 计算方差\n\tdouble quare = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tquare += pow((i - med), 2) * (midu[i] / size);\n\t}\n\n\treturn quare;\n}\n\n// 自适应均值滤波\nMat self_adapt_mean_filter(Mat image, int self_adapt_mean_filter_size) {\n\t// 滤波窗口尺寸必须为奇数\n\tMat pScr, dst;\n\t// 1为加载图像的颜色类型,1为原图返回,0为灰度返回\n\tpScr = image.clone();\n\tint row = pScr.rows;\n\tint col = pScr.cols;\n\tblur(pScr, dst, Size(7, 7));\n\tint pos = (self_adapt_mean_filter_size - 1) / 2;\n\tdouble Sn = 100.0;\n\t// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值\n\tfor (int m = pos; m < row - pos; m++) {\n\t\tfor (int n = pos; n < col - pos; n++) {\n\t\t\tint Zxy = int(pScr.at<uchar>(m, n));\n\t\t\tint Zmed = int(dst.at<uchar>(m, n));\n\t\t\tdouble Sl = 0.0;\n\t\t\tint count = 0;\n\t\t\tfor (int i = m - (self_adapt_mean_filter_size - 1) / 2; i <= m + (self_adapt_mean_filter_size - 1) / 2; i++) {\n\t\t\t\tfor (int j = n - (self_adapt_mean_filter_size - 1) / 2; j <= n + (self_adapt_mean_filter_size - 1) / 2; j++) {\n\t\t\t\t\tint Sxy = pScr.at<uchar>(i, j);\n\t\t\t\t\tSl += pow(Sxy - Zmed, 2);\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tSl = Sl / count;\n\t\t\tpScr.at<uchar>(m, n) = (int)(Zxy - Sn / Sl * (Zxy - Zmed));\n\n\t\t}\n\t}\n\treturn pScr;\n}\nvoid self_adapt(Mat image, int size) {\n\tMat res = image.clone();\n\t\n\tres = guassion(res);\n\timshow(\"加入高斯噪声后图片\", res);\n\tres = self_adapt_mean_filter(res, size);\n\timshow(\"使用自适应均值滤波\", res);\n}\n```\n\n![image-20240302185819182](digital-image-test04/image-20240302185819182.png)\n\n### 4、自适应中值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，设计自适应中值滤波算法对椒盐图像进行去噪。模板大小 7*7（对比中值滤波器的效果） \n\n完成程度：自适应的中值滤波和自适应的均值滤波具有相似的原理，与均值滤波不同的便是，中值滤波适应的是模板的大小，而均值滤波适应的是去噪比例大小。\n\n```c++\n//4、自适应中值滤波\n// 自适应中值滤波\nMat self_adapt_median_filter(Mat image, int self_adapt_median_filter_size) {\n\t// 滤波窗口尺寸必须为奇数\n\tMat pScr = image.clone();\n\t// 1为加载图像的颜色类型,1为原图返回,0为灰度返回\n\tint row = pScr.rows;\n\tint col = pScr.cols;\n\tint channel = pScr.channels();\n\t// 滤波器窗口的起始尺寸\n\tint pos = (self_adapt_median_filter_size - 1) / 2;\n\t// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值\n\tfor (int m = pos; m < row - pos; m++) {\n\t\tfor (int n = pos; n < col - pos; n++) {\n\t\t\tint minValue = 255;\n\t\t\tint maxValue = 0;\n\t\t\tint medValue = 0;\n\t\t\tvector<int> filter_value;\n\t\t\tfor (int i = m - (self_adapt_median_filter_size - 1) / 2; i <= m + (self_adapt_median_filter_size - 1) / 2; i++) {\n\t\t\t\tfor (int j = n - (self_adapt_median_filter_size - 1) / 2; j <= n + (self_adapt_median_filter_size - 1) / 2; j++) {\n\t\t\t\t\tfilter_value.push_back(int(pScr.at<uchar>(i, j)));\n\t\t\t\t\tif (int(pScr.at<uchar>(i, j)) > maxValue)\n\t\t\t\t\t\tmaxValue = int(pScr.at<uchar>(i, j));\n\t\t\t\t\tif (int(pScr.at<uchar>(i, j)) < minValue)\n\t\t\t\t\t\tminValue = int(pScr.at<uchar>(i, j));\n\t\t\t\t}\n\t\t\t}\n\t\t\tsort(filter_value.begin(), filter_value.end());\n\t\t\tmedValue = filter_value[int(self_adapt_median_filter_size * self_adapt_median_filter_size / 2)];\n\t\t\tint fxy = int(pScr.at<uchar>(m, n));\n\t\t\tif (medValue > minValue && medValue < maxValue)\n\t\t\t\tif (fxy <= minValue || fxy >= maxValue)\n\t\t\t\t\tpScr.at<uchar>(m, n) = medValue;\n\t\t\t\telse\n\t\t\t\t\tpScr.at<uchar>(m, n) = medValue;\n\t\t}\n\t}\n\t\n\treturn pScr;\n}\n\nvoid self_median(Mat image, int size) {\n\n\tMat res = image.clone();\n\tres = guassion(res);\n\tres = self_adapt_median_filter(image, 7);\n\timshow(\"使用自适应中值滤波\", res);\n\t\n}\n```\n\n![image-20240302185829105](digital-image-test04/image-20240302185829105.png)\n\n### 5、彩色图像均值滤波 \n\n具体内容: 利用 OpenCV 对彩色图像 RGB 三个通道的像素进行操作，利用算术均值滤波器和几何均值滤波器进行彩色图像去噪。模板大小为 5*5。\n\n完成程度：分别对彩色图像的三个通道加入高斯噪声，然后再合并三个通道，得到的便是加入有高斯噪声的彩色图像。通过对带有噪声的彩色图像进行通道分离，再分别使用自适应的均值滤波对三个通道进行处理，最终合并以后便是，处理的结果。\n\n```c++\n//5、彩色图像均值滤波\nvoid color_quzao(Mat image, int size) {\n\tvector<Mat>channels;\n\tvector<Mat>channels1;\n\tsplit(image, channels);\n\tchannels1 = channels;\n\n\tfor (int i = 0; i < 3; ++i) {\n\t\tchannels[i] = guassion(channels[i]);\n\t}\n\tMat res;\n\tMat res1;\n\tmerge(channels, res);\n\n\timshow(\"彩色图像加入高斯噪声\", res);\n\tfor (int i = 0; i < 3; ++i) {\n\t\tchannels[i] = self_adapt_mean_filter(channels[i].clone(), 7);\n\n\t\tchannels1[i] = self_adapt_median_filter(channels[i].clone(), 7);\n\t}\n\n\tmerge(channels, res);\n\tmerge(channels1, res1);\n\timshow(\"自适应均值滤波处理彩色图像\", res);\n\timshow(\"自适应中值滤波处理彩色图像\", res1);\n\n}\n```\n\n![image-20240302185837682](digital-image-test04/image-20240302185837682.png)\n\n![image-20240302185841933](digital-image-test04/image-20240302185841933.png)","source":"_posts/digital-image-test04.md","raw":"---\ntitle: 数字图像处理实验-图像去噪\ncategories: 算法实践\ndate: 2022-10-19 18:32:15\ntags: [数字图像, OpenCV]\ncover:\ntop_img:\n---\n### 1、均值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用算术均值滤波器、几何均值滤波器、谐波和逆谐波均值滤波器进行图像去噪。模板大小为5*5。（注：请分别为图像添加高斯噪声、胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果）\n\n完成程度：读入灰度图像，分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是用模板中的像素取平均值后赋值给中心像素，最终得到处理结果。\n\n```c++\n// 1、均值滤波\nMat average_filter(Mat image1, string s) {\n\t// 构建均值滤波模板\n\n\tMat image = image1.clone();\n\tint size = 5;\n\timage.convertTo(image, CV_8U);\n\tMat meta = Mat::ones(size, size, CV_8U);\n\n\tint count_size = size * size;\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tsum_ += image.at<uchar>(i + s, j + t) * meta.at<uchar>(s, t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.at<uchar>(i, j) = sum_ / count_size;\n\t\t}\n\t}\n\n\n\n\timshow(\"均值滤波处理\" + s, res);\n\n\treturn res;\n\n}\nvoid junzhi_quzao(Mat image) {\n\n\timshow(\"原图\", image);\n\n\taverage_filter(guassion(image), \"高斯噪声\");\n\taverage_filter(jiao_salty(image), \"椒盐噪声\");\n\taverage_filter(salty(image), \"盐噪声\");\n\taverage_filter(jiao(image), \"椒噪声\");\n\n}\n```\n\n添加噪声\n\n![image-20240302185557410](digital-image-test04/image-20240302185557410.png)\n\n![image-20240302185602980](digital-image-test04/image-20240302185602980.png)\n\n![image-20240302185608155](digital-image-test04/image-20240302185608155.png)\n\n均值滤波\n\n![image-20240302185735104](digital-image-test04/image-20240302185735104.png)\n\n![image-20240302185739084](digital-image-test04/image-20240302185739084.png)\n\n### 2、中值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用 5*5 和 9*9尺寸的模板对图像进行中值滤波。（注：请分别为图像添加胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果） \n\n完成程度：分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是，将模板内的像素灰度进行排序，取排序后的中间灰度值作为模板中心像素的灰度值，最终得到处理结果。\n\n```c++\n// 2、中值滤波\n// 将窗口中的点按照从小到大的排序，取中间的值作为窗口中心的值\nMat median_filter(Mat image1, int size, string s1) {\n\t// 构建均值滤波模板\n\tMat image = image1.clone();\n\timage.convertTo(image, CV_8U);\n\n\t// 对原始图像进行填充操作\n\timage = fill_zero(image, size);\n\tint row = image.rows;\n\tint col = image.cols;\n\t// 输出图像保存在res中\n\tMat res(row - size + 1, col - size + 1, CV_8U);\n\t// 使用meta模板对图像进行处理\n\tfor (int i = 0; i < row - size + 1; ++i) {\n\n\t\tfor (int j = 0; j < col - size + 1; ++j) {\n\t\t\tvector<int> num;\n\t\t\tint sum_ = 0;\n\t\t\tfor (int s = 0; s < size; ++s) {\n\t\t\t\tfor (int t = 0; t < size; ++t) {\n\t\t\t\t\tint k = image.at<uchar>(i + s, j + t);\n\t\t\t\t\tnum.push_back(k);\n\t\t\t\t}\n\t\t\t}\n\t\t\tsort(num.begin(), num.end());\n\t\t\tres.at<uchar>(i, j) = num[int(num.size() / 2)];\n\t\t}\n\t}\n\timshow(\"中值滤波处理\" + s1, res);\n\n\treturn res;\n\n}\nvoid zhongzhi_quzao(Mat image) {\n\n\timshow(\"原图\", image);\n\n\tmedian_filter(guassion(image), 5, \"高斯噪声\");\n\tmedian_filter(jiao_salty(image), 5, \"椒盐噪声\");\n\tmedian_filter(salty(image), 5, \"盐噪声\");\n\tmedian_filter(jiao(image), 5, \"椒噪声\");\n\n}\n```\n\n![image-20240302185751435](digital-image-test04/image-20240302185751435.png)\n\n![image-20240302185800747](digital-image-test04/image-20240302185800747.png)\n\n### 3、自适应均值滤波\n\n具体内容:利用 OpenCV 对灰度图像像素进行操作，设计自适应局部降低噪声滤波器去噪算法。模板大小 7*7（对比该算法的效果和均值滤波器的效果） \n\n完成程度：自适应的均值滤波，可以通过局部的均值方差，以及噪声的均值方差之间的关系，来自动的调整对噪声处理强的大小，将原始图片的方差作为分子，将局部图片的方差作为分母，用7*7的模板对加入高斯噪声的图像进行了处理。\n\n```c++\n// 3、自适应均值滤波\n// 计算图像全局的方差\ndouble quare_sub(Mat image) {\n\t// 统计不同灰度的概率密度\n\tdouble midu[256] = { 0 };\n\n\tint col = image.cols;\n\tint row = image.rows;\n\n\tfor (int i = 0; i < row; ++i) {\n\t\tfor (int j = 0; j < col; ++j) {\n\t\t\tmidu[image.at<uchar>(i, j)] += 1;\n\t\t}\n\t}\n\n\tint size = col * row;\n\n\t// 计算均值\n\tdouble med = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tmed += i * (midu[i] / size);\n\t}\n\n\t// 计算方差\n\tdouble quare = 0;\n\tfor (int i = 0; i < 256; ++i) {\n\t\tquare += pow((i - med), 2) * (midu[i] / size);\n\t}\n\n\treturn quare;\n}\n\n// 自适应均值滤波\nMat self_adapt_mean_filter(Mat image, int self_adapt_mean_filter_size) {\n\t// 滤波窗口尺寸必须为奇数\n\tMat pScr, dst;\n\t// 1为加载图像的颜色类型,1为原图返回,0为灰度返回\n\tpScr = image.clone();\n\tint row = pScr.rows;\n\tint col = pScr.cols;\n\tblur(pScr, dst, Size(7, 7));\n\tint pos = (self_adapt_mean_filter_size - 1) / 2;\n\tdouble Sn = 100.0;\n\t// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值\n\tfor (int m = pos; m < row - pos; m++) {\n\t\tfor (int n = pos; n < col - pos; n++) {\n\t\t\tint Zxy = int(pScr.at<uchar>(m, n));\n\t\t\tint Zmed = int(dst.at<uchar>(m, n));\n\t\t\tdouble Sl = 0.0;\n\t\t\tint count = 0;\n\t\t\tfor (int i = m - (self_adapt_mean_filter_size - 1) / 2; i <= m + (self_adapt_mean_filter_size - 1) / 2; i++) {\n\t\t\t\tfor (int j = n - (self_adapt_mean_filter_size - 1) / 2; j <= n + (self_adapt_mean_filter_size - 1) / 2; j++) {\n\t\t\t\t\tint Sxy = pScr.at<uchar>(i, j);\n\t\t\t\t\tSl += pow(Sxy - Zmed, 2);\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tSl = Sl / count;\n\t\t\tpScr.at<uchar>(m, n) = (int)(Zxy - Sn / Sl * (Zxy - Zmed));\n\n\t\t}\n\t}\n\treturn pScr;\n}\nvoid self_adapt(Mat image, int size) {\n\tMat res = image.clone();\n\t\n\tres = guassion(res);\n\timshow(\"加入高斯噪声后图片\", res);\n\tres = self_adapt_mean_filter(res, size);\n\timshow(\"使用自适应均值滤波\", res);\n}\n```\n\n![image-20240302185819182](digital-image-test04/image-20240302185819182.png)\n\n### 4、自适应中值滤波\n\n具体内容: 利用 OpenCV 对灰度图像像素进行操作，设计自适应中值滤波算法对椒盐图像进行去噪。模板大小 7*7（对比中值滤波器的效果） \n\n完成程度：自适应的中值滤波和自适应的均值滤波具有相似的原理，与均值滤波不同的便是，中值滤波适应的是模板的大小，而均值滤波适应的是去噪比例大小。\n\n```c++\n//4、自适应中值滤波\n// 自适应中值滤波\nMat self_adapt_median_filter(Mat image, int self_adapt_median_filter_size) {\n\t// 滤波窗口尺寸必须为奇数\n\tMat pScr = image.clone();\n\t// 1为加载图像的颜色类型,1为原图返回,0为灰度返回\n\tint row = pScr.rows;\n\tint col = pScr.cols;\n\tint channel = pScr.channels();\n\t// 滤波器窗口的起始尺寸\n\tint pos = (self_adapt_median_filter_size - 1) / 2;\n\t// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值\n\tfor (int m = pos; m < row - pos; m++) {\n\t\tfor (int n = pos; n < col - pos; n++) {\n\t\t\tint minValue = 255;\n\t\t\tint maxValue = 0;\n\t\t\tint medValue = 0;\n\t\t\tvector<int> filter_value;\n\t\t\tfor (int i = m - (self_adapt_median_filter_size - 1) / 2; i <= m + (self_adapt_median_filter_size - 1) / 2; i++) {\n\t\t\t\tfor (int j = n - (self_adapt_median_filter_size - 1) / 2; j <= n + (self_adapt_median_filter_size - 1) / 2; j++) {\n\t\t\t\t\tfilter_value.push_back(int(pScr.at<uchar>(i, j)));\n\t\t\t\t\tif (int(pScr.at<uchar>(i, j)) > maxValue)\n\t\t\t\t\t\tmaxValue = int(pScr.at<uchar>(i, j));\n\t\t\t\t\tif (int(pScr.at<uchar>(i, j)) < minValue)\n\t\t\t\t\t\tminValue = int(pScr.at<uchar>(i, j));\n\t\t\t\t}\n\t\t\t}\n\t\t\tsort(filter_value.begin(), filter_value.end());\n\t\t\tmedValue = filter_value[int(self_adapt_median_filter_size * self_adapt_median_filter_size / 2)];\n\t\t\tint fxy = int(pScr.at<uchar>(m, n));\n\t\t\tif (medValue > minValue && medValue < maxValue)\n\t\t\t\tif (fxy <= minValue || fxy >= maxValue)\n\t\t\t\t\tpScr.at<uchar>(m, n) = medValue;\n\t\t\t\telse\n\t\t\t\t\tpScr.at<uchar>(m, n) = medValue;\n\t\t}\n\t}\n\t\n\treturn pScr;\n}\n\nvoid self_median(Mat image, int size) {\n\n\tMat res = image.clone();\n\tres = guassion(res);\n\tres = self_adapt_median_filter(image, 7);\n\timshow(\"使用自适应中值滤波\", res);\n\t\n}\n```\n\n![image-20240302185829105](digital-image-test04/image-20240302185829105.png)\n\n### 5、彩色图像均值滤波 \n\n具体内容: 利用 OpenCV 对彩色图像 RGB 三个通道的像素进行操作，利用算术均值滤波器和几何均值滤波器进行彩色图像去噪。模板大小为 5*5。\n\n完成程度：分别对彩色图像的三个通道加入高斯噪声，然后再合并三个通道，得到的便是加入有高斯噪声的彩色图像。通过对带有噪声的彩色图像进行通道分离，再分别使用自适应的均值滤波对三个通道进行处理，最终合并以后便是，处理的结果。\n\n```c++\n//5、彩色图像均值滤波\nvoid color_quzao(Mat image, int size) {\n\tvector<Mat>channels;\n\tvector<Mat>channels1;\n\tsplit(image, channels);\n\tchannels1 = channels;\n\n\tfor (int i = 0; i < 3; ++i) {\n\t\tchannels[i] = guassion(channels[i]);\n\t}\n\tMat res;\n\tMat res1;\n\tmerge(channels, res);\n\n\timshow(\"彩色图像加入高斯噪声\", res);\n\tfor (int i = 0; i < 3; ++i) {\n\t\tchannels[i] = self_adapt_mean_filter(channels[i].clone(), 7);\n\n\t\tchannels1[i] = self_adapt_median_filter(channels[i].clone(), 7);\n\t}\n\n\tmerge(channels, res);\n\tmerge(channels1, res1);\n\timshow(\"自适应均值滤波处理彩色图像\", res);\n\timshow(\"自适应中值滤波处理彩色图像\", res1);\n\n}\n```\n\n![image-20240302185837682](digital-image-test04/image-20240302185837682.png)\n\n![image-20240302185841933](digital-image-test04/image-20240302185841933.png)","slug":"digital-image-test04","published":1,"updated":"2024-06-05T09:03:03.731Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttu002808jv4g1bgyej","content":"<h3 id=\"1、均值滤波\"><a href=\"#1、均值滤波\" class=\"headerlink\" title=\"1、均值滤波\"></a>1、均值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用算术均值滤波器、几何均值滤波器、谐波和逆谐波均值滤波器进行图像去噪。模板大小为5*5。（注：请分别为图像添加高斯噪声、胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果）</p>\n<p>完成程度：读入灰度图像，分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是用模板中的像素取平均值后赋值给中心像素，最终得到处理结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 1、均值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_filter</span><span class=\"hljs-params\">(Mat image1, string s)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br><br>\tMat image = image1.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-type\">int</span> size = <span class=\"hljs-number\">5</span>;<br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br>\tMat meta = Mat::<span class=\"hljs-built_in\">ones</span>(size, size, CV_8U);<br><br>\t<span class=\"hljs-type\">int</span> count_size = size * size;<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br><br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_ += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * meta.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(s, t);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = sum_ / count_size;<br>\t\t&#125;<br>\t&#125;<br><br><br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;均值滤波处理&quot;</span> + s, res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">junzhi_quzao</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image);<br><br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">guassion</span>(image), <span class=\"hljs-string\">&quot;高斯噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">jiao_salty</span>(image), <span class=\"hljs-string\">&quot;椒盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">salty</span>(image), <span class=\"hljs-string\">&quot;盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">jiao</span>(image), <span class=\"hljs-string\">&quot;椒噪声&quot;</span>);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>添加噪声</p>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185557410.png\" class=\"\" title=\"image-20240302185557410\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185602980.png\" class=\"\" title=\"image-20240302185602980\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185608155.png\" class=\"\" title=\"image-20240302185608155\">\n<p>均值滤波</p>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185735104.png\" class=\"\" title=\"image-20240302185735104\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185739084.png\" class=\"\" title=\"image-20240302185739084\">\n<h3 id=\"2、中值滤波\"><a href=\"#2、中值滤波\" class=\"headerlink\" title=\"2、中值滤波\"></a>2、中值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用 5<em>5 和 9</em>9尺寸的模板对图像进行中值滤波。（注：请分别为图像添加胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果） </p>\n<p>完成程度：分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是，将模板内的像素灰度进行排序，取排序后的中间灰度值作为模板中心像素的灰度值，最终得到处理结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 2、中值滤波</span><br><span class=\"hljs-comment\">// 将窗口中的点按照从小到大的排序，取中间的值作为窗口中心的值</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">median_filter</span><span class=\"hljs-params\">(Mat image1, <span class=\"hljs-type\">int</span> size, string s1)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br>\tMat image = image1.<span class=\"hljs-built_in\">clone</span>();<br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\tvector&lt;<span class=\"hljs-type\">int</span>&gt; num;<br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\t<span class=\"hljs-type\">int</span> k = image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t);<br>\t\t\t\t\tnum.<span class=\"hljs-built_in\">push_back</span>(k);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-built_in\">sort</span>(num.<span class=\"hljs-built_in\">begin</span>(), num.<span class=\"hljs-built_in\">end</span>());<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = num[<span class=\"hljs-built_in\">int</span>(num.<span class=\"hljs-built_in\">size</span>() / <span class=\"hljs-number\">2</span>)];<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;中值滤波处理&quot;</span> + s1, res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zhongzhi_quzao</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image);<br><br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">guassion</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;高斯噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">jiao_salty</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;椒盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">salty</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">jiao</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;椒噪声&quot;</span>);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185751435.png\" class=\"\" title=\"image-20240302185751435\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185800747.png\" class=\"\" title=\"image-20240302185800747\">\n<h3 id=\"3、自适应均值滤波\"><a href=\"#3、自适应均值滤波\" class=\"headerlink\" title=\"3、自适应均值滤波\"></a>3、自适应均值滤波</h3><p>具体内容:利用 OpenCV 对灰度图像像素进行操作，设计自适应局部降低噪声滤波器去噪算法。模板大小 7*7（对比该算法的效果和均值滤波器的效果） </p>\n<p>完成程度：自适应的均值滤波，可以通过局部的均值方差，以及噪声的均值方差之间的关系，来自动的调整对噪声处理强的大小，将原始图片的方差作为分子，将局部图片的方差作为分母，用7*7的模板对加入高斯噪声的图像进行了处理。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、自适应均值滤波</span><br><span class=\"hljs-comment\">// 计算图像全局的方差</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">quare_sub</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 统计不同灰度的概率密度</span><br>\t<span class=\"hljs-type\">double</span> midu[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; ++j) &#123;<br>\t\t\tmidu[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] += <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-type\">int</span> size = col * row;<br><br>\t<span class=\"hljs-comment\">// 计算均值</span><br>\t<span class=\"hljs-type\">double</span> med = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tmed += i * (midu[i] / size);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 计算方差</span><br>\t<span class=\"hljs-type\">double</span> quare = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tquare += <span class=\"hljs-built_in\">pow</span>((i - med), <span class=\"hljs-number\">2</span>) * (midu[i] / size);<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">return</span> quare;<br>&#125;<br><br><span class=\"hljs-comment\">// 自适应均值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">self_adapt_mean_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> self_adapt_mean_filter_size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 滤波窗口尺寸必须为奇数</span><br>\tMat pScr, dst;<br>\t<span class=\"hljs-comment\">// 1为加载图像的颜色类型,1为原图返回,0为灰度返回</span><br>\tpScr = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-type\">int</span> row = pScr.rows;<br>\t<span class=\"hljs-type\">int</span> col = pScr.cols;<br>\t<span class=\"hljs-built_in\">blur</span>(pScr, dst, <span class=\"hljs-built_in\">Size</span>(<span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">7</span>));<br>\t<span class=\"hljs-type\">int</span> pos = (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-type\">double</span> Sn = <span class=\"hljs-number\">100.0</span>;<br>\t<span class=\"hljs-comment\">// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> m = pos; m &lt; row - pos; m++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> n = pos; n &lt; col - pos; n++) &#123;<br>\t\t\t<span class=\"hljs-type\">int</span> Zxy = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-type\">int</span> Zmed = <span class=\"hljs-built_in\">int</span>(dst.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-type\">double</span> Sl = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = m - (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i &lt;= m + (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i++) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = n - (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j &lt;= n + (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j++) &#123;<br>\t\t\t\t\t<span class=\"hljs-type\">int</span> Sxy = pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j);<br>\t\t\t\t\tSl += <span class=\"hljs-built_in\">pow</span>(Sxy - Zmed, <span class=\"hljs-number\">2</span>);<br>\t\t\t\t\tcount++;<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tSl = Sl / count;<br>\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = (<span class=\"hljs-type\">int</span>)(Zxy - Sn / Sl * (Zxy - Zmed));<br><br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> pScr;<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">self_adapt</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\tMat res = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<br>\tres = <span class=\"hljs-built_in\">guassion</span>(res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;加入高斯噪声后图片&quot;</span>, res);<br>\tres = <span class=\"hljs-built_in\">self_adapt_mean_filter</span>(res, size);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;使用自适应均值滤波&quot;</span>, res);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185819182.png\" class=\"\" title=\"image-20240302185819182\">\n<h3 id=\"4、自适应中值滤波\"><a href=\"#4、自适应中值滤波\" class=\"headerlink\" title=\"4、自适应中值滤波\"></a>4、自适应中值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，设计自适应中值滤波算法对椒盐图像进行去噪。模板大小 7*7（对比中值滤波器的效果） </p>\n<p>完成程度：自适应的中值滤波和自适应的均值滤波具有相似的原理，与均值滤波不同的便是，中值滤波适应的是模板的大小，而均值滤波适应的是去噪比例大小。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">//4、自适应中值滤波</span><br><span class=\"hljs-comment\">// 自适应中值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">self_adapt_median_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> self_adapt_median_filter_size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 滤波窗口尺寸必须为奇数</span><br>\tMat pScr = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-comment\">// 1为加载图像的颜色类型,1为原图返回,0为灰度返回</span><br>\t<span class=\"hljs-type\">int</span> row = pScr.rows;<br>\t<span class=\"hljs-type\">int</span> col = pScr.cols;<br>\t<span class=\"hljs-type\">int</span> channel = pScr.<span class=\"hljs-built_in\">channels</span>();<br>\t<span class=\"hljs-comment\">// 滤波器窗口的起始尺寸</span><br>\t<span class=\"hljs-type\">int</span> pos = (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-comment\">// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> m = pos; m &lt; row - pos; m++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> n = pos; n &lt; col - pos; n++) &#123;<br>\t\t\t<span class=\"hljs-type\">int</span> minValue = <span class=\"hljs-number\">255</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> maxValue = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> medValue = <span class=\"hljs-number\">0</span>;<br>\t\t\tvector&lt;<span class=\"hljs-type\">int</span>&gt; filter_value;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = m - (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i &lt;= m + (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i++) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = n - (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j &lt;= n + (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j++) &#123;<br>\t\t\t\t\tfilter_value.<span class=\"hljs-built_in\">push_back</span>(<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)));<br>\t\t\t\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)) &gt; maxValue)<br>\t\t\t\t\t\tmaxValue = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j));<br>\t\t\t\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)) &lt; minValue)<br>\t\t\t\t\t\tminValue = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j));<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-built_in\">sort</span>(filter_value.<span class=\"hljs-built_in\">begin</span>(), filter_value.<span class=\"hljs-built_in\">end</span>());<br>\t\t\tmedValue = filter_value[<span class=\"hljs-built_in\">int</span>(self_adapt_median_filter_size * self_adapt_median_filter_size / <span class=\"hljs-number\">2</span>)];<br>\t\t\t<span class=\"hljs-type\">int</span> fxy = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-keyword\">if</span> (medValue &gt; minValue &amp;&amp; medValue &lt; maxValue)<br>\t\t\t\t<span class=\"hljs-keyword\">if</span> (fxy &lt;= minValue || fxy &gt;= maxValue)<br>\t\t\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = medValue;<br>\t\t\t\t<span class=\"hljs-keyword\">else</span><br>\t\t\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = medValue;<br>\t\t&#125;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-keyword\">return</span> pScr;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">self_median</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\tMat res = image.<span class=\"hljs-built_in\">clone</span>();<br>\tres = <span class=\"hljs-built_in\">guassion</span>(res);<br>\tres = <span class=\"hljs-built_in\">self_adapt_median_filter</span>(image, <span class=\"hljs-number\">7</span>);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;使用自适应中值滤波&quot;</span>, res);<br>\t<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185829105.png\" class=\"\" title=\"image-20240302185829105\">\n<h3 id=\"5、彩色图像均值滤波\"><a href=\"#5、彩色图像均值滤波\" class=\"headerlink\" title=\"5、彩色图像均值滤波\"></a>5、彩色图像均值滤波</h3><p>具体内容: 利用 OpenCV 对彩色图像 RGB 三个通道的像素进行操作，利用算术均值滤波器和几何均值滤波器进行彩色图像去噪。模板大小为 5*5。</p>\n<p>完成程度：分别对彩色图像的三个通道加入高斯噪声，然后再合并三个通道，得到的便是加入有高斯噪声的彩色图像。通过对带有噪声的彩色图像进行通道分离，再分别使用自适应的均值滤波对三个通道进行处理，最终合并以后便是，处理的结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">//5、彩色图像均值滤波</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">color_quzao</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\tvector&lt;Mat&gt;channels;<br>\tvector&lt;Mat&gt;channels1;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tchannels1 = channels;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">guassion</span>(channels[i]);<br>\t&#125;<br>\tMat res;<br>\tMat res1;<br>\t<span class=\"hljs-built_in\">merge</span>(channels, res);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩色图像加入高斯噪声&quot;</span>, res);<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">self_adapt_mean_filter</span>(channels[i].<span class=\"hljs-built_in\">clone</span>(), <span class=\"hljs-number\">7</span>);<br><br>\t\tchannels1[i] = <span class=\"hljs-built_in\">self_adapt_median_filter</span>(channels[i].<span class=\"hljs-built_in\">clone</span>(), <span class=\"hljs-number\">7</span>);<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">merge</span>(channels, res);<br>\t<span class=\"hljs-built_in\">merge</span>(channels1, res1);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;自适应均值滤波处理彩色图像&quot;</span>, res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;自适应中值滤波处理彩色图像&quot;</span>, res1);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185837682.png\" class=\"\" title=\"image-20240302185837682\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185841933.png\" class=\"\" title=\"image-20240302185841933\">","cover_type":"img","excerpt":"","more":"<h3 id=\"1、均值滤波\"><a href=\"#1、均值滤波\" class=\"headerlink\" title=\"1、均值滤波\"></a>1、均值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用算术均值滤波器、几何均值滤波器、谐波和逆谐波均值滤波器进行图像去噪。模板大小为5*5。（注：请分别为图像添加高斯噪声、胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果）</p>\n<p>完成程度：读入灰度图像，分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是用模板中的像素取平均值后赋值给中心像素，最终得到处理结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 1、均值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">average_filter</span><span class=\"hljs-params\">(Mat image1, string s)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br><br>\tMat image = image1.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-type\">int</span> size = <span class=\"hljs-number\">5</span>;<br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br>\tMat meta = Mat::<span class=\"hljs-built_in\">ones</span>(size, size, CV_8U);<br><br>\t<span class=\"hljs-type\">int</span> count_size = size * size;<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br><br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\tsum_ += image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t) * meta.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(s, t);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = sum_ / count_size;<br>\t\t&#125;<br>\t&#125;<br><br><br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;均值滤波处理&quot;</span> + s, res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">junzhi_quzao</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image);<br><br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">guassion</span>(image), <span class=\"hljs-string\">&quot;高斯噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">jiao_salty</span>(image), <span class=\"hljs-string\">&quot;椒盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">salty</span>(image), <span class=\"hljs-string\">&quot;盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">average_filter</span>(<span class=\"hljs-built_in\">jiao</span>(image), <span class=\"hljs-string\">&quot;椒噪声&quot;</span>);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<p>添加噪声</p>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185557410.png\" class=\"\" title=\"image-20240302185557410\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185602980.png\" class=\"\" title=\"image-20240302185602980\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185608155.png\" class=\"\" title=\"image-20240302185608155\">\n<p>均值滤波</p>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185735104.png\" class=\"\" title=\"image-20240302185735104\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185739084.png\" class=\"\" title=\"image-20240302185739084\">\n<h3 id=\"2、中值滤波\"><a href=\"#2、中值滤波\" class=\"headerlink\" title=\"2、中值滤波\"></a>2、中值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，分别利用 5<em>5 和 9</em>9尺寸的模板对图像进行中值滤波。（注：请分别为图像添加胡椒噪声、盐噪声和椒盐噪声，并观察滤波效果） </p>\n<p>完成程度：分别为图像加入椒噪声、盐噪声、椒盐噪声以及高斯噪声，并使用5*5的模板分别对不同的噪声图像进行处理，处理的过程是，将模板内的像素灰度进行排序，取排序后的中间灰度值作为模板中心像素的灰度值，最终得到处理结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 2、中值滤波</span><br><span class=\"hljs-comment\">// 将窗口中的点按照从小到大的排序，取中间的值作为窗口中心的值</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">median_filter</span><span class=\"hljs-params\">(Mat image1, <span class=\"hljs-type\">int</span> size, string s1)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 构建均值滤波模板</span><br>\tMat image = image1.<span class=\"hljs-built_in\">clone</span>();<br>\timage.<span class=\"hljs-built_in\">convertTo</span>(image, CV_8U);<br><br>\t<span class=\"hljs-comment\">// 对原始图像进行填充操作</span><br>\timage = <span class=\"hljs-built_in\">fill_zero</span>(image, size);<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-comment\">// 输出图像保存在res中</span><br>\t<span class=\"hljs-function\">Mat <span class=\"hljs-title\">res</span><span class=\"hljs-params\">(row - size + <span class=\"hljs-number\">1</span>, col - size + <span class=\"hljs-number\">1</span>, CV_8U)</span></span>;<br>\t<span class=\"hljs-comment\">// 使用meta模板对图像进行处理</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row - size + <span class=\"hljs-number\">1</span>; ++i) &#123;<br><br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col - size + <span class=\"hljs-number\">1</span>; ++j) &#123;<br>\t\t\tvector&lt;<span class=\"hljs-type\">int</span>&gt; num;<br>\t\t\t<span class=\"hljs-type\">int</span> sum_ = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> s = <span class=\"hljs-number\">0</span>; s &lt; size; ++s) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> t = <span class=\"hljs-number\">0</span>; t &lt; size; ++t) &#123;<br>\t\t\t\t\t<span class=\"hljs-type\">int</span> k = image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i + s, j + t);<br>\t\t\t\t\tnum.<span class=\"hljs-built_in\">push_back</span>(k);<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-built_in\">sort</span>(num.<span class=\"hljs-built_in\">begin</span>(), num.<span class=\"hljs-built_in\">end</span>());<br>\t\t\tres.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j) = num[<span class=\"hljs-built_in\">int</span>(num.<span class=\"hljs-built_in\">size</span>() / <span class=\"hljs-number\">2</span>)];<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;中值滤波处理&quot;</span> + s1, res);<br><br>\t<span class=\"hljs-keyword\">return</span> res;<br><br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">zhongzhi_quzao</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;原图&quot;</span>, image);<br><br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">guassion</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;高斯噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">jiao_salty</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;椒盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">salty</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;盐噪声&quot;</span>);<br>\t<span class=\"hljs-built_in\">median_filter</span>(<span class=\"hljs-built_in\">jiao</span>(image), <span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">&quot;椒噪声&quot;</span>);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185751435.png\" class=\"\" title=\"image-20240302185751435\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185800747.png\" class=\"\" title=\"image-20240302185800747\">\n<h3 id=\"3、自适应均值滤波\"><a href=\"#3、自适应均值滤波\" class=\"headerlink\" title=\"3、自适应均值滤波\"></a>3、自适应均值滤波</h3><p>具体内容:利用 OpenCV 对灰度图像像素进行操作，设计自适应局部降低噪声滤波器去噪算法。模板大小 7*7（对比该算法的效果和均值滤波器的效果） </p>\n<p>完成程度：自适应的均值滤波，可以通过局部的均值方差，以及噪声的均值方差之间的关系，来自动的调整对噪声处理强的大小，将原始图片的方差作为分子，将局部图片的方差作为分母，用7*7的模板对加入高斯噪声的图像进行了处理。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 3、自适应均值滤波</span><br><span class=\"hljs-comment\">// 计算图像全局的方差</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">quare_sub</span><span class=\"hljs-params\">(Mat image)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 统计不同灰度的概率密度</span><br>\t<span class=\"hljs-type\">double</span> midu[<span class=\"hljs-number\">256</span>] = &#123; <span class=\"hljs-number\">0</span> &#125;;<br><br>\t<span class=\"hljs-type\">int</span> col = image.cols;<br>\t<span class=\"hljs-type\">int</span> row = image.rows;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; row; ++i) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; col; ++j) &#123;<br>\t\t\tmidu[image.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)] += <span class=\"hljs-number\">1</span>;<br>\t\t&#125;<br>\t&#125;<br><br>\t<span class=\"hljs-type\">int</span> size = col * row;<br><br>\t<span class=\"hljs-comment\">// 计算均值</span><br>\t<span class=\"hljs-type\">double</span> med = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tmed += i * (midu[i] / size);<br>\t&#125;<br><br>\t<span class=\"hljs-comment\">// 计算方差</span><br>\t<span class=\"hljs-type\">double</span> quare = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">256</span>; ++i) &#123;<br>\t\tquare += <span class=\"hljs-built_in\">pow</span>((i - med), <span class=\"hljs-number\">2</span>) * (midu[i] / size);<br>\t&#125;<br><br>\t<span class=\"hljs-keyword\">return</span> quare;<br>&#125;<br><br><span class=\"hljs-comment\">// 自适应均值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">self_adapt_mean_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> self_adapt_mean_filter_size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 滤波窗口尺寸必须为奇数</span><br>\tMat pScr, dst;<br>\t<span class=\"hljs-comment\">// 1为加载图像的颜色类型,1为原图返回,0为灰度返回</span><br>\tpScr = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-type\">int</span> row = pScr.rows;<br>\t<span class=\"hljs-type\">int</span> col = pScr.cols;<br>\t<span class=\"hljs-built_in\">blur</span>(pScr, dst, <span class=\"hljs-built_in\">Size</span>(<span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">7</span>));<br>\t<span class=\"hljs-type\">int</span> pos = (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-type\">double</span> Sn = <span class=\"hljs-number\">100.0</span>;<br>\t<span class=\"hljs-comment\">// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> m = pos; m &lt; row - pos; m++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> n = pos; n &lt; col - pos; n++) &#123;<br>\t\t\t<span class=\"hljs-type\">int</span> Zxy = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-type\">int</span> Zmed = <span class=\"hljs-built_in\">int</span>(dst.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-type\">double</span> Sl = <span class=\"hljs-number\">0.0</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = m - (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i &lt;= m + (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i++) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = n - (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j &lt;= n + (self_adapt_mean_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j++) &#123;<br>\t\t\t\t\t<span class=\"hljs-type\">int</span> Sxy = pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j);<br>\t\t\t\t\tSl += <span class=\"hljs-built_in\">pow</span>(Sxy - Zmed, <span class=\"hljs-number\">2</span>);<br>\t\t\t\t\tcount++;<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\tSl = Sl / count;<br>\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = (<span class=\"hljs-type\">int</span>)(Zxy - Sn / Sl * (Zxy - Zmed));<br><br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> pScr;<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">self_adapt</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\tMat res = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<br>\tres = <span class=\"hljs-built_in\">guassion</span>(res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;加入高斯噪声后图片&quot;</span>, res);<br>\tres = <span class=\"hljs-built_in\">self_adapt_mean_filter</span>(res, size);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;使用自适应均值滤波&quot;</span>, res);<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185819182.png\" class=\"\" title=\"image-20240302185819182\">\n<h3 id=\"4、自适应中值滤波\"><a href=\"#4、自适应中值滤波\" class=\"headerlink\" title=\"4、自适应中值滤波\"></a>4、自适应中值滤波</h3><p>具体内容: 利用 OpenCV 对灰度图像像素进行操作，设计自适应中值滤波算法对椒盐图像进行去噪。模板大小 7*7（对比中值滤波器的效果） </p>\n<p>完成程度：自适应的中值滤波和自适应的均值滤波具有相似的原理，与均值滤波不同的便是，中值滤波适应的是模板的大小，而均值滤波适应的是去噪比例大小。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">//4、自适应中值滤波</span><br><span class=\"hljs-comment\">// 自适应中值滤波</span><br><span class=\"hljs-function\">Mat <span class=\"hljs-title\">self_adapt_median_filter</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> self_adapt_median_filter_size)</span> </span>&#123;<br>\t<span class=\"hljs-comment\">// 滤波窗口尺寸必须为奇数</span><br>\tMat pScr = image.<span class=\"hljs-built_in\">clone</span>();<br>\t<span class=\"hljs-comment\">// 1为加载图像的颜色类型,1为原图返回,0为灰度返回</span><br>\t<span class=\"hljs-type\">int</span> row = pScr.rows;<br>\t<span class=\"hljs-type\">int</span> col = pScr.cols;<br>\t<span class=\"hljs-type\">int</span> channel = pScr.<span class=\"hljs-built_in\">channels</span>();<br>\t<span class=\"hljs-comment\">// 滤波器窗口的起始尺寸</span><br>\t<span class=\"hljs-type\">int</span> pos = (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>;<br>\t<span class=\"hljs-comment\">// 每个滤波窗口中心位置都计算滤波窗口内通道值的平均值</span><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> m = pos; m &lt; row - pos; m++) &#123;<br>\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> n = pos; n &lt; col - pos; n++) &#123;<br>\t\t\t<span class=\"hljs-type\">int</span> minValue = <span class=\"hljs-number\">255</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> maxValue = <span class=\"hljs-number\">0</span>;<br>\t\t\t<span class=\"hljs-type\">int</span> medValue = <span class=\"hljs-number\">0</span>;<br>\t\t\tvector&lt;<span class=\"hljs-type\">int</span>&gt; filter_value;<br>\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = m - (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i &lt;= m + (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; i++) &#123;<br>\t\t\t\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = n - (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j &lt;= n + (self_adapt_median_filter_size - <span class=\"hljs-number\">1</span>) / <span class=\"hljs-number\">2</span>; j++) &#123;<br>\t\t\t\t\tfilter_value.<span class=\"hljs-built_in\">push_back</span>(<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)));<br>\t\t\t\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)) &gt; maxValue)<br>\t\t\t\t\t\tmaxValue = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j));<br>\t\t\t\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j)) &lt; minValue)<br>\t\t\t\t\t\tminValue = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(i, j));<br>\t\t\t\t&#125;<br>\t\t\t&#125;<br>\t\t\t<span class=\"hljs-built_in\">sort</span>(filter_value.<span class=\"hljs-built_in\">begin</span>(), filter_value.<span class=\"hljs-built_in\">end</span>());<br>\t\t\tmedValue = filter_value[<span class=\"hljs-built_in\">int</span>(self_adapt_median_filter_size * self_adapt_median_filter_size / <span class=\"hljs-number\">2</span>)];<br>\t\t\t<span class=\"hljs-type\">int</span> fxy = <span class=\"hljs-built_in\">int</span>(pScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n));<br>\t\t\t<span class=\"hljs-keyword\">if</span> (medValue &gt; minValue &amp;&amp; medValue &lt; maxValue)<br>\t\t\t\t<span class=\"hljs-keyword\">if</span> (fxy &lt;= minValue || fxy &gt;= maxValue)<br>\t\t\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = medValue;<br>\t\t\t\t<span class=\"hljs-keyword\">else</span><br>\t\t\t\t\tpScr.<span class=\"hljs-built_in\">at</span>&lt;uchar&gt;(m, n) = medValue;<br>\t\t&#125;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-keyword\">return</span> pScr;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">self_median</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br><br>\tMat res = image.<span class=\"hljs-built_in\">clone</span>();<br>\tres = <span class=\"hljs-built_in\">guassion</span>(res);<br>\tres = <span class=\"hljs-built_in\">self_adapt_median_filter</span>(image, <span class=\"hljs-number\">7</span>);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;使用自适应中值滤波&quot;</span>, res);<br>\t<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185829105.png\" class=\"\" title=\"image-20240302185829105\">\n<h3 id=\"5、彩色图像均值滤波\"><a href=\"#5、彩色图像均值滤波\" class=\"headerlink\" title=\"5、彩色图像均值滤波\"></a>5、彩色图像均值滤波</h3><p>具体内容: 利用 OpenCV 对彩色图像 RGB 三个通道的像素进行操作，利用算术均值滤波器和几何均值滤波器进行彩色图像去噪。模板大小为 5*5。</p>\n<p>完成程度：分别对彩色图像的三个通道加入高斯噪声，然后再合并三个通道，得到的便是加入有高斯噪声的彩色图像。通过对带有噪声的彩色图像进行通道分离，再分别使用自适应的均值滤波对三个通道进行处理，最终合并以后便是，处理的结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">//5、彩色图像均值滤波</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">color_quzao</span><span class=\"hljs-params\">(Mat image, <span class=\"hljs-type\">int</span> size)</span> </span>&#123;<br>\tvector&lt;Mat&gt;channels;<br>\tvector&lt;Mat&gt;channels1;<br>\t<span class=\"hljs-built_in\">split</span>(image, channels);<br>\tchannels1 = channels;<br><br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">guassion</span>(channels[i]);<br>\t&#125;<br>\tMat res;<br>\tMat res1;<br>\t<span class=\"hljs-built_in\">merge</span>(channels, res);<br><br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;彩色图像加入高斯噪声&quot;</span>, res);<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i) &#123;<br>\t\tchannels[i] = <span class=\"hljs-built_in\">self_adapt_mean_filter</span>(channels[i].<span class=\"hljs-built_in\">clone</span>(), <span class=\"hljs-number\">7</span>);<br><br>\t\tchannels1[i] = <span class=\"hljs-built_in\">self_adapt_median_filter</span>(channels[i].<span class=\"hljs-built_in\">clone</span>(), <span class=\"hljs-number\">7</span>);<br>\t&#125;<br><br>\t<span class=\"hljs-built_in\">merge</span>(channels, res);<br>\t<span class=\"hljs-built_in\">merge</span>(channels1, res1);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;自适应均值滤波处理彩色图像&quot;</span>, res);<br>\t<span class=\"hljs-built_in\">imshow</span>(<span class=\"hljs-string\">&quot;自适应中值滤波处理彩色图像&quot;</span>, res1);<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185837682.png\" class=\"\" title=\"image-20240302185837682\">\n<img src=\"/2022/10/19/digital-image-test04/image-20240302185841933.png\" class=\"\" title=\"image-20240302185841933\">"},{"title":"分布式系统学习笔记","date":"2023-03-02T08:59:29.000Z","cover":"/img/default_cover02.jpg","top_img":null,"_content":"## 概述\n\n### 分布式系统的定义\n\n> 分布式系统是若干独立计算机的集合，这些计算机对于用户来说，像是单个相关系统\n\n* 重要特性\n  * 各种计算机之间的差别以及计算机之间的通信方式的差别对用户是隐藏的\n  * 用户看不到分布式系统的内部组织结构\n  * 用户和应用程序无论在何时何地都能够以一种一致和同意的方式与分布式系统进行交互\n  * 分布式系统的拓展或者升级应该时相对比较容易的\n\n### 分布式系统的目标\n\n* 使资源可访问（资源共享）\n* 透明性\n\n![image-20221126155708747](distributed-system/image-20221126155708747.png)\n\n![image-20221126155754925](distributed-system/image-20221126155754925.png)\n\n* 开放性（openess）\n\n  > 根据一系列准则来提供服务，这些准则描述了所提供服务的语义和语法。\n  >\n  > 在分布式系统中，服务通常时通过接口指定的，接口时通过接口定义语言来描述的。\n  >\n  > 开放的分布式系统应该时可扩展的。\n\n  * 完整性：完成接口实现不可少的内容都已经规定好了\n  * 中立性：开发人员能够添加针对特定实现的细节\n  * 互操作性：来自不同厂商的系统或组件的两种实现能够在何种程度上共存并且协同工作\n  * 可移植性：如果分布式系统A开发了某个应用，并且另一个分布式系统B与A具有相同的接口，该程序在不做修改在B上执行的可行程度\n\n* 可扩展性（scale in distributed system）scalablity\n\n  > 可扩展性通常可以从三个方面来度量，规模上可扩展（size）、地域上可扩展（geographical）、管理上可扩展（administrative）\n\n  * 规模上可拓展存在的问题\n\n    * 受集中式的服务、数据以及算法限制\n    * 集中式算法与分布式算法的对比\n\n    ```\n    分布式算法不同特性\n    1、没有任何计算机拥有关于系统状态的完整信息\n    2、计算机只根据本地信息做出决策\n    3、某台计算机的故障不会使算法奔溃\n    4、没有全局性时钟，来统一设定时间\n    ```\n\n  * 地域上可扩展存在的问题\n\n    * 基于同步的通信，在请求服务的一方得到回应之前都是处于阻塞状态，在局域网中速度快，广域网中很慢\n    * 广域网中的通信是不可靠的，都是点对点的\n    * 如何对一个跨越多个独立管理域的分布式系统进行拓展\n\n  * 管理上可扩展存在的问题\n\n    * 资源使用（以及付费）、管理和安全问题上，不同的管理域之间有着相互冲突的问题\n\n  * 拓展技术\n\n    > 拓展技术基本上只有三种技术：隐藏通信等待时间、分布技术以及复制技术\n\n    * 隐藏通信等待时间：尽量避免远程服务对请求的响应，实质上是异步通信。也可以将服务器上的部分任务交由客户端完成。\n    * 分布技术： 把某个组件分割成多个部分，再将他们分散到系统中，如DNS。\n    * 复制技术：会产生一致性问题。\n\n### 分布式系统的类型\n\n> 分布式计算系统、分布式信息系统、分布式嵌入系统\n\n* 分布式计算系统（高性能的分布式系统）\n\n  * 集群计算系统\n\n    > 同构性：集群中的计算机大多数是相同的。相同的操作系统，同一网络。\n\n    * 单个主节点，多个从节点，主节点可访问控制群（从节点）\n    * 主节点：负责对特定并行程序的结点定位，维护已经提交的工作队列，为系统用户提供接口\n\n    ![image-20221130091729650](distributed-system/image-20221130091729650.png)\n\n  * 网格计算系统\n\n    > 具有高度的异构性：硬件，操作系统，网络，管理域和安全策略都不尽相同\n\n    * 解决异构性的方式：虚拟组织\n    * 光纤层：在特定站点提供对局部资源的接口\n    * 连接层：由通信协议组成，用于支持网格事务处理\n    * 资源层：负责管理单个资源\n    * 汇集层：负责处理对多个资源的访问\n    * 应用层：由应用程序组成，在虚拟组织中运行\n\n    ![image-20221130092344725](distributed-system/image-20221130092344725.png)\n\n* 分布式信息系统\n\n* 分布式普适系统\n\n\n\n## 体系结构\n\n### 体系结构的样式\n\n> 体系结构样式是根据组件，组件之间互相连接方式、组件之间的数据交换以及这些元素如何集成到一个系统中来定义的。\n\n* 分层体系结构\n\n* 基于对象的体系结构\n\n  * 每个对象对应一个组件，组件通过远程过程调用机制来连接\n\n  ![image-20221130094553260](distributed-system/image-20221130094553260.png)\n\n* 以数据为中心的体系结构\n\n  * 进程通信需要通过一个公用仓库\n\n* 基于事件的体系结构\n\n  * 进程发布事件，中间件确保订阅了这些事件的进程接收它们。去耦合强。\n\n  ![image-20221130101949954](distributed-system/image-20221130101949954.png)\n\n### 系统体系结构\n\n* 集中式体系结构（客户—服务器）\n\n  * 应用分层\n\n    * 应用层：提供与用户交互的接口\n    * 处理层：处理用户的请求，实现与数据的交互\n    * 数据层：存储数据，如，文件系统，数据库\n\n  * 多层体系结构\n\n    * 两层体系结构：客户机和服务器\n      * 根据将客户机和服务器实现的不同功能可以分为以下5种，d和e较为普遍\n\n    ![image-20221130101048848](distributed-system/image-20221130101048848.png)\n\n    * 三层体系结构：用户接口、应用程序服务器、数据库服务器\n\n      ![image-20221130102217372](distributed-system/image-20221130102217372.png)\n\n* 非集中式体系结构（回头听一听课）点对点\n\n  垂直分布性（分层）：按逻辑把不同组件放在不同机器上\n\n  水平分布性：客户和服务器可能在物理上被分割成逻辑上相等的几个部分，但每个部分都操作在整个数据集中自己共享的部分，从而实现负载均衡。例如点对点系统\n\n  * 结构化的点对点体系结构\n\n    * Chord系统分布式哈希表（后面章节）理解加入和退出\n\n    ![image-20221130140722941](distributed-system/image-20221130140722941.png)\n\n    * CAN：上下文可编制网络（后面章节）\n\n  * 非结构化点对点体系结构\n\n    > 主要依靠随机化算法来构造覆盖网络，每个节点维护一个邻接点列表，列表由随机的方法来构造。使用泛洪法来查找。\n\n  * 覆盖网络的拓扑管理\n\n  * 超级对等体\n\n* 混合体系结构\n\n  > 特殊的分布式系统，将客户服务器体系结构和非集中式体系结构组合在一起\n\n  * 边界服务器系统\n\n  * 协作分布式系统\n\n    * 文件共享系统\n\n      > 是一种点对点的文件下载系统，一个用户从其他用户下载文件块，知道所下载的文件块能够组装成完整的文件。一旦结点确定了从哪里可以下载文件块，下载结点将被强制为其他节点提供帮助。瓶颈期在于跟踪器。\n\n    ![image-20221130143607842](distributed-system/image-20221130143607842.png)\n\n    * 协作内容分布式网络Globule\n\n### 体系结构与中间件\n\n> 中间件具有一定程度的透明性，一定程度上向应用程序隐藏了数据处理和控制的分布性\n\n* 中断器\n\n  > 是一种软件结构，能中断正常的控制流，从而允许其他代码运行。\n\n  * 请求级中断器：为每个副本调用invoke函数\n  * 消息级中断器：协助把消息传递接口激活转移给目标对象\n\n* 自适应软件常见方法（基本技术）\n\n  * 要点分离\n  * 计算映像：程序检查自己\n  * 基于组件的设计：通过组件的不同组合来支持自适应\n\n### 分布式系统的自我管理\n\n> 以高级反馈控制系统的形式来组织分布式系统，允许自动自适应变化。称为自治计算或自主系统。\n\n自适应的多样性：自我管理、自我恢复、自我配置、自我优化\n\n* 反馈控制模型：通过反馈控制循环实现\n\n  * 形成反馈控制循环的三个元素\n    * 系统本身需要被监视：对系统的各个方面进行测量（尺度预测组件）\n    * 分析上述测量值：控制循环的核心部分，包含决定自适应的算法（反馈分析组件）\n    * 其他组件\n\n  ![image-20221130151005907](distributed-system/image-20221130151005907.png)\n\n\n## 进程\n\n### 线程\n\n> 就粒度而言，将每个进程细分为若干控制线程的形式更加合适，可以使构建分布式应用程序变得更加方便，并可获得更好的性能。\n\n* 线程简介\n\n  > 线程上下文中一般值包含CPU上下文以及某些其他线程管理信息。\n\n  * 非分布式系统中线程用法，好处\n\n    * 多线程的系统中，线程阻塞不会造成进程阻塞\n    * 在多处理系统上执行多线程程序时，可以使用并行操作技术\n    * 线程之间的上下文切换小\n\n  * 线程的实现\n\n    > 一般以线程包的形式提供，这种包中含有创建和销毁线程的操作。分为用户及线程和内核级线程。\n\n    * 用户级线程的好处\n      * 创建和销毁线程开销小\n      * 可以通过为数不多的几条指令实现线程上下文切换\n    * 用户及线程的缺陷\n      * 对引起阻塞的系统调用的调用将会立即阻塞该线程所属的整个进程\n    * 轻量级进程：使用用户及线程和内核级线程的混合形式\n\n* 分布式系统中的线程\n\n  * 多线程客户\n\n    > 隐藏通信事件延迟的方法：启动通信后立即进行其他工作\n\n    * web浏览器显示HTML页面\n\n  * 多线程服务器\n\n    * 能够保留顺序处理的思路，使用阻塞性的系统调用，并且仍能够达到并行处理的目的\n\n    ![image-20221201100317779](distributed-system/image-20221201100317779.png)\n\n    分发器线程：读取文件操作请求\n\n    工作者线程：处理请求\n\n### 虚拟化\n\n> 虚拟化的本质是拓展或替换一个现存界面来模仿另一个系统的行为。\n\n* 虚拟化在分布式系统中的作用\n\n  * 旧有软件的维护，跟不上下层平台更新的步伐，硬件更新速度太快，需要软件兼容。通过移植旧有软件的底层接口到新平台，虚拟化可以帮助解决这个问题\n  * 虚拟化便于减少服务器和硬件机器的种类和数目，提供了高度的移植性和灵活性\n\n* 虚拟机体系结构\n\n  ```\n  在四个不同层次提供四个不同界面\n  由机器指令组成，可由任何程序激起的硬件软件界面\n  由机器指令组成，只有特权程序才可激起的硬件软件界面\n  由操作系统提供的系统调用（system call）组成的界面\n  由库调用组成的界面，通常形成了所谓的应用程序编程接口（API）\n  ```\n\n  ![image-20221201101403269](distributed-system/image-20221201101403269.png)\n\n  \n\n  * 虚拟化的两种方式\n\n    ![image-20221201101451311](distributed-system/image-20221201101451311.png)\n\n    * 构建一个运行时的系统，提供一套抽象指令集来执行程序（进程虚拟机）\n    * 提供一种系统，如VMware（虚拟机监视器）\n\n### 客户端\n\n* 客户端软件与分布式透明性\n\n  > 理论上来说，客户端不应该察觉到它与远程进程的通信，而服务器来说，分布常常不那么透明\n\n  * 许多分布式系统利用客户端解决方案来实现复制透明性\n\n    * 调用请求转发给每一个服务器发送副本来达到复制透明性\n\n    ![image-20221201110722218](distributed-system/image-20221201110722218.png)\n\n  * 故障透明性，一般是通过客户中间件完成\n\n### 服务器\n\n* 常见的设计问题\n\n  > 服务器的组织方式：等待来自客户的请求，随后负责处理该请求，等待下一个请求\n\n  服务器的不同组织结构\n\n  * 迭代服务器：自己处理请求，并且在必要的情况下将响应返回给发出请求的客户\n\n  * 并发服务器：并不自己处理请求，而是将请求传递给某个独立线程或其他进程来处理，只用于等待请求。如：多线程服务器。\n\n  * 超级服务器：用于负责监听所有与服务关联的端口，缓解了每一个服务器都要对端口监听的浪费。\n\n    ![image-20221201111903470](distributed-system/image-20221201111903470.png)\n\n  * 状态无关服务器：不保存客户的状态信息且不将自身状态告知客户\n\n    * 好处\n      * 不需要采取任何特殊措施来使得奔溃的服务器恢复，重启即可\n\n  * 状态相关服务器：一直保存客户端的信息直到显式的删除\n\n    * 好处：\n      * 性能能够提升\n    * 缺陷：\n      * 如果服务器崩溃，就必须恢复客户端的状态表\n\n* 服务器集群\n\n  > 服务器集群式一组经网络连接的机器，每台机器运行一个或多个服务器\n\n  * 常见的组织\n\n    * 多数情况下逻辑上由三层组成\n\n      ![image-20221201151303341](distributed-system/image-20221201151303341.png)\n\n      * （逻辑上的）交换机：分配客户请求给服务器\n\n        * 作为服务器集群的入口，提供唯一的网络地址\n\n        ![image-20221201152139305](distributed-system/image-20221201152139305.png)\n\n        * 交换机收到tcp连接请求，将请求分发给最佳服务器，服务器发送应答信号，并嵌入交换器的IP\n\n      * 专用的应用/计算处理服务器：提供高性能计算能力\n\n      * 文件和数据库服务器（数据存取是瓶颈）\n\n  * 分布式服务器\n\n    > 分布式服务器是指可动态变化的集群，它的访问点也可以变化，但对外却表现为一台强有力的单台机器。\n\n    * 基本思想：可靠、高性能、稳定\n    * 如何实现一个稳定访问点\n      * 使用宿主代理（宿主网络的特别的路由器）\n\n* 管理服务器集群的方法\n\n  * 通用方法\n    * 把传统的单台计算机管理功能拓展到服务器集群，从远程客户登录到集群的一个节点并执行本地管理命令\n\n### 代码迁移\n\n> 传递程序，甚至传递正在执行中的程序。\n\n* 代码迁移方案\n\n  > 代码迁移是以进程迁移的形式进行的，代码迁移会带来巨大的开销\n\n  * 进行代码迁移的好处\n\n    * 如果把进程由负载较重的机器上转移负载较轻的机器上，能提升系统的整体性能\n    * 灵活性，如果代码可以在不同的机器之间移动，就可以动态的配置分布式系统\n\n  * 代码迁移模型\n\n    进程包含3段：代码段（包含正在运行程序的所有指令），资源段（包含外部资源的指针），执行段（存储进程当前状态）\n\n    * 弱可移动性：只传输代码段以及初始化数据\n      * 传输的程序总是从预先定义的位置开始执行。较简单\n    * 强可移动性：可以传输执行段\n      * 可以先停止运行中的进程，然后将它移到另一台机器上去，再从中断的位置继续执行\n\n    另一种分类方式\n\n    * 发送者启动迁移：由正在执行该代码的机器启动迁移\n    * 接收者启动迁移：代码迁移主动权掌握在目标机器手里\n\n    ![image-20221201160233164](distributed-system/image-20221201160233164.png)\n\n## 通信\n\n> 四个广泛使用的通信模型：远程过程调用（RPC，remote procedure call）、远程方法调用（RMI，remote method invocation）、面向消息的中间件（MOM，message-oriented middleware）、流（stream）\n\n> RPC的目的在于将消息传递的大部分复杂性隐藏起来，比较适合客户-服务器应用程序。\n\n* 基础知识\n\n  * 分层协议\n    * OSI七层模型：略\n    * 中间件协议：中间件是一种应用程序，位于应用层中\n  * 通信类型\n    * 持久通信：提交传输的消息一直由通信中间件存储，直到消息被传送给接收方\n    * 瞬时通信：通信系统只有在发送和接受应用程序正在运行时才能存储消息\n    * 异步通信（asynchronous）：发送方在提交要传输的消息后立即往下进行\n    * 同步通信（synchronous）：发送方将被阻塞，直到其请求被接受\n\n* 远程过程调用\n\n  > 当机器A上的进程调用机器B上的进程是，A上的调用进程被挂起，而B上的被调用的进程开始执行，调用方可以通过使用参数将信息传给被调用放，然后通过传回的结果得到信息。编程人员看不到任何消息传递过程，这种方法称为远程过程调用\n\n  复杂性：地址空间不同、参数和结果的传递、机器如果发生崩溃\n\n  * 基本的RPC操作\n\n## 命名系统 - Naming\n\n> 命名是在分布式中表示这个实体，且要访问到这个实体。\n\n- 访问点：用来实体的一种特殊实体。\n- 地址：访问点的名称。\n\n所以**访问点**就是实体的**地址**。\n\n### DHT\n\n全称是Distributed Hash Tables，是P2P环境下最经典的解决方案\n\n### Chord\n\n使用一个m位的标识符空间，把**随机选择**的标识符赋给结点，并把键值赋值给特定实体（任意的东西，比如文件、进程）。\n\n**构造Finger table算法：**\n\n每个Chord结点维护一个最多有m个实体的指状表(Finger table)，如果用$FT_p[i]$表示结点$p$的指状表，那么有：\n$$\nFT_p[i] = succ(p+2^{(i-1)})\n$$\n\n\n$-p$是当前结点$-i$是指状表的$index-succ(k)$表示k（若结点k存在）或k的下一个**存在**的结点，即$succ(k)>=k$\n\n例：\n\n![image-20240302163915592](distributed-system/image-20240302163915592.png)\n\n根据$FT_p[i] = succ(p+2^{(i-1)})$公式，构造结点p=4的Finger table：\n\n|  i   |   $FT_p[i]$   |\n| :--: | :-----------: |\n|  1   |  succ(4+1)=9  |\n|  2   |  succ(4+2)=9  |\n|  3   |  succ(4+4)=9  |\n|  4   | succ(4+8)=14  |\n|  5   | succ(4+16)=20 |\n\n**解析算法：**\n\n目标：从节点p开始解析key=k的结点\n\n搜索节点p的Finger table，从上依次向下搜索，如果一个结点q满足：\n$$\nq=FT_p[j]<=k<FT_p[j+1]\n$$\n\n\n那么就将该请求转发给结点q；\n\n如果p的Finger table第一个结点就比k还大，即：\n$$\np<k<FT_p[1]\n$$\n\n\n那么就转发给$FT_p[1]$结点，此节点负责结点k，将k的地址返回给结点p。\n\n**例：**\n\n还是上面那个图\n\n从结点1开始解析k=26：\n\n1. 结点1的指状表里，$FT_1[5]$=18≤26，将请求转发给18；\n2. 结点18的指状表里，$FT_{18}[2]$=20≤26<$FT_{18}[3]$=28，将请求转发给20；\n3. 结点20的指状表里，$FT_{20}[1]$=21≤26<$FT_{20}[2]$=28，将请求转发给21；\n4. 结点21的指状表里，21<26<$FT_{21}[1]$=28，将请求转发给28，该结点负责解析k=26；\n\n从结点28开始解析k=12：\n\n1. 结点28的指状表里，$FT_{28}[4]$=4≤12<$FT_{28}[5]$=14，将请求转发给4；\n2. 结点4的指状表里，$FT_{4}[4]$=9≤12<$FT_{4}[4]$=14，将请求转发给9；\n3. 结点9的指状表里，$FT_{9}[2]$=11≤12<$FT_{9}[3]$=14，将请求转发给11；\n4. 结点11的指状表里，11<12<$FT_{11}[1]$=14，将请求转发给14，该结点负责解析k=12；\n\n### HLS\n\n网络被划分为一组域。每个域D都有关联的目录节点dir(D)，dir(D)会跟踪域中的实体，形成一颗目录结点树。\n\n### HLS结构\n\n看下面这个图来解释一下HLS吧：\n\n![image-20240302165702511](distributed-system/image-20240302165702511.png)\n\n为了跟踪实体E的位置，实体E位于域S中，所以域S的目录结点N含有E在该域中的位置信息。\n\n而在比域S更高一级的域T中，域T的目录结点N'也有实体E的位置信息，但是这个位置信息只有N的指针，也就是要找实体E，就先去找到其子域的目录结点N，然后通过目录节点N找到E。\n\n同理，在比域T更大的域中，那个域的目录节点也有实体E的位置信息，不过这个位置信息只有N'的指针，要找实体E，就要先找N'，然后找到N，最后找到E。\n\n所以顶级域的目录结点，即根（目录）节点，包括全部实体位置信息。\n\n### 如果一个实体有多个地址\n\n实体可以拥有多个地址，比如被复制了，实体在域D1和域D2中都有地址，那么同时包含D1和D2的最小域目录结点将有两个指针，每个指针都指向一个包含地址的子域。\n\n![image-20240302165713656](distributed-system/image-20240302165713656.png)\n\n### HLS查询操作\n\n![image-20240302165721466](distributed-system/image-20240302165721466.png)\n\n现在希望能定位实体E的位置信息，那么就向当前域的目录结点发送查找请求：\n\n```\nif 目录结点找到了实体E的位置信息:\n\tif 找到的是子域目录结点的地址\n\t\t把查找请求转发给子域的目录结点\n\telse \n\t\t找到了叶节点，把地址返回给请求的客户\nelse\n\t把查找请求转发给父节点\n```\n\n最差情况是一直找不到，向上转发直到根节点。","source":"_posts/distributed-system.md","raw":"---\ntitle: 分布式系统学习笔记\ncategories: 学习笔记\ndate: 2023-03-02 16:59:29\ntags: [分布式系统]\ncover:\ntop_img:\n---\n## 概述\n\n### 分布式系统的定义\n\n> 分布式系统是若干独立计算机的集合，这些计算机对于用户来说，像是单个相关系统\n\n* 重要特性\n  * 各种计算机之间的差别以及计算机之间的通信方式的差别对用户是隐藏的\n  * 用户看不到分布式系统的内部组织结构\n  * 用户和应用程序无论在何时何地都能够以一种一致和同意的方式与分布式系统进行交互\n  * 分布式系统的拓展或者升级应该时相对比较容易的\n\n### 分布式系统的目标\n\n* 使资源可访问（资源共享）\n* 透明性\n\n![image-20221126155708747](distributed-system/image-20221126155708747.png)\n\n![image-20221126155754925](distributed-system/image-20221126155754925.png)\n\n* 开放性（openess）\n\n  > 根据一系列准则来提供服务，这些准则描述了所提供服务的语义和语法。\n  >\n  > 在分布式系统中，服务通常时通过接口指定的，接口时通过接口定义语言来描述的。\n  >\n  > 开放的分布式系统应该时可扩展的。\n\n  * 完整性：完成接口实现不可少的内容都已经规定好了\n  * 中立性：开发人员能够添加针对特定实现的细节\n  * 互操作性：来自不同厂商的系统或组件的两种实现能够在何种程度上共存并且协同工作\n  * 可移植性：如果分布式系统A开发了某个应用，并且另一个分布式系统B与A具有相同的接口，该程序在不做修改在B上执行的可行程度\n\n* 可扩展性（scale in distributed system）scalablity\n\n  > 可扩展性通常可以从三个方面来度量，规模上可扩展（size）、地域上可扩展（geographical）、管理上可扩展（administrative）\n\n  * 规模上可拓展存在的问题\n\n    * 受集中式的服务、数据以及算法限制\n    * 集中式算法与分布式算法的对比\n\n    ```\n    分布式算法不同特性\n    1、没有任何计算机拥有关于系统状态的完整信息\n    2、计算机只根据本地信息做出决策\n    3、某台计算机的故障不会使算法奔溃\n    4、没有全局性时钟，来统一设定时间\n    ```\n\n  * 地域上可扩展存在的问题\n\n    * 基于同步的通信，在请求服务的一方得到回应之前都是处于阻塞状态，在局域网中速度快，广域网中很慢\n    * 广域网中的通信是不可靠的，都是点对点的\n    * 如何对一个跨越多个独立管理域的分布式系统进行拓展\n\n  * 管理上可扩展存在的问题\n\n    * 资源使用（以及付费）、管理和安全问题上，不同的管理域之间有着相互冲突的问题\n\n  * 拓展技术\n\n    > 拓展技术基本上只有三种技术：隐藏通信等待时间、分布技术以及复制技术\n\n    * 隐藏通信等待时间：尽量避免远程服务对请求的响应，实质上是异步通信。也可以将服务器上的部分任务交由客户端完成。\n    * 分布技术： 把某个组件分割成多个部分，再将他们分散到系统中，如DNS。\n    * 复制技术：会产生一致性问题。\n\n### 分布式系统的类型\n\n> 分布式计算系统、分布式信息系统、分布式嵌入系统\n\n* 分布式计算系统（高性能的分布式系统）\n\n  * 集群计算系统\n\n    > 同构性：集群中的计算机大多数是相同的。相同的操作系统，同一网络。\n\n    * 单个主节点，多个从节点，主节点可访问控制群（从节点）\n    * 主节点：负责对特定并行程序的结点定位，维护已经提交的工作队列，为系统用户提供接口\n\n    ![image-20221130091729650](distributed-system/image-20221130091729650.png)\n\n  * 网格计算系统\n\n    > 具有高度的异构性：硬件，操作系统，网络，管理域和安全策略都不尽相同\n\n    * 解决异构性的方式：虚拟组织\n    * 光纤层：在特定站点提供对局部资源的接口\n    * 连接层：由通信协议组成，用于支持网格事务处理\n    * 资源层：负责管理单个资源\n    * 汇集层：负责处理对多个资源的访问\n    * 应用层：由应用程序组成，在虚拟组织中运行\n\n    ![image-20221130092344725](distributed-system/image-20221130092344725.png)\n\n* 分布式信息系统\n\n* 分布式普适系统\n\n\n\n## 体系结构\n\n### 体系结构的样式\n\n> 体系结构样式是根据组件，组件之间互相连接方式、组件之间的数据交换以及这些元素如何集成到一个系统中来定义的。\n\n* 分层体系结构\n\n* 基于对象的体系结构\n\n  * 每个对象对应一个组件，组件通过远程过程调用机制来连接\n\n  ![image-20221130094553260](distributed-system/image-20221130094553260.png)\n\n* 以数据为中心的体系结构\n\n  * 进程通信需要通过一个公用仓库\n\n* 基于事件的体系结构\n\n  * 进程发布事件，中间件确保订阅了这些事件的进程接收它们。去耦合强。\n\n  ![image-20221130101949954](distributed-system/image-20221130101949954.png)\n\n### 系统体系结构\n\n* 集中式体系结构（客户—服务器）\n\n  * 应用分层\n\n    * 应用层：提供与用户交互的接口\n    * 处理层：处理用户的请求，实现与数据的交互\n    * 数据层：存储数据，如，文件系统，数据库\n\n  * 多层体系结构\n\n    * 两层体系结构：客户机和服务器\n      * 根据将客户机和服务器实现的不同功能可以分为以下5种，d和e较为普遍\n\n    ![image-20221130101048848](distributed-system/image-20221130101048848.png)\n\n    * 三层体系结构：用户接口、应用程序服务器、数据库服务器\n\n      ![image-20221130102217372](distributed-system/image-20221130102217372.png)\n\n* 非集中式体系结构（回头听一听课）点对点\n\n  垂直分布性（分层）：按逻辑把不同组件放在不同机器上\n\n  水平分布性：客户和服务器可能在物理上被分割成逻辑上相等的几个部分，但每个部分都操作在整个数据集中自己共享的部分，从而实现负载均衡。例如点对点系统\n\n  * 结构化的点对点体系结构\n\n    * Chord系统分布式哈希表（后面章节）理解加入和退出\n\n    ![image-20221130140722941](distributed-system/image-20221130140722941.png)\n\n    * CAN：上下文可编制网络（后面章节）\n\n  * 非结构化点对点体系结构\n\n    > 主要依靠随机化算法来构造覆盖网络，每个节点维护一个邻接点列表，列表由随机的方法来构造。使用泛洪法来查找。\n\n  * 覆盖网络的拓扑管理\n\n  * 超级对等体\n\n* 混合体系结构\n\n  > 特殊的分布式系统，将客户服务器体系结构和非集中式体系结构组合在一起\n\n  * 边界服务器系统\n\n  * 协作分布式系统\n\n    * 文件共享系统\n\n      > 是一种点对点的文件下载系统，一个用户从其他用户下载文件块，知道所下载的文件块能够组装成完整的文件。一旦结点确定了从哪里可以下载文件块，下载结点将被强制为其他节点提供帮助。瓶颈期在于跟踪器。\n\n    ![image-20221130143607842](distributed-system/image-20221130143607842.png)\n\n    * 协作内容分布式网络Globule\n\n### 体系结构与中间件\n\n> 中间件具有一定程度的透明性，一定程度上向应用程序隐藏了数据处理和控制的分布性\n\n* 中断器\n\n  > 是一种软件结构，能中断正常的控制流，从而允许其他代码运行。\n\n  * 请求级中断器：为每个副本调用invoke函数\n  * 消息级中断器：协助把消息传递接口激活转移给目标对象\n\n* 自适应软件常见方法（基本技术）\n\n  * 要点分离\n  * 计算映像：程序检查自己\n  * 基于组件的设计：通过组件的不同组合来支持自适应\n\n### 分布式系统的自我管理\n\n> 以高级反馈控制系统的形式来组织分布式系统，允许自动自适应变化。称为自治计算或自主系统。\n\n自适应的多样性：自我管理、自我恢复、自我配置、自我优化\n\n* 反馈控制模型：通过反馈控制循环实现\n\n  * 形成反馈控制循环的三个元素\n    * 系统本身需要被监视：对系统的各个方面进行测量（尺度预测组件）\n    * 分析上述测量值：控制循环的核心部分，包含决定自适应的算法（反馈分析组件）\n    * 其他组件\n\n  ![image-20221130151005907](distributed-system/image-20221130151005907.png)\n\n\n## 进程\n\n### 线程\n\n> 就粒度而言，将每个进程细分为若干控制线程的形式更加合适，可以使构建分布式应用程序变得更加方便，并可获得更好的性能。\n\n* 线程简介\n\n  > 线程上下文中一般值包含CPU上下文以及某些其他线程管理信息。\n\n  * 非分布式系统中线程用法，好处\n\n    * 多线程的系统中，线程阻塞不会造成进程阻塞\n    * 在多处理系统上执行多线程程序时，可以使用并行操作技术\n    * 线程之间的上下文切换小\n\n  * 线程的实现\n\n    > 一般以线程包的形式提供，这种包中含有创建和销毁线程的操作。分为用户及线程和内核级线程。\n\n    * 用户级线程的好处\n      * 创建和销毁线程开销小\n      * 可以通过为数不多的几条指令实现线程上下文切换\n    * 用户及线程的缺陷\n      * 对引起阻塞的系统调用的调用将会立即阻塞该线程所属的整个进程\n    * 轻量级进程：使用用户及线程和内核级线程的混合形式\n\n* 分布式系统中的线程\n\n  * 多线程客户\n\n    > 隐藏通信事件延迟的方法：启动通信后立即进行其他工作\n\n    * web浏览器显示HTML页面\n\n  * 多线程服务器\n\n    * 能够保留顺序处理的思路，使用阻塞性的系统调用，并且仍能够达到并行处理的目的\n\n    ![image-20221201100317779](distributed-system/image-20221201100317779.png)\n\n    分发器线程：读取文件操作请求\n\n    工作者线程：处理请求\n\n### 虚拟化\n\n> 虚拟化的本质是拓展或替换一个现存界面来模仿另一个系统的行为。\n\n* 虚拟化在分布式系统中的作用\n\n  * 旧有软件的维护，跟不上下层平台更新的步伐，硬件更新速度太快，需要软件兼容。通过移植旧有软件的底层接口到新平台，虚拟化可以帮助解决这个问题\n  * 虚拟化便于减少服务器和硬件机器的种类和数目，提供了高度的移植性和灵活性\n\n* 虚拟机体系结构\n\n  ```\n  在四个不同层次提供四个不同界面\n  由机器指令组成，可由任何程序激起的硬件软件界面\n  由机器指令组成，只有特权程序才可激起的硬件软件界面\n  由操作系统提供的系统调用（system call）组成的界面\n  由库调用组成的界面，通常形成了所谓的应用程序编程接口（API）\n  ```\n\n  ![image-20221201101403269](distributed-system/image-20221201101403269.png)\n\n  \n\n  * 虚拟化的两种方式\n\n    ![image-20221201101451311](distributed-system/image-20221201101451311.png)\n\n    * 构建一个运行时的系统，提供一套抽象指令集来执行程序（进程虚拟机）\n    * 提供一种系统，如VMware（虚拟机监视器）\n\n### 客户端\n\n* 客户端软件与分布式透明性\n\n  > 理论上来说，客户端不应该察觉到它与远程进程的通信，而服务器来说，分布常常不那么透明\n\n  * 许多分布式系统利用客户端解决方案来实现复制透明性\n\n    * 调用请求转发给每一个服务器发送副本来达到复制透明性\n\n    ![image-20221201110722218](distributed-system/image-20221201110722218.png)\n\n  * 故障透明性，一般是通过客户中间件完成\n\n### 服务器\n\n* 常见的设计问题\n\n  > 服务器的组织方式：等待来自客户的请求，随后负责处理该请求，等待下一个请求\n\n  服务器的不同组织结构\n\n  * 迭代服务器：自己处理请求，并且在必要的情况下将响应返回给发出请求的客户\n\n  * 并发服务器：并不自己处理请求，而是将请求传递给某个独立线程或其他进程来处理，只用于等待请求。如：多线程服务器。\n\n  * 超级服务器：用于负责监听所有与服务关联的端口，缓解了每一个服务器都要对端口监听的浪费。\n\n    ![image-20221201111903470](distributed-system/image-20221201111903470.png)\n\n  * 状态无关服务器：不保存客户的状态信息且不将自身状态告知客户\n\n    * 好处\n      * 不需要采取任何特殊措施来使得奔溃的服务器恢复，重启即可\n\n  * 状态相关服务器：一直保存客户端的信息直到显式的删除\n\n    * 好处：\n      * 性能能够提升\n    * 缺陷：\n      * 如果服务器崩溃，就必须恢复客户端的状态表\n\n* 服务器集群\n\n  > 服务器集群式一组经网络连接的机器，每台机器运行一个或多个服务器\n\n  * 常见的组织\n\n    * 多数情况下逻辑上由三层组成\n\n      ![image-20221201151303341](distributed-system/image-20221201151303341.png)\n\n      * （逻辑上的）交换机：分配客户请求给服务器\n\n        * 作为服务器集群的入口，提供唯一的网络地址\n\n        ![image-20221201152139305](distributed-system/image-20221201152139305.png)\n\n        * 交换机收到tcp连接请求，将请求分发给最佳服务器，服务器发送应答信号，并嵌入交换器的IP\n\n      * 专用的应用/计算处理服务器：提供高性能计算能力\n\n      * 文件和数据库服务器（数据存取是瓶颈）\n\n  * 分布式服务器\n\n    > 分布式服务器是指可动态变化的集群，它的访问点也可以变化，但对外却表现为一台强有力的单台机器。\n\n    * 基本思想：可靠、高性能、稳定\n    * 如何实现一个稳定访问点\n      * 使用宿主代理（宿主网络的特别的路由器）\n\n* 管理服务器集群的方法\n\n  * 通用方法\n    * 把传统的单台计算机管理功能拓展到服务器集群，从远程客户登录到集群的一个节点并执行本地管理命令\n\n### 代码迁移\n\n> 传递程序，甚至传递正在执行中的程序。\n\n* 代码迁移方案\n\n  > 代码迁移是以进程迁移的形式进行的，代码迁移会带来巨大的开销\n\n  * 进行代码迁移的好处\n\n    * 如果把进程由负载较重的机器上转移负载较轻的机器上，能提升系统的整体性能\n    * 灵活性，如果代码可以在不同的机器之间移动，就可以动态的配置分布式系统\n\n  * 代码迁移模型\n\n    进程包含3段：代码段（包含正在运行程序的所有指令），资源段（包含外部资源的指针），执行段（存储进程当前状态）\n\n    * 弱可移动性：只传输代码段以及初始化数据\n      * 传输的程序总是从预先定义的位置开始执行。较简单\n    * 强可移动性：可以传输执行段\n      * 可以先停止运行中的进程，然后将它移到另一台机器上去，再从中断的位置继续执行\n\n    另一种分类方式\n\n    * 发送者启动迁移：由正在执行该代码的机器启动迁移\n    * 接收者启动迁移：代码迁移主动权掌握在目标机器手里\n\n    ![image-20221201160233164](distributed-system/image-20221201160233164.png)\n\n## 通信\n\n> 四个广泛使用的通信模型：远程过程调用（RPC，remote procedure call）、远程方法调用（RMI，remote method invocation）、面向消息的中间件（MOM，message-oriented middleware）、流（stream）\n\n> RPC的目的在于将消息传递的大部分复杂性隐藏起来，比较适合客户-服务器应用程序。\n\n* 基础知识\n\n  * 分层协议\n    * OSI七层模型：略\n    * 中间件协议：中间件是一种应用程序，位于应用层中\n  * 通信类型\n    * 持久通信：提交传输的消息一直由通信中间件存储，直到消息被传送给接收方\n    * 瞬时通信：通信系统只有在发送和接受应用程序正在运行时才能存储消息\n    * 异步通信（asynchronous）：发送方在提交要传输的消息后立即往下进行\n    * 同步通信（synchronous）：发送方将被阻塞，直到其请求被接受\n\n* 远程过程调用\n\n  > 当机器A上的进程调用机器B上的进程是，A上的调用进程被挂起，而B上的被调用的进程开始执行，调用方可以通过使用参数将信息传给被调用放，然后通过传回的结果得到信息。编程人员看不到任何消息传递过程，这种方法称为远程过程调用\n\n  复杂性：地址空间不同、参数和结果的传递、机器如果发生崩溃\n\n  * 基本的RPC操作\n\n## 命名系统 - Naming\n\n> 命名是在分布式中表示这个实体，且要访问到这个实体。\n\n- 访问点：用来实体的一种特殊实体。\n- 地址：访问点的名称。\n\n所以**访问点**就是实体的**地址**。\n\n### DHT\n\n全称是Distributed Hash Tables，是P2P环境下最经典的解决方案\n\n### Chord\n\n使用一个m位的标识符空间，把**随机选择**的标识符赋给结点，并把键值赋值给特定实体（任意的东西，比如文件、进程）。\n\n**构造Finger table算法：**\n\n每个Chord结点维护一个最多有m个实体的指状表(Finger table)，如果用$FT_p[i]$表示结点$p$的指状表，那么有：\n$$\nFT_p[i] = succ(p+2^{(i-1)})\n$$\n\n\n$-p$是当前结点$-i$是指状表的$index-succ(k)$表示k（若结点k存在）或k的下一个**存在**的结点，即$succ(k)>=k$\n\n例：\n\n![image-20240302163915592](distributed-system/image-20240302163915592.png)\n\n根据$FT_p[i] = succ(p+2^{(i-1)})$公式，构造结点p=4的Finger table：\n\n|  i   |   $FT_p[i]$   |\n| :--: | :-----------: |\n|  1   |  succ(4+1)=9  |\n|  2   |  succ(4+2)=9  |\n|  3   |  succ(4+4)=9  |\n|  4   | succ(4+8)=14  |\n|  5   | succ(4+16)=20 |\n\n**解析算法：**\n\n目标：从节点p开始解析key=k的结点\n\n搜索节点p的Finger table，从上依次向下搜索，如果一个结点q满足：\n$$\nq=FT_p[j]<=k<FT_p[j+1]\n$$\n\n\n那么就将该请求转发给结点q；\n\n如果p的Finger table第一个结点就比k还大，即：\n$$\np<k<FT_p[1]\n$$\n\n\n那么就转发给$FT_p[1]$结点，此节点负责结点k，将k的地址返回给结点p。\n\n**例：**\n\n还是上面那个图\n\n从结点1开始解析k=26：\n\n1. 结点1的指状表里，$FT_1[5]$=18≤26，将请求转发给18；\n2. 结点18的指状表里，$FT_{18}[2]$=20≤26<$FT_{18}[3]$=28，将请求转发给20；\n3. 结点20的指状表里，$FT_{20}[1]$=21≤26<$FT_{20}[2]$=28，将请求转发给21；\n4. 结点21的指状表里，21<26<$FT_{21}[1]$=28，将请求转发给28，该结点负责解析k=26；\n\n从结点28开始解析k=12：\n\n1. 结点28的指状表里，$FT_{28}[4]$=4≤12<$FT_{28}[5]$=14，将请求转发给4；\n2. 结点4的指状表里，$FT_{4}[4]$=9≤12<$FT_{4}[4]$=14，将请求转发给9；\n3. 结点9的指状表里，$FT_{9}[2]$=11≤12<$FT_{9}[3]$=14，将请求转发给11；\n4. 结点11的指状表里，11<12<$FT_{11}[1]$=14，将请求转发给14，该结点负责解析k=12；\n\n### HLS\n\n网络被划分为一组域。每个域D都有关联的目录节点dir(D)，dir(D)会跟踪域中的实体，形成一颗目录结点树。\n\n### HLS结构\n\n看下面这个图来解释一下HLS吧：\n\n![image-20240302165702511](distributed-system/image-20240302165702511.png)\n\n为了跟踪实体E的位置，实体E位于域S中，所以域S的目录结点N含有E在该域中的位置信息。\n\n而在比域S更高一级的域T中，域T的目录结点N'也有实体E的位置信息，但是这个位置信息只有N的指针，也就是要找实体E，就先去找到其子域的目录结点N，然后通过目录节点N找到E。\n\n同理，在比域T更大的域中，那个域的目录节点也有实体E的位置信息，不过这个位置信息只有N'的指针，要找实体E，就要先找N'，然后找到N，最后找到E。\n\n所以顶级域的目录结点，即根（目录）节点，包括全部实体位置信息。\n\n### 如果一个实体有多个地址\n\n实体可以拥有多个地址，比如被复制了，实体在域D1和域D2中都有地址，那么同时包含D1和D2的最小域目录结点将有两个指针，每个指针都指向一个包含地址的子域。\n\n![image-20240302165713656](distributed-system/image-20240302165713656.png)\n\n### HLS查询操作\n\n![image-20240302165721466](distributed-system/image-20240302165721466.png)\n\n现在希望能定位实体E的位置信息，那么就向当前域的目录结点发送查找请求：\n\n```\nif 目录结点找到了实体E的位置信息:\n\tif 找到的是子域目录结点的地址\n\t\t把查找请求转发给子域的目录结点\n\telse \n\t\t找到了叶节点，把地址返回给请求的客户\nelse\n\t把查找请求转发给父节点\n```\n\n最差情况是一直找不到，向上转发直到根节点。","slug":"distributed-system","published":1,"updated":"2024-06-05T09:03:03.748Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttv002c08jv98rtc5ym","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><h3 id=\"分布式系统的定义\"><a href=\"#分布式系统的定义\" class=\"headerlink\" title=\"分布式系统的定义\"></a>分布式系统的定义</h3><blockquote>\n<p>分布式系统是若干独立计算机的集合，这些计算机对于用户来说，像是单个相关系统</p>\n</blockquote>\n<ul>\n<li>重要特性<ul>\n<li>各种计算机之间的差别以及计算机之间的通信方式的差别对用户是隐藏的</li>\n<li>用户看不到分布式系统的内部组织结构</li>\n<li>用户和应用程序无论在何时何地都能够以一种一致和同意的方式与分布式系统进行交互</li>\n<li>分布式系统的拓展或者升级应该时相对比较容易的</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的目标\"><a href=\"#分布式系统的目标\" class=\"headerlink\" title=\"分布式系统的目标\"></a>分布式系统的目标</h3><ul>\n<li>使资源可访问（资源共享）</li>\n<li>透明性</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221126155708747.png\" class=\"\" title=\"image-20221126155708747\">\n<img src=\"/2023/03/02/distributed-system/image-20221126155754925.png\" class=\"\" title=\"image-20221126155754925\">\n<ul>\n<li><p>开放性（openess）</p>\n<blockquote>\n<p>根据一系列准则来提供服务，这些准则描述了所提供服务的语义和语法。</p>\n<p>在分布式系统中，服务通常时通过接口指定的，接口时通过接口定义语言来描述的。</p>\n<p>开放的分布式系统应该时可扩展的。</p>\n</blockquote>\n<ul>\n<li>完整性：完成接口实现不可少的内容都已经规定好了</li>\n<li>中立性：开发人员能够添加针对特定实现的细节</li>\n<li>互操作性：来自不同厂商的系统或组件的两种实现能够在何种程度上共存并且协同工作</li>\n<li>可移植性：如果分布式系统A开发了某个应用，并且另一个分布式系统B与A具有相同的接口，该程序在不做修改在B上执行的可行程度</li>\n</ul>\n</li>\n<li><p>可扩展性（scale in distributed system）scalablity</p>\n<blockquote>\n<p>可扩展性通常可以从三个方面来度量，规模上可扩展（size）、地域上可扩展（geographical）、管理上可扩展（administrative）</p>\n</blockquote>\n<ul>\n<li><p>规模上可拓展存在的问题</p>\n<ul>\n<li>受集中式的服务、数据以及算法限制</li>\n<li>集中式算法与分布式算法的对比</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">分布式算法不同特性<br>1、没有任何计算机拥有关于系统状态的完整信息<br>2、计算机只根据本地信息做出决策<br>3、某台计算机的故障不会使算法奔溃<br>4、没有全局性时钟，来统一设定时间<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>地域上可扩展存在的问题</p>\n<ul>\n<li>基于同步的通信，在请求服务的一方得到回应之前都是处于阻塞状态，在局域网中速度快，广域网中很慢</li>\n<li>广域网中的通信是不可靠的，都是点对点的</li>\n<li>如何对一个跨越多个独立管理域的分布式系统进行拓展</li>\n</ul>\n</li>\n<li><p>管理上可扩展存在的问题</p>\n<ul>\n<li>资源使用（以及付费）、管理和安全问题上，不同的管理域之间有着相互冲突的问题</li>\n</ul>\n</li>\n<li><p>拓展技术</p>\n<blockquote>\n<p>拓展技术基本上只有三种技术：隐藏通信等待时间、分布技术以及复制技术</p>\n</blockquote>\n<ul>\n<li>隐藏通信等待时间：尽量避免远程服务对请求的响应，实质上是异步通信。也可以将服务器上的部分任务交由客户端完成。</li>\n<li>分布技术： 把某个组件分割成多个部分，再将他们分散到系统中，如DNS。</li>\n<li>复制技术：会产生一致性问题。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的类型\"><a href=\"#分布式系统的类型\" class=\"headerlink\" title=\"分布式系统的类型\"></a>分布式系统的类型</h3><blockquote>\n<p>分布式计算系统、分布式信息系统、分布式嵌入系统</p>\n</blockquote>\n<ul>\n<li><p>分布式计算系统（高性能的分布式系统）</p>\n<ul>\n<li><p>集群计算系统</p>\n<blockquote>\n<p>同构性：集群中的计算机大多数是相同的。相同的操作系统，同一网络。</p>\n</blockquote>\n<ul>\n<li>单个主节点，多个从节点，主节点可访问控制群（从节点）</li>\n<li>主节点：负责对特定并行程序的结点定位，维护已经提交的工作队列，为系统用户提供接口</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130091729650.png\" class=\"\" title=\"image-20221130091729650\">\n</li>\n<li><p>网格计算系统</p>\n<blockquote>\n<p>具有高度的异构性：硬件，操作系统，网络，管理域和安全策略都不尽相同</p>\n</blockquote>\n<ul>\n<li>解决异构性的方式：虚拟组织</li>\n<li>光纤层：在特定站点提供对局部资源的接口</li>\n<li>连接层：由通信协议组成，用于支持网格事务处理</li>\n<li>资源层：负责管理单个资源</li>\n<li>汇集层：负责处理对多个资源的访问</li>\n<li>应用层：由应用程序组成，在虚拟组织中运行</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130092344725.png\" class=\"\" title=\"image-20221130092344725\">\n</li>\n</ul>\n</li>\n<li><p>分布式信息系统</p>\n</li>\n<li><p>分布式普适系统</p>\n</li>\n</ul>\n<h2 id=\"体系结构\"><a href=\"#体系结构\" class=\"headerlink\" title=\"体系结构\"></a>体系结构</h2><h3 id=\"体系结构的样式\"><a href=\"#体系结构的样式\" class=\"headerlink\" title=\"体系结构的样式\"></a>体系结构的样式</h3><blockquote>\n<p>体系结构样式是根据组件，组件之间互相连接方式、组件之间的数据交换以及这些元素如何集成到一个系统中来定义的。</p>\n</blockquote>\n<ul>\n<li><p>分层体系结构</p>\n</li>\n<li><p>基于对象的体系结构</p>\n<ul>\n<li>每个对象对应一个组件，组件通过远程过程调用机制来连接</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130094553260.png\" class=\"\" title=\"image-20221130094553260\">\n</li>\n<li><p>以数据为中心的体系结构</p>\n<ul>\n<li>进程通信需要通过一个公用仓库</li>\n</ul>\n</li>\n<li><p>基于事件的体系结构</p>\n<ul>\n<li>进程发布事件，中间件确保订阅了这些事件的进程接收它们。去耦合强。</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130101949954.png\" class=\"\" title=\"image-20221130101949954\">\n</li>\n</ul>\n<h3 id=\"系统体系结构\"><a href=\"#系统体系结构\" class=\"headerlink\" title=\"系统体系结构\"></a>系统体系结构</h3><ul>\n<li><p>集中式体系结构（客户—服务器）</p>\n<ul>\n<li><p>应用分层</p>\n<ul>\n<li>应用层：提供与用户交互的接口</li>\n<li>处理层：处理用户的请求，实现与数据的交互</li>\n<li>数据层：存储数据，如，文件系统，数据库</li>\n</ul>\n</li>\n<li><p>多层体系结构</p>\n<ul>\n<li>两层体系结构：客户机和服务器<ul>\n<li>根据将客户机和服务器实现的不同功能可以分为以下5种，d和e较为普遍</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130101048848.png\" class=\"\" title=\"image-20221130101048848\">\n<ul>\n<li><p>三层体系结构：用户接口、应用程序服务器、数据库服务器</p>\n<img src=\"/2023/03/02/distributed-system/image-20221130102217372.png\" class=\"\" title=\"image-20221130102217372\">\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>非集中式体系结构（回头听一听课）点对点</p>\n<p>垂直分布性（分层）：按逻辑把不同组件放在不同机器上</p>\n<p>水平分布性：客户和服务器可能在物理上被分割成逻辑上相等的几个部分，但每个部分都操作在整个数据集中自己共享的部分，从而实现负载均衡。例如点对点系统</p>\n<ul>\n<li><p>结构化的点对点体系结构</p>\n<ul>\n<li>Chord系统分布式哈希表（后面章节）理解加入和退出</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130140722941.png\" class=\"\" title=\"image-20221130140722941\">\n<ul>\n<li>CAN：上下文可编制网络（后面章节）</li>\n</ul>\n</li>\n<li><p>非结构化点对点体系结构</p>\n<blockquote>\n<p>主要依靠随机化算法来构造覆盖网络，每个节点维护一个邻接点列表，列表由随机的方法来构造。使用泛洪法来查找。</p>\n</blockquote>\n</li>\n<li><p>覆盖网络的拓扑管理</p>\n</li>\n<li><p>超级对等体</p>\n</li>\n</ul>\n</li>\n<li><p>混合体系结构</p>\n<blockquote>\n<p>特殊的分布式系统，将客户服务器体系结构和非集中式体系结构组合在一起</p>\n</blockquote>\n<ul>\n<li><p>边界服务器系统</p>\n</li>\n<li><p>协作分布式系统</p>\n<ul>\n<li><p>文件共享系统</p>\n<blockquote>\n<p>是一种点对点的文件下载系统，一个用户从其他用户下载文件块，知道所下载的文件块能够组装成完整的文件。一旦结点确定了从哪里可以下载文件块，下载结点将被强制为其他节点提供帮助。瓶颈期在于跟踪器。</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130143607842.png\" class=\"\" title=\"image-20221130143607842\">\n<ul>\n<li>协作内容分布式网络Globule</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"体系结构与中间件\"><a href=\"#体系结构与中间件\" class=\"headerlink\" title=\"体系结构与中间件\"></a>体系结构与中间件</h3><blockquote>\n<p>中间件具有一定程度的透明性，一定程度上向应用程序隐藏了数据处理和控制的分布性</p>\n</blockquote>\n<ul>\n<li><p>中断器</p>\n<blockquote>\n<p>是一种软件结构，能中断正常的控制流，从而允许其他代码运行。</p>\n</blockquote>\n<ul>\n<li>请求级中断器：为每个副本调用invoke函数</li>\n<li>消息级中断器：协助把消息传递接口激活转移给目标对象</li>\n</ul>\n</li>\n<li><p>自适应软件常见方法（基本技术）</p>\n<ul>\n<li>要点分离</li>\n<li>计算映像：程序检查自己</li>\n<li>基于组件的设计：通过组件的不同组合来支持自适应</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的自我管理\"><a href=\"#分布式系统的自我管理\" class=\"headerlink\" title=\"分布式系统的自我管理\"></a>分布式系统的自我管理</h3><blockquote>\n<p>以高级反馈控制系统的形式来组织分布式系统，允许自动自适应变化。称为自治计算或自主系统。</p>\n</blockquote>\n<p>自适应的多样性：自我管理、自我恢复、自我配置、自我优化</p>\n<ul>\n<li><p>反馈控制模型：通过反馈控制循环实现</p>\n<ul>\n<li>形成反馈控制循环的三个元素<ul>\n<li>系统本身需要被监视：对系统的各个方面进行测量（尺度预测组件）</li>\n<li>分析上述测量值：控制循环的核心部分，包含决定自适应的算法（反馈分析组件）</li>\n<li>其他组件</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130151005907.png\" class=\"\" title=\"image-20221130151005907\">\n</li>\n</ul>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><h3 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h3><blockquote>\n<p>就粒度而言，将每个进程细分为若干控制线程的形式更加合适，可以使构建分布式应用程序变得更加方便，并可获得更好的性能。</p>\n</blockquote>\n<ul>\n<li><p>线程简介</p>\n<blockquote>\n<p>线程上下文中一般值包含CPU上下文以及某些其他线程管理信息。</p>\n</blockquote>\n<ul>\n<li><p>非分布式系统中线程用法，好处</p>\n<ul>\n<li>多线程的系统中，线程阻塞不会造成进程阻塞</li>\n<li>在多处理系统上执行多线程程序时，可以使用并行操作技术</li>\n<li>线程之间的上下文切换小</li>\n</ul>\n</li>\n<li><p>线程的实现</p>\n<blockquote>\n<p>一般以线程包的形式提供，这种包中含有创建和销毁线程的操作。分为用户及线程和内核级线程。</p>\n</blockquote>\n<ul>\n<li>用户级线程的好处<ul>\n<li>创建和销毁线程开销小</li>\n<li>可以通过为数不多的几条指令实现线程上下文切换</li>\n</ul>\n</li>\n<li>用户及线程的缺陷<ul>\n<li>对引起阻塞的系统调用的调用将会立即阻塞该线程所属的整个进程</li>\n</ul>\n</li>\n<li>轻量级进程：使用用户及线程和内核级线程的混合形式</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分布式系统中的线程</p>\n<ul>\n<li><p>多线程客户</p>\n<blockquote>\n<p>隐藏通信事件延迟的方法：启动通信后立即进行其他工作</p>\n</blockquote>\n<ul>\n<li>web浏览器显示HTML页面</li>\n</ul>\n</li>\n<li><p>多线程服务器</p>\n<ul>\n<li>能够保留顺序处理的思路，使用阻塞性的系统调用，并且仍能够达到并行处理的目的</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201100317779.png\" class=\"\" title=\"image-20221201100317779\">\n<p>分发器线程：读取文件操作请求</p>\n<p>工作者线程：处理请求</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"虚拟化\"><a href=\"#虚拟化\" class=\"headerlink\" title=\"虚拟化\"></a>虚拟化</h3><blockquote>\n<p>虚拟化的本质是拓展或替换一个现存界面来模仿另一个系统的行为。</p>\n</blockquote>\n<ul>\n<li><p>虚拟化在分布式系统中的作用</p>\n<ul>\n<li>旧有软件的维护，跟不上下层平台更新的步伐，硬件更新速度太快，需要软件兼容。通过移植旧有软件的底层接口到新平台，虚拟化可以帮助解决这个问题</li>\n<li>虚拟化便于减少服务器和硬件机器的种类和数目，提供了高度的移植性和灵活性</li>\n</ul>\n</li>\n<li><p>虚拟机体系结构</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">在四个不同层次提供四个不同界面<br>由机器指令组成，可由任何程序激起的硬件软件界面<br>由机器指令组成，只有特权程序才可激起的硬件软件界面<br>由操作系统提供的系统调用（<span class=\"hljs-keyword\">system</span> <span class=\"hljs-keyword\">call</span>）组成的界面<br>由库调用组成的界面，通常形成了所谓的应用程序编程接口（API）<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/03/02/distributed-system/image-20221201101403269.png\" class=\"\" title=\"image-20221201101403269\">\n</li>\n</ul>\n<ul>\n<li><p>虚拟化的两种方式</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201101451311.png\" class=\"\" title=\"image-20221201101451311\">\n<ul>\n<li>构建一个运行时的系统，提供一套抽象指令集来执行程序（进程虚拟机）</li>\n<li>提供一种系统，如VMware（虚拟机监视器）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><ul>\n<li><p>客户端软件与分布式透明性</p>\n<blockquote>\n<p>理论上来说，客户端不应该察觉到它与远程进程的通信，而服务器来说，分布常常不那么透明</p>\n</blockquote>\n<ul>\n<li><p>许多分布式系统利用客户端解决方案来实现复制透明性</p>\n<ul>\n<li>调用请求转发给每一个服务器发送副本来达到复制透明性</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201110722218.png\" class=\"\" title=\"image-20221201110722218\">\n</li>\n<li><p>故障透明性，一般是通过客户中间件完成</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"服务器\"><a href=\"#服务器\" class=\"headerlink\" title=\"服务器\"></a>服务器</h3><ul>\n<li><p>常见的设计问题</p>\n<blockquote>\n<p>服务器的组织方式：等待来自客户的请求，随后负责处理该请求，等待下一个请求</p>\n</blockquote>\n<p>服务器的不同组织结构</p>\n<ul>\n<li><p>迭代服务器：自己处理请求，并且在必要的情况下将响应返回给发出请求的客户</p>\n</li>\n<li><p>并发服务器：并不自己处理请求，而是将请求传递给某个独立线程或其他进程来处理，只用于等待请求。如：多线程服务器。</p>\n</li>\n<li><p>超级服务器：用于负责监听所有与服务关联的端口，缓解了每一个服务器都要对端口监听的浪费。</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201111903470.png\" class=\"\" title=\"image-20221201111903470\">\n</li>\n<li><p>状态无关服务器：不保存客户的状态信息且不将自身状态告知客户</p>\n<ul>\n<li>好处<ul>\n<li>不需要采取任何特殊措施来使得奔溃的服务器恢复，重启即可</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>状态相关服务器：一直保存客户端的信息直到显式的删除</p>\n<ul>\n<li>好处：<ul>\n<li>性能能够提升</li>\n</ul>\n</li>\n<li>缺陷：<ul>\n<li>如果服务器崩溃，就必须恢复客户端的状态表</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>服务器集群</p>\n<blockquote>\n<p>服务器集群式一组经网络连接的机器，每台机器运行一个或多个服务器</p>\n</blockquote>\n<ul>\n<li><p>常见的组织</p>\n<ul>\n<li><p>多数情况下逻辑上由三层组成</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201151303341.png\" class=\"\" title=\"image-20221201151303341\">\n<ul>\n<li><p>（逻辑上的）交换机：分配客户请求给服务器</p>\n<ul>\n<li>作为服务器集群的入口，提供唯一的网络地址</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201152139305.png\" class=\"\" title=\"image-20221201152139305\">\n<ul>\n<li>交换机收到tcp连接请求，将请求分发给最佳服务器，服务器发送应答信号，并嵌入交换器的IP</li>\n</ul>\n</li>\n<li><p>专用的应用/计算处理服务器：提供高性能计算能力</p>\n</li>\n<li><p>文件和数据库服务器（数据存取是瓶颈）</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分布式服务器</p>\n<blockquote>\n<p>分布式服务器是指可动态变化的集群，它的访问点也可以变化，但对外却表现为一台强有力的单台机器。</p>\n</blockquote>\n<ul>\n<li>基本思想：可靠、高性能、稳定</li>\n<li>如何实现一个稳定访问点<ul>\n<li>使用宿主代理（宿主网络的特别的路由器）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>管理服务器集群的方法</p>\n<ul>\n<li>通用方法<ul>\n<li>把传统的单台计算机管理功能拓展到服务器集群，从远程客户登录到集群的一个节点并执行本地管理命令</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"代码迁移\"><a href=\"#代码迁移\" class=\"headerlink\" title=\"代码迁移\"></a>代码迁移</h3><blockquote>\n<p>传递程序，甚至传递正在执行中的程序。</p>\n</blockquote>\n<ul>\n<li><p>代码迁移方案</p>\n<blockquote>\n<p>代码迁移是以进程迁移的形式进行的，代码迁移会带来巨大的开销</p>\n</blockquote>\n<ul>\n<li><p>进行代码迁移的好处</p>\n<ul>\n<li>如果把进程由负载较重的机器上转移负载较轻的机器上，能提升系统的整体性能</li>\n<li>灵活性，如果代码可以在不同的机器之间移动，就可以动态的配置分布式系统</li>\n</ul>\n</li>\n<li><p>代码迁移模型</p>\n<p>进程包含3段：代码段（包含正在运行程序的所有指令），资源段（包含外部资源的指针），执行段（存储进程当前状态）</p>\n<ul>\n<li>弱可移动性：只传输代码段以及初始化数据<ul>\n<li>传输的程序总是从预先定义的位置开始执行。较简单</li>\n</ul>\n</li>\n<li>强可移动性：可以传输执行段<ul>\n<li>可以先停止运行中的进程，然后将它移到另一台机器上去，再从中断的位置继续执行</li>\n</ul>\n</li>\n</ul>\n<p>另一种分类方式</p>\n<ul>\n<li>发送者启动迁移：由正在执行该代码的机器启动迁移</li>\n<li>接收者启动迁移：代码迁移主动权掌握在目标机器手里</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201160233164.png\" class=\"\" title=\"image-20221201160233164\">\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"通信\"><a href=\"#通信\" class=\"headerlink\" title=\"通信\"></a>通信</h2><blockquote>\n<p>四个广泛使用的通信模型：远程过程调用（RPC，remote procedure call）、远程方法调用（RMI，remote method invocation）、面向消息的中间件（MOM，message-oriented middleware）、流（stream）</p>\n<p>RPC的目的在于将消息传递的大部分复杂性隐藏起来，比较适合客户-服务器应用程序。</p>\n</blockquote>\n<ul>\n<li><p>基础知识</p>\n<ul>\n<li>分层协议<ul>\n<li>OSI七层模型：略</li>\n<li>中间件协议：中间件是一种应用程序，位于应用层中</li>\n</ul>\n</li>\n<li>通信类型<ul>\n<li>持久通信：提交传输的消息一直由通信中间件存储，直到消息被传送给接收方</li>\n<li>瞬时通信：通信系统只有在发送和接受应用程序正在运行时才能存储消息</li>\n<li>异步通信（asynchronous）：发送方在提交要传输的消息后立即往下进行</li>\n<li>同步通信（synchronous）：发送方将被阻塞，直到其请求被接受</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>远程过程调用</p>\n<blockquote>\n<p>当机器A上的进程调用机器B上的进程是，A上的调用进程被挂起，而B上的被调用的进程开始执行，调用方可以通过使用参数将信息传给被调用放，然后通过传回的结果得到信息。编程人员看不到任何消息传递过程，这种方法称为远程过程调用</p>\n</blockquote>\n<p>复杂性：地址空间不同、参数和结果的传递、机器如果发生崩溃</p>\n<ul>\n<li>基本的RPC操作</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"命名系统-Naming\"><a href=\"#命名系统-Naming\" class=\"headerlink\" title=\"命名系统 - Naming\"></a>命名系统 - Naming</h2><blockquote>\n<p>命名是在分布式中表示这个实体，且要访问到这个实体。</p>\n</blockquote>\n<ul>\n<li>访问点：用来实体的一种特殊实体。</li>\n<li>地址：访问点的名称。</li>\n</ul>\n<p>所以<strong>访问点</strong>就是实体的<strong>地址</strong>。</p>\n<h3 id=\"DHT\"><a href=\"#DHT\" class=\"headerlink\" title=\"DHT\"></a>DHT</h3><p>全称是Distributed Hash Tables，是P2P环境下最经典的解决方案</p>\n<h3 id=\"Chord\"><a href=\"#Chord\" class=\"headerlink\" title=\"Chord\"></a>Chord</h3><p>使用一个m位的标识符空间，把<strong>随机选择</strong>的标识符赋给结点，并把键值赋值给特定实体（任意的东西，比如文件、进程）。</p>\n<p><strong>构造Finger table算法：</strong></p>\n<p>每个Chord结点维护一个最多有m个实体的指状表(Finger table)，如果用$FT_p[i]$表示结点$p$的指状表，那么有：</p>\n<script type=\"math/tex; mode=display\">\nFT_p[i] = succ(p+2^{(i-1)})</script><p>$-p$是当前结点$-i$是指状表的$index-succ(k)$表示k（若结点k存在）或k的下一个<strong>存在</strong>的结点，即$succ(k)&gt;=k$</p>\n<p>例：</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302163915592.png\" class=\"\" title=\"image-20240302163915592\">\n<p>根据$FT_p[i] = succ(p+2^{(i-1)})$公式，构造结点p=4的Finger table：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">i</th>\n<th style=\"text-align:center\">$FT_p[i]$</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">succ(4+1)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">succ(4+2)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">succ(4+4)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">succ(4+8)=14</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">5</td>\n<td style=\"text-align:center\">succ(4+16)=20</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>解析算法：</strong></p>\n<p>目标：从节点p开始解析key=k的结点</p>\n<p>搜索节点p的Finger table，从上依次向下搜索，如果一个结点q满足：</p>\n<script type=\"math/tex; mode=display\">\nq=FT_p[j]<=k<FT_p[j+1]</script><p>那么就将该请求转发给结点q；</p>\n<p>如果p的Finger table第一个结点就比k还大，即：</p>\n<script type=\"math/tex; mode=display\">\np<k<FT_p[1]</script><p>那么就转发给$FT_p[1]$结点，此节点负责结点k，将k的地址返回给结点p。</p>\n<p><strong>例：</strong></p>\n<p>还是上面那个图</p>\n<p>从结点1开始解析k=26：</p>\n<ol>\n<li>结点1的指状表里，$FT_1[5]$=18≤26，将请求转发给18；</li>\n<li>结点18的指状表里，$FT_{18}[2]$=20≤26&lt;$FT_{18}[3]$=28，将请求转发给20；</li>\n<li>结点20的指状表里，$FT_{20}[1]$=21≤26&lt;$FT_{20}[2]$=28，将请求转发给21；</li>\n<li>结点21的指状表里，21&lt;26&lt;$FT_{21}[1]$=28，将请求转发给28，该结点负责解析k=26；</li>\n</ol>\n<p>从结点28开始解析k=12：</p>\n<ol>\n<li>结点28的指状表里，$FT_{28}[4]$=4≤12&lt;$FT_{28}[5]$=14，将请求转发给4；</li>\n<li>结点4的指状表里，$FT_{4}[4]$=9≤12&lt;$FT_{4}[4]$=14，将请求转发给9；</li>\n<li>结点9的指状表里，$FT_{9}[2]$=11≤12&lt;$FT_{9}[3]$=14，将请求转发给11；</li>\n<li>结点11的指状表里，11&lt;12&lt;$FT_{11}[1]$=14，将请求转发给14，该结点负责解析k=12；</li>\n</ol>\n<h3 id=\"HLS\"><a href=\"#HLS\" class=\"headerlink\" title=\"HLS\"></a>HLS</h3><p>网络被划分为一组域。每个域D都有关联的目录节点dir(D)，dir(D)会跟踪域中的实体，形成一颗目录结点树。</p>\n<h3 id=\"HLS结构\"><a href=\"#HLS结构\" class=\"headerlink\" title=\"HLS结构\"></a>HLS结构</h3><p>看下面这个图来解释一下HLS吧：</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302165702511.png\" class=\"\" title=\"image-20240302165702511\">\n<p>为了跟踪实体E的位置，实体E位于域S中，所以域S的目录结点N含有E在该域中的位置信息。</p>\n<p>而在比域S更高一级的域T中，域T的目录结点N’也有实体E的位置信息，但是这个位置信息只有N的指针，也就是要找实体E，就先去找到其子域的目录结点N，然后通过目录节点N找到E。</p>\n<p>同理，在比域T更大的域中，那个域的目录节点也有实体E的位置信息，不过这个位置信息只有N’的指针，要找实体E，就要先找N’，然后找到N，最后找到E。</p>\n<p>所以顶级域的目录结点，即根（目录）节点，包括全部实体位置信息。</p>\n<h3 id=\"如果一个实体有多个地址\"><a href=\"#如果一个实体有多个地址\" class=\"headerlink\" title=\"如果一个实体有多个地址\"></a>如果一个实体有多个地址</h3><p>实体可以拥有多个地址，比如被复制了，实体在域D1和域D2中都有地址，那么同时包含D1和D2的最小域目录结点将有两个指针，每个指针都指向一个包含地址的子域。</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302165713656.png\" class=\"\" title=\"image-20240302165713656\">\n<h3 id=\"HLS查询操作\"><a href=\"#HLS查询操作\" class=\"headerlink\" title=\"HLS查询操作\"></a>HLS查询操作</h3><img src=\"/2023/03/02/distributed-system/image-20240302165721466.png\" class=\"\" title=\"image-20240302165721466\">\n<p>现在希望能定位实体E的位置信息，那么就向当前域的目录结点发送查找请求：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\"><span class=\"hljs-keyword\">if</span> 目录结点找到了实体E的位置信息:<br>\t<span class=\"hljs-keyword\">if</span> 找到的是子域目录结点的地址<br>\t\t把查找请求转发给子域的目录结点<br>\t<span class=\"hljs-keyword\">else</span> <br>\t\t找到了叶节点，把地址返回给请求的客户<br><span class=\"hljs-keyword\">else</span><br>\t把查找请求转发给父节点<br></code></pre></td></tr></table></figure>\n<p>最差情况是一直找不到，向上转发直到根节点。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><h3 id=\"分布式系统的定义\"><a href=\"#分布式系统的定义\" class=\"headerlink\" title=\"分布式系统的定义\"></a>分布式系统的定义</h3><blockquote>\n<p>分布式系统是若干独立计算机的集合，这些计算机对于用户来说，像是单个相关系统</p>\n</blockquote>\n<ul>\n<li>重要特性<ul>\n<li>各种计算机之间的差别以及计算机之间的通信方式的差别对用户是隐藏的</li>\n<li>用户看不到分布式系统的内部组织结构</li>\n<li>用户和应用程序无论在何时何地都能够以一种一致和同意的方式与分布式系统进行交互</li>\n<li>分布式系统的拓展或者升级应该时相对比较容易的</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的目标\"><a href=\"#分布式系统的目标\" class=\"headerlink\" title=\"分布式系统的目标\"></a>分布式系统的目标</h3><ul>\n<li>使资源可访问（资源共享）</li>\n<li>透明性</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221126155708747.png\" class=\"\" title=\"image-20221126155708747\">\n<img src=\"/2023/03/02/distributed-system/image-20221126155754925.png\" class=\"\" title=\"image-20221126155754925\">\n<ul>\n<li><p>开放性（openess）</p>\n<blockquote>\n<p>根据一系列准则来提供服务，这些准则描述了所提供服务的语义和语法。</p>\n<p>在分布式系统中，服务通常时通过接口指定的，接口时通过接口定义语言来描述的。</p>\n<p>开放的分布式系统应该时可扩展的。</p>\n</blockquote>\n<ul>\n<li>完整性：完成接口实现不可少的内容都已经规定好了</li>\n<li>中立性：开发人员能够添加针对特定实现的细节</li>\n<li>互操作性：来自不同厂商的系统或组件的两种实现能够在何种程度上共存并且协同工作</li>\n<li>可移植性：如果分布式系统A开发了某个应用，并且另一个分布式系统B与A具有相同的接口，该程序在不做修改在B上执行的可行程度</li>\n</ul>\n</li>\n<li><p>可扩展性（scale in distributed system）scalablity</p>\n<blockquote>\n<p>可扩展性通常可以从三个方面来度量，规模上可扩展（size）、地域上可扩展（geographical）、管理上可扩展（administrative）</p>\n</blockquote>\n<ul>\n<li><p>规模上可拓展存在的问题</p>\n<ul>\n<li>受集中式的服务、数据以及算法限制</li>\n<li>集中式算法与分布式算法的对比</li>\n</ul>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">分布式算法不同特性<br>1、没有任何计算机拥有关于系统状态的完整信息<br>2、计算机只根据本地信息做出决策<br>3、某台计算机的故障不会使算法奔溃<br>4、没有全局性时钟，来统一设定时间<br></code></pre></td></tr></table></figure>\n</li>\n<li><p>地域上可扩展存在的问题</p>\n<ul>\n<li>基于同步的通信，在请求服务的一方得到回应之前都是处于阻塞状态，在局域网中速度快，广域网中很慢</li>\n<li>广域网中的通信是不可靠的，都是点对点的</li>\n<li>如何对一个跨越多个独立管理域的分布式系统进行拓展</li>\n</ul>\n</li>\n<li><p>管理上可扩展存在的问题</p>\n<ul>\n<li>资源使用（以及付费）、管理和安全问题上，不同的管理域之间有着相互冲突的问题</li>\n</ul>\n</li>\n<li><p>拓展技术</p>\n<blockquote>\n<p>拓展技术基本上只有三种技术：隐藏通信等待时间、分布技术以及复制技术</p>\n</blockquote>\n<ul>\n<li>隐藏通信等待时间：尽量避免远程服务对请求的响应，实质上是异步通信。也可以将服务器上的部分任务交由客户端完成。</li>\n<li>分布技术： 把某个组件分割成多个部分，再将他们分散到系统中，如DNS。</li>\n<li>复制技术：会产生一致性问题。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的类型\"><a href=\"#分布式系统的类型\" class=\"headerlink\" title=\"分布式系统的类型\"></a>分布式系统的类型</h3><blockquote>\n<p>分布式计算系统、分布式信息系统、分布式嵌入系统</p>\n</blockquote>\n<ul>\n<li><p>分布式计算系统（高性能的分布式系统）</p>\n<ul>\n<li><p>集群计算系统</p>\n<blockquote>\n<p>同构性：集群中的计算机大多数是相同的。相同的操作系统，同一网络。</p>\n</blockquote>\n<ul>\n<li>单个主节点，多个从节点，主节点可访问控制群（从节点）</li>\n<li>主节点：负责对特定并行程序的结点定位，维护已经提交的工作队列，为系统用户提供接口</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130091729650.png\" class=\"\" title=\"image-20221130091729650\">\n</li>\n<li><p>网格计算系统</p>\n<blockquote>\n<p>具有高度的异构性：硬件，操作系统，网络，管理域和安全策略都不尽相同</p>\n</blockquote>\n<ul>\n<li>解决异构性的方式：虚拟组织</li>\n<li>光纤层：在特定站点提供对局部资源的接口</li>\n<li>连接层：由通信协议组成，用于支持网格事务处理</li>\n<li>资源层：负责管理单个资源</li>\n<li>汇集层：负责处理对多个资源的访问</li>\n<li>应用层：由应用程序组成，在虚拟组织中运行</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130092344725.png\" class=\"\" title=\"image-20221130092344725\">\n</li>\n</ul>\n</li>\n<li><p>分布式信息系统</p>\n</li>\n<li><p>分布式普适系统</p>\n</li>\n</ul>\n<h2 id=\"体系结构\"><a href=\"#体系结构\" class=\"headerlink\" title=\"体系结构\"></a>体系结构</h2><h3 id=\"体系结构的样式\"><a href=\"#体系结构的样式\" class=\"headerlink\" title=\"体系结构的样式\"></a>体系结构的样式</h3><blockquote>\n<p>体系结构样式是根据组件，组件之间互相连接方式、组件之间的数据交换以及这些元素如何集成到一个系统中来定义的。</p>\n</blockquote>\n<ul>\n<li><p>分层体系结构</p>\n</li>\n<li><p>基于对象的体系结构</p>\n<ul>\n<li>每个对象对应一个组件，组件通过远程过程调用机制来连接</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130094553260.png\" class=\"\" title=\"image-20221130094553260\">\n</li>\n<li><p>以数据为中心的体系结构</p>\n<ul>\n<li>进程通信需要通过一个公用仓库</li>\n</ul>\n</li>\n<li><p>基于事件的体系结构</p>\n<ul>\n<li>进程发布事件，中间件确保订阅了这些事件的进程接收它们。去耦合强。</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130101949954.png\" class=\"\" title=\"image-20221130101949954\">\n</li>\n</ul>\n<h3 id=\"系统体系结构\"><a href=\"#系统体系结构\" class=\"headerlink\" title=\"系统体系结构\"></a>系统体系结构</h3><ul>\n<li><p>集中式体系结构（客户—服务器）</p>\n<ul>\n<li><p>应用分层</p>\n<ul>\n<li>应用层：提供与用户交互的接口</li>\n<li>处理层：处理用户的请求，实现与数据的交互</li>\n<li>数据层：存储数据，如，文件系统，数据库</li>\n</ul>\n</li>\n<li><p>多层体系结构</p>\n<ul>\n<li>两层体系结构：客户机和服务器<ul>\n<li>根据将客户机和服务器实现的不同功能可以分为以下5种，d和e较为普遍</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130101048848.png\" class=\"\" title=\"image-20221130101048848\">\n<ul>\n<li><p>三层体系结构：用户接口、应用程序服务器、数据库服务器</p>\n<img src=\"/2023/03/02/distributed-system/image-20221130102217372.png\" class=\"\" title=\"image-20221130102217372\">\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>非集中式体系结构（回头听一听课）点对点</p>\n<p>垂直分布性（分层）：按逻辑把不同组件放在不同机器上</p>\n<p>水平分布性：客户和服务器可能在物理上被分割成逻辑上相等的几个部分，但每个部分都操作在整个数据集中自己共享的部分，从而实现负载均衡。例如点对点系统</p>\n<ul>\n<li><p>结构化的点对点体系结构</p>\n<ul>\n<li>Chord系统分布式哈希表（后面章节）理解加入和退出</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130140722941.png\" class=\"\" title=\"image-20221130140722941\">\n<ul>\n<li>CAN：上下文可编制网络（后面章节）</li>\n</ul>\n</li>\n<li><p>非结构化点对点体系结构</p>\n<blockquote>\n<p>主要依靠随机化算法来构造覆盖网络，每个节点维护一个邻接点列表，列表由随机的方法来构造。使用泛洪法来查找。</p>\n</blockquote>\n</li>\n<li><p>覆盖网络的拓扑管理</p>\n</li>\n<li><p>超级对等体</p>\n</li>\n</ul>\n</li>\n<li><p>混合体系结构</p>\n<blockquote>\n<p>特殊的分布式系统，将客户服务器体系结构和非集中式体系结构组合在一起</p>\n</blockquote>\n<ul>\n<li><p>边界服务器系统</p>\n</li>\n<li><p>协作分布式系统</p>\n<ul>\n<li><p>文件共享系统</p>\n<blockquote>\n<p>是一种点对点的文件下载系统，一个用户从其他用户下载文件块，知道所下载的文件块能够组装成完整的文件。一旦结点确定了从哪里可以下载文件块，下载结点将被强制为其他节点提供帮助。瓶颈期在于跟踪器。</p>\n</blockquote>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130143607842.png\" class=\"\" title=\"image-20221130143607842\">\n<ul>\n<li>协作内容分布式网络Globule</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"体系结构与中间件\"><a href=\"#体系结构与中间件\" class=\"headerlink\" title=\"体系结构与中间件\"></a>体系结构与中间件</h3><blockquote>\n<p>中间件具有一定程度的透明性，一定程度上向应用程序隐藏了数据处理和控制的分布性</p>\n</blockquote>\n<ul>\n<li><p>中断器</p>\n<blockquote>\n<p>是一种软件结构，能中断正常的控制流，从而允许其他代码运行。</p>\n</blockquote>\n<ul>\n<li>请求级中断器：为每个副本调用invoke函数</li>\n<li>消息级中断器：协助把消息传递接口激活转移给目标对象</li>\n</ul>\n</li>\n<li><p>自适应软件常见方法（基本技术）</p>\n<ul>\n<li>要点分离</li>\n<li>计算映像：程序检查自己</li>\n<li>基于组件的设计：通过组件的不同组合来支持自适应</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分布式系统的自我管理\"><a href=\"#分布式系统的自我管理\" class=\"headerlink\" title=\"分布式系统的自我管理\"></a>分布式系统的自我管理</h3><blockquote>\n<p>以高级反馈控制系统的形式来组织分布式系统，允许自动自适应变化。称为自治计算或自主系统。</p>\n</blockquote>\n<p>自适应的多样性：自我管理、自我恢复、自我配置、自我优化</p>\n<ul>\n<li><p>反馈控制模型：通过反馈控制循环实现</p>\n<ul>\n<li>形成反馈控制循环的三个元素<ul>\n<li>系统本身需要被监视：对系统的各个方面进行测量（尺度预测组件）</li>\n<li>分析上述测量值：控制循环的核心部分，包含决定自适应的算法（反馈分析组件）</li>\n<li>其他组件</li>\n</ul>\n</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221130151005907.png\" class=\"\" title=\"image-20221130151005907\">\n</li>\n</ul>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><h3 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h3><blockquote>\n<p>就粒度而言，将每个进程细分为若干控制线程的形式更加合适，可以使构建分布式应用程序变得更加方便，并可获得更好的性能。</p>\n</blockquote>\n<ul>\n<li><p>线程简介</p>\n<blockquote>\n<p>线程上下文中一般值包含CPU上下文以及某些其他线程管理信息。</p>\n</blockquote>\n<ul>\n<li><p>非分布式系统中线程用法，好处</p>\n<ul>\n<li>多线程的系统中，线程阻塞不会造成进程阻塞</li>\n<li>在多处理系统上执行多线程程序时，可以使用并行操作技术</li>\n<li>线程之间的上下文切换小</li>\n</ul>\n</li>\n<li><p>线程的实现</p>\n<blockquote>\n<p>一般以线程包的形式提供，这种包中含有创建和销毁线程的操作。分为用户及线程和内核级线程。</p>\n</blockquote>\n<ul>\n<li>用户级线程的好处<ul>\n<li>创建和销毁线程开销小</li>\n<li>可以通过为数不多的几条指令实现线程上下文切换</li>\n</ul>\n</li>\n<li>用户及线程的缺陷<ul>\n<li>对引起阻塞的系统调用的调用将会立即阻塞该线程所属的整个进程</li>\n</ul>\n</li>\n<li>轻量级进程：使用用户及线程和内核级线程的混合形式</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分布式系统中的线程</p>\n<ul>\n<li><p>多线程客户</p>\n<blockquote>\n<p>隐藏通信事件延迟的方法：启动通信后立即进行其他工作</p>\n</blockquote>\n<ul>\n<li>web浏览器显示HTML页面</li>\n</ul>\n</li>\n<li><p>多线程服务器</p>\n<ul>\n<li>能够保留顺序处理的思路，使用阻塞性的系统调用，并且仍能够达到并行处理的目的</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201100317779.png\" class=\"\" title=\"image-20221201100317779\">\n<p>分发器线程：读取文件操作请求</p>\n<p>工作者线程：处理请求</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"虚拟化\"><a href=\"#虚拟化\" class=\"headerlink\" title=\"虚拟化\"></a>虚拟化</h3><blockquote>\n<p>虚拟化的本质是拓展或替换一个现存界面来模仿另一个系统的行为。</p>\n</blockquote>\n<ul>\n<li><p>虚拟化在分布式系统中的作用</p>\n<ul>\n<li>旧有软件的维护，跟不上下层平台更新的步伐，硬件更新速度太快，需要软件兼容。通过移植旧有软件的底层接口到新平台，虚拟化可以帮助解决这个问题</li>\n<li>虚拟化便于减少服务器和硬件机器的种类和数目，提供了高度的移植性和灵活性</li>\n</ul>\n</li>\n<li><p>虚拟机体系结构</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">在四个不同层次提供四个不同界面<br>由机器指令组成，可由任何程序激起的硬件软件界面<br>由机器指令组成，只有特权程序才可激起的硬件软件界面<br>由操作系统提供的系统调用（<span class=\"hljs-keyword\">system</span> <span class=\"hljs-keyword\">call</span>）组成的界面<br>由库调用组成的界面，通常形成了所谓的应用程序编程接口（API）<br></code></pre></td></tr></table></figure>\n<img src=\"/2023/03/02/distributed-system/image-20221201101403269.png\" class=\"\" title=\"image-20221201101403269\">\n</li>\n</ul>\n<ul>\n<li><p>虚拟化的两种方式</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201101451311.png\" class=\"\" title=\"image-20221201101451311\">\n<ul>\n<li>构建一个运行时的系统，提供一套抽象指令集来执行程序（进程虚拟机）</li>\n<li>提供一种系统，如VMware（虚拟机监视器）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"客户端\"><a href=\"#客户端\" class=\"headerlink\" title=\"客户端\"></a>客户端</h3><ul>\n<li><p>客户端软件与分布式透明性</p>\n<blockquote>\n<p>理论上来说，客户端不应该察觉到它与远程进程的通信，而服务器来说，分布常常不那么透明</p>\n</blockquote>\n<ul>\n<li><p>许多分布式系统利用客户端解决方案来实现复制透明性</p>\n<ul>\n<li>调用请求转发给每一个服务器发送副本来达到复制透明性</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201110722218.png\" class=\"\" title=\"image-20221201110722218\">\n</li>\n<li><p>故障透明性，一般是通过客户中间件完成</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"服务器\"><a href=\"#服务器\" class=\"headerlink\" title=\"服务器\"></a>服务器</h3><ul>\n<li><p>常见的设计问题</p>\n<blockquote>\n<p>服务器的组织方式：等待来自客户的请求，随后负责处理该请求，等待下一个请求</p>\n</blockquote>\n<p>服务器的不同组织结构</p>\n<ul>\n<li><p>迭代服务器：自己处理请求，并且在必要的情况下将响应返回给发出请求的客户</p>\n</li>\n<li><p>并发服务器：并不自己处理请求，而是将请求传递给某个独立线程或其他进程来处理，只用于等待请求。如：多线程服务器。</p>\n</li>\n<li><p>超级服务器：用于负责监听所有与服务关联的端口，缓解了每一个服务器都要对端口监听的浪费。</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201111903470.png\" class=\"\" title=\"image-20221201111903470\">\n</li>\n<li><p>状态无关服务器：不保存客户的状态信息且不将自身状态告知客户</p>\n<ul>\n<li>好处<ul>\n<li>不需要采取任何特殊措施来使得奔溃的服务器恢复，重启即可</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>状态相关服务器：一直保存客户端的信息直到显式的删除</p>\n<ul>\n<li>好处：<ul>\n<li>性能能够提升</li>\n</ul>\n</li>\n<li>缺陷：<ul>\n<li>如果服务器崩溃，就必须恢复客户端的状态表</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>服务器集群</p>\n<blockquote>\n<p>服务器集群式一组经网络连接的机器，每台机器运行一个或多个服务器</p>\n</blockquote>\n<ul>\n<li><p>常见的组织</p>\n<ul>\n<li><p>多数情况下逻辑上由三层组成</p>\n<img src=\"/2023/03/02/distributed-system/image-20221201151303341.png\" class=\"\" title=\"image-20221201151303341\">\n<ul>\n<li><p>（逻辑上的）交换机：分配客户请求给服务器</p>\n<ul>\n<li>作为服务器集群的入口，提供唯一的网络地址</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201152139305.png\" class=\"\" title=\"image-20221201152139305\">\n<ul>\n<li>交换机收到tcp连接请求，将请求分发给最佳服务器，服务器发送应答信号，并嵌入交换器的IP</li>\n</ul>\n</li>\n<li><p>专用的应用/计算处理服务器：提供高性能计算能力</p>\n</li>\n<li><p>文件和数据库服务器（数据存取是瓶颈）</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分布式服务器</p>\n<blockquote>\n<p>分布式服务器是指可动态变化的集群，它的访问点也可以变化，但对外却表现为一台强有力的单台机器。</p>\n</blockquote>\n<ul>\n<li>基本思想：可靠、高性能、稳定</li>\n<li>如何实现一个稳定访问点<ul>\n<li>使用宿主代理（宿主网络的特别的路由器）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>管理服务器集群的方法</p>\n<ul>\n<li>通用方法<ul>\n<li>把传统的单台计算机管理功能拓展到服务器集群，从远程客户登录到集群的一个节点并执行本地管理命令</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"代码迁移\"><a href=\"#代码迁移\" class=\"headerlink\" title=\"代码迁移\"></a>代码迁移</h3><blockquote>\n<p>传递程序，甚至传递正在执行中的程序。</p>\n</blockquote>\n<ul>\n<li><p>代码迁移方案</p>\n<blockquote>\n<p>代码迁移是以进程迁移的形式进行的，代码迁移会带来巨大的开销</p>\n</blockquote>\n<ul>\n<li><p>进行代码迁移的好处</p>\n<ul>\n<li>如果把进程由负载较重的机器上转移负载较轻的机器上，能提升系统的整体性能</li>\n<li>灵活性，如果代码可以在不同的机器之间移动，就可以动态的配置分布式系统</li>\n</ul>\n</li>\n<li><p>代码迁移模型</p>\n<p>进程包含3段：代码段（包含正在运行程序的所有指令），资源段（包含外部资源的指针），执行段（存储进程当前状态）</p>\n<ul>\n<li>弱可移动性：只传输代码段以及初始化数据<ul>\n<li>传输的程序总是从预先定义的位置开始执行。较简单</li>\n</ul>\n</li>\n<li>强可移动性：可以传输执行段<ul>\n<li>可以先停止运行中的进程，然后将它移到另一台机器上去，再从中断的位置继续执行</li>\n</ul>\n</li>\n</ul>\n<p>另一种分类方式</p>\n<ul>\n<li>发送者启动迁移：由正在执行该代码的机器启动迁移</li>\n<li>接收者启动迁移：代码迁移主动权掌握在目标机器手里</li>\n</ul>\n<img src=\"/2023/03/02/distributed-system/image-20221201160233164.png\" class=\"\" title=\"image-20221201160233164\">\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"通信\"><a href=\"#通信\" class=\"headerlink\" title=\"通信\"></a>通信</h2><blockquote>\n<p>四个广泛使用的通信模型：远程过程调用（RPC，remote procedure call）、远程方法调用（RMI，remote method invocation）、面向消息的中间件（MOM，message-oriented middleware）、流（stream）</p>\n<p>RPC的目的在于将消息传递的大部分复杂性隐藏起来，比较适合客户-服务器应用程序。</p>\n</blockquote>\n<ul>\n<li><p>基础知识</p>\n<ul>\n<li>分层协议<ul>\n<li>OSI七层模型：略</li>\n<li>中间件协议：中间件是一种应用程序，位于应用层中</li>\n</ul>\n</li>\n<li>通信类型<ul>\n<li>持久通信：提交传输的消息一直由通信中间件存储，直到消息被传送给接收方</li>\n<li>瞬时通信：通信系统只有在发送和接受应用程序正在运行时才能存储消息</li>\n<li>异步通信（asynchronous）：发送方在提交要传输的消息后立即往下进行</li>\n<li>同步通信（synchronous）：发送方将被阻塞，直到其请求被接受</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>远程过程调用</p>\n<blockquote>\n<p>当机器A上的进程调用机器B上的进程是，A上的调用进程被挂起，而B上的被调用的进程开始执行，调用方可以通过使用参数将信息传给被调用放，然后通过传回的结果得到信息。编程人员看不到任何消息传递过程，这种方法称为远程过程调用</p>\n</blockquote>\n<p>复杂性：地址空间不同、参数和结果的传递、机器如果发生崩溃</p>\n<ul>\n<li>基本的RPC操作</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"命名系统-Naming\"><a href=\"#命名系统-Naming\" class=\"headerlink\" title=\"命名系统 - Naming\"></a>命名系统 - Naming</h2><blockquote>\n<p>命名是在分布式中表示这个实体，且要访问到这个实体。</p>\n</blockquote>\n<ul>\n<li>访问点：用来实体的一种特殊实体。</li>\n<li>地址：访问点的名称。</li>\n</ul>\n<p>所以<strong>访问点</strong>就是实体的<strong>地址</strong>。</p>\n<h3 id=\"DHT\"><a href=\"#DHT\" class=\"headerlink\" title=\"DHT\"></a>DHT</h3><p>全称是Distributed Hash Tables，是P2P环境下最经典的解决方案</p>\n<h3 id=\"Chord\"><a href=\"#Chord\" class=\"headerlink\" title=\"Chord\"></a>Chord</h3><p>使用一个m位的标识符空间，把<strong>随机选择</strong>的标识符赋给结点，并把键值赋值给特定实体（任意的东西，比如文件、进程）。</p>\n<p><strong>构造Finger table算法：</strong></p>\n<p>每个Chord结点维护一个最多有m个实体的指状表(Finger table)，如果用$FT_p[i]$表示结点$p$的指状表，那么有：</p>\n<script type=\"math/tex; mode=display\">\nFT_p[i] = succ(p+2^{(i-1)})</script><p>$-p$是当前结点$-i$是指状表的$index-succ(k)$表示k（若结点k存在）或k的下一个<strong>存在</strong>的结点，即$succ(k)&gt;=k$</p>\n<p>例：</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302163915592.png\" class=\"\" title=\"image-20240302163915592\">\n<p>根据$FT_p[i] = succ(p+2^{(i-1)})$公式，构造结点p=4的Finger table：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">i</th>\n<th style=\"text-align:center\">$FT_p[i]$</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">succ(4+1)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">succ(4+2)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">succ(4+4)=9</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">succ(4+8)=14</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">5</td>\n<td style=\"text-align:center\">succ(4+16)=20</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>解析算法：</strong></p>\n<p>目标：从节点p开始解析key=k的结点</p>\n<p>搜索节点p的Finger table，从上依次向下搜索，如果一个结点q满足：</p>\n<script type=\"math/tex; mode=display\">\nq=FT_p[j]<=k<FT_p[j+1]</script><p>那么就将该请求转发给结点q；</p>\n<p>如果p的Finger table第一个结点就比k还大，即：</p>\n<script type=\"math/tex; mode=display\">\np<k<FT_p[1]</script><p>那么就转发给$FT_p[1]$结点，此节点负责结点k，将k的地址返回给结点p。</p>\n<p><strong>例：</strong></p>\n<p>还是上面那个图</p>\n<p>从结点1开始解析k=26：</p>\n<ol>\n<li>结点1的指状表里，$FT_1[5]$=18≤26，将请求转发给18；</li>\n<li>结点18的指状表里，$FT_{18}[2]$=20≤26&lt;$FT_{18}[3]$=28，将请求转发给20；</li>\n<li>结点20的指状表里，$FT_{20}[1]$=21≤26&lt;$FT_{20}[2]$=28，将请求转发给21；</li>\n<li>结点21的指状表里，21&lt;26&lt;$FT_{21}[1]$=28，将请求转发给28，该结点负责解析k=26；</li>\n</ol>\n<p>从结点28开始解析k=12：</p>\n<ol>\n<li>结点28的指状表里，$FT_{28}[4]$=4≤12&lt;$FT_{28}[5]$=14，将请求转发给4；</li>\n<li>结点4的指状表里，$FT_{4}[4]$=9≤12&lt;$FT_{4}[4]$=14，将请求转发给9；</li>\n<li>结点9的指状表里，$FT_{9}[2]$=11≤12&lt;$FT_{9}[3]$=14，将请求转发给11；</li>\n<li>结点11的指状表里，11&lt;12&lt;$FT_{11}[1]$=14，将请求转发给14，该结点负责解析k=12；</li>\n</ol>\n<h3 id=\"HLS\"><a href=\"#HLS\" class=\"headerlink\" title=\"HLS\"></a>HLS</h3><p>网络被划分为一组域。每个域D都有关联的目录节点dir(D)，dir(D)会跟踪域中的实体，形成一颗目录结点树。</p>\n<h3 id=\"HLS结构\"><a href=\"#HLS结构\" class=\"headerlink\" title=\"HLS结构\"></a>HLS结构</h3><p>看下面这个图来解释一下HLS吧：</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302165702511.png\" class=\"\" title=\"image-20240302165702511\">\n<p>为了跟踪实体E的位置，实体E位于域S中，所以域S的目录结点N含有E在该域中的位置信息。</p>\n<p>而在比域S更高一级的域T中，域T的目录结点N’也有实体E的位置信息，但是这个位置信息只有N的指针，也就是要找实体E，就先去找到其子域的目录结点N，然后通过目录节点N找到E。</p>\n<p>同理，在比域T更大的域中，那个域的目录节点也有实体E的位置信息，不过这个位置信息只有N’的指针，要找实体E，就要先找N’，然后找到N，最后找到E。</p>\n<p>所以顶级域的目录结点，即根（目录）节点，包括全部实体位置信息。</p>\n<h3 id=\"如果一个实体有多个地址\"><a href=\"#如果一个实体有多个地址\" class=\"headerlink\" title=\"如果一个实体有多个地址\"></a>如果一个实体有多个地址</h3><p>实体可以拥有多个地址，比如被复制了，实体在域D1和域D2中都有地址，那么同时包含D1和D2的最小域目录结点将有两个指针，每个指针都指向一个包含地址的子域。</p>\n<img src=\"/2023/03/02/distributed-system/image-20240302165713656.png\" class=\"\" title=\"image-20240302165713656\">\n<h3 id=\"HLS查询操作\"><a href=\"#HLS查询操作\" class=\"headerlink\" title=\"HLS查询操作\"></a>HLS查询操作</h3><img src=\"/2023/03/02/distributed-system/image-20240302165721466.png\" class=\"\" title=\"image-20240302165721466\">\n<p>现在希望能定位实体E的位置信息，那么就向当前域的目录结点发送查找请求：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs actionscript\"><span class=\"hljs-keyword\">if</span> 目录结点找到了实体E的位置信息:<br>\t<span class=\"hljs-keyword\">if</span> 找到的是子域目录结点的地址<br>\t\t把查找请求转发给子域的目录结点<br>\t<span class=\"hljs-keyword\">else</span> <br>\t\t找到了叶节点，把地址返回给请求的客户<br><span class=\"hljs-keyword\">else</span><br>\t把查找请求转发给父节点<br></code></pre></td></tr></table></figure>\n<p>最差情况是一直找不到，向上转发直到根节点。</p>\n"},{"title":"EDA基础知识总结","date":"2023-09-04T08:47:03.000Z","cover":"/img/default_cover11.jpg","top_img":null,"_content":"### 一、布局\n\n#### **布局算法：二次线长布局算法+力矢量布局**\n\n设计目标：调整不同元胞在元胞中的摆放位置，使得元胞在版图中的连线最短，同时确保在布局中没有重叠\n\n> 二次线长布局分为两个阶段\n>\n> 第一阶段：依据元胞的中心对元胞进行布局，从而对二次线长函数最小化\n>\n> 第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有单元原来的重叠消除\n\n```\\\n输入：线网连接，限制的版图区域\n输出：所有元胞的x坐标和y坐标\n```\n\n#### 数据结构设计\n\n1、元胞可以抽象成一个含有x，y坐标的结构体\n\n2、网表抽象为二维map，记录不同元胞之间的连线情况，同时x，y代表元胞在map中所处的位置信息\n\n#### 算法主要思想\n\n**第一阶段：全局布局（二次线长布局）**\n\n> 在全局布局的过程中，将元胞的坐标抽象成为中心点的坐标，不考虑其面积、大小以及布局的合法化，仅仅是以最优化模块之间的线长为目标。\n\n```\n已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。\n求：所有的元胞的x坐标和y坐标。\n\n1、列出所有连接的元胞线网的X的总线长L(p)：所有的x距离的差的平方\n2、分别对所有参数中的x求偏导，并令偏导为0\n3、列出方程组，解出来的x阵列就是所需要求的解\n对于Y方向也是同理\n\n该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题\n```\n\n距离计算代价函数\n\n![image-20230818160028154](eda-summary/image-20230818160028154.png)\n\n通过求偏导数，解出x和y。\n\n**第二阶段：详细布局（力矢量布局）**\n\n> 用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。\n>\n> 采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。**将目标转化为将所有的元胞放在一个力平衡的位置上。**——**称为零力目标**（ZFT）\n\n```\n1、以二次线长布局过后的布局为初始布局\n2、为每个布局中的元胞设定坐标，并标记为UNMOVED\n3、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序\n4、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成\n5、若ZFT位置被占据，则移动到其他的位置\n\n第5步确定p的ZFT时，若ZFT被元胞q占据，则移动位置的确定\n1、如果可能，将p移动到靠近q的位置\n2、若交换p，q后，代价变小，则交换\n3、链式移动，p移动到q，q移动到下一个，以此类推\n4、波状移动，p移动到q，再重新计算q的ZFT\n```\n\nLoss为权重乘以坐标差的累计和\n\n**时间复杂度**\n\n假设元胞的数量为n\n\n二次线长布局的时间复杂度为：O(n^2)，需要遍历一遍map，找到各个节点之间的连线信息\n\n力矢量布局的时间复杂度为：O(n^2)\n\n### 二、布线\n\n#### 布线算法：FLUTE算法\n\n设计目标：找到能将节点连接的最小斯坦纳生成树\n\n> 在EDA的布线中，各个板块的IO接口以及时钟接口之间，通常是走的斯坦纳线，而直接求斯坦纳最小树是NP完全问题，使用FLUTE算法可以将RSMT问题转化为查找表的问题\n\n```\n输入：pin结点，以及结点的位置\n输出：将所有结点连接起来的斯坦纳树\n```\n\n#### 算法数据结构设计\n\n**1、POWV（Potentially optimal wirelength vectors）**\n\n在FLUTE算法中，会使用一种带有信息（权重）的数据结构（向量）来表示一种斯坦纳树，任意一棵斯坦纳树都可以使用唯一的POWV来表示，一个POWV向量可以表示多棵不一样的斯坦纳树，如下图。\n\n> 前面三位表示x方向上的length\n>\n> 后面三位表示y方向上的length\n\n![image-20230828141138808](eda-summary/image-20230828141138808.png)\n\n**2、POST（potentially optimal Steiner tree）**\n\n对每一个POWV都会对应存储一个POST，也就是说，不是存储所有的斯坦纳树，只是存储一个可能的斯坦纳树，因为同一个向量的所有斯坦纳树的代价总和总是一样的。POWV和POST会构建成一个映射关系，同时将其存入到一个Table中，表中还包含POWV的总权重。而此时，权重最小的则可代表一个最小斯坦纳生成树。\n\n**3、table可以使用哈希表来进行设计**\n\n使用POWV做表头，权重和POST作为value，给出节点后，生成所有的可能的POWV表，再通过权重对其进行排序，取其POST作为斯坦纳树结果。\n\n#### 算法主要思想\n\n```\n总体流程：\n所有N点线网根据pin脚的位置都可以划分到n！个group中，每个group中存有POWV，对于一个线网最优线长可由POWV来获得，FLUTE算法首先会预计算这些POWV形成一个查找表。\n与POWV一起存储的还有POST，一个POWV对应多个POST，一个POST只有一个POWV\n基于此，要得到一棵RSMT，只需要计算线网所在的组对应的POWV的线长，然后返回对应的POST即可\n上述查找表算法最高支持9点线网，对于9点以上的需要递归的切分线网\n```\n\n* 生成查找表算法\n\n![image-20230828144127572](eda-summary/image-20230828144127572.png)\n\n#### 时间复杂度\n\n时间复杂度为：O(nlgn)\n\n### 三、静态时序分析\n\n#### 单元库\n\n在静态时序分析中，单元库（library）是指一个集合，其中包含了各种标准的逻辑元件、时序元件和组合元件的建模。单元库中的元件通常带有特定的时钟延迟和逻辑功能，以及电压和温度等方面的参数，通过使用单元库，可以在时序分析中模拟和评估设计的时序特性，以帮助发现和解决潜在的时序冲突和时序失效问题。\n\n#### 互连寄生\n\n互连寄生是指在集成电路或电子系统中，由于导线或连接器的存在，引起的非理想的电特性和效果。主要包括电容和电阻，互连寄生会对电路的信号传输、功耗、噪声和时序等方面产生不良的影响。\n\n电阻寄生：互连导线的电阻会引起信号的衰减和功率损耗。较长的导线通常具有更大的电阻。\n\n电容寄生：互连导线的电容会引起信号的延迟和功耗。电容会存储和释放电荷，导致信号传输速度变慢。\n\n#### 单元时延（NLDM表格）\n\n单元时延（NLDM表格），全称为非线性延迟模型（Non-Linear Delay Model），是一种常用的静态时序分析中的时延模型。在数字电路设计中，时延模型用于描述逻辑元件（如门级电路或时序元件）的输出到输入之间的传播延迟。\n\nNLDM表格是一种常见的时延模型，它以表格的形式表示输入到输出之间的传播延迟。表格的输入是逻辑元件的输入端的不同组合，并且通常包括输入的电压和电流等参数。表格的输出是逻辑元件的输出端的延迟时间，通常以纳秒或皮秒为单位。\n\nNLDM表格通常由电路设计工具根据所用的逻辑元件和工艺库生成。基于这个模型，可以进行静态时序分析，以评估电路的时序性能，如时钟周期、信号传输延迟和时序失效等。\n\n#### 线网时延（Elmore计算）\n\n线网时延，也称为Elmore时延，是一种常用的近似计算方法，用于估计电路中导线上的传播延迟。它是一种简化的时延模型，适用于传输线上电压/电流从输入端到达输出端的时间。\n\n```\nElmore计算基于以下假设和简化：\n1、传输线上的时延主要由传播速度和传输线上的等效电容决定。\n2、传播速度是恒定的，不考虑传输线上的阻抗匹配或反射等因素。\n3、传输线被近似为一系列等效电容连接起来的节点。\n\n根据这些假设，Elmore计算使用以下步骤来估计线网时延：\n1、将电路中的传输线划分为一系列节点，每个节点对应于传输线上一个等效电容。\n2、从输入端开始，依次计算每个节点的时延。每个节点的时延等于前一节点的时延加上当前节点的等效电容与前一节点电流之积。\n3、在达到输出端后，最后一个节点的时延就是整个线网的传播延迟。\n```\n\n#### 串扰噪声的定义\n\n噪声是指电路中任意节点上不希望出现的电压或电流的偏差。当噪声作用于某个电路节点上时，它可以瞬间破坏该节点上存储的逻辑信息。如果这一破坏状态被锁存到锁存器中，那么将会导致功能性错误。\n\n主要有毛刺和延时噪声。\n\n#### 时序检查（Setup/Hold）\n\n时序检查是在数字电路设计中进行的一种重要时序分析，用于验证和确保输入信号在时钟边沿触发时的稳定性和正确性。\n\nSetup Time：是指在时钟边沿到达之前，输入信号必须稳定在其有效值的时间。如果输入信号在设置时间窗口内没有稳定，可能会导致电路中的逻辑冲突和错误。\n\nHold Time：是指在时钟边沿到达之后，输入信号必须继续保持在其有效值的时间。如果输入信号在保持时间之前改变或不稳定，也会导致电路中的逻辑错误。\n\n#### 时序路径定义\n\n时序路径（Timing Path）是指信号从一个寄存器节点（如时钟触发器）通过逻辑路径传播到另一个寄存器节点的路径。它描述了数据在电路中的传输和处理过程，并对时序分析和时序优化提供了重要信息。\n\n通过分析时序路径，可以确定信号在路径中的传播延迟，包括设置时间和保持时间等重要时序要求。时序路径分析可用于预测时钟频率、检测时序冲突、优化时序性能，以及验证设计是否满足时序规约等。\n\n#### 时序约束命令\n\n![image-20230818170602715](eda-summary/image-20230818170602715.png)\n\n### 四、EDA性能\n\n* 解决EDA软件中的性能问题\n\n  算法：优化数据结构，提高算法性能，降低算法的复杂度\n\n  硬件：确保计算机的硬件资源重组，对于一些矩阵操作可以考虑使用GPU加速\n\n  分布式：将问题拆解成可以并行计算的小问题，开发支持并行计算的EDA工具\n\n\n### 五、EDA后端\n\n* EDA后端软件开发的流程\n\n![](eda-summary/EDA流程.jpg)\n\n### 六、EDA工具\n\n* 常见的EDA仿真工具和Debug工具分别有哪些？它们有什么优势和不足？\n\n  仿真工具：\n\n  - ModelSim/QuestaSim (Mentor)\n  - VCS (Synopsys)\n  - Xilinx Vivado Simulator (Xilinx)\n  - Incisive (Cadence)\n  - Icarus Verilog\n\n  优势：\n\n  - 高度准确和精确的模拟功能。\n  - 可以模拟各种不同级别的设计，从门级仿真到系统级仿真。\n  - 支持时序和功能仿真，可以检测和调试设计中的逻辑错误和时序问题。\n\n  不足：\n\n  - 仿真时间较长，尤其是对于大型和复杂的设计。\n  - 需要大量的计算资源（CPU和内存）。\n  - 对于某些特定的设计场景，可能需要针对特定工具进行配置和优化。","source":"_posts/eda-summary.md","raw":"---\ntitle: EDA基础知识总结\ncategories: 学习笔记\ndate: 2023-09-04 16:47:03\ntags: [EDA, 布局, 布线, 物理设计]\ncover:\ntop_img:\n---\n### 一、布局\n\n#### **布局算法：二次线长布局算法+力矢量布局**\n\n设计目标：调整不同元胞在元胞中的摆放位置，使得元胞在版图中的连线最短，同时确保在布局中没有重叠\n\n> 二次线长布局分为两个阶段\n>\n> 第一阶段：依据元胞的中心对元胞进行布局，从而对二次线长函数最小化\n>\n> 第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有单元原来的重叠消除\n\n```\\\n输入：线网连接，限制的版图区域\n输出：所有元胞的x坐标和y坐标\n```\n\n#### 数据结构设计\n\n1、元胞可以抽象成一个含有x，y坐标的结构体\n\n2、网表抽象为二维map，记录不同元胞之间的连线情况，同时x，y代表元胞在map中所处的位置信息\n\n#### 算法主要思想\n\n**第一阶段：全局布局（二次线长布局）**\n\n> 在全局布局的过程中，将元胞的坐标抽象成为中心点的坐标，不考虑其面积、大小以及布局的合法化，仅仅是以最优化模块之间的线长为目标。\n\n```\n已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。\n求：所有的元胞的x坐标和y坐标。\n\n1、列出所有连接的元胞线网的X的总线长L(p)：所有的x距离的差的平方\n2、分别对所有参数中的x求偏导，并令偏导为0\n3、列出方程组，解出来的x阵列就是所需要求的解\n对于Y方向也是同理\n\n该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题\n```\n\n距离计算代价函数\n\n![image-20230818160028154](eda-summary/image-20230818160028154.png)\n\n通过求偏导数，解出x和y。\n\n**第二阶段：详细布局（力矢量布局）**\n\n> 用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。\n>\n> 采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。**将目标转化为将所有的元胞放在一个力平衡的位置上。**——**称为零力目标**（ZFT）\n\n```\n1、以二次线长布局过后的布局为初始布局\n2、为每个布局中的元胞设定坐标，并标记为UNMOVED\n3、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序\n4、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成\n5、若ZFT位置被占据，则移动到其他的位置\n\n第5步确定p的ZFT时，若ZFT被元胞q占据，则移动位置的确定\n1、如果可能，将p移动到靠近q的位置\n2、若交换p，q后，代价变小，则交换\n3、链式移动，p移动到q，q移动到下一个，以此类推\n4、波状移动，p移动到q，再重新计算q的ZFT\n```\n\nLoss为权重乘以坐标差的累计和\n\n**时间复杂度**\n\n假设元胞的数量为n\n\n二次线长布局的时间复杂度为：O(n^2)，需要遍历一遍map，找到各个节点之间的连线信息\n\n力矢量布局的时间复杂度为：O(n^2)\n\n### 二、布线\n\n#### 布线算法：FLUTE算法\n\n设计目标：找到能将节点连接的最小斯坦纳生成树\n\n> 在EDA的布线中，各个板块的IO接口以及时钟接口之间，通常是走的斯坦纳线，而直接求斯坦纳最小树是NP完全问题，使用FLUTE算法可以将RSMT问题转化为查找表的问题\n\n```\n输入：pin结点，以及结点的位置\n输出：将所有结点连接起来的斯坦纳树\n```\n\n#### 算法数据结构设计\n\n**1、POWV（Potentially optimal wirelength vectors）**\n\n在FLUTE算法中，会使用一种带有信息（权重）的数据结构（向量）来表示一种斯坦纳树，任意一棵斯坦纳树都可以使用唯一的POWV来表示，一个POWV向量可以表示多棵不一样的斯坦纳树，如下图。\n\n> 前面三位表示x方向上的length\n>\n> 后面三位表示y方向上的length\n\n![image-20230828141138808](eda-summary/image-20230828141138808.png)\n\n**2、POST（potentially optimal Steiner tree）**\n\n对每一个POWV都会对应存储一个POST，也就是说，不是存储所有的斯坦纳树，只是存储一个可能的斯坦纳树，因为同一个向量的所有斯坦纳树的代价总和总是一样的。POWV和POST会构建成一个映射关系，同时将其存入到一个Table中，表中还包含POWV的总权重。而此时，权重最小的则可代表一个最小斯坦纳生成树。\n\n**3、table可以使用哈希表来进行设计**\n\n使用POWV做表头，权重和POST作为value，给出节点后，生成所有的可能的POWV表，再通过权重对其进行排序，取其POST作为斯坦纳树结果。\n\n#### 算法主要思想\n\n```\n总体流程：\n所有N点线网根据pin脚的位置都可以划分到n！个group中，每个group中存有POWV，对于一个线网最优线长可由POWV来获得，FLUTE算法首先会预计算这些POWV形成一个查找表。\n与POWV一起存储的还有POST，一个POWV对应多个POST，一个POST只有一个POWV\n基于此，要得到一棵RSMT，只需要计算线网所在的组对应的POWV的线长，然后返回对应的POST即可\n上述查找表算法最高支持9点线网，对于9点以上的需要递归的切分线网\n```\n\n* 生成查找表算法\n\n![image-20230828144127572](eda-summary/image-20230828144127572.png)\n\n#### 时间复杂度\n\n时间复杂度为：O(nlgn)\n\n### 三、静态时序分析\n\n#### 单元库\n\n在静态时序分析中，单元库（library）是指一个集合，其中包含了各种标准的逻辑元件、时序元件和组合元件的建模。单元库中的元件通常带有特定的时钟延迟和逻辑功能，以及电压和温度等方面的参数，通过使用单元库，可以在时序分析中模拟和评估设计的时序特性，以帮助发现和解决潜在的时序冲突和时序失效问题。\n\n#### 互连寄生\n\n互连寄生是指在集成电路或电子系统中，由于导线或连接器的存在，引起的非理想的电特性和效果。主要包括电容和电阻，互连寄生会对电路的信号传输、功耗、噪声和时序等方面产生不良的影响。\n\n电阻寄生：互连导线的电阻会引起信号的衰减和功率损耗。较长的导线通常具有更大的电阻。\n\n电容寄生：互连导线的电容会引起信号的延迟和功耗。电容会存储和释放电荷，导致信号传输速度变慢。\n\n#### 单元时延（NLDM表格）\n\n单元时延（NLDM表格），全称为非线性延迟模型（Non-Linear Delay Model），是一种常用的静态时序分析中的时延模型。在数字电路设计中，时延模型用于描述逻辑元件（如门级电路或时序元件）的输出到输入之间的传播延迟。\n\nNLDM表格是一种常见的时延模型，它以表格的形式表示输入到输出之间的传播延迟。表格的输入是逻辑元件的输入端的不同组合，并且通常包括输入的电压和电流等参数。表格的输出是逻辑元件的输出端的延迟时间，通常以纳秒或皮秒为单位。\n\nNLDM表格通常由电路设计工具根据所用的逻辑元件和工艺库生成。基于这个模型，可以进行静态时序分析，以评估电路的时序性能，如时钟周期、信号传输延迟和时序失效等。\n\n#### 线网时延（Elmore计算）\n\n线网时延，也称为Elmore时延，是一种常用的近似计算方法，用于估计电路中导线上的传播延迟。它是一种简化的时延模型，适用于传输线上电压/电流从输入端到达输出端的时间。\n\n```\nElmore计算基于以下假设和简化：\n1、传输线上的时延主要由传播速度和传输线上的等效电容决定。\n2、传播速度是恒定的，不考虑传输线上的阻抗匹配或反射等因素。\n3、传输线被近似为一系列等效电容连接起来的节点。\n\n根据这些假设，Elmore计算使用以下步骤来估计线网时延：\n1、将电路中的传输线划分为一系列节点，每个节点对应于传输线上一个等效电容。\n2、从输入端开始，依次计算每个节点的时延。每个节点的时延等于前一节点的时延加上当前节点的等效电容与前一节点电流之积。\n3、在达到输出端后，最后一个节点的时延就是整个线网的传播延迟。\n```\n\n#### 串扰噪声的定义\n\n噪声是指电路中任意节点上不希望出现的电压或电流的偏差。当噪声作用于某个电路节点上时，它可以瞬间破坏该节点上存储的逻辑信息。如果这一破坏状态被锁存到锁存器中，那么将会导致功能性错误。\n\n主要有毛刺和延时噪声。\n\n#### 时序检查（Setup/Hold）\n\n时序检查是在数字电路设计中进行的一种重要时序分析，用于验证和确保输入信号在时钟边沿触发时的稳定性和正确性。\n\nSetup Time：是指在时钟边沿到达之前，输入信号必须稳定在其有效值的时间。如果输入信号在设置时间窗口内没有稳定，可能会导致电路中的逻辑冲突和错误。\n\nHold Time：是指在时钟边沿到达之后，输入信号必须继续保持在其有效值的时间。如果输入信号在保持时间之前改变或不稳定，也会导致电路中的逻辑错误。\n\n#### 时序路径定义\n\n时序路径（Timing Path）是指信号从一个寄存器节点（如时钟触发器）通过逻辑路径传播到另一个寄存器节点的路径。它描述了数据在电路中的传输和处理过程，并对时序分析和时序优化提供了重要信息。\n\n通过分析时序路径，可以确定信号在路径中的传播延迟，包括设置时间和保持时间等重要时序要求。时序路径分析可用于预测时钟频率、检测时序冲突、优化时序性能，以及验证设计是否满足时序规约等。\n\n#### 时序约束命令\n\n![image-20230818170602715](eda-summary/image-20230818170602715.png)\n\n### 四、EDA性能\n\n* 解决EDA软件中的性能问题\n\n  算法：优化数据结构，提高算法性能，降低算法的复杂度\n\n  硬件：确保计算机的硬件资源重组，对于一些矩阵操作可以考虑使用GPU加速\n\n  分布式：将问题拆解成可以并行计算的小问题，开发支持并行计算的EDA工具\n\n\n### 五、EDA后端\n\n* EDA后端软件开发的流程\n\n![](eda-summary/EDA流程.jpg)\n\n### 六、EDA工具\n\n* 常见的EDA仿真工具和Debug工具分别有哪些？它们有什么优势和不足？\n\n  仿真工具：\n\n  - ModelSim/QuestaSim (Mentor)\n  - VCS (Synopsys)\n  - Xilinx Vivado Simulator (Xilinx)\n  - Incisive (Cadence)\n  - Icarus Verilog\n\n  优势：\n\n  - 高度准确和精确的模拟功能。\n  - 可以模拟各种不同级别的设计，从门级仿真到系统级仿真。\n  - 支持时序和功能仿真，可以检测和调试设计中的逻辑错误和时序问题。\n\n  不足：\n\n  - 仿真时间较长，尤其是对于大型和复杂的设计。\n  - 需要大量的计算资源（CPU和内存）。\n  - 对于某些特定的设计场景，可能需要针对特定工具进行配置和优化。","slug":"eda-summary","published":1,"updated":"2024-06-05T09:03:03.775Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttv002f08jv8fih51z5","content":"<h3 id=\"一、布局\"><a href=\"#一、布局\" class=\"headerlink\" title=\"一、布局\"></a>一、布局</h3><h4 id=\"布局算法：二次线长布局算法-力矢量布局\"><a href=\"#布局算法：二次线长布局算法-力矢量布局\" class=\"headerlink\" title=\"布局算法：二次线长布局算法+力矢量布局\"></a><strong>布局算法：二次线长布局算法+力矢量布局</strong></h4><p>设计目标：调整不同元胞在元胞中的摆放位置，使得元胞在版图中的连线最短，同时确保在布局中没有重叠</p>\n<blockquote>\n<p>二次线长布局分为两个阶段</p>\n<p>第一阶段：依据元胞的中心对元胞进行布局，从而对二次线长函数最小化</p>\n<p>第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有单元原来的重叠消除</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs \\\">输入：线网连接，限制的版图区域<br>输出：所有元胞的x坐标和y坐标<br></code></pre></td></tr></table></figure>\n<h4 id=\"数据结构设计\"><a href=\"#数据结构设计\" class=\"headerlink\" title=\"数据结构设计\"></a>数据结构设计</h4><p>1、元胞可以抽象成一个含有x，y坐标的结构体</p>\n<p>2、网表抽象为二维map，记录不同元胞之间的连线情况，同时x，y代表元胞在map中所处的位置信息</p>\n<h4 id=\"算法主要思想\"><a href=\"#算法主要思想\" class=\"headerlink\" title=\"算法主要思想\"></a>算法主要思想</h4><p><strong>第一阶段：全局布局（二次线长布局）</strong></p>\n<blockquote>\n<p>在全局布局的过程中，将元胞的坐标抽象成为中心点的坐标，不考虑其面积、大小以及布局的合法化，仅仅是以最优化模块之间的线长为目标。</p>\n</blockquote>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。<br>求：所有的元胞的<span class=\"hljs-keyword\">x</span>坐标和y坐标。<br><br><span class=\"hljs-number\">1</span>、列出所有连接的元胞线网的X的总线长L(p)：所有的<span class=\"hljs-keyword\">x</span>距离的差的平方<br><span class=\"hljs-number\">2</span>、分别对所有参数中的<span class=\"hljs-keyword\">x</span>求偏导，并令偏导为<span class=\"hljs-number\">0</span><br><span class=\"hljs-number\">3</span>、列出方程组，解出来的<span class=\"hljs-keyword\">x</span>阵列就是所需要求的解<br>对于Y方向也是同理<br><br>该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题<br></code></pre></td></tr></table></figure>\n<p>距离计算代价函数</p>\n<img src=\"/2023/09/04/eda-summary/image-20230818160028154.png\" class=\"\" title=\"image-20230818160028154\">\n<p>通过求偏导数，解出x和y。</p>\n<p><strong>第二阶段：详细布局（力矢量布局）</strong></p>\n<blockquote>\n<p>用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。</p>\n<p>采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。<strong>将目标转化为将所有的元胞放在一个力平衡的位置上。</strong>——<strong>称为零力目标</strong>（ZFT）</p>\n</blockquote>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-number\">1</span>、以二次线长布局过后的布局为初始布局<br><span class=\"hljs-number\">2</span>、为每个布局中的元胞设定坐标，并标记为UNMOVED<br><span class=\"hljs-number\">3</span>、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序<br><span class=\"hljs-number\">4</span>、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成<br><span class=\"hljs-number\">5</span>、若ZFT位置被占据，则移动到其他的位置<br><br>第<span class=\"hljs-number\">5</span>步确定<span class=\"hljs-selector-tag\">p</span>的ZFT时，若ZFT被元胞<span class=\"hljs-selector-tag\">q</span>占据，则移动位置的确定<br><span class=\"hljs-number\">1</span>、如果可能，将<span class=\"hljs-selector-tag\">p</span>移动到靠近<span class=\"hljs-selector-tag\">q</span>的位置<br><span class=\"hljs-number\">2</span>、若交换<span class=\"hljs-selector-tag\">p</span>，<span class=\"hljs-selector-tag\">q</span>后，代价变小，则交换<br><span class=\"hljs-number\">3</span>、链式移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，<span class=\"hljs-selector-tag\">q</span>移动到下一个，以此类推<br><span class=\"hljs-number\">4</span>、波状移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，再重新计算<span class=\"hljs-selector-tag\">q</span>的ZFT<br></code></pre></td></tr></table></figure>\n<p>Loss为权重乘以坐标差的累计和</p>\n<p><strong>时间复杂度</strong></p>\n<p>假设元胞的数量为n</p>\n<p>二次线长布局的时间复杂度为：O(n^2)，需要遍历一遍map，找到各个节点之间的连线信息</p>\n<p>力矢量布局的时间复杂度为：O(n^2)</p>\n<h3 id=\"二、布线\"><a href=\"#二、布线\" class=\"headerlink\" title=\"二、布线\"></a>二、布线</h3><h4 id=\"布线算法：FLUTE算法\"><a href=\"#布线算法：FLUTE算法\" class=\"headerlink\" title=\"布线算法：FLUTE算法\"></a>布线算法：FLUTE算法</h4><p>设计目标：找到能将节点连接的最小斯坦纳生成树</p>\n<blockquote>\n<p>在EDA的布线中，各个板块的IO接口以及时钟接口之间，通常是走的斯坦纳线，而直接求斯坦纳最小树是NP完全问题，使用FLUTE算法可以将RSMT问题转化为查找表的问题</p>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">输入：pin结点，以及结点的位置<br>输出：将所有结点连接起来的斯坦纳树<br></code></pre></td></tr></table></figure>\n<h4 id=\"算法数据结构设计\"><a href=\"#算法数据结构设计\" class=\"headerlink\" title=\"算法数据结构设计\"></a>算法数据结构设计</h4><p><strong>1、POWV（Potentially optimal wirelength vectors）</strong></p>\n<p>在FLUTE算法中，会使用一种带有信息（权重）的数据结构（向量）来表示一种斯坦纳树，任意一棵斯坦纳树都可以使用唯一的POWV来表示，一个POWV向量可以表示多棵不一样的斯坦纳树，如下图。</p>\n<blockquote>\n<p>前面三位表示x方向上的length</p>\n<p>后面三位表示y方向上的length</p>\n</blockquote>\n<img src=\"/2023/09/04/eda-summary/image-20230828141138808.png\" class=\"\" title=\"image-20230828141138808\">\n<p><strong>2、POST（potentially optimal Steiner tree）</strong></p>\n<p>对每一个POWV都会对应存储一个POST，也就是说，不是存储所有的斯坦纳树，只是存储一个可能的斯坦纳树，因为同一个向量的所有斯坦纳树的代价总和总是一样的。POWV和POST会构建成一个映射关系，同时将其存入到一个Table中，表中还包含POWV的总权重。而此时，权重最小的则可代表一个最小斯坦纳生成树。</p>\n<p><strong>3、table可以使用哈希表来进行设计</strong></p>\n<p>使用POWV做表头，权重和POST作为value，给出节点后，生成所有的可能的POWV表，再通过权重对其进行排序，取其POST作为斯坦纳树结果。</p>\n<h4 id=\"算法主要思想-1\"><a href=\"#算法主要思想-1\" class=\"headerlink\" title=\"算法主要思想\"></a>算法主要思想</h4><figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">总体流程：<br>所有<span class=\"hljs-keyword\">N</span>点线网根据pin脚的位置都可以划分到<span class=\"hljs-keyword\">n</span>！个group中，每个group中存有POWV，对于一个线网最优线长可由POWV来获得，FLUTE算法首先会预计算这些POWV形成一个查找表。<br>与POWV一起存储的还有<span class=\"hljs-keyword\">POST</span>，一个POWV对应多个<span class=\"hljs-keyword\">POST</span>，一个<span class=\"hljs-keyword\">POST</span>只有一个POWV<br>基于此，要得到一棵RSMT，只需要计算线网所在的组对应的POWV的线长，然后返回对应的<span class=\"hljs-keyword\">POST</span>即可<br>上述查找表算法最高支持9点线网，对于9点以上的需要递归的切分线网<br></code></pre></td></tr></table></figure>\n<ul>\n<li>生成查找表算法</li>\n</ul>\n<img src=\"/2023/09/04/eda-summary/image-20230828144127572.png\" class=\"\" title=\"image-20230828144127572\">\n<h4 id=\"时间复杂度\"><a href=\"#时间复杂度\" class=\"headerlink\" title=\"时间复杂度\"></a>时间复杂度</h4><p>时间复杂度为：O(nlgn)</p>\n<h3 id=\"三、静态时序分析\"><a href=\"#三、静态时序分析\" class=\"headerlink\" title=\"三、静态时序分析\"></a>三、静态时序分析</h3><h4 id=\"单元库\"><a href=\"#单元库\" class=\"headerlink\" title=\"单元库\"></a>单元库</h4><p>在静态时序分析中，单元库（library）是指一个集合，其中包含了各种标准的逻辑元件、时序元件和组合元件的建模。单元库中的元件通常带有特定的时钟延迟和逻辑功能，以及电压和温度等方面的参数，通过使用单元库，可以在时序分析中模拟和评估设计的时序特性，以帮助发现和解决潜在的时序冲突和时序失效问题。</p>\n<h4 id=\"互连寄生\"><a href=\"#互连寄生\" class=\"headerlink\" title=\"互连寄生\"></a>互连寄生</h4><p>互连寄生是指在集成电路或电子系统中，由于导线或连接器的存在，引起的非理想的电特性和效果。主要包括电容和电阻，互连寄生会对电路的信号传输、功耗、噪声和时序等方面产生不良的影响。</p>\n<p>电阻寄生：互连导线的电阻会引起信号的衰减和功率损耗。较长的导线通常具有更大的电阻。</p>\n<p>电容寄生：互连导线的电容会引起信号的延迟和功耗。电容会存储和释放电荷，导致信号传输速度变慢。</p>\n<h4 id=\"单元时延（NLDM表格）\"><a href=\"#单元时延（NLDM表格）\" class=\"headerlink\" title=\"单元时延（NLDM表格）\"></a>单元时延（NLDM表格）</h4><p>单元时延（NLDM表格），全称为非线性延迟模型（Non-Linear Delay Model），是一种常用的静态时序分析中的时延模型。在数字电路设计中，时延模型用于描述逻辑元件（如门级电路或时序元件）的输出到输入之间的传播延迟。</p>\n<p>NLDM表格是一种常见的时延模型，它以表格的形式表示输入到输出之间的传播延迟。表格的输入是逻辑元件的输入端的不同组合，并且通常包括输入的电压和电流等参数。表格的输出是逻辑元件的输出端的延迟时间，通常以纳秒或皮秒为单位。</p>\n<p>NLDM表格通常由电路设计工具根据所用的逻辑元件和工艺库生成。基于这个模型，可以进行静态时序分析，以评估电路的时序性能，如时钟周期、信号传输延迟和时序失效等。</p>\n<h4 id=\"线网时延（Elmore计算）\"><a href=\"#线网时延（Elmore计算）\" class=\"headerlink\" title=\"线网时延（Elmore计算）\"></a>线网时延（Elmore计算）</h4><p>线网时延，也称为Elmore时延，是一种常用的近似计算方法，用于估计电路中导线上的传播延迟。它是一种简化的时延模型，适用于传输线上电压/电流从输入端到达输出端的时间。</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">Elmore计算基于以下假设和简化：<br>1、传输线上的时延主要由传播速度和传输线上的等效电容决定。<br>2、传播速度是恒定的，不考虑传输线上的阻抗匹配或反射等因素。<br>3、传输线被近似为一系列等效电容连接起来的节点。<br><br>根据这些假设，Elmore计算使用以下步骤来估计线网时延：<br>1、将电路中的传输线划分为一系列节点，每个节点对应于传输线上一个等效电容。<br>2、从输入端开始，依次计算每个节点的时延。每个节点的时延等于前一节点的时延加上当前节点的等效电容与前一节点电流之积。<br>3、在达到输出端后，最后一个节点的时延就是整个线网的传播延迟。<br></code></pre></td></tr></table></figure>\n<h4 id=\"串扰噪声的定义\"><a href=\"#串扰噪声的定义\" class=\"headerlink\" title=\"串扰噪声的定义\"></a>串扰噪声的定义</h4><p>噪声是指电路中任意节点上不希望出现的电压或电流的偏差。当噪声作用于某个电路节点上时，它可以瞬间破坏该节点上存储的逻辑信息。如果这一破坏状态被锁存到锁存器中，那么将会导致功能性错误。</p>\n<p>主要有毛刺和延时噪声。</p>\n<h4 id=\"时序检查（Setup-Hold）\"><a href=\"#时序检查（Setup-Hold）\" class=\"headerlink\" title=\"时序检查（Setup/Hold）\"></a>时序检查（Setup/Hold）</h4><p>时序检查是在数字电路设计中进行的一种重要时序分析，用于验证和确保输入信号在时钟边沿触发时的稳定性和正确性。</p>\n<p>Setup Time：是指在时钟边沿到达之前，输入信号必须稳定在其有效值的时间。如果输入信号在设置时间窗口内没有稳定，可能会导致电路中的逻辑冲突和错误。</p>\n<p>Hold Time：是指在时钟边沿到达之后，输入信号必须继续保持在其有效值的时间。如果输入信号在保持时间之前改变或不稳定，也会导致电路中的逻辑错误。</p>\n<h4 id=\"时序路径定义\"><a href=\"#时序路径定义\" class=\"headerlink\" title=\"时序路径定义\"></a>时序路径定义</h4><p>时序路径（Timing Path）是指信号从一个寄存器节点（如时钟触发器）通过逻辑路径传播到另一个寄存器节点的路径。它描述了数据在电路中的传输和处理过程，并对时序分析和时序优化提供了重要信息。</p>\n<p>通过分析时序路径，可以确定信号在路径中的传播延迟，包括设置时间和保持时间等重要时序要求。时序路径分析可用于预测时钟频率、检测时序冲突、优化时序性能，以及验证设计是否满足时序规约等。</p>\n<h4 id=\"时序约束命令\"><a href=\"#时序约束命令\" class=\"headerlink\" title=\"时序约束命令\"></a>时序约束命令</h4><img src=\"/2023/09/04/eda-summary/image-20230818170602715.png\" class=\"\" title=\"image-20230818170602715\">\n<h3 id=\"四、EDA性能\"><a href=\"#四、EDA性能\" class=\"headerlink\" title=\"四、EDA性能\"></a>四、EDA性能</h3><ul>\n<li><p>解决EDA软件中的性能问题</p>\n<p>算法：优化数据结构，提高算法性能，降低算法的复杂度</p>\n<p>硬件：确保计算机的硬件资源重组，对于一些矩阵操作可以考虑使用GPU加速</p>\n<p>分布式：将问题拆解成可以并行计算的小问题，开发支持并行计算的EDA工具</p>\n</li>\n</ul>\n<h3 id=\"五、EDA后端\"><a href=\"#五、EDA后端\" class=\"headerlink\" title=\"五、EDA后端\"></a>五、EDA后端</h3><ul>\n<li>EDA后端软件开发的流程</li>\n</ul>\n<img src=\"/2023/09/04/eda-summary/EDA%E6%B5%81%E7%A8%8B.jpg\" class=\"\">\n<h3 id=\"六、EDA工具\"><a href=\"#六、EDA工具\" class=\"headerlink\" title=\"六、EDA工具\"></a>六、EDA工具</h3><ul>\n<li><p>常见的EDA仿真工具和Debug工具分别有哪些？它们有什么优势和不足？</p>\n<p>仿真工具：</p>\n<ul>\n<li>ModelSim/QuestaSim (Mentor)</li>\n<li>VCS (Synopsys)</li>\n<li>Xilinx Vivado Simulator (Xilinx)</li>\n<li>Incisive (Cadence)</li>\n<li>Icarus Verilog</li>\n</ul>\n<p>优势：</p>\n<ul>\n<li>高度准确和精确的模拟功能。</li>\n<li>可以模拟各种不同级别的设计，从门级仿真到系统级仿真。</li>\n<li>支持时序和功能仿真，可以检测和调试设计中的逻辑错误和时序问题。</li>\n</ul>\n<p>不足：</p>\n<ul>\n<li>仿真时间较长，尤其是对于大型和复杂的设计。</li>\n<li>需要大量的计算资源（CPU和内存）。</li>\n<li>对于某些特定的设计场景，可能需要针对特定工具进行配置和优化。</li>\n</ul>\n</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"一、布局\"><a href=\"#一、布局\" class=\"headerlink\" title=\"一、布局\"></a>一、布局</h3><h4 id=\"布局算法：二次线长布局算法-力矢量布局\"><a href=\"#布局算法：二次线长布局算法-力矢量布局\" class=\"headerlink\" title=\"布局算法：二次线长布局算法+力矢量布局\"></a><strong>布局算法：二次线长布局算法+力矢量布局</strong></h4><p>设计目标：调整不同元胞在元胞中的摆放位置，使得元胞在版图中的连线最短，同时确保在布局中没有重叠</p>\n<blockquote>\n<p>二次线长布局分为两个阶段</p>\n<p>第一阶段：依据元胞的中心对元胞进行布局，从而对二次线长函数最小化</p>\n<p>第二阶段：将元胞中集中在许多元胞重叠的大的结群打散，从而使所有单元原来的重叠消除</p>\n</blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs \\\">输入：线网连接，限制的版图区域<br>输出：所有元胞的x坐标和y坐标<br></code></pre></td></tr></table></figure>\n<h4 id=\"数据结构设计\"><a href=\"#数据结构设计\" class=\"headerlink\" title=\"数据结构设计\"></a>数据结构设计</h4><p>1、元胞可以抽象成一个含有x，y坐标的结构体</p>\n<p>2、网表抽象为二维map，记录不同元胞之间的连线情况，同时x，y代表元胞在map中所处的位置信息</p>\n<h4 id=\"算法主要思想\"><a href=\"#算法主要思想\" class=\"headerlink\" title=\"算法主要思想\"></a>算法主要思想</h4><p><strong>第一阶段：全局布局（二次线长布局）</strong></p>\n<blockquote>\n<p>在全局布局的过程中，将元胞的坐标抽象成为中心点的坐标，不考虑其面积、大小以及布局的合法化，仅仅是以最优化模块之间的线长为目标。</p>\n</blockquote>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\">已知线网的的连接，限制的版图区域，求不同元胞在版图中摆放的位置，使得所有元胞在版图中的连线最短。<br>求：所有的元胞的<span class=\"hljs-keyword\">x</span>坐标和y坐标。<br><br><span class=\"hljs-number\">1</span>、列出所有连接的元胞线网的X的总线长L(p)：所有的<span class=\"hljs-keyword\">x</span>距离的差的平方<br><span class=\"hljs-number\">2</span>、分别对所有参数中的<span class=\"hljs-keyword\">x</span>求偏导，并令偏导为<span class=\"hljs-number\">0</span><br><span class=\"hljs-number\">3</span>、列出方程组，解出来的<span class=\"hljs-keyword\">x</span>阵列就是所需要求的解<br>对于Y方向也是同理<br><br>该算法只是以中心点作为元胞的坐标，所有没有考虑到不同元胞的大小，会存在重叠的问题<br></code></pre></td></tr></table></figure>\n<p>距离计算代价函数</p>\n<img src=\"/2023/09/04/eda-summary/image-20230818160028154.png\" class=\"\" title=\"image-20230818160028154\">\n<p>通过求偏导数，解出x和y。</p>\n<p><strong>第二阶段：详细布局（力矢量布局）</strong></p>\n<blockquote>\n<p>用于在已经布置好的版图中，新加入一个元胞，通过找到让该元胞平衡的状态，来确定该元胞在版图中的位置。</p>\n<p>采用力学中的质点弹簧系统来建模，每个元胞运动吸引其他元胞，其中吸引力与距离成正比。如果所有元胞到达它们的平衡位置，线长将得到最小化。<strong>将目标转化为将所有的元胞放在一个力平衡的位置上。</strong>——<strong>称为零力目标</strong>（ZFT）</p>\n</blockquote>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-number\">1</span>、以二次线长布局过后的布局为初始布局<br><span class=\"hljs-number\">2</span>、为每个布局中的元胞设定坐标，并标记为UNMOVED<br><span class=\"hljs-number\">3</span>、对元胞按照元胞的连接数进行排序，该顺序就是元胞迭代的顺序<br><span class=\"hljs-number\">4</span>、迭代的取出每一个元胞，并寻找它的ZFT位置，直到所有的都完成<br><span class=\"hljs-number\">5</span>、若ZFT位置被占据，则移动到其他的位置<br><br>第<span class=\"hljs-number\">5</span>步确定<span class=\"hljs-selector-tag\">p</span>的ZFT时，若ZFT被元胞<span class=\"hljs-selector-tag\">q</span>占据，则移动位置的确定<br><span class=\"hljs-number\">1</span>、如果可能，将<span class=\"hljs-selector-tag\">p</span>移动到靠近<span class=\"hljs-selector-tag\">q</span>的位置<br><span class=\"hljs-number\">2</span>、若交换<span class=\"hljs-selector-tag\">p</span>，<span class=\"hljs-selector-tag\">q</span>后，代价变小，则交换<br><span class=\"hljs-number\">3</span>、链式移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，<span class=\"hljs-selector-tag\">q</span>移动到下一个，以此类推<br><span class=\"hljs-number\">4</span>、波状移动，<span class=\"hljs-selector-tag\">p</span>移动到<span class=\"hljs-selector-tag\">q</span>，再重新计算<span class=\"hljs-selector-tag\">q</span>的ZFT<br></code></pre></td></tr></table></figure>\n<p>Loss为权重乘以坐标差的累计和</p>\n<p><strong>时间复杂度</strong></p>\n<p>假设元胞的数量为n</p>\n<p>二次线长布局的时间复杂度为：O(n^2)，需要遍历一遍map，找到各个节点之间的连线信息</p>\n<p>力矢量布局的时间复杂度为：O(n^2)</p>\n<h3 id=\"二、布线\"><a href=\"#二、布线\" class=\"headerlink\" title=\"二、布线\"></a>二、布线</h3><h4 id=\"布线算法：FLUTE算法\"><a href=\"#布线算法：FLUTE算法\" class=\"headerlink\" title=\"布线算法：FLUTE算法\"></a>布线算法：FLUTE算法</h4><p>设计目标：找到能将节点连接的最小斯坦纳生成树</p>\n<blockquote>\n<p>在EDA的布线中，各个板块的IO接口以及时钟接口之间，通常是走的斯坦纳线，而直接求斯坦纳最小树是NP完全问题，使用FLUTE算法可以将RSMT问题转化为查找表的问题</p>\n</blockquote>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">输入：pin结点，以及结点的位置<br>输出：将所有结点连接起来的斯坦纳树<br></code></pre></td></tr></table></figure>\n<h4 id=\"算法数据结构设计\"><a href=\"#算法数据结构设计\" class=\"headerlink\" title=\"算法数据结构设计\"></a>算法数据结构设计</h4><p><strong>1、POWV（Potentially optimal wirelength vectors）</strong></p>\n<p>在FLUTE算法中，会使用一种带有信息（权重）的数据结构（向量）来表示一种斯坦纳树，任意一棵斯坦纳树都可以使用唯一的POWV来表示，一个POWV向量可以表示多棵不一样的斯坦纳树，如下图。</p>\n<blockquote>\n<p>前面三位表示x方向上的length</p>\n<p>后面三位表示y方向上的length</p>\n</blockquote>\n<img src=\"/2023/09/04/eda-summary/image-20230828141138808.png\" class=\"\" title=\"image-20230828141138808\">\n<p><strong>2、POST（potentially optimal Steiner tree）</strong></p>\n<p>对每一个POWV都会对应存储一个POST，也就是说，不是存储所有的斯坦纳树，只是存储一个可能的斯坦纳树，因为同一个向量的所有斯坦纳树的代价总和总是一样的。POWV和POST会构建成一个映射关系，同时将其存入到一个Table中，表中还包含POWV的总权重。而此时，权重最小的则可代表一个最小斯坦纳生成树。</p>\n<p><strong>3、table可以使用哈希表来进行设计</strong></p>\n<p>使用POWV做表头，权重和POST作为value，给出节点后，生成所有的可能的POWV表，再通过权重对其进行排序，取其POST作为斯坦纳树结果。</p>\n<h4 id=\"算法主要思想-1\"><a href=\"#算法主要思想-1\" class=\"headerlink\" title=\"算法主要思想\"></a>算法主要思想</h4><figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">总体流程：<br>所有<span class=\"hljs-keyword\">N</span>点线网根据pin脚的位置都可以划分到<span class=\"hljs-keyword\">n</span>！个group中，每个group中存有POWV，对于一个线网最优线长可由POWV来获得，FLUTE算法首先会预计算这些POWV形成一个查找表。<br>与POWV一起存储的还有<span class=\"hljs-keyword\">POST</span>，一个POWV对应多个<span class=\"hljs-keyword\">POST</span>，一个<span class=\"hljs-keyword\">POST</span>只有一个POWV<br>基于此，要得到一棵RSMT，只需要计算线网所在的组对应的POWV的线长，然后返回对应的<span class=\"hljs-keyword\">POST</span>即可<br>上述查找表算法最高支持9点线网，对于9点以上的需要递归的切分线网<br></code></pre></td></tr></table></figure>\n<ul>\n<li>生成查找表算法</li>\n</ul>\n<img src=\"/2023/09/04/eda-summary/image-20230828144127572.png\" class=\"\" title=\"image-20230828144127572\">\n<h4 id=\"时间复杂度\"><a href=\"#时间复杂度\" class=\"headerlink\" title=\"时间复杂度\"></a>时间复杂度</h4><p>时间复杂度为：O(nlgn)</p>\n<h3 id=\"三、静态时序分析\"><a href=\"#三、静态时序分析\" class=\"headerlink\" title=\"三、静态时序分析\"></a>三、静态时序分析</h3><h4 id=\"单元库\"><a href=\"#单元库\" class=\"headerlink\" title=\"单元库\"></a>单元库</h4><p>在静态时序分析中，单元库（library）是指一个集合，其中包含了各种标准的逻辑元件、时序元件和组合元件的建模。单元库中的元件通常带有特定的时钟延迟和逻辑功能，以及电压和温度等方面的参数，通过使用单元库，可以在时序分析中模拟和评估设计的时序特性，以帮助发现和解决潜在的时序冲突和时序失效问题。</p>\n<h4 id=\"互连寄生\"><a href=\"#互连寄生\" class=\"headerlink\" title=\"互连寄生\"></a>互连寄生</h4><p>互连寄生是指在集成电路或电子系统中，由于导线或连接器的存在，引起的非理想的电特性和效果。主要包括电容和电阻，互连寄生会对电路的信号传输、功耗、噪声和时序等方面产生不良的影响。</p>\n<p>电阻寄生：互连导线的电阻会引起信号的衰减和功率损耗。较长的导线通常具有更大的电阻。</p>\n<p>电容寄生：互连导线的电容会引起信号的延迟和功耗。电容会存储和释放电荷，导致信号传输速度变慢。</p>\n<h4 id=\"单元时延（NLDM表格）\"><a href=\"#单元时延（NLDM表格）\" class=\"headerlink\" title=\"单元时延（NLDM表格）\"></a>单元时延（NLDM表格）</h4><p>单元时延（NLDM表格），全称为非线性延迟模型（Non-Linear Delay Model），是一种常用的静态时序分析中的时延模型。在数字电路设计中，时延模型用于描述逻辑元件（如门级电路或时序元件）的输出到输入之间的传播延迟。</p>\n<p>NLDM表格是一种常见的时延模型，它以表格的形式表示输入到输出之间的传播延迟。表格的输入是逻辑元件的输入端的不同组合，并且通常包括输入的电压和电流等参数。表格的输出是逻辑元件的输出端的延迟时间，通常以纳秒或皮秒为单位。</p>\n<p>NLDM表格通常由电路设计工具根据所用的逻辑元件和工艺库生成。基于这个模型，可以进行静态时序分析，以评估电路的时序性能，如时钟周期、信号传输延迟和时序失效等。</p>\n<h4 id=\"线网时延（Elmore计算）\"><a href=\"#线网时延（Elmore计算）\" class=\"headerlink\" title=\"线网时延（Elmore计算）\"></a>线网时延（Elmore计算）</h4><p>线网时延，也称为Elmore时延，是一种常用的近似计算方法，用于估计电路中导线上的传播延迟。它是一种简化的时延模型，适用于传输线上电压/电流从输入端到达输出端的时间。</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs\">Elmore计算基于以下假设和简化：<br>1、传输线上的时延主要由传播速度和传输线上的等效电容决定。<br>2、传播速度是恒定的，不考虑传输线上的阻抗匹配或反射等因素。<br>3、传输线被近似为一系列等效电容连接起来的节点。<br><br>根据这些假设，Elmore计算使用以下步骤来估计线网时延：<br>1、将电路中的传输线划分为一系列节点，每个节点对应于传输线上一个等效电容。<br>2、从输入端开始，依次计算每个节点的时延。每个节点的时延等于前一节点的时延加上当前节点的等效电容与前一节点电流之积。<br>3、在达到输出端后，最后一个节点的时延就是整个线网的传播延迟。<br></code></pre></td></tr></table></figure>\n<h4 id=\"串扰噪声的定义\"><a href=\"#串扰噪声的定义\" class=\"headerlink\" title=\"串扰噪声的定义\"></a>串扰噪声的定义</h4><p>噪声是指电路中任意节点上不希望出现的电压或电流的偏差。当噪声作用于某个电路节点上时，它可以瞬间破坏该节点上存储的逻辑信息。如果这一破坏状态被锁存到锁存器中，那么将会导致功能性错误。</p>\n<p>主要有毛刺和延时噪声。</p>\n<h4 id=\"时序检查（Setup-Hold）\"><a href=\"#时序检查（Setup-Hold）\" class=\"headerlink\" title=\"时序检查（Setup/Hold）\"></a>时序检查（Setup/Hold）</h4><p>时序检查是在数字电路设计中进行的一种重要时序分析，用于验证和确保输入信号在时钟边沿触发时的稳定性和正确性。</p>\n<p>Setup Time：是指在时钟边沿到达之前，输入信号必须稳定在其有效值的时间。如果输入信号在设置时间窗口内没有稳定，可能会导致电路中的逻辑冲突和错误。</p>\n<p>Hold Time：是指在时钟边沿到达之后，输入信号必须继续保持在其有效值的时间。如果输入信号在保持时间之前改变或不稳定，也会导致电路中的逻辑错误。</p>\n<h4 id=\"时序路径定义\"><a href=\"#时序路径定义\" class=\"headerlink\" title=\"时序路径定义\"></a>时序路径定义</h4><p>时序路径（Timing Path）是指信号从一个寄存器节点（如时钟触发器）通过逻辑路径传播到另一个寄存器节点的路径。它描述了数据在电路中的传输和处理过程，并对时序分析和时序优化提供了重要信息。</p>\n<p>通过分析时序路径，可以确定信号在路径中的传播延迟，包括设置时间和保持时间等重要时序要求。时序路径分析可用于预测时钟频率、检测时序冲突、优化时序性能，以及验证设计是否满足时序规约等。</p>\n<h4 id=\"时序约束命令\"><a href=\"#时序约束命令\" class=\"headerlink\" title=\"时序约束命令\"></a>时序约束命令</h4><img src=\"/2023/09/04/eda-summary/image-20230818170602715.png\" class=\"\" title=\"image-20230818170602715\">\n<h3 id=\"四、EDA性能\"><a href=\"#四、EDA性能\" class=\"headerlink\" title=\"四、EDA性能\"></a>四、EDA性能</h3><ul>\n<li><p>解决EDA软件中的性能问题</p>\n<p>算法：优化数据结构，提高算法性能，降低算法的复杂度</p>\n<p>硬件：确保计算机的硬件资源重组，对于一些矩阵操作可以考虑使用GPU加速</p>\n<p>分布式：将问题拆解成可以并行计算的小问题，开发支持并行计算的EDA工具</p>\n</li>\n</ul>\n<h3 id=\"五、EDA后端\"><a href=\"#五、EDA后端\" class=\"headerlink\" title=\"五、EDA后端\"></a>五、EDA后端</h3><ul>\n<li>EDA后端软件开发的流程</li>\n</ul>\n<img src=\"/2023/09/04/eda-summary/EDA%E6%B5%81%E7%A8%8B.jpg\" class=\"\">\n<h3 id=\"六、EDA工具\"><a href=\"#六、EDA工具\" class=\"headerlink\" title=\"六、EDA工具\"></a>六、EDA工具</h3><ul>\n<li><p>常见的EDA仿真工具和Debug工具分别有哪些？它们有什么优势和不足？</p>\n<p>仿真工具：</p>\n<ul>\n<li>ModelSim/QuestaSim (Mentor)</li>\n<li>VCS (Synopsys)</li>\n<li>Xilinx Vivado Simulator (Xilinx)</li>\n<li>Incisive (Cadence)</li>\n<li>Icarus Verilog</li>\n</ul>\n<p>优势：</p>\n<ul>\n<li>高度准确和精确的模拟功能。</li>\n<li>可以模拟各种不同级别的设计，从门级仿真到系统级仿真。</li>\n<li>支持时序和功能仿真，可以检测和调试设计中的逻辑错误和时序问题。</li>\n</ul>\n<p>不足：</p>\n<ul>\n<li>仿真时间较长，尤其是对于大型和复杂的设计。</li>\n<li>需要大量的计算资源（CPU和内存）。</li>\n<li>对于某些特定的设计场景，可能需要针对特定工具进行配置和优化。</li>\n</ul>\n</li>\n</ul>\n"},{"title":"C/C++中gcc/g++的参数详解","date":"2024-03-02T14:16:10.000Z","cover":"/img/default_cover01.jpg","top_img":null,"_content":"## C/C++中gcc/g++的参数详解\n\n> 参考链接：https://www.runoob.com/w3cnote/gcc-parameter-detail.html\n\nGCC（GNU Compiler Collection）和G++分别是GNU（自由和开放源码的操作系统）的C和C++编译器。在执行编译的过程中，总共需要执行4步\n\n* 预处理：预处理器（cpp：C Preprocessor）根据以字符`#`开头的命令，修改原始的C程序，即将头文件作为当前文件的内容插入到程序文本当中。得到另一个C程序，生成的文件为`.i`文件\n* 编译：编译器（ccl）将预处理后的文本文件文件`.i`翻译成文本文件`.s`文件，即汇编语言\n* 汇编：汇编器（as）将汇编语言翻译成能够供机器识别的机器指令，并保存在`.o`目标文件中，这是二进制文件\n* 链接：链接器负责链接目标代码，生成可执行文件，如：main中调用的一个函数，则会把那个函数进行链接\n\n### 基本编译参数\n\n- `-o <file>`: 指定输出的可执行文件名。如果不使用该参数，默认的输出文件名为`a.out`。\n- `-c`: 只编译并生成目标文件（`.o`文件），不进行链接。\n- `-E`: 只进行预处理，不进行编译、汇编和链接。\n- `-S`: 只进行预处理和编译，不进行汇编和链接，生成汇编代码。\n- `-x  language`: 设置文件所使用的语言，对后缀名无效\n- `-pipe`: 使用管道代替编译中的临时文件\n- `include file`: 包含某个文件代码\n- `imacros file`: 将file文件的宏，拓展到gcc/g++的输入文件，宏定义本身不出现在输入文件中\n- `Dmacro`: 定义宏\n- `-C`: 预处理时，不删除注释信息\n\n### 调试和优化信息\n\n- `-g`: 生成调试信息。可以用GDB等调试器调试程序。\n- `-O<level>`: 设置优化级别。`<level>`可以是0、1、2、3，其中`-O0`表示不进行优化，`-O2`和`-O3`表示更高级别的优化。\n- `-Og`: 优化生成的代码，但不会干扰调试。\n\n### 警告控制\n\n- `-Wall`: 打开几乎所有的警告。\n- `-Wextra`: 打开额外的警告。\n- `-Werror`: 把所有的警告当作错误。\n\n### 链接库和路径\n\n- `-l<library>`: 链接一个库。例如，使用`-lm`来链接数学库`libm.so`。\n- `-L<directory>`: 添加库文件搜索的目录。\n- `-I<directory>`: 添加头文件搜索的目录。\n\n- `-static`: 使用静态链接，不使用动态链接库。编译出来的东西，一般都很大。\n- `-fPIC`: 生成位置无关代码，通常用于创建共享库。\n- `-share`: 尽量使用动态库，生成的文件会较小，但需要系统有动态库。\n\n### 预处理器选项\n\n- `-D<macro>`: 定义宏。例如，`-DDEBUG`会定义宏`DEBUG`。\n- `-U<macro>`: 取消宏的定义。\n\n### 其他选项\n\n| 选项         | 解释                                                         |\n| :----------- | :----------------------------------------------------------- |\n| -ansi        | 只支持 ANSI 标准的 C 语法。这一选项将禁止 GNU C 的某些特色， 例如 asm 或 typeof 关键词。 |\n| -c           | 只编译并生成目标文件。                                       |\n| -DMACRO      | 以字符串\"1\"定义 MACRO 宏。                                   |\n| -DMACRO=DEFN | 以字符串\"DEFN\"定义 MACRO 宏。                                |\n| -E           | 只运行 C 预编译器。                                          |\n| -g           | 生成调试信息。GNU 调试器可利用该信息。                       |\n| -IDIRECTORY  | 指定额外的头文件搜索路径DIRECTORY。                          |\n| -LDIRECTORY  | 指定额外的函数库搜索路径DIRECTORY。                          |\n| -lLIBRARY    | 连接时搜索指定的函数库LIBRARY。                              |\n| -m486        | 针对 486 进行代码优化。                                      |\n| -o FILE      | 生成指定的输出文件。用在生成可执行文件时。                   |\n| -O0          | 不进行优化处理。                                             |\n| -O 或 -O1    | 优化生成代码。                                               |\n| -O2          | 进一步优化。                                                 |\n| -O3          | 比 -O2 更进一步优化，包括 inline 函数。                      |\n| -shared      | 生成共享目标文件。通常用在建立共享库时。                     |\n| -static      | 禁止使用共享连接。                                           |\n| -UMACRO      | 取消对 MACRO 宏的定义。                                      |\n| -w           | 不生成任何警告信息。                                         |\n| -Wall        | 生成所有警告信息。                                           |\n\n","source":"_posts/gcc-parameters.md","raw":"---\ntitle: C/C++中gcc/g++的参数详解\ncategories: 技术研究\ndate: 2024-03-02 22:16:10\ntags: [C++, GCC, G++, 编译]\ncover:\ntop_img:\n---\n## C/C++中gcc/g++的参数详解\n\n> 参考链接：https://www.runoob.com/w3cnote/gcc-parameter-detail.html\n\nGCC（GNU Compiler Collection）和G++分别是GNU（自由和开放源码的操作系统）的C和C++编译器。在执行编译的过程中，总共需要执行4步\n\n* 预处理：预处理器（cpp：C Preprocessor）根据以字符`#`开头的命令，修改原始的C程序，即将头文件作为当前文件的内容插入到程序文本当中。得到另一个C程序，生成的文件为`.i`文件\n* 编译：编译器（ccl）将预处理后的文本文件文件`.i`翻译成文本文件`.s`文件，即汇编语言\n* 汇编：汇编器（as）将汇编语言翻译成能够供机器识别的机器指令，并保存在`.o`目标文件中，这是二进制文件\n* 链接：链接器负责链接目标代码，生成可执行文件，如：main中调用的一个函数，则会把那个函数进行链接\n\n### 基本编译参数\n\n- `-o <file>`: 指定输出的可执行文件名。如果不使用该参数，默认的输出文件名为`a.out`。\n- `-c`: 只编译并生成目标文件（`.o`文件），不进行链接。\n- `-E`: 只进行预处理，不进行编译、汇编和链接。\n- `-S`: 只进行预处理和编译，不进行汇编和链接，生成汇编代码。\n- `-x  language`: 设置文件所使用的语言，对后缀名无效\n- `-pipe`: 使用管道代替编译中的临时文件\n- `include file`: 包含某个文件代码\n- `imacros file`: 将file文件的宏，拓展到gcc/g++的输入文件，宏定义本身不出现在输入文件中\n- `Dmacro`: 定义宏\n- `-C`: 预处理时，不删除注释信息\n\n### 调试和优化信息\n\n- `-g`: 生成调试信息。可以用GDB等调试器调试程序。\n- `-O<level>`: 设置优化级别。`<level>`可以是0、1、2、3，其中`-O0`表示不进行优化，`-O2`和`-O3`表示更高级别的优化。\n- `-Og`: 优化生成的代码，但不会干扰调试。\n\n### 警告控制\n\n- `-Wall`: 打开几乎所有的警告。\n- `-Wextra`: 打开额外的警告。\n- `-Werror`: 把所有的警告当作错误。\n\n### 链接库和路径\n\n- `-l<library>`: 链接一个库。例如，使用`-lm`来链接数学库`libm.so`。\n- `-L<directory>`: 添加库文件搜索的目录。\n- `-I<directory>`: 添加头文件搜索的目录。\n\n- `-static`: 使用静态链接，不使用动态链接库。编译出来的东西，一般都很大。\n- `-fPIC`: 生成位置无关代码，通常用于创建共享库。\n- `-share`: 尽量使用动态库，生成的文件会较小，但需要系统有动态库。\n\n### 预处理器选项\n\n- `-D<macro>`: 定义宏。例如，`-DDEBUG`会定义宏`DEBUG`。\n- `-U<macro>`: 取消宏的定义。\n\n### 其他选项\n\n| 选项         | 解释                                                         |\n| :----------- | :----------------------------------------------------------- |\n| -ansi        | 只支持 ANSI 标准的 C 语法。这一选项将禁止 GNU C 的某些特色， 例如 asm 或 typeof 关键词。 |\n| -c           | 只编译并生成目标文件。                                       |\n| -DMACRO      | 以字符串\"1\"定义 MACRO 宏。                                   |\n| -DMACRO=DEFN | 以字符串\"DEFN\"定义 MACRO 宏。                                |\n| -E           | 只运行 C 预编译器。                                          |\n| -g           | 生成调试信息。GNU 调试器可利用该信息。                       |\n| -IDIRECTORY  | 指定额外的头文件搜索路径DIRECTORY。                          |\n| -LDIRECTORY  | 指定额外的函数库搜索路径DIRECTORY。                          |\n| -lLIBRARY    | 连接时搜索指定的函数库LIBRARY。                              |\n| -m486        | 针对 486 进行代码优化。                                      |\n| -o FILE      | 生成指定的输出文件。用在生成可执行文件时。                   |\n| -O0          | 不进行优化处理。                                             |\n| -O 或 -O1    | 优化生成代码。                                               |\n| -O2          | 进一步优化。                                                 |\n| -O3          | 比 -O2 更进一步优化，包括 inline 函数。                      |\n| -shared      | 生成共享目标文件。通常用在建立共享库时。                     |\n| -static      | 禁止使用共享连接。                                           |\n| -UMACRO      | 取消对 MACRO 宏的定义。                                      |\n| -w           | 不生成任何警告信息。                                         |\n| -Wall        | 生成所有警告信息。                                           |\n\n","slug":"gcc-parameters","published":1,"updated":"2024-06-05T09:03:03.788Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttv002j08jvaxnfdxdu","content":"<h2 id=\"C-C-中gcc-g-的参数详解\"><a href=\"#C-C-中gcc-g-的参数详解\" class=\"headerlink\" title=\"C/C++中gcc/g++的参数详解\"></a>C/C++中gcc/g++的参数详解</h2><blockquote>\n<p>参考链接：<a href=\"https://www.runoob.com/w3cnote/gcc-parameter-detail.html\">https://www.runoob.com/w3cnote/gcc-parameter-detail.html</a></p>\n</blockquote>\n<p>GCC（GNU Compiler Collection）和G++分别是GNU（自由和开放源码的操作系统）的C和C++编译器。在执行编译的过程中，总共需要执行4步</p>\n<ul>\n<li>预处理：预处理器（cpp：C Preprocessor）根据以字符<code>#</code>开头的命令，修改原始的C程序，即将头文件作为当前文件的内容插入到程序文本当中。得到另一个C程序，生成的文件为<code>.i</code>文件</li>\n<li>编译：编译器（ccl）将预处理后的文本文件文件<code>.i</code>翻译成文本文件<code>.s</code>文件，即汇编语言</li>\n<li>汇编：汇编器（as）将汇编语言翻译成能够供机器识别的机器指令，并保存在<code>.o</code>目标文件中，这是二进制文件</li>\n<li>链接：链接器负责链接目标代码，生成可执行文件，如：main中调用的一个函数，则会把那个函数进行链接</li>\n</ul>\n<h3 id=\"基本编译参数\"><a href=\"#基本编译参数\" class=\"headerlink\" title=\"基本编译参数\"></a>基本编译参数</h3><ul>\n<li><code>-o &lt;file&gt;</code>: 指定输出的可执行文件名。如果不使用该参数，默认的输出文件名为<code>a.out</code>。</li>\n<li><code>-c</code>: 只编译并生成目标文件（<code>.o</code>文件），不进行链接。</li>\n<li><code>-E</code>: 只进行预处理，不进行编译、汇编和链接。</li>\n<li><code>-S</code>: 只进行预处理和编译，不进行汇编和链接，生成汇编代码。</li>\n<li><code>-x  language</code>: 设置文件所使用的语言，对后缀名无效</li>\n<li><code>-pipe</code>: 使用管道代替编译中的临时文件</li>\n<li><code>include file</code>: 包含某个文件代码</li>\n<li><code>imacros file</code>: 将file文件的宏，拓展到gcc/g++的输入文件，宏定义本身不出现在输入文件中</li>\n<li><code>Dmacro</code>: 定义宏</li>\n<li><code>-C</code>: 预处理时，不删除注释信息</li>\n</ul>\n<h3 id=\"调试和优化信息\"><a href=\"#调试和优化信息\" class=\"headerlink\" title=\"调试和优化信息\"></a>调试和优化信息</h3><ul>\n<li><code>-g</code>: 生成调试信息。可以用GDB等调试器调试程序。</li>\n<li><code>-O&lt;level&gt;</code>: 设置优化级别。<code>&lt;level&gt;</code>可以是0、1、2、3，其中<code>-O0</code>表示不进行优化，<code>-O2</code>和<code>-O3</code>表示更高级别的优化。</li>\n<li><code>-Og</code>: 优化生成的代码，但不会干扰调试。</li>\n</ul>\n<h3 id=\"警告控制\"><a href=\"#警告控制\" class=\"headerlink\" title=\"警告控制\"></a>警告控制</h3><ul>\n<li><code>-Wall</code>: 打开几乎所有的警告。</li>\n<li><code>-Wextra</code>: 打开额外的警告。</li>\n<li><code>-Werror</code>: 把所有的警告当作错误。</li>\n</ul>\n<h3 id=\"链接库和路径\"><a href=\"#链接库和路径\" class=\"headerlink\" title=\"链接库和路径\"></a>链接库和路径</h3><ul>\n<li><code>-l&lt;library&gt;</code>: 链接一个库。例如，使用<code>-lm</code>来链接数学库<code>libm.so</code>。</li>\n<li><code>-L&lt;directory&gt;</code>: 添加库文件搜索的目录。</li>\n<li><p><code>-I&lt;directory&gt;</code>: 添加头文件搜索的目录。</p>\n</li>\n<li><p><code>-static</code>: 使用静态链接，不使用动态链接库。编译出来的东西，一般都很大。</p>\n</li>\n<li><code>-fPIC</code>: 生成位置无关代码，通常用于创建共享库。</li>\n<li><code>-share</code>: 尽量使用动态库，生成的文件会较小，但需要系统有动态库。</li>\n</ul>\n<h3 id=\"预处理器选项\"><a href=\"#预处理器选项\" class=\"headerlink\" title=\"预处理器选项\"></a>预处理器选项</h3><ul>\n<li><code>-D&lt;macro&gt;</code>: 定义宏。例如，<code>-DDEBUG</code>会定义宏<code>DEBUG</code>。</li>\n<li><code>-U&lt;macro&gt;</code>: 取消宏的定义。</li>\n</ul>\n<h3 id=\"其他选项\"><a href=\"#其他选项\" class=\"headerlink\" title=\"其他选项\"></a>其他选项</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-ansi</td>\n<td style=\"text-align:left\">只支持 ANSI 标准的 C 语法。这一选项将禁止 GNU C 的某些特色， 例如 asm 或 typeof 关键词。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-c</td>\n<td style=\"text-align:left\">只编译并生成目标文件。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-DMACRO</td>\n<td style=\"text-align:left\">以字符串”1”定义 MACRO 宏。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-DMACRO=DEFN</td>\n<td style=\"text-align:left\">以字符串”DEFN”定义 MACRO 宏。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-E</td>\n<td style=\"text-align:left\">只运行 C 预编译器。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-g</td>\n<td style=\"text-align:left\">生成调试信息。GNU 调试器可利用该信息。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-IDIRECTORY</td>\n<td style=\"text-align:left\">指定额外的头文件搜索路径DIRECTORY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-LDIRECTORY</td>\n<td style=\"text-align:left\">指定额外的函数库搜索路径DIRECTORY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-lLIBRARY</td>\n<td style=\"text-align:left\">连接时搜索指定的函数库LIBRARY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-m486</td>\n<td style=\"text-align:left\">针对 486 进行代码优化。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-o FILE</td>\n<td style=\"text-align:left\">生成指定的输出文件。用在生成可执行文件时。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O0</td>\n<td style=\"text-align:left\">不进行优化处理。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O 或 -O1</td>\n<td style=\"text-align:left\">优化生成代码。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O2</td>\n<td style=\"text-align:left\">进一步优化。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O3</td>\n<td style=\"text-align:left\">比 -O2 更进一步优化，包括 inline 函数。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-shared</td>\n<td style=\"text-align:left\">生成共享目标文件。通常用在建立共享库时。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-static</td>\n<td style=\"text-align:left\">禁止使用共享连接。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-UMACRO</td>\n<td style=\"text-align:left\">取消对 MACRO 宏的定义。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-w</td>\n<td style=\"text-align:left\">不生成任何警告信息。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-Wall</td>\n<td style=\"text-align:left\">生成所有警告信息。</td>\n</tr>\n</tbody>\n</table>\n</div>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"C-C-中gcc-g-的参数详解\"><a href=\"#C-C-中gcc-g-的参数详解\" class=\"headerlink\" title=\"C/C++中gcc/g++的参数详解\"></a>C/C++中gcc/g++的参数详解</h2><blockquote>\n<p>参考链接：<a href=\"https://www.runoob.com/w3cnote/gcc-parameter-detail.html\">https://www.runoob.com/w3cnote/gcc-parameter-detail.html</a></p>\n</blockquote>\n<p>GCC（GNU Compiler Collection）和G++分别是GNU（自由和开放源码的操作系统）的C和C++编译器。在执行编译的过程中，总共需要执行4步</p>\n<ul>\n<li>预处理：预处理器（cpp：C Preprocessor）根据以字符<code>#</code>开头的命令，修改原始的C程序，即将头文件作为当前文件的内容插入到程序文本当中。得到另一个C程序，生成的文件为<code>.i</code>文件</li>\n<li>编译：编译器（ccl）将预处理后的文本文件文件<code>.i</code>翻译成文本文件<code>.s</code>文件，即汇编语言</li>\n<li>汇编：汇编器（as）将汇编语言翻译成能够供机器识别的机器指令，并保存在<code>.o</code>目标文件中，这是二进制文件</li>\n<li>链接：链接器负责链接目标代码，生成可执行文件，如：main中调用的一个函数，则会把那个函数进行链接</li>\n</ul>\n<h3 id=\"基本编译参数\"><a href=\"#基本编译参数\" class=\"headerlink\" title=\"基本编译参数\"></a>基本编译参数</h3><ul>\n<li><code>-o &lt;file&gt;</code>: 指定输出的可执行文件名。如果不使用该参数，默认的输出文件名为<code>a.out</code>。</li>\n<li><code>-c</code>: 只编译并生成目标文件（<code>.o</code>文件），不进行链接。</li>\n<li><code>-E</code>: 只进行预处理，不进行编译、汇编和链接。</li>\n<li><code>-S</code>: 只进行预处理和编译，不进行汇编和链接，生成汇编代码。</li>\n<li><code>-x  language</code>: 设置文件所使用的语言，对后缀名无效</li>\n<li><code>-pipe</code>: 使用管道代替编译中的临时文件</li>\n<li><code>include file</code>: 包含某个文件代码</li>\n<li><code>imacros file</code>: 将file文件的宏，拓展到gcc/g++的输入文件，宏定义本身不出现在输入文件中</li>\n<li><code>Dmacro</code>: 定义宏</li>\n<li><code>-C</code>: 预处理时，不删除注释信息</li>\n</ul>\n<h3 id=\"调试和优化信息\"><a href=\"#调试和优化信息\" class=\"headerlink\" title=\"调试和优化信息\"></a>调试和优化信息</h3><ul>\n<li><code>-g</code>: 生成调试信息。可以用GDB等调试器调试程序。</li>\n<li><code>-O&lt;level&gt;</code>: 设置优化级别。<code>&lt;level&gt;</code>可以是0、1、2、3，其中<code>-O0</code>表示不进行优化，<code>-O2</code>和<code>-O3</code>表示更高级别的优化。</li>\n<li><code>-Og</code>: 优化生成的代码，但不会干扰调试。</li>\n</ul>\n<h3 id=\"警告控制\"><a href=\"#警告控制\" class=\"headerlink\" title=\"警告控制\"></a>警告控制</h3><ul>\n<li><code>-Wall</code>: 打开几乎所有的警告。</li>\n<li><code>-Wextra</code>: 打开额外的警告。</li>\n<li><code>-Werror</code>: 把所有的警告当作错误。</li>\n</ul>\n<h3 id=\"链接库和路径\"><a href=\"#链接库和路径\" class=\"headerlink\" title=\"链接库和路径\"></a>链接库和路径</h3><ul>\n<li><code>-l&lt;library&gt;</code>: 链接一个库。例如，使用<code>-lm</code>来链接数学库<code>libm.so</code>。</li>\n<li><code>-L&lt;directory&gt;</code>: 添加库文件搜索的目录。</li>\n<li><p><code>-I&lt;directory&gt;</code>: 添加头文件搜索的目录。</p>\n</li>\n<li><p><code>-static</code>: 使用静态链接，不使用动态链接库。编译出来的东西，一般都很大。</p>\n</li>\n<li><code>-fPIC</code>: 生成位置无关代码，通常用于创建共享库。</li>\n<li><code>-share</code>: 尽量使用动态库，生成的文件会较小，但需要系统有动态库。</li>\n</ul>\n<h3 id=\"预处理器选项\"><a href=\"#预处理器选项\" class=\"headerlink\" title=\"预处理器选项\"></a>预处理器选项</h3><ul>\n<li><code>-D&lt;macro&gt;</code>: 定义宏。例如，<code>-DDEBUG</code>会定义宏<code>DEBUG</code>。</li>\n<li><code>-U&lt;macro&gt;</code>: 取消宏的定义。</li>\n</ul>\n<h3 id=\"其他选项\"><a href=\"#其他选项\" class=\"headerlink\" title=\"其他选项\"></a>其他选项</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">选项</th>\n<th style=\"text-align:left\">解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">-ansi</td>\n<td style=\"text-align:left\">只支持 ANSI 标准的 C 语法。这一选项将禁止 GNU C 的某些特色， 例如 asm 或 typeof 关键词。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-c</td>\n<td style=\"text-align:left\">只编译并生成目标文件。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-DMACRO</td>\n<td style=\"text-align:left\">以字符串”1”定义 MACRO 宏。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-DMACRO=DEFN</td>\n<td style=\"text-align:left\">以字符串”DEFN”定义 MACRO 宏。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-E</td>\n<td style=\"text-align:left\">只运行 C 预编译器。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-g</td>\n<td style=\"text-align:left\">生成调试信息。GNU 调试器可利用该信息。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-IDIRECTORY</td>\n<td style=\"text-align:left\">指定额外的头文件搜索路径DIRECTORY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-LDIRECTORY</td>\n<td style=\"text-align:left\">指定额外的函数库搜索路径DIRECTORY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-lLIBRARY</td>\n<td style=\"text-align:left\">连接时搜索指定的函数库LIBRARY。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-m486</td>\n<td style=\"text-align:left\">针对 486 进行代码优化。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-o FILE</td>\n<td style=\"text-align:left\">生成指定的输出文件。用在生成可执行文件时。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O0</td>\n<td style=\"text-align:left\">不进行优化处理。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O 或 -O1</td>\n<td style=\"text-align:left\">优化生成代码。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O2</td>\n<td style=\"text-align:left\">进一步优化。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-O3</td>\n<td style=\"text-align:left\">比 -O2 更进一步优化，包括 inline 函数。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-shared</td>\n<td style=\"text-align:left\">生成共享目标文件。通常用在建立共享库时。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-static</td>\n<td style=\"text-align:left\">禁止使用共享连接。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-UMACRO</td>\n<td style=\"text-align:left\">取消对 MACRO 宏的定义。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-w</td>\n<td style=\"text-align:left\">不生成任何警告信息。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">-Wall</td>\n<td style=\"text-align:left\">生成所有警告信息。</td>\n</tr>\n</tbody>\n</table>\n</div>\n"},{"title":"Git常见用法","date":"2024-01-04T04:07:20.000Z","cover":"/img/default_cover01.jpg","top_img":"2024/01/04/git/image-20231204110955462.png","_content":"\n#### 怎样撤销一个已经push到远端的版本\n\n```\n每次push之前线pull一下\n\n1、查看当前提交的信息，找到需要撤回到的版本号复制，一串十六进制的数\ngit log\n\n2、使用git reset\ngit reset --soft 复制的版本号\n\n3、强制回退当前版本号\n// 确认一下当前版本\ngit log\n// 谨慎使用，强制使用本地仓库代码修改远程仓库\ngit push orgin master --force\n```\n\n#### 新建分支并同步到远端的分支\n\n```\n# 在本地新建一个名字为branch_name的分支，并与远端的origin/branch_name同步\ngit checkout -b branch_name origin/branch_name\n```\n\n#### 解决git clone超时的问题\n\n从github上clone代码仓库报错`Failed to connect to github.com port 443 after 21038 ms: Couldn't connect to server`且尝试去ping一下github官网会丢包\n\n![image-20231204110955462](git/image-20231204110955462.png)\n\n解决方案\n\n修改系统的hosts，跳过域名解析的过程，直接用ip地址访问\n\n```\n192.30.255.112 github.com git\n185.31.16.184 github.global.ssl.fastly.net\n```\n\n![image-20231204111125551](git/image-20231204111125551.png)\n\n修改hosts需要给文件更高的权限\n\n![image-20231204111350240](git/image-20231204111350240.png)\n\n#### github中git push出现超时的问题\n\n![image-20231204112945547](git/image-20231204112945547.png)\n\n解决方案\n\n1、打开本机的代理服务器\n\n![image-20231204113100512](git/image-20231204113100512.png)\n\n2、取消git config里面的http和https代理\n\n![image-20231204113208566](git/image-20231204113208566.png)\n\n3、设置http代理服务器\n\n![image-20231204113304822](git/image-20231204113304822.png)\n\n#### linux中输出一个文件夹下面的所有文件名\n\n- **`/path/to/directory`**: 替换为目标目录的路径。\n- **`-maxdepth 1`**: 限制`find`的搜索深度为1，即仅在指定的目录中搜索，而不会搜索其子目录。\n- **`-type f`**: 限制搜索结果为普通文件（不包括目录和其他类型的文件）。\n- **`-exec basename {} \\;`**: 对每一个找到的文件执行`basename`命令，即输出文件的基本名称。`{}`是`find`命令的占位符，表示每个找到的文件的路径。`\\;`表示命令结束。\n\n```\nfind /path/to/directory -maxdepth 1 -type f -exec basename {} \\;\n```\n\n#### git查看远端仓库地址\n\n```\ngit remote -v\n\n# 更改远程仓库\ngit remote set-url origin 仓库地址\n```\n\n#### 查看代码贡献量\n\n> 按照各个作者的修改代码总数排序\n\n```\ngit log --pretty=\"%aN\" | sort | uniq -c | while read count author; do echo -n \"$author \"; git log --author=\"$author\" --pretty=tformat: --numstat | awk '{ add += $1; subs += $2 } END { total = add + subs; printf \"%d\\n\", total }'; done | sort -rnk2\n```\n\n","source":"_posts/git.md","raw":"---\ntitle: Git常见用法\ndate: 2024-01-04 12:07:20\ntags: git\ncategories: 技术研究\ncover: /img/default_cover01.jpg\ntop_img: image-20231204110955462.png\n---\n\n#### 怎样撤销一个已经push到远端的版本\n\n```\n每次push之前线pull一下\n\n1、查看当前提交的信息，找到需要撤回到的版本号复制，一串十六进制的数\ngit log\n\n2、使用git reset\ngit reset --soft 复制的版本号\n\n3、强制回退当前版本号\n// 确认一下当前版本\ngit log\n// 谨慎使用，强制使用本地仓库代码修改远程仓库\ngit push orgin master --force\n```\n\n#### 新建分支并同步到远端的分支\n\n```\n# 在本地新建一个名字为branch_name的分支，并与远端的origin/branch_name同步\ngit checkout -b branch_name origin/branch_name\n```\n\n#### 解决git clone超时的问题\n\n从github上clone代码仓库报错`Failed to connect to github.com port 443 after 21038 ms: Couldn't connect to server`且尝试去ping一下github官网会丢包\n\n![image-20231204110955462](git/image-20231204110955462.png)\n\n解决方案\n\n修改系统的hosts，跳过域名解析的过程，直接用ip地址访问\n\n```\n192.30.255.112 github.com git\n185.31.16.184 github.global.ssl.fastly.net\n```\n\n![image-20231204111125551](git/image-20231204111125551.png)\n\n修改hosts需要给文件更高的权限\n\n![image-20231204111350240](git/image-20231204111350240.png)\n\n#### github中git push出现超时的问题\n\n![image-20231204112945547](git/image-20231204112945547.png)\n\n解决方案\n\n1、打开本机的代理服务器\n\n![image-20231204113100512](git/image-20231204113100512.png)\n\n2、取消git config里面的http和https代理\n\n![image-20231204113208566](git/image-20231204113208566.png)\n\n3、设置http代理服务器\n\n![image-20231204113304822](git/image-20231204113304822.png)\n\n#### linux中输出一个文件夹下面的所有文件名\n\n- **`/path/to/directory`**: 替换为目标目录的路径。\n- **`-maxdepth 1`**: 限制`find`的搜索深度为1，即仅在指定的目录中搜索，而不会搜索其子目录。\n- **`-type f`**: 限制搜索结果为普通文件（不包括目录和其他类型的文件）。\n- **`-exec basename {} \\;`**: 对每一个找到的文件执行`basename`命令，即输出文件的基本名称。`{}`是`find`命令的占位符，表示每个找到的文件的路径。`\\;`表示命令结束。\n\n```\nfind /path/to/directory -maxdepth 1 -type f -exec basename {} \\;\n```\n\n#### git查看远端仓库地址\n\n```\ngit remote -v\n\n# 更改远程仓库\ngit remote set-url origin 仓库地址\n```\n\n#### 查看代码贡献量\n\n> 按照各个作者的修改代码总数排序\n\n```\ngit log --pretty=\"%aN\" | sort | uniq -c | while read count author; do echo -n \"$author \"; git log --author=\"$author\" --pretty=tformat: --numstat | awk '{ add += $1; subs += $2 } END { total = add + subs; printf \"%d\\n\", total }'; done | sort -rnk2\n```\n\n","slug":"git","published":1,"updated":"2024-06-05T09:03:03.788Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttw002m08jvbn4chfz2","content":"<h4 id=\"怎样撤销一个已经push到远端的版本\"><a href=\"#怎样撤销一个已经push到远端的版本\" class=\"headerlink\" title=\"怎样撤销一个已经push到远端的版本\"></a>怎样撤销一个已经push到远端的版本</h4><figure class=\"highlight arcade\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arcade\">每次<span class=\"hljs-built_in\">push</span>之前线pull一下<br><br><span class=\"hljs-number\">1</span>、查看当前提交的信息，找到需要撤回到的版本号复制，一串十六进制的数<br>git <span class=\"hljs-built_in\">log</span><br><br><span class=\"hljs-number\">2</span>、使用git reset<br>git reset --soft 复制的版本号<br><br><span class=\"hljs-number\">3</span>、强制回退当前版本号<br><span class=\"hljs-comment\">// 确认一下当前版本</span><br>git <span class=\"hljs-built_in\">log</span><br><span class=\"hljs-comment\">// 谨慎使用，强制使用本地仓库代码修改远程仓库</span><br>git <span class=\"hljs-built_in\">push</span> orgin master --force<br></code></pre></td></tr></table></figure>\n<h4 id=\"新建分支并同步到远端的分支\"><a href=\"#新建分支并同步到远端的分支\" class=\"headerlink\" title=\"新建分支并同步到远端的分支\"></a>新建分支并同步到远端的分支</h4><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-comment\"># 在本地新建一个名字为branch_name的分支，并与远端的origin/branch_name同步</span><br>git checkout -<span class=\"hljs-keyword\">b </span><span class=\"hljs-keyword\">branch_name </span><span class=\"hljs-keyword\">origin/branch_name</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"解决git-clone超时的问题\"><a href=\"#解决git-clone超时的问题\" class=\"headerlink\" title=\"解决git clone超时的问题\"></a>解决git clone超时的问题</h4><p>从github上clone代码仓库报错<code>Failed to connect to github.com port 443 after 21038 ms: Couldn&#39;t connect to server</code>且尝试去ping一下github官网会丢包</p>\n<img src=\"/2024/01/04/git/image-20231204110955462.png\" class=\"\" title=\"image-20231204110955462\">\n<p>解决方案</p>\n<p>修改系统的hosts，跳过域名解析的过程，直接用ip地址访问</p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\"><span class=\"hljs-number\">192.30.255.112</span> github.com git<br><span class=\"hljs-number\">185.31.16.184</span> github.global.ssl.fastly.net<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/01/04/git/image-20231204111125551.png\" class=\"\" title=\"image-20231204111125551\">\n<p>修改hosts需要给文件更高的权限</p>\n<img src=\"/2024/01/04/git/image-20231204111350240.png\" class=\"\" title=\"image-20231204111350240\">\n<h4 id=\"github中git-push出现超时的问题\"><a href=\"#github中git-push出现超时的问题\" class=\"headerlink\" title=\"github中git push出现超时的问题\"></a>github中git push出现超时的问题</h4><img src=\"/2024/01/04/git/image-20231204112945547.png\" class=\"\" title=\"image-20231204112945547\">\n<p>解决方案</p>\n<p>1、打开本机的代理服务器</p>\n<img src=\"/2024/01/04/git/image-20231204113100512.png\" class=\"\" title=\"image-20231204113100512\">\n<p>2、取消git config里面的http和https代理</p>\n<img src=\"/2024/01/04/git/image-20231204113208566.png\" class=\"\" title=\"image-20231204113208566\">\n<p>3、设置http代理服务器</p>\n<img src=\"/2024/01/04/git/image-20231204113304822.png\" class=\"\" title=\"image-20231204113304822\">\n<h4 id=\"linux中输出一个文件夹下面的所有文件名\"><a href=\"#linux中输出一个文件夹下面的所有文件名\" class=\"headerlink\" title=\"linux中输出一个文件夹下面的所有文件名\"></a>linux中输出一个文件夹下面的所有文件名</h4><ul>\n<li><strong><code>/path/to/directory</code></strong>: 替换为目标目录的路径。</li>\n<li><strong><code>-maxdepth 1</code></strong>: 限制<code>find</code>的搜索深度为1，即仅在指定的目录中搜索，而不会搜索其子目录。</li>\n<li><strong><code>-type f</code></strong>: 限制搜索结果为普通文件（不包括目录和其他类型的文件）。</li>\n<li><strong><code>-exec basename &#123;&#125; \\;</code></strong>: 对每一个找到的文件执行<code>basename</code>命令，即输出文件的基本名称。<code>&#123;&#125;</code>是<code>find</code>命令的占位符，表示每个找到的文件的路径。<code>\\;</code>表示命令结束。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">find /path/to/directory -maxdepth 1 -<span class=\"hljs-built_in\">type</span> f -<span class=\"hljs-built_in\">exec</span> <span class=\"hljs-built_in\">basename</span> &#123;&#125; \\;<br></code></pre></td></tr></table></figure>\n<h4 id=\"git查看远端仓库地址\"><a href=\"#git查看远端仓库地址\" class=\"headerlink\" title=\"git查看远端仓库地址\"></a>git查看远端仓库地址</h4><figure class=\"highlight dsconfig\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dsconfig\"><span class=\"hljs-string\">git</span> <span class=\"hljs-string\">remote</span> -<span class=\"hljs-string\">v</span><br><br><span class=\"hljs-comment\"># 更改远程仓库</span><br><span class=\"hljs-string\">git</span> <span class=\"hljs-string\">remote</span> <span class=\"hljs-built_in\">set-url</span> <span class=\"hljs-string\">origin</span> 仓库地址<br></code></pre></td></tr></table></figure>\n<h4 id=\"查看代码贡献量\"><a href=\"#查看代码贡献量\" class=\"headerlink\" title=\"查看代码贡献量\"></a>查看代码贡献量</h4><blockquote>\n<p>按照各个作者的修改代码总数排序</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">git <span class=\"hljs-built_in\">log</span> --pretty=<span class=\"hljs-string\">&quot;%aN&quot;</span> | <span class=\"hljs-built_in\">sort</span> | <span class=\"hljs-built_in\">uniq</span> -c | <span class=\"hljs-keyword\">while</span> <span class=\"hljs-built_in\">read</span> count author; <span class=\"hljs-keyword\">do</span> <span class=\"hljs-built_in\">echo</span> -n <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$author</span> &quot;</span>; git <span class=\"hljs-built_in\">log</span> --author=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$author</span>&quot;</span> --pretty=tformat: --numstat | awk <span class=\"hljs-string\">&#x27;&#123; add += $1; subs += $2 &#125; END &#123; total = add + subs; printf &quot;%d\\n&quot;, total &#125;&#x27;</span>; <span class=\"hljs-keyword\">done</span> | <span class=\"hljs-built_in\">sort</span> -rnk2<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h4 id=\"怎样撤销一个已经push到远端的版本\"><a href=\"#怎样撤销一个已经push到远端的版本\" class=\"headerlink\" title=\"怎样撤销一个已经push到远端的版本\"></a>怎样撤销一个已经push到远端的版本</h4><figure class=\"highlight arcade\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arcade\">每次<span class=\"hljs-built_in\">push</span>之前线pull一下<br><br><span class=\"hljs-number\">1</span>、查看当前提交的信息，找到需要撤回到的版本号复制，一串十六进制的数<br>git <span class=\"hljs-built_in\">log</span><br><br><span class=\"hljs-number\">2</span>、使用git reset<br>git reset --soft 复制的版本号<br><br><span class=\"hljs-number\">3</span>、强制回退当前版本号<br><span class=\"hljs-comment\">// 确认一下当前版本</span><br>git <span class=\"hljs-built_in\">log</span><br><span class=\"hljs-comment\">// 谨慎使用，强制使用本地仓库代码修改远程仓库</span><br>git <span class=\"hljs-built_in\">push</span> orgin master --force<br></code></pre></td></tr></table></figure>\n<h4 id=\"新建分支并同步到远端的分支\"><a href=\"#新建分支并同步到远端的分支\" class=\"headerlink\" title=\"新建分支并同步到远端的分支\"></a>新建分支并同步到远端的分支</h4><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-comment\"># 在本地新建一个名字为branch_name的分支，并与远端的origin/branch_name同步</span><br>git checkout -<span class=\"hljs-keyword\">b </span><span class=\"hljs-keyword\">branch_name </span><span class=\"hljs-keyword\">origin/branch_name</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"解决git-clone超时的问题\"><a href=\"#解决git-clone超时的问题\" class=\"headerlink\" title=\"解决git clone超时的问题\"></a>解决git clone超时的问题</h4><p>从github上clone代码仓库报错<code>Failed to connect to github.com port 443 after 21038 ms: Couldn&#39;t connect to server</code>且尝试去ping一下github官网会丢包</p>\n<img src=\"/2024/01/04/git/image-20231204110955462.png\" class=\"\" title=\"image-20231204110955462\">\n<p>解决方案</p>\n<p>修改系统的hosts，跳过域名解析的过程，直接用ip地址访问</p>\n<figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\"><span class=\"hljs-number\">192.30.255.112</span> github.com git<br><span class=\"hljs-number\">185.31.16.184</span> github.global.ssl.fastly.net<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/01/04/git/image-20231204111125551.png\" class=\"\" title=\"image-20231204111125551\">\n<p>修改hosts需要给文件更高的权限</p>\n<img src=\"/2024/01/04/git/image-20231204111350240.png\" class=\"\" title=\"image-20231204111350240\">\n<h4 id=\"github中git-push出现超时的问题\"><a href=\"#github中git-push出现超时的问题\" class=\"headerlink\" title=\"github中git push出现超时的问题\"></a>github中git push出现超时的问题</h4><img src=\"/2024/01/04/git/image-20231204112945547.png\" class=\"\" title=\"image-20231204112945547\">\n<p>解决方案</p>\n<p>1、打开本机的代理服务器</p>\n<img src=\"/2024/01/04/git/image-20231204113100512.png\" class=\"\" title=\"image-20231204113100512\">\n<p>2、取消git config里面的http和https代理</p>\n<img src=\"/2024/01/04/git/image-20231204113208566.png\" class=\"\" title=\"image-20231204113208566\">\n<p>3、设置http代理服务器</p>\n<img src=\"/2024/01/04/git/image-20231204113304822.png\" class=\"\" title=\"image-20231204113304822\">\n<h4 id=\"linux中输出一个文件夹下面的所有文件名\"><a href=\"#linux中输出一个文件夹下面的所有文件名\" class=\"headerlink\" title=\"linux中输出一个文件夹下面的所有文件名\"></a>linux中输出一个文件夹下面的所有文件名</h4><ul>\n<li><strong><code>/path/to/directory</code></strong>: 替换为目标目录的路径。</li>\n<li><strong><code>-maxdepth 1</code></strong>: 限制<code>find</code>的搜索深度为1，即仅在指定的目录中搜索，而不会搜索其子目录。</li>\n<li><strong><code>-type f</code></strong>: 限制搜索结果为普通文件（不包括目录和其他类型的文件）。</li>\n<li><strong><code>-exec basename &#123;&#125; \\;</code></strong>: 对每一个找到的文件执行<code>basename</code>命令，即输出文件的基本名称。<code>&#123;&#125;</code>是<code>find</code>命令的占位符，表示每个找到的文件的路径。<code>\\;</code>表示命令结束。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">find /path/to/directory -maxdepth 1 -<span class=\"hljs-built_in\">type</span> f -<span class=\"hljs-built_in\">exec</span> <span class=\"hljs-built_in\">basename</span> &#123;&#125; \\;<br></code></pre></td></tr></table></figure>\n<h4 id=\"git查看远端仓库地址\"><a href=\"#git查看远端仓库地址\" class=\"headerlink\" title=\"git查看远端仓库地址\"></a>git查看远端仓库地址</h4><figure class=\"highlight dsconfig\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dsconfig\"><span class=\"hljs-string\">git</span> <span class=\"hljs-string\">remote</span> -<span class=\"hljs-string\">v</span><br><br><span class=\"hljs-comment\"># 更改远程仓库</span><br><span class=\"hljs-string\">git</span> <span class=\"hljs-string\">remote</span> <span class=\"hljs-built_in\">set-url</span> <span class=\"hljs-string\">origin</span> 仓库地址<br></code></pre></td></tr></table></figure>\n<h4 id=\"查看代码贡献量\"><a href=\"#查看代码贡献量\" class=\"headerlink\" title=\"查看代码贡献量\"></a>查看代码贡献量</h4><blockquote>\n<p>按照各个作者的修改代码总数排序</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">git <span class=\"hljs-built_in\">log</span> --pretty=<span class=\"hljs-string\">&quot;%aN&quot;</span> | <span class=\"hljs-built_in\">sort</span> | <span class=\"hljs-built_in\">uniq</span> -c | <span class=\"hljs-keyword\">while</span> <span class=\"hljs-built_in\">read</span> count author; <span class=\"hljs-keyword\">do</span> <span class=\"hljs-built_in\">echo</span> -n <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$author</span> &quot;</span>; git <span class=\"hljs-built_in\">log</span> --author=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$author</span>&quot;</span> --pretty=tformat: --numstat | awk <span class=\"hljs-string\">&#x27;&#123; add += $1; subs += $2 &#125; END &#123; total = add + subs; printf &quot;%d\\n&quot;, total &#125;&#x27;</span>; <span class=\"hljs-keyword\">done</span> | <span class=\"hljs-built_in\">sort</span> -rnk2<br></code></pre></td></tr></table></figure>\n"},{"title":"Go语言学习-函数","date":"2024-07-09T08:41:53.000Z","cover":"/img/default_cover.jpg","top_img":null,"_content":"### \n\n# 函数\n\n`Go`语言中，函数的命名定义需要`func`来作为唯一标识，并且使用首字母大小写来区分，在当前文件夹下的某一个函数是否可以通过`import bag`的方式来对其他文件的可见性，如果是大写则说明可以导入，小写则只能在当前文件内可见。\n\n函数通过四个属性来唯一确定函数签名-函数名、形参列表、返回值列表、函数体。\n\n```go\nfunc name(parameter-list) (result-list) {\n    body\n}\n```\n\n*多返回值*\n\n在`Go`中，一个函数可以返回多个值，并且函数的返回值必须要有变量来接收，如果我们不需要某一个返回值，通常我们会用`_`下划线来接收这个返回值，作为接收某一个返回值的占位符。\n\n我们通常想要保留函数运行过程中的某一些局部变量的结果，或者想要拥有多个返回变量，比较常见的方法就是，定义一个全局变量，并把变量作为引用类型传入到函数内，这样的方式可以达到效果，但是会有参数列表冗余的现象，如果我们需要保留的局部变量的参数非常多，那么也需要定义多个参数来一一完成。\n\n使用多返回值可以更清晰的表达结果，避免全局变量定义的冗余，以及引用传入的冗余，我们可以将局部变量返回，并在全局中定义接收。\n\n使用多返回值的另一个好处就是错误的处理更加方便，通常我们会将错误作为函数的最后一个返回值。这允许调用者很容易地判断操作是否成功，而不必单独检查错误变量或异常。\n\n```go\nfunc divide(dividend, divisor float64) (float64, error) {\n    if divisor == 0.0 {\n        return 0.0, errors.New(\"cannot divide by zero\")\n    }\n    return dividend / divisor, nil\n}\n```\n\n## 函数值\n\n在`Go`中，函数被看作第一类值（第一类值意思就是说明这一个值可以像基本数据类型一样使用），具体来说：被赋值给变量、作为参数传递给函数、作为函数的返回值、在运行时动态创建、被存储在数据结构中。\n\n函数类型的零值是`nil`，调用值为`nil`的函数会引起`panic`错误，而且函数可以与`nil`进行比较。但是函数与函数之间时不可以比较的，也不能使用函数值作为`map`的`key`。\n\n```go\nfunc square(n int) int { return n * n }\nfunc negative(n int) int { return -n }\nfunc product(m, n int) int { return m * n }\n\nf := square\nfmt.Println(f(3)) // \"9\"\n\nf = negative\nfmt.Println(f(3))     // \"-3\"\nfmt.Printf(\"%T\\n\", f) // \"func(int) int\"\n\nf = product // compile error: can't assign func(int, int) int to func(int) int\n```\n\n函数值使得我们不仅仅可以通过数据来参数化函数，也可以通过行为。\n\n> `strings.Map()`是一个高阶函数，它允许你对字符串中的每个字符执行一个指定的映射操作。这个函数接受两个参数：第一个参数是一个映射函数，此映射函数会被应用到字符串中的每个字符上；第二个参数是要进行操作的字符串。映射函数需要接收一个rune类型的值，并返回一个rune类型的值。如果映射函数返回负值，则该字符会从结果字符串中被删除。\n\n```go\nfunc add1(r rune) rune { return r + 1 }\n\nfmt.Println(strings.Map(add1, \"HAL-9000\")) // \"IBM.:111\"\nfmt.Println(strings.Map(add1, \"VMS\"))      // \"WNT\"\nfmt.Println(strings.Map(add1, \"Admix\"))    // \"Benjy\"\n```\n\n## 可变参数\n\n参数数量可变的函数称为可变参数函数。在`go`中一般通过`...`的形式来接收任意数量的参数，比如使用`vals ...int`接收任意数量的`int`类型参数。我们可以通过切片的方式来读取参数列表里面实际的值。在实际的运行过程中，调用者会隐式的创建一个数组，并将原始参数复制到数组当中，再把数组的一个切片作为参数传给被调用的函数。\n\n```go\nfunc sum(vals ...int) int {\n    total := 0\n    for _, val := range vals {\n        total += val\n    }\n    return total\n}\n```\n\n## 错误\n\n* Defferred函数\n\n    `defer`机制类似于延迟执行的感觉，在我们的代码当中，可能会因为打开某一些文件，但是由于打开失败或者一些其他的原因，导致我们的执行异常退出，或者提前退出，这个时候要确保能够让文件正常关闭，我们可以使用`defer`来在文件关闭语句前标记，这样子，即使异常退出，在函数返回前也会执行`defer`的语句，通常`defer`修饰的语句执行顺序和定义的顺序相反。\n\n* Panic异常\n\n    `Go`的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等，这些运行时错误会引起`panic`异常。\n\n    一般来说，当`panic`异常发生时，程序会中断运行，并立即执行在该协程中的被延迟的`defer`函数，随后输出错误日志。通常会在发生严重错误的时候来使用。\n\n* Recover捕获异常\n\n    在`Go`语言中，异常捕获是通过内置的`recover`函数实现的。当一个`goroutine`发生`panic`时，你可以使用`defer`机制来确保调用`recover`，这样就能拦截到`panic`引起的异常并进行处理。\n\n    `recover`只有在`defer`延迟执行的函数中直接调用时才有效。如果`panic`被触发，`recover`会捕获到引发`panic`的值，并且恢复正常的程序执行流程，即不再继续向上传递`panic`，转而执行`recover`所在的`defer`之后的代码。如果没有发生`panic`，或者`recover`没有在适当的位置被调用，则`recover`返回`nil`。\n\n    ```go\n    package main\n\n    import \"fmt\"\n\n    func potentiallyPanic() {\n        panic(\"something went wrong\")\n    }\n\n    func catchPanic() {\n        if r := recover(); r != nil {\n            fmt.Println(\"Recovered from panic:\", r)\n        }\n    }\n\n    func main() {\n        // 使用 defer 语句注册 catchPanic 函数\n        // 它将在 main 函数返回前最后执行\n        defer catchPanic()\n\n        // 这个函数可能会触发 panic\n        potentiallyPanic()\n\n        // 这行代码不会被执行，因为上面的函数已经触发了 panic\n        fmt.Println(\"This line will not be executed.\")\n    }\n\n    ```","source":"_posts/go-function.md","raw":"---\ntitle: Go语言学习-函数\ntags:\n  - Golang\ncategories: 技术研究\ndate: 2024-07-09 16:41:53\ncover:\ntop_img:\n---\n### \n\n# 函数\n\n`Go`语言中，函数的命名定义需要`func`来作为唯一标识，并且使用首字母大小写来区分，在当前文件夹下的某一个函数是否可以通过`import bag`的方式来对其他文件的可见性，如果是大写则说明可以导入，小写则只能在当前文件内可见。\n\n函数通过四个属性来唯一确定函数签名-函数名、形参列表、返回值列表、函数体。\n\n```go\nfunc name(parameter-list) (result-list) {\n    body\n}\n```\n\n*多返回值*\n\n在`Go`中，一个函数可以返回多个值，并且函数的返回值必须要有变量来接收，如果我们不需要某一个返回值，通常我们会用`_`下划线来接收这个返回值，作为接收某一个返回值的占位符。\n\n我们通常想要保留函数运行过程中的某一些局部变量的结果，或者想要拥有多个返回变量，比较常见的方法就是，定义一个全局变量，并把变量作为引用类型传入到函数内，这样的方式可以达到效果，但是会有参数列表冗余的现象，如果我们需要保留的局部变量的参数非常多，那么也需要定义多个参数来一一完成。\n\n使用多返回值可以更清晰的表达结果，避免全局变量定义的冗余，以及引用传入的冗余，我们可以将局部变量返回，并在全局中定义接收。\n\n使用多返回值的另一个好处就是错误的处理更加方便，通常我们会将错误作为函数的最后一个返回值。这允许调用者很容易地判断操作是否成功，而不必单独检查错误变量或异常。\n\n```go\nfunc divide(dividend, divisor float64) (float64, error) {\n    if divisor == 0.0 {\n        return 0.0, errors.New(\"cannot divide by zero\")\n    }\n    return dividend / divisor, nil\n}\n```\n\n## 函数值\n\n在`Go`中，函数被看作第一类值（第一类值意思就是说明这一个值可以像基本数据类型一样使用），具体来说：被赋值给变量、作为参数传递给函数、作为函数的返回值、在运行时动态创建、被存储在数据结构中。\n\n函数类型的零值是`nil`，调用值为`nil`的函数会引起`panic`错误，而且函数可以与`nil`进行比较。但是函数与函数之间时不可以比较的，也不能使用函数值作为`map`的`key`。\n\n```go\nfunc square(n int) int { return n * n }\nfunc negative(n int) int { return -n }\nfunc product(m, n int) int { return m * n }\n\nf := square\nfmt.Println(f(3)) // \"9\"\n\nf = negative\nfmt.Println(f(3))     // \"-3\"\nfmt.Printf(\"%T\\n\", f) // \"func(int) int\"\n\nf = product // compile error: can't assign func(int, int) int to func(int) int\n```\n\n函数值使得我们不仅仅可以通过数据来参数化函数，也可以通过行为。\n\n> `strings.Map()`是一个高阶函数，它允许你对字符串中的每个字符执行一个指定的映射操作。这个函数接受两个参数：第一个参数是一个映射函数，此映射函数会被应用到字符串中的每个字符上；第二个参数是要进行操作的字符串。映射函数需要接收一个rune类型的值，并返回一个rune类型的值。如果映射函数返回负值，则该字符会从结果字符串中被删除。\n\n```go\nfunc add1(r rune) rune { return r + 1 }\n\nfmt.Println(strings.Map(add1, \"HAL-9000\")) // \"IBM.:111\"\nfmt.Println(strings.Map(add1, \"VMS\"))      // \"WNT\"\nfmt.Println(strings.Map(add1, \"Admix\"))    // \"Benjy\"\n```\n\n## 可变参数\n\n参数数量可变的函数称为可变参数函数。在`go`中一般通过`...`的形式来接收任意数量的参数，比如使用`vals ...int`接收任意数量的`int`类型参数。我们可以通过切片的方式来读取参数列表里面实际的值。在实际的运行过程中，调用者会隐式的创建一个数组，并将原始参数复制到数组当中，再把数组的一个切片作为参数传给被调用的函数。\n\n```go\nfunc sum(vals ...int) int {\n    total := 0\n    for _, val := range vals {\n        total += val\n    }\n    return total\n}\n```\n\n## 错误\n\n* Defferred函数\n\n    `defer`机制类似于延迟执行的感觉，在我们的代码当中，可能会因为打开某一些文件，但是由于打开失败或者一些其他的原因，导致我们的执行异常退出，或者提前退出，这个时候要确保能够让文件正常关闭，我们可以使用`defer`来在文件关闭语句前标记，这样子，即使异常退出，在函数返回前也会执行`defer`的语句，通常`defer`修饰的语句执行顺序和定义的顺序相反。\n\n* Panic异常\n\n    `Go`的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等，这些运行时错误会引起`panic`异常。\n\n    一般来说，当`panic`异常发生时，程序会中断运行，并立即执行在该协程中的被延迟的`defer`函数，随后输出错误日志。通常会在发生严重错误的时候来使用。\n\n* Recover捕获异常\n\n    在`Go`语言中，异常捕获是通过内置的`recover`函数实现的。当一个`goroutine`发生`panic`时，你可以使用`defer`机制来确保调用`recover`，这样就能拦截到`panic`引起的异常并进行处理。\n\n    `recover`只有在`defer`延迟执行的函数中直接调用时才有效。如果`panic`被触发，`recover`会捕获到引发`panic`的值，并且恢复正常的程序执行流程，即不再继续向上传递`panic`，转而执行`recover`所在的`defer`之后的代码。如果没有发生`panic`，或者`recover`没有在适当的位置被调用，则`recover`返回`nil`。\n\n    ```go\n    package main\n\n    import \"fmt\"\n\n    func potentiallyPanic() {\n        panic(\"something went wrong\")\n    }\n\n    func catchPanic() {\n        if r := recover(); r != nil {\n            fmt.Println(\"Recovered from panic:\", r)\n        }\n    }\n\n    func main() {\n        // 使用 defer 语句注册 catchPanic 函数\n        // 它将在 main 函数返回前最后执行\n        defer catchPanic()\n\n        // 这个函数可能会触发 panic\n        potentiallyPanic()\n\n        // 这行代码不会被执行，因为上面的函数已经触发了 panic\n        fmt.Println(\"This line will not be executed.\")\n    }\n\n    ```","slug":"go-function","published":1,"updated":"2024-07-10T07:24:55.828Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttw002q08jva3na0k4k","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h1><p><code>Go</code>语言中，函数的命名定义需要<code>func</code>来作为唯一标识，并且使用首字母大小写来区分，在当前文件夹下的某一个函数是否可以通过<code>import bag</code>的方式来对其他文件的可见性，如果是大写则说明可以导入，小写则只能在当前文件内可见。</p>\n<p>函数通过四个属性来唯一确定函数签名-函数名、形参列表、返回值列表、函数体。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">name</span><span class=\"hljs-params\">(parameter-list)</span></span> (result-list) &#123;<br>    body<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><em>多返回值</em></p>\n<p>在<code>Go</code>中，一个函数可以返回多个值，并且函数的返回值必须要有变量来接收，如果我们不需要某一个返回值，通常我们会用<code>_</code>下划线来接收这个返回值，作为接收某一个返回值的占位符。</p>\n<p>我们通常想要保留函数运行过程中的某一些局部变量的结果，或者想要拥有多个返回变量，比较常见的方法就是，定义一个全局变量，并把变量作为引用类型传入到函数内，这样的方式可以达到效果，但是会有参数列表冗余的现象，如果我们需要保留的局部变量的参数非常多，那么也需要定义多个参数来一一完成。</p>\n<p>使用多返回值可以更清晰的表达结果，避免全局变量定义的冗余，以及引用传入的冗余，我们可以将局部变量返回，并在全局中定义接收。</p>\n<p>使用多返回值的另一个好处就是错误的处理更加方便，通常我们会将错误作为函数的最后一个返回值。这允许调用者很容易地判断操作是否成功，而不必单独检查错误变量或异常。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">divide</span><span class=\"hljs-params\">(dividend, divisor <span class=\"hljs-type\">float64</span>)</span></span> (<span class=\"hljs-type\">float64</span>, <span class=\"hljs-type\">error</span>) &#123;<br>    <span class=\"hljs-keyword\">if</span> divisor == <span class=\"hljs-number\">0.0</span> &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0.0</span>, errors.New(<span class=\"hljs-string\">&quot;cannot divide by zero&quot;</span>)<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> dividend / divisor, <span class=\"hljs-literal\">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"函数值\"><a href=\"#函数值\" class=\"headerlink\" title=\"函数值\"></a>函数值</h2><p>在<code>Go</code>中，函数被看作第一类值（第一类值意思就是说明这一个值可以像基本数据类型一样使用），具体来说：被赋值给变量、作为参数传递给函数、作为函数的返回值、在运行时动态创建、被存储在数据结构中。</p>\n<p>函数类型的零值是<code>nil</code>，调用值为<code>nil</code>的函数会引起<code>panic</code>错误，而且函数可以与<code>nil</code>进行比较。但是函数与函数之间时不可以比较的，也不能使用函数值作为<code>map</code>的<code>key</code>。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">square</span><span class=\"hljs-params\">(n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> n * n &#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">negative</span><span class=\"hljs-params\">(n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> -n &#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">product</span><span class=\"hljs-params\">(m, n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> m * n &#125;<br><br>f := square<br>fmt.Println(f(<span class=\"hljs-number\">3</span>)) <span class=\"hljs-comment\">// &quot;9&quot;</span><br><br>f = negative<br>fmt.Println(f(<span class=\"hljs-number\">3</span>))     <span class=\"hljs-comment\">// &quot;-3&quot;</span><br>fmt.Printf(<span class=\"hljs-string\">&quot;%T\\n&quot;</span>, f) <span class=\"hljs-comment\">// &quot;func(int) int&quot;</span><br><br>f = product <span class=\"hljs-comment\">// compile error: can&#x27;t assign func(int, int) int to func(int) int</span><br></code></pre></td></tr></table></figure>\n<p>函数值使得我们不仅仅可以通过数据来参数化函数，也可以通过行为。</p>\n<blockquote>\n<p><code>strings.Map()</code>是一个高阶函数，它允许你对字符串中的每个字符执行一个指定的映射操作。这个函数接受两个参数：第一个参数是一个映射函数，此映射函数会被应用到字符串中的每个字符上；第二个参数是要进行操作的字符串。映射函数需要接收一个rune类型的值，并返回一个rune类型的值。如果映射函数返回负值，则该字符会从结果字符串中被删除。</p>\n</blockquote>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">add1</span><span class=\"hljs-params\">(r <span class=\"hljs-type\">rune</span>)</span></span> <span class=\"hljs-type\">rune</span> &#123; <span class=\"hljs-keyword\">return</span> r + <span class=\"hljs-number\">1</span> &#125;<br><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;HAL-9000&quot;</span>)) <span class=\"hljs-comment\">// &quot;IBM.:111&quot;</span><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;VMS&quot;</span>))      <span class=\"hljs-comment\">// &quot;WNT&quot;</span><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;Admix&quot;</span>))    <span class=\"hljs-comment\">// &quot;Benjy&quot;</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"可变参数\"><a href=\"#可变参数\" class=\"headerlink\" title=\"可变参数\"></a>可变参数</h2><p>参数数量可变的函数称为可变参数函数。在<code>go</code>中一般通过<code>...</code>的形式来接收任意数量的参数，比如使用<code>vals ...int</code>接收任意数量的<code>int</code>类型参数。我们可以通过切片的方式来读取参数列表里面实际的值。在实际的运行过程中，调用者会隐式的创建一个数组，并将原始参数复制到数组当中，再把数组的一个切片作为参数传给被调用的函数。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">sum</span><span class=\"hljs-params\">(vals ...<span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123;<br>    total := <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">for</span> _, val := <span class=\"hljs-keyword\">range</span> vals &#123;<br>        total += val<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> total<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"错误\"><a href=\"#错误\" class=\"headerlink\" title=\"错误\"></a>错误</h2><ul>\n<li><p>Defferred函数</p>\n<p>  <code>defer</code>机制类似于延迟执行的感觉，在我们的代码当中，可能会因为打开某一些文件，但是由于打开失败或者一些其他的原因，导致我们的执行异常退出，或者提前退出，这个时候要确保能够让文件正常关闭，我们可以使用<code>defer</code>来在文件关闭语句前标记，这样子，即使异常退出，在函数返回前也会执行<code>defer</code>的语句，通常<code>defer</code>修饰的语句执行顺序和定义的顺序相反。</p>\n</li>\n<li><p>Panic异常</p>\n<p>  <code>Go</code>的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等，这些运行时错误会引起<code>panic</code>异常。</p>\n<p>  一般来说，当<code>panic</code>异常发生时，程序会中断运行，并立即执行在该协程中的被延迟的<code>defer</code>函数，随后输出错误日志。通常会在发生严重错误的时候来使用。</p>\n</li>\n<li><p>Recover捕获异常</p>\n<p>  在<code>Go</code>语言中，异常捕获是通过内置的<code>recover</code>函数实现的。当一个<code>goroutine</code>发生<code>panic</code>时，你可以使用<code>defer</code>机制来确保调用<code>recover</code>，这样就能拦截到<code>panic</code>引起的异常并进行处理。</p>\n<p>  <code>recover</code>只有在<code>defer</code>延迟执行的函数中直接调用时才有效。如果<code>panic</code>被触发，<code>recover</code>会捕获到引发<code>panic</code>的值，并且恢复正常的程序执行流程，即不再继续向上传递<code>panic</code>，转而执行<code>recover</code>所在的<code>defer</code>之后的代码。如果没有发生<code>panic</code>，或者<code>recover</code>没有在适当的位置被调用，则<code>recover</code>返回<code>nil</code>。</p>\n  <figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">&quot;fmt&quot;</span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">potentiallyPanic</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-built_in\">panic</span>(<span class=\"hljs-string\">&quot;something went wrong&quot;</span>)<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">catchPanic</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-keyword\">if</span> r := <span class=\"hljs-built_in\">recover</span>(); r != <span class=\"hljs-literal\">nil</span> &#123;<br>        fmt.Println(<span class=\"hljs-string\">&quot;Recovered from panic:&quot;</span>, r)<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-comment\">// 使用 defer 语句注册 catchPanic 函数</span><br>    <span class=\"hljs-comment\">// 它将在 main 函数返回前最后执行</span><br>    <span class=\"hljs-keyword\">defer</span> catchPanic()<br><br>    <span class=\"hljs-comment\">// 这个函数可能会触发 panic</span><br>    potentiallyPanic()<br><br>    <span class=\"hljs-comment\">// 这行代码不会被执行，因为上面的函数已经触发了 panic</span><br>    fmt.Println(<span class=\"hljs-string\">&quot;This line will not be executed.&quot;</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure></li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><h1 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h1><p><code>Go</code>语言中，函数的命名定义需要<code>func</code>来作为唯一标识，并且使用首字母大小写来区分，在当前文件夹下的某一个函数是否可以通过<code>import bag</code>的方式来对其他文件的可见性，如果是大写则说明可以导入，小写则只能在当前文件内可见。</p>\n<p>函数通过四个属性来唯一确定函数签名-函数名、形参列表、返回值列表、函数体。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">name</span><span class=\"hljs-params\">(parameter-list)</span></span> (result-list) &#123;<br>    body<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><em>多返回值</em></p>\n<p>在<code>Go</code>中，一个函数可以返回多个值，并且函数的返回值必须要有变量来接收，如果我们不需要某一个返回值，通常我们会用<code>_</code>下划线来接收这个返回值，作为接收某一个返回值的占位符。</p>\n<p>我们通常想要保留函数运行过程中的某一些局部变量的结果，或者想要拥有多个返回变量，比较常见的方法就是，定义一个全局变量，并把变量作为引用类型传入到函数内，这样的方式可以达到效果，但是会有参数列表冗余的现象，如果我们需要保留的局部变量的参数非常多，那么也需要定义多个参数来一一完成。</p>\n<p>使用多返回值可以更清晰的表达结果，避免全局变量定义的冗余，以及引用传入的冗余，我们可以将局部变量返回，并在全局中定义接收。</p>\n<p>使用多返回值的另一个好处就是错误的处理更加方便，通常我们会将错误作为函数的最后一个返回值。这允许调用者很容易地判断操作是否成功，而不必单独检查错误变量或异常。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">divide</span><span class=\"hljs-params\">(dividend, divisor <span class=\"hljs-type\">float64</span>)</span></span> (<span class=\"hljs-type\">float64</span>, <span class=\"hljs-type\">error</span>) &#123;<br>    <span class=\"hljs-keyword\">if</span> divisor == <span class=\"hljs-number\">0.0</span> &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0.0</span>, errors.New(<span class=\"hljs-string\">&quot;cannot divide by zero&quot;</span>)<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> dividend / divisor, <span class=\"hljs-literal\">nil</span><br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"函数值\"><a href=\"#函数值\" class=\"headerlink\" title=\"函数值\"></a>函数值</h2><p>在<code>Go</code>中，函数被看作第一类值（第一类值意思就是说明这一个值可以像基本数据类型一样使用），具体来说：被赋值给变量、作为参数传递给函数、作为函数的返回值、在运行时动态创建、被存储在数据结构中。</p>\n<p>函数类型的零值是<code>nil</code>，调用值为<code>nil</code>的函数会引起<code>panic</code>错误，而且函数可以与<code>nil</code>进行比较。但是函数与函数之间时不可以比较的，也不能使用函数值作为<code>map</code>的<code>key</code>。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">square</span><span class=\"hljs-params\">(n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> n * n &#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">negative</span><span class=\"hljs-params\">(n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> -n &#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">product</span><span class=\"hljs-params\">(m, n <span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123; <span class=\"hljs-keyword\">return</span> m * n &#125;<br><br>f := square<br>fmt.Println(f(<span class=\"hljs-number\">3</span>)) <span class=\"hljs-comment\">// &quot;9&quot;</span><br><br>f = negative<br>fmt.Println(f(<span class=\"hljs-number\">3</span>))     <span class=\"hljs-comment\">// &quot;-3&quot;</span><br>fmt.Printf(<span class=\"hljs-string\">&quot;%T\\n&quot;</span>, f) <span class=\"hljs-comment\">// &quot;func(int) int&quot;</span><br><br>f = product <span class=\"hljs-comment\">// compile error: can&#x27;t assign func(int, int) int to func(int) int</span><br></code></pre></td></tr></table></figure>\n<p>函数值使得我们不仅仅可以通过数据来参数化函数，也可以通过行为。</p>\n<blockquote>\n<p><code>strings.Map()</code>是一个高阶函数，它允许你对字符串中的每个字符执行一个指定的映射操作。这个函数接受两个参数：第一个参数是一个映射函数，此映射函数会被应用到字符串中的每个字符上；第二个参数是要进行操作的字符串。映射函数需要接收一个rune类型的值，并返回一个rune类型的值。如果映射函数返回负值，则该字符会从结果字符串中被删除。</p>\n</blockquote>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">add1</span><span class=\"hljs-params\">(r <span class=\"hljs-type\">rune</span>)</span></span> <span class=\"hljs-type\">rune</span> &#123; <span class=\"hljs-keyword\">return</span> r + <span class=\"hljs-number\">1</span> &#125;<br><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;HAL-9000&quot;</span>)) <span class=\"hljs-comment\">// &quot;IBM.:111&quot;</span><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;VMS&quot;</span>))      <span class=\"hljs-comment\">// &quot;WNT&quot;</span><br>fmt.Println(strings.Map(add1, <span class=\"hljs-string\">&quot;Admix&quot;</span>))    <span class=\"hljs-comment\">// &quot;Benjy&quot;</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"可变参数\"><a href=\"#可变参数\" class=\"headerlink\" title=\"可变参数\"></a>可变参数</h2><p>参数数量可变的函数称为可变参数函数。在<code>go</code>中一般通过<code>...</code>的形式来接收任意数量的参数，比如使用<code>vals ...int</code>接收任意数量的<code>int</code>类型参数。我们可以通过切片的方式来读取参数列表里面实际的值。在实际的运行过程中，调用者会隐式的创建一个数组，并将原始参数复制到数组当中，再把数组的一个切片作为参数传给被调用的函数。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">sum</span><span class=\"hljs-params\">(vals ...<span class=\"hljs-type\">int</span>)</span></span> <span class=\"hljs-type\">int</span> &#123;<br>    total := <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">for</span> _, val := <span class=\"hljs-keyword\">range</span> vals &#123;<br>        total += val<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> total<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"错误\"><a href=\"#错误\" class=\"headerlink\" title=\"错误\"></a>错误</h2><ul>\n<li><p>Defferred函数</p>\n<p>  <code>defer</code>机制类似于延迟执行的感觉，在我们的代码当中，可能会因为打开某一些文件，但是由于打开失败或者一些其他的原因，导致我们的执行异常退出，或者提前退出，这个时候要确保能够让文件正常关闭，我们可以使用<code>defer</code>来在文件关闭语句前标记，这样子，即使异常退出，在函数返回前也会执行<code>defer</code>的语句，通常<code>defer</code>修饰的语句执行顺序和定义的顺序相反。</p>\n</li>\n<li><p>Panic异常</p>\n<p>  <code>Go</code>的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等，这些运行时错误会引起<code>panic</code>异常。</p>\n<p>  一般来说，当<code>panic</code>异常发生时，程序会中断运行，并立即执行在该协程中的被延迟的<code>defer</code>函数，随后输出错误日志。通常会在发生严重错误的时候来使用。</p>\n</li>\n<li><p>Recover捕获异常</p>\n<p>  在<code>Go</code>语言中，异常捕获是通过内置的<code>recover</code>函数实现的。当一个<code>goroutine</code>发生<code>panic</code>时，你可以使用<code>defer</code>机制来确保调用<code>recover</code>，这样就能拦截到<code>panic</code>引起的异常并进行处理。</p>\n<p>  <code>recover</code>只有在<code>defer</code>延迟执行的函数中直接调用时才有效。如果<code>panic</code>被触发，<code>recover</code>会捕获到引发<code>panic</code>的值，并且恢复正常的程序执行流程，即不再继续向上传递<code>panic</code>，转而执行<code>recover</code>所在的<code>defer</code>之后的代码。如果没有发生<code>panic</code>，或者<code>recover</code>没有在适当的位置被调用，则<code>recover</code>返回<code>nil</code>。</p>\n  <figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs go\"><span class=\"hljs-keyword\">package</span> main<br><br><span class=\"hljs-keyword\">import</span> <span class=\"hljs-string\">&quot;fmt&quot;</span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">potentiallyPanic</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-built_in\">panic</span>(<span class=\"hljs-string\">&quot;something went wrong&quot;</span>)<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">catchPanic</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-keyword\">if</span> r := <span class=\"hljs-built_in\">recover</span>(); r != <span class=\"hljs-literal\">nil</span> &#123;<br>        fmt.Println(<span class=\"hljs-string\">&quot;Recovered from panic:&quot;</span>, r)<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> &#123;<br>    <span class=\"hljs-comment\">// 使用 defer 语句注册 catchPanic 函数</span><br>    <span class=\"hljs-comment\">// 它将在 main 函数返回前最后执行</span><br>    <span class=\"hljs-keyword\">defer</span> catchPanic()<br><br>    <span class=\"hljs-comment\">// 这个函数可能会触发 panic</span><br>    potentiallyPanic()<br><br>    <span class=\"hljs-comment\">// 这行代码不会被执行，因为上面的函数已经触发了 panic</span><br>    fmt.Println(<span class=\"hljs-string\">&quot;This line will not be executed.&quot;</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure></li>\n</ul>\n"},{"title":"iEDA项目代码实践","date":"2023-09-10T08:51:14.000Z","cover":"/img/default_cover04.jpg","top_img":null,"_content":"## iEDA工程代码实践—布局合法化（LG）\n\n> 开源项目iEDA链接:https://gitee.com/oscc-project/iEDA.git\n\n### 一、理论知识\n\n布局合法化是全局布局以后的一个过程，在全局布局过后，规划版图中的宏单元会放置在相应的位置并保持不再移动，于此同时，对于标准单元的规划，也会通过一些相关算法完成大致位置的摆放，这些摆放是基于相关优化目标下进行的，例如线长，面积等，但是在全局布局中并不会考虑标准单元之间的非法情况，即标准单元重叠的问题，因此在布局合法化中，需要完成的任务就是在尽可能的不破坏全局布局的布局结构的情况下，使得所有标准单元不再重叠。核心算法用到的是`Abacus`算法和`Tetris`算法。\n\n### 二、Abacus算法\n\n> 同一时间只放置一个单元\n\n**算法伪代码**\n\n<img src=\"iEDA-test/image-20230823094215828.png\" alt=\"image-20230823094215828\"  />\n\n**核心代码**\n\n![image-20230825151306959](iEDA-test/image-20230825151306959.png)\n\n```\n1、根据单元的x坐标进行排序\n2、对于每一个排序好的单元，按照顺序取出每一个单元\n3、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置\n4、按照第3步的方式遍历每一行，找出全局中能够放置当前单元并使得cost最小的位置\n5、放置该单元\n```\n\n**placeRow解析**\n\n> 这个函数是`AbacusLegalizer`中的一个函数，它用于在布局合法化过程中放置一个实例（instance）到一个行（row）中。函数的输入参数包括一个`LGInstance`实例指针、行的索引`row_idx`和一个标志`is_trial`，用于指示是否是试验性放置。\n\n该函数主要完成了以下工作：\n\n- 在给定的行中找到合适的间隔来放置实例。\n- 计算放置实例的移动代价，包括实例在`x`和`y`方向上的移动代价以及超过最大移动约束的处罚。\n- 进行非试验性放置时，更新簇的信息和间隔的剩余长度。\n\n![image-20230825154317023](iEDA-test/image-20230825154317023.png)\n\n```\n函数的主要步骤如下：\n1. 获取实例的形状（inst_shape）。\n2. 从_layout对象中获取指定行的间隔列表（interval_list）。\n3. 通过搜索找到最近的间隔，即与实例重叠的间隔（interval_idx）。\n   - 如果找不到重叠的间隔，则返回INT32_MAX表示失败。\n4. 检查选定的间隔是否能够容纳实例的宽度，如果不行，则查找最近的非满间隔，并重新选择。\n   - 如果找不到合适的间隔，则返回INT32_MAX表示失败。\n5. 将实例安排到选定的间隔中，形成一个簇（target_cluster）。\n6. 计算移动代价（movement_cost）：\n   - 从簇中的每个实例计算到目标位置的x方向移动代价，并累加到movement_cost中。\n   - 计算实例在y方向上的移动代价。\n   - 将实例在x和y方向上的移动代价相加，得到实例的位移代价（inst_displacement）。\n   - 将实例位移代价加到movement_cost中。\n7. 根据最大移动约束处罚超过最大移动约束的位移代价。\n8. 如果is_trial为false，即非试验性放置，则替换簇的信息（replaceClusterInfo）和更新间隔的剩余长度（updateRemainLength）。\n9. 返回移动代价（movement_cost）。\n```\n\n### 三、Tetris算法\n\n`Abacus`是在`Tetris`算法上的改进，在`Tetris`中，对于`placeRow`的选择是一个单次即可完成的过程，即在当前行中找到了能够合适的位置以后即将该`instance`放置到该行。因此整体算法流程相似，但复杂度会降低很多。\n\n```\n1、根据单元的x坐标进行排序\n2、对于每一个排序好的单元，按照顺序取出每一个单元\n3、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置\n4、放置该单元\n\n若改行无法放置该单元，进行换行策略选择，重新执行，直到所有行都无法放置，返回false\n```\n\n<img src=\"iEDA-test/image-20230825163454933.png\" alt=\"image-20230825163454933\" style=\"zoom: 67%;\" />\n\n因此对`iEDA`原始代码`Abacus`算法调整成`Tetris`只需要确定两个策略即可：1、如何选择当前`instance`初始行的策略。2、若初始行无法放置当前`instance`后，选择其它行的调整策略。\n\n* 选择初始行策略\n\n  > 合法化是在全局布局过后的步骤，应尽可能的减少相关单元的移动，且尽可能地保证单元移动后和移动前地位置相近，因此最好是在该单元所在行的附近行进行移动\n\n  1、加上`_row_height`后做除法\n\n```\nauto row_idx = int32_t((inst_shape.get_center().get_y()+float_t(_row_height/2))/_row_height);\nif(inst_shape.get_ll_y() % _row_height == 0){\n  row_idx -= 1;\n}\n```\n\n​\t\t2、直接使用`y`坐标与`_row_height`做整数相除\n\n```\nauto row_idx = inst_shape.get_center().get_y()/_row_height;\n```\n\n* 换行策略\n\n```\nif(cost == INT32_MAX){\n  // 更新row_idx的策略\n  auto i = 1;\n  while(cost == INT32_MAX){\n    // 使用向上向下的扫描线完成\n    if(row_idx + i >= _database._lg_layout->get_row_num() && row_idx - i < 0){\n      return false;\n    }\n    if(row_idx + i < _database._lg_layout->get_row_num()){\n      cost = placeRow(inst, row_idx + i, false);\n      if(cost != INT32_MAX)break;\n    }\n    if(row_idx - i >= 0){\n      cost = placeRow(inst, row_idx - i, false);\n      if(cost != INT32_MAX)break;\n    }\n    i += 1;\n  }\n}\n```\n\n### 四、结果\n\n* 使用原始的`Abacus`算法\n\n![image-20230825163939716](iEDA-test/image-20230825163939716.png)\n\n* 初始行策略使用：加上`_row_height`后做除法\n\n![image-20230825164152609](iEDA-test/image-20230825164152609.png)\n\n* 初始行策略使用：直接使用`y`坐标与`_row_height`做整数相除\n\n![image-20230825164459060](iEDA-test/image-20230825164459060.png)\n\n* 使用手册上`Tetris`的方法\n\n![image-20230830164032304](iEDA-test/image-20230830164032304.png)\n\n![image-20230830164051317](iEDA-test/image-20230830164051317.png)\n\n* 对比\n\n|                             |  Abacus   |     1     |     2     |      Tetris       |\n| :-------------------------: | :-------: | :-------: | :-------: | :---------------: |\n|        全局布局HPWL         |  8703921  |  8703921  |  8703921  |      8703921      |\n|    合法化移动总Movement     |  781382   |  1410142  |  865332   | 11052260(14.144)  |\n|       合法化运行时间        | 0.010062s | 0.000919s | 0.000944s |     0.086068s     |\n|       布局合法化HPWL        | 10798293  | 10786671  | 10749832  | 21674741（2.007） |\n|        详细布局HPWL         | 10069766  | 10105715  | 10070071  |     13192372      |\n| Average Congestion of Edges | 0.728164  | 0.718681  | 0.713207  |     0.713207      |\n|       Total Overflow        | 10.000000 | 10.000000 | 10.000000 |     10.000000     |\n|      Maximal Overflow       | 2.000000  | 2.000000  | 2.000000  |     2.000000      |\n|       Peak BinDensity       |     1     |     1     |     1     |         1         |\n|         Total HPWL          | 10069766  | 10105715  | 10070071  |     13192372      |\n|         Total STWL          | 10862347  | 10863122  | 10864139  |     14100332      |\n|          Max STWL           |  437405   |  442445   |  460685   |      518305       |\n\n**结果分析**\n\n* 将`Abacus`换成`Tetris`后，在同样的全局布局的版图中\n\n  * `Movement`会增加\n\n    因为在`Abacus`中计算的是每一个单元在所有行中的最小`cost`，而`Tetris`中则是计算的是周围行内，会存在差异性，这样的差异性在**较为密集**的全局布局中体现更为明显。\n\n  * 合法化运行时间会减少\n\n    很显然，`Abacus`算法能够降低`Movement`就是以牺牲时间复杂度作为代价的，每一次`instance`的放置，平摊下来都会多出`_row_nums-1`轮次\n\n  * 布局合法化`HPWL`存在不确定性\n\n    在实验中表现出来的是减少的特性，但实际上是表现出的不确定性，因为`Abacus`算法中的`cost`仅仅是以当前能够移动的最少的`x`和`y`的总和作为基准，并没有将线长给加进去，所以对于线长来说使用`Abacus`算法仅仅是一个贪心策略，不一定能够达到全局最优的效果\n\n* 个人感觉`Abacus`算法还是有点暴力\n\n\n\n### PS：在重新复盘Tetris算法过后\n\n最开始并没有完全理解要求完成的任务所描述的`Tetris`算法，仅仅是在`Abacus`的基础上置换了一个选择初始行和换行的策略，所以在最开始的代码当中调用的依然是原始的`placeRow`函数，在这个函数中的操作依然选择的是距离当前`instance`当中最近的`internel`，所以能够达到在时间减小的情况之下能够使得`HPWL`也减小的情况，这样的结果显然是存在偶然性的，因为找到的解都不一定都是最优解，与全局布局的结果有关。\n\n当使用手册上描述的`Tetris`算法后，最终运行期间的`Movement`变为原来的14倍多，而`HPWL`也是原来的2倍左右。\n\n","source":"_posts/iEDA-test.md","raw":"---\ntitle: iEDA项目代码实践\ncategories: 算法实践\ndate: 2023-09-10 16:51:14\ntags: [iEDA, EDA, 布局, 开源项目]\ncover:\ntop_img:\n---\n## iEDA工程代码实践—布局合法化（LG）\n\n> 开源项目iEDA链接:https://gitee.com/oscc-project/iEDA.git\n\n### 一、理论知识\n\n布局合法化是全局布局以后的一个过程，在全局布局过后，规划版图中的宏单元会放置在相应的位置并保持不再移动，于此同时，对于标准单元的规划，也会通过一些相关算法完成大致位置的摆放，这些摆放是基于相关优化目标下进行的，例如线长，面积等，但是在全局布局中并不会考虑标准单元之间的非法情况，即标准单元重叠的问题，因此在布局合法化中，需要完成的任务就是在尽可能的不破坏全局布局的布局结构的情况下，使得所有标准单元不再重叠。核心算法用到的是`Abacus`算法和`Tetris`算法。\n\n### 二、Abacus算法\n\n> 同一时间只放置一个单元\n\n**算法伪代码**\n\n<img src=\"iEDA-test/image-20230823094215828.png\" alt=\"image-20230823094215828\"  />\n\n**核心代码**\n\n![image-20230825151306959](iEDA-test/image-20230825151306959.png)\n\n```\n1、根据单元的x坐标进行排序\n2、对于每一个排序好的单元，按照顺序取出每一个单元\n3、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置\n4、按照第3步的方式遍历每一行，找出全局中能够放置当前单元并使得cost最小的位置\n5、放置该单元\n```\n\n**placeRow解析**\n\n> 这个函数是`AbacusLegalizer`中的一个函数，它用于在布局合法化过程中放置一个实例（instance）到一个行（row）中。函数的输入参数包括一个`LGInstance`实例指针、行的索引`row_idx`和一个标志`is_trial`，用于指示是否是试验性放置。\n\n该函数主要完成了以下工作：\n\n- 在给定的行中找到合适的间隔来放置实例。\n- 计算放置实例的移动代价，包括实例在`x`和`y`方向上的移动代价以及超过最大移动约束的处罚。\n- 进行非试验性放置时，更新簇的信息和间隔的剩余长度。\n\n![image-20230825154317023](iEDA-test/image-20230825154317023.png)\n\n```\n函数的主要步骤如下：\n1. 获取实例的形状（inst_shape）。\n2. 从_layout对象中获取指定行的间隔列表（interval_list）。\n3. 通过搜索找到最近的间隔，即与实例重叠的间隔（interval_idx）。\n   - 如果找不到重叠的间隔，则返回INT32_MAX表示失败。\n4. 检查选定的间隔是否能够容纳实例的宽度，如果不行，则查找最近的非满间隔，并重新选择。\n   - 如果找不到合适的间隔，则返回INT32_MAX表示失败。\n5. 将实例安排到选定的间隔中，形成一个簇（target_cluster）。\n6. 计算移动代价（movement_cost）：\n   - 从簇中的每个实例计算到目标位置的x方向移动代价，并累加到movement_cost中。\n   - 计算实例在y方向上的移动代价。\n   - 将实例在x和y方向上的移动代价相加，得到实例的位移代价（inst_displacement）。\n   - 将实例位移代价加到movement_cost中。\n7. 根据最大移动约束处罚超过最大移动约束的位移代价。\n8. 如果is_trial为false，即非试验性放置，则替换簇的信息（replaceClusterInfo）和更新间隔的剩余长度（updateRemainLength）。\n9. 返回移动代价（movement_cost）。\n```\n\n### 三、Tetris算法\n\n`Abacus`是在`Tetris`算法上的改进，在`Tetris`中，对于`placeRow`的选择是一个单次即可完成的过程，即在当前行中找到了能够合适的位置以后即将该`instance`放置到该行。因此整体算法流程相似，但复杂度会降低很多。\n\n```\n1、根据单元的x坐标进行排序\n2、对于每一个排序好的单元，按照顺序取出每一个单元\n3、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置\n4、放置该单元\n\n若改行无法放置该单元，进行换行策略选择，重新执行，直到所有行都无法放置，返回false\n```\n\n<img src=\"iEDA-test/image-20230825163454933.png\" alt=\"image-20230825163454933\" style=\"zoom: 67%;\" />\n\n因此对`iEDA`原始代码`Abacus`算法调整成`Tetris`只需要确定两个策略即可：1、如何选择当前`instance`初始行的策略。2、若初始行无法放置当前`instance`后，选择其它行的调整策略。\n\n* 选择初始行策略\n\n  > 合法化是在全局布局过后的步骤，应尽可能的减少相关单元的移动，且尽可能地保证单元移动后和移动前地位置相近，因此最好是在该单元所在行的附近行进行移动\n\n  1、加上`_row_height`后做除法\n\n```\nauto row_idx = int32_t((inst_shape.get_center().get_y()+float_t(_row_height/2))/_row_height);\nif(inst_shape.get_ll_y() % _row_height == 0){\n  row_idx -= 1;\n}\n```\n\n​\t\t2、直接使用`y`坐标与`_row_height`做整数相除\n\n```\nauto row_idx = inst_shape.get_center().get_y()/_row_height;\n```\n\n* 换行策略\n\n```\nif(cost == INT32_MAX){\n  // 更新row_idx的策略\n  auto i = 1;\n  while(cost == INT32_MAX){\n    // 使用向上向下的扫描线完成\n    if(row_idx + i >= _database._lg_layout->get_row_num() && row_idx - i < 0){\n      return false;\n    }\n    if(row_idx + i < _database._lg_layout->get_row_num()){\n      cost = placeRow(inst, row_idx + i, false);\n      if(cost != INT32_MAX)break;\n    }\n    if(row_idx - i >= 0){\n      cost = placeRow(inst, row_idx - i, false);\n      if(cost != INT32_MAX)break;\n    }\n    i += 1;\n  }\n}\n```\n\n### 四、结果\n\n* 使用原始的`Abacus`算法\n\n![image-20230825163939716](iEDA-test/image-20230825163939716.png)\n\n* 初始行策略使用：加上`_row_height`后做除法\n\n![image-20230825164152609](iEDA-test/image-20230825164152609.png)\n\n* 初始行策略使用：直接使用`y`坐标与`_row_height`做整数相除\n\n![image-20230825164459060](iEDA-test/image-20230825164459060.png)\n\n* 使用手册上`Tetris`的方法\n\n![image-20230830164032304](iEDA-test/image-20230830164032304.png)\n\n![image-20230830164051317](iEDA-test/image-20230830164051317.png)\n\n* 对比\n\n|                             |  Abacus   |     1     |     2     |      Tetris       |\n| :-------------------------: | :-------: | :-------: | :-------: | :---------------: |\n|        全局布局HPWL         |  8703921  |  8703921  |  8703921  |      8703921      |\n|    合法化移动总Movement     |  781382   |  1410142  |  865332   | 11052260(14.144)  |\n|       合法化运行时间        | 0.010062s | 0.000919s | 0.000944s |     0.086068s     |\n|       布局合法化HPWL        | 10798293  | 10786671  | 10749832  | 21674741（2.007） |\n|        详细布局HPWL         | 10069766  | 10105715  | 10070071  |     13192372      |\n| Average Congestion of Edges | 0.728164  | 0.718681  | 0.713207  |     0.713207      |\n|       Total Overflow        | 10.000000 | 10.000000 | 10.000000 |     10.000000     |\n|      Maximal Overflow       | 2.000000  | 2.000000  | 2.000000  |     2.000000      |\n|       Peak BinDensity       |     1     |     1     |     1     |         1         |\n|         Total HPWL          | 10069766  | 10105715  | 10070071  |     13192372      |\n|         Total STWL          | 10862347  | 10863122  | 10864139  |     14100332      |\n|          Max STWL           |  437405   |  442445   |  460685   |      518305       |\n\n**结果分析**\n\n* 将`Abacus`换成`Tetris`后，在同样的全局布局的版图中\n\n  * `Movement`会增加\n\n    因为在`Abacus`中计算的是每一个单元在所有行中的最小`cost`，而`Tetris`中则是计算的是周围行内，会存在差异性，这样的差异性在**较为密集**的全局布局中体现更为明显。\n\n  * 合法化运行时间会减少\n\n    很显然，`Abacus`算法能够降低`Movement`就是以牺牲时间复杂度作为代价的，每一次`instance`的放置，平摊下来都会多出`_row_nums-1`轮次\n\n  * 布局合法化`HPWL`存在不确定性\n\n    在实验中表现出来的是减少的特性，但实际上是表现出的不确定性，因为`Abacus`算法中的`cost`仅仅是以当前能够移动的最少的`x`和`y`的总和作为基准，并没有将线长给加进去，所以对于线长来说使用`Abacus`算法仅仅是一个贪心策略，不一定能够达到全局最优的效果\n\n* 个人感觉`Abacus`算法还是有点暴力\n\n\n\n### PS：在重新复盘Tetris算法过后\n\n最开始并没有完全理解要求完成的任务所描述的`Tetris`算法，仅仅是在`Abacus`的基础上置换了一个选择初始行和换行的策略，所以在最开始的代码当中调用的依然是原始的`placeRow`函数，在这个函数中的操作依然选择的是距离当前`instance`当中最近的`internel`，所以能够达到在时间减小的情况之下能够使得`HPWL`也减小的情况，这样的结果显然是存在偶然性的，因为找到的解都不一定都是最优解，与全局布局的结果有关。\n\n当使用手册上描述的`Tetris`算法后，最终运行期间的`Movement`变为原来的14倍多，而`HPWL`也是原来的2倍左右。\n\n","slug":"iEDA-test","published":1,"updated":"2024-06-05T09:03:03.793Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttx002t08jvhsjzdl7x","content":"<h2 id=\"iEDA工程代码实践—布局合法化（LG）\"><a href=\"#iEDA工程代码实践—布局合法化（LG）\" class=\"headerlink\" title=\"iEDA工程代码实践—布局合法化（LG）\"></a>iEDA工程代码实践—布局合法化（LG）</h2><blockquote>\n<p>开源项目iEDA链接:<a href=\"https://gitee.com/oscc-project/iEDA.git\">https://gitee.com/oscc-project/iEDA.git</a></p>\n</blockquote>\n<h3 id=\"一、理论知识\"><a href=\"#一、理论知识\" class=\"headerlink\" title=\"一、理论知识\"></a>一、理论知识</h3><p>布局合法化是全局布局以后的一个过程，在全局布局过后，规划版图中的宏单元会放置在相应的位置并保持不再移动，于此同时，对于标准单元的规划，也会通过一些相关算法完成大致位置的摆放，这些摆放是基于相关优化目标下进行的，例如线长，面积等，但是在全局布局中并不会考虑标准单元之间的非法情况，即标准单元重叠的问题，因此在布局合法化中，需要完成的任务就是在尽可能的不破坏全局布局的布局结构的情况下，使得所有标准单元不再重叠。核心算法用到的是<code>Abacus</code>算法和<code>Tetris</code>算法。</p>\n<h3 id=\"二、Abacus算法\"><a href=\"#二、Abacus算法\" class=\"headerlink\" title=\"二、Abacus算法\"></a>二、Abacus算法</h3><blockquote>\n<p>同一时间只放置一个单元</p>\n</blockquote>\n<p><strong>算法伪代码</strong></p>\n<p><style>.pllxznnbfehe{}</style><img src=\"/2023/09/10/iEDA-test/image-20230823094215828.png\" class=\"pllxznnbfehe\" alt=\"image-20230823094215828\"></p>\n<p><strong>核心代码</strong></p>\n<img src=\"/2023/09/10/iEDA-test/image-20230825151306959.png\" class=\"\" title=\"image-20230825151306959\">\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-number\">1</span>、根据单元的x坐标进行排序<br><span class=\"hljs-number\">2</span>、对于每一个排序好的单元，按照顺序取出每一个单元<br><span class=\"hljs-number\">3</span>、遍历第一行，找出当前行中放置该单元后能够使得<span class=\"hljs-keyword\">cost</span>最小的位置<br><span class=\"hljs-number\">4</span>、按照第<span class=\"hljs-number\">3</span>步的方式遍历每一行，找出全局中能够放置当前单元并使得<span class=\"hljs-keyword\">cost</span>最小的位置<br><span class=\"hljs-number\">5</span>、放置该单元<br></code></pre></td></tr></table></figure>\n<p><strong>placeRow解析</strong></p>\n<blockquote>\n<p>这个函数是<code>AbacusLegalizer</code>中的一个函数，它用于在布局合法化过程中放置一个实例（instance）到一个行（row）中。函数的输入参数包括一个<code>LGInstance</code>实例指针、行的索引<code>row_idx</code>和一个标志<code>is_trial</code>，用于指示是否是试验性放置。</p>\n</blockquote>\n<p>该函数主要完成了以下工作：</p>\n<ul>\n<li>在给定的行中找到合适的间隔来放置实例。</li>\n<li>计算放置实例的移动代价，包括实例在<code>x</code>和<code>y</code>方向上的移动代价以及超过最大移动约束的处罚。</li>\n<li>进行非试验性放置时，更新簇的信息和间隔的剩余长度。</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825154317023.png\" class=\"\" title=\"image-20230825154317023\">\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs markdown\">函数的主要步骤如下：<br><span class=\"hljs-bullet\">1.</span> 获取实例的形状（inst<span class=\"hljs-emphasis\">_shape）。</span><br><span class=\"hljs-emphasis\">2. 从_</span>layout对象中获取指定行的间隔列表（interval<span class=\"hljs-emphasis\">_list）。</span><br><span class=\"hljs-emphasis\">3. 通过搜索找到最近的间隔，即与实例重叠的间隔（interval_</span>idx）。<br><span class=\"hljs-bullet\">   -</span> 如果找不到重叠的间隔，则返回INT32<span class=\"hljs-emphasis\">_MAX表示失败。</span><br><span class=\"hljs-emphasis\">4. 检查选定的间隔是否能够容纳实例的宽度，如果不行，则查找最近的非满间隔，并重新选择。</span><br><span class=\"hljs-emphasis\">   - 如果找不到合适的间隔，则返回INT32_</span>MAX表示失败。<br><span class=\"hljs-bullet\">5.</span> 将实例安排到选定的间隔中，形成一个簇（target<span class=\"hljs-emphasis\">_cluster）。</span><br><span class=\"hljs-emphasis\">6. 计算移动代价（movement_</span>cost）：<br><span class=\"hljs-bullet\">   -</span> 从簇中的每个实例计算到目标位置的x方向移动代价，并累加到movement<span class=\"hljs-emphasis\">_cost中。</span><br><span class=\"hljs-emphasis\">   - 计算实例在y方向上的移动代价。</span><br><span class=\"hljs-emphasis\">   - 将实例在x和y方向上的移动代价相加，得到实例的位移代价（inst_</span>displacement）。<br><span class=\"hljs-bullet\">   -</span> 将实例位移代价加到movement<span class=\"hljs-emphasis\">_cost中。</span><br><span class=\"hljs-emphasis\">7. 根据最大移动约束处罚超过最大移动约束的位移代价。</span><br><span class=\"hljs-emphasis\">8. 如果is_</span>trial为false，即非试验性放置，则替换簇的信息（replaceClusterInfo）和更新间隔的剩余长度（updateRemainLength）。<br><span class=\"hljs-bullet\">9.</span> 返回移动代价（movement<span class=\"hljs-emphasis\">_cost）。</span><br></code></pre></td></tr></table></figure>\n<h3 id=\"三、Tetris算法\"><a href=\"#三、Tetris算法\" class=\"headerlink\" title=\"三、Tetris算法\"></a>三、Tetris算法</h3><p><code>Abacus</code>是在<code>Tetris</code>算法上的改进，在<code>Tetris</code>中，对于<code>placeRow</code>的选择是一个单次即可完成的过程，即在当前行中找到了能够合适的位置以后即将该<code>instance</code>放置到该行。因此整体算法流程相似，但复杂度会降低很多。</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\"><span class=\"hljs-number\">1</span>、根据单元的<span class=\"hljs-keyword\">x</span>坐标进行排序<br><span class=\"hljs-number\">2</span>、对于每一个排序好的单元，按照顺序取出每一个单元<br><span class=\"hljs-number\">3</span>、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置<br><span class=\"hljs-number\">4</span>、放置该单元<br><br>若改行无法放置该单元，进行换行策略选择，重新执行，直到所有行都无法放置，返回<span class=\"hljs-keyword\">false</span><br></code></pre></td></tr></table></figure>\n<p><style>.jweudmfdtnob{zoom: 67%;}</style><img src=\"/2023/09/10/iEDA-test/image-20230825163454933.png\" class=\"jweudmfdtnob\" alt=\"image-20230825163454933\"></p>\n<p>因此对<code>iEDA</code>原始代码<code>Abacus</code>算法调整成<code>Tetris</code>只需要确定两个策略即可：1、如何选择当前<code>instance</code>初始行的策略。2、若初始行无法放置当前<code>instance</code>后，选择其它行的调整策略。</p>\n<ul>\n<li><p>选择初始行策略</p>\n<blockquote>\n<p>合法化是在全局布局过后的步骤，应尽可能的减少相关单元的移动，且尽可能地保证单元移动后和移动前地位置相近，因此最好是在该单元所在行的附近行进行移动</p>\n</blockquote>\n<p>1、加上<code>_row_height</code>后做除法</p>\n</li>\n</ul>\n<figure class=\"highlight gcode\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gcode\">auto row_idx = i<span class=\"hljs-symbol\">nt32</span>_t<span class=\"hljs-comment\">((inst_shape.get_center()</span>.get_y<span class=\"hljs-comment\">()</span>+float_t<span class=\"hljs-comment\">(_row_height/2)</span>)/_row_height);<br><span class=\"hljs-keyword\">if</span><span class=\"hljs-comment\">(inst_shape.get_ll_y()</span> <span class=\"hljs-meta\">%</span> _row_height == <span class=\"hljs-number\">0</span>)&#123;<br>  row_idx -= <span class=\"hljs-number\">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>​        2、直接使用<code>y</code>坐标与<code>_row_height</code>做整数相除</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">auto row_idx <span class=\"hljs-operator\">=</span> inst_shape.get_center().get_y()/_row_height<span class=\"hljs-comment\">;</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>换行策略</li>\n</ul>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\"><span class=\"hljs-keyword\">if</span>(cost == INT32_MAX)&#123;<br>  <span class=\"hljs-comment\">// 更新row_idx的策略</span><br>  auto i = <span class=\"hljs-number\">1</span>;<br>  <span class=\"hljs-keyword\">while</span>(cost == INT32_MAX)&#123;<br>    <span class=\"hljs-comment\">// 使用向上向下的扫描线完成</span><br>    <span class=\"hljs-keyword\">if</span>(row_idx + i &gt;= _database._lg_layout-&gt;get_row_num() &amp;&amp; row_idx - i &lt; <span class=\"hljs-number\">0</span>)&#123;<br>      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(row_idx + i &lt; _database._lg_layout-&gt;get_row_num())&#123;<br>      cost = placeRow(inst, row_idx + i, <span class=\"hljs-literal\">false</span>);<br>      <span class=\"hljs-keyword\">if</span>(cost != INT32_MAX)<span class=\"hljs-keyword\">break</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(row_idx - i &gt;= <span class=\"hljs-number\">0</span>)&#123;<br>      cost = placeRow(inst, row_idx - i, <span class=\"hljs-literal\">false</span>);<br>      <span class=\"hljs-keyword\">if</span>(cost != INT32_MAX)<span class=\"hljs-keyword\">break</span>;<br>    &#125;<br>    i += <span class=\"hljs-number\">1</span>;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"四、结果\"><a href=\"#四、结果\" class=\"headerlink\" title=\"四、结果\"></a>四、结果</h3><ul>\n<li>使用原始的<code>Abacus</code>算法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825163939716.png\" class=\"\" title=\"image-20230825163939716\">\n<ul>\n<li>初始行策略使用：加上<code>_row_height</code>后做除法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825164152609.png\" class=\"\" title=\"image-20230825164152609\">\n<ul>\n<li>初始行策略使用：直接使用<code>y</code>坐标与<code>_row_height</code>做整数相除</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825164459060.png\" class=\"\" title=\"image-20230825164459060\">\n<ul>\n<li>使用手册上<code>Tetris</code>的方法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230830164032304.png\" class=\"\" title=\"image-20230830164032304\">\n<img src=\"/2023/09/10/iEDA-test/image-20230830164051317.png\" class=\"\" title=\"image-20230830164051317\">\n<ul>\n<li>对比</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">Abacus</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">Tetris</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">全局布局HPWL</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">合法化移动总Movement</td>\n<td style=\"text-align:center\">781382</td>\n<td style=\"text-align:center\">1410142</td>\n<td style=\"text-align:center\">865332</td>\n<td style=\"text-align:center\">11052260(14.144)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">合法化运行时间</td>\n<td style=\"text-align:center\">0.010062s</td>\n<td style=\"text-align:center\">0.000919s</td>\n<td style=\"text-align:center\">0.000944s</td>\n<td style=\"text-align:center\">0.086068s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">布局合法化HPWL</td>\n<td style=\"text-align:center\">10798293</td>\n<td style=\"text-align:center\">10786671</td>\n<td style=\"text-align:center\">10749832</td>\n<td style=\"text-align:center\">21674741（2.007）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">详细布局HPWL</td>\n<td style=\"text-align:center\">10069766</td>\n<td style=\"text-align:center\">10105715</td>\n<td style=\"text-align:center\">10070071</td>\n<td style=\"text-align:center\">13192372</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Average Congestion of Edges</td>\n<td style=\"text-align:center\">0.728164</td>\n<td style=\"text-align:center\">0.718681</td>\n<td style=\"text-align:center\">0.713207</td>\n<td style=\"text-align:center\">0.713207</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total Overflow</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Maximal Overflow</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Peak BinDensity</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total HPWL</td>\n<td style=\"text-align:center\">10069766</td>\n<td style=\"text-align:center\">10105715</td>\n<td style=\"text-align:center\">10070071</td>\n<td style=\"text-align:center\">13192372</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total STWL</td>\n<td style=\"text-align:center\">10862347</td>\n<td style=\"text-align:center\">10863122</td>\n<td style=\"text-align:center\">10864139</td>\n<td style=\"text-align:center\">14100332</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Max STWL</td>\n<td style=\"text-align:center\">437405</td>\n<td style=\"text-align:center\">442445</td>\n<td style=\"text-align:center\">460685</td>\n<td style=\"text-align:center\">518305</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>结果分析</strong></p>\n<ul>\n<li><p>将<code>Abacus</code>换成<code>Tetris</code>后，在同样的全局布局的版图中</p>\n<ul>\n<li><p><code>Movement</code>会增加</p>\n<p>因为在<code>Abacus</code>中计算的是每一个单元在所有行中的最小<code>cost</code>，而<code>Tetris</code>中则是计算的是周围行内，会存在差异性，这样的差异性在<strong>较为密集</strong>的全局布局中体现更为明显。</p>\n</li>\n<li><p>合法化运行时间会减少</p>\n<p>很显然，<code>Abacus</code>算法能够降低<code>Movement</code>就是以牺牲时间复杂度作为代价的，每一次<code>instance</code>的放置，平摊下来都会多出<code>_row_nums-1</code>轮次</p>\n</li>\n<li><p>布局合法化<code>HPWL</code>存在不确定性</p>\n<p>在实验中表现出来的是减少的特性，但实际上是表现出的不确定性，因为<code>Abacus</code>算法中的<code>cost</code>仅仅是以当前能够移动的最少的<code>x</code>和<code>y</code>的总和作为基准，并没有将线长给加进去，所以对于线长来说使用<code>Abacus</code>算法仅仅是一个贪心策略，不一定能够达到全局最优的效果</p>\n</li>\n</ul>\n</li>\n<li><p>个人感觉<code>Abacus</code>算法还是有点暴力</p>\n</li>\n</ul>\n<h3 id=\"PS：在重新复盘Tetris算法过后\"><a href=\"#PS：在重新复盘Tetris算法过后\" class=\"headerlink\" title=\"PS：在重新复盘Tetris算法过后\"></a>PS：在重新复盘Tetris算法过后</h3><p>最开始并没有完全理解要求完成的任务所描述的<code>Tetris</code>算法，仅仅是在<code>Abacus</code>的基础上置换了一个选择初始行和换行的策略，所以在最开始的代码当中调用的依然是原始的<code>placeRow</code>函数，在这个函数中的操作依然选择的是距离当前<code>instance</code>当中最近的<code>internel</code>，所以能够达到在时间减小的情况之下能够使得<code>HPWL</code>也减小的情况，这样的结果显然是存在偶然性的，因为找到的解都不一定都是最优解，与全局布局的结果有关。</p>\n<p>当使用手册上描述的<code>Tetris</code>算法后，最终运行期间的<code>Movement</code>变为原来的14倍多，而<code>HPWL</code>也是原来的2倍左右。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"iEDA工程代码实践—布局合法化（LG）\"><a href=\"#iEDA工程代码实践—布局合法化（LG）\" class=\"headerlink\" title=\"iEDA工程代码实践—布局合法化（LG）\"></a>iEDA工程代码实践—布局合法化（LG）</h2><blockquote>\n<p>开源项目iEDA链接:<a href=\"https://gitee.com/oscc-project/iEDA.git\">https://gitee.com/oscc-project/iEDA.git</a></p>\n</blockquote>\n<h3 id=\"一、理论知识\"><a href=\"#一、理论知识\" class=\"headerlink\" title=\"一、理论知识\"></a>一、理论知识</h3><p>布局合法化是全局布局以后的一个过程，在全局布局过后，规划版图中的宏单元会放置在相应的位置并保持不再移动，于此同时，对于标准单元的规划，也会通过一些相关算法完成大致位置的摆放，这些摆放是基于相关优化目标下进行的，例如线长，面积等，但是在全局布局中并不会考虑标准单元之间的非法情况，即标准单元重叠的问题，因此在布局合法化中，需要完成的任务就是在尽可能的不破坏全局布局的布局结构的情况下，使得所有标准单元不再重叠。核心算法用到的是<code>Abacus</code>算法和<code>Tetris</code>算法。</p>\n<h3 id=\"二、Abacus算法\"><a href=\"#二、Abacus算法\" class=\"headerlink\" title=\"二、Abacus算法\"></a>二、Abacus算法</h3><blockquote>\n<p>同一时间只放置一个单元</p>\n</blockquote>\n<p><strong>算法伪代码</strong></p>\n<p><style>.pllxznnbfehe{}</style><img src=\"/2023/09/10/iEDA-test/image-20230823094215828.png\" class=\"pllxznnbfehe\" alt=\"image-20230823094215828\"></p>\n<p><strong>核心代码</strong></p>\n<img src=\"/2023/09/10/iEDA-test/image-20230825151306959.png\" class=\"\" title=\"image-20230825151306959\">\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-number\">1</span>、根据单元的x坐标进行排序<br><span class=\"hljs-number\">2</span>、对于每一个排序好的单元，按照顺序取出每一个单元<br><span class=\"hljs-number\">3</span>、遍历第一行，找出当前行中放置该单元后能够使得<span class=\"hljs-keyword\">cost</span>最小的位置<br><span class=\"hljs-number\">4</span>、按照第<span class=\"hljs-number\">3</span>步的方式遍历每一行，找出全局中能够放置当前单元并使得<span class=\"hljs-keyword\">cost</span>最小的位置<br><span class=\"hljs-number\">5</span>、放置该单元<br></code></pre></td></tr></table></figure>\n<p><strong>placeRow解析</strong></p>\n<blockquote>\n<p>这个函数是<code>AbacusLegalizer</code>中的一个函数，它用于在布局合法化过程中放置一个实例（instance）到一个行（row）中。函数的输入参数包括一个<code>LGInstance</code>实例指针、行的索引<code>row_idx</code>和一个标志<code>is_trial</code>，用于指示是否是试验性放置。</p>\n</blockquote>\n<p>该函数主要完成了以下工作：</p>\n<ul>\n<li>在给定的行中找到合适的间隔来放置实例。</li>\n<li>计算放置实例的移动代价，包括实例在<code>x</code>和<code>y</code>方向上的移动代价以及超过最大移动约束的处罚。</li>\n<li>进行非试验性放置时，更新簇的信息和间隔的剩余长度。</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825154317023.png\" class=\"\" title=\"image-20230825154317023\">\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs markdown\">函数的主要步骤如下：<br><span class=\"hljs-bullet\">1.</span> 获取实例的形状（inst<span class=\"hljs-emphasis\">_shape）。</span><br><span class=\"hljs-emphasis\">2. 从_</span>layout对象中获取指定行的间隔列表（interval<span class=\"hljs-emphasis\">_list）。</span><br><span class=\"hljs-emphasis\">3. 通过搜索找到最近的间隔，即与实例重叠的间隔（interval_</span>idx）。<br><span class=\"hljs-bullet\">   -</span> 如果找不到重叠的间隔，则返回INT32<span class=\"hljs-emphasis\">_MAX表示失败。</span><br><span class=\"hljs-emphasis\">4. 检查选定的间隔是否能够容纳实例的宽度，如果不行，则查找最近的非满间隔，并重新选择。</span><br><span class=\"hljs-emphasis\">   - 如果找不到合适的间隔，则返回INT32_</span>MAX表示失败。<br><span class=\"hljs-bullet\">5.</span> 将实例安排到选定的间隔中，形成一个簇（target<span class=\"hljs-emphasis\">_cluster）。</span><br><span class=\"hljs-emphasis\">6. 计算移动代价（movement_</span>cost）：<br><span class=\"hljs-bullet\">   -</span> 从簇中的每个实例计算到目标位置的x方向移动代价，并累加到movement<span class=\"hljs-emphasis\">_cost中。</span><br><span class=\"hljs-emphasis\">   - 计算实例在y方向上的移动代价。</span><br><span class=\"hljs-emphasis\">   - 将实例在x和y方向上的移动代价相加，得到实例的位移代价（inst_</span>displacement）。<br><span class=\"hljs-bullet\">   -</span> 将实例位移代价加到movement<span class=\"hljs-emphasis\">_cost中。</span><br><span class=\"hljs-emphasis\">7. 根据最大移动约束处罚超过最大移动约束的位移代价。</span><br><span class=\"hljs-emphasis\">8. 如果is_</span>trial为false，即非试验性放置，则替换簇的信息（replaceClusterInfo）和更新间隔的剩余长度（updateRemainLength）。<br><span class=\"hljs-bullet\">9.</span> 返回移动代价（movement<span class=\"hljs-emphasis\">_cost）。</span><br></code></pre></td></tr></table></figure>\n<h3 id=\"三、Tetris算法\"><a href=\"#三、Tetris算法\" class=\"headerlink\" title=\"三、Tetris算法\"></a>三、Tetris算法</h3><p><code>Abacus</code>是在<code>Tetris</code>算法上的改进，在<code>Tetris</code>中，对于<code>placeRow</code>的选择是一个单次即可完成的过程，即在当前行中找到了能够合适的位置以后即将该<code>instance</code>放置到该行。因此整体算法流程相似，但复杂度会降低很多。</p>\n<figure class=\"highlight llvm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs llvm\"><span class=\"hljs-number\">1</span>、根据单元的<span class=\"hljs-keyword\">x</span>坐标进行排序<br><span class=\"hljs-number\">2</span>、对于每一个排序好的单元，按照顺序取出每一个单元<br><span class=\"hljs-number\">3</span>、遍历第一行，找出当前行中放置该单元后能够使得cost最小的位置<br><span class=\"hljs-number\">4</span>、放置该单元<br><br>若改行无法放置该单元，进行换行策略选择，重新执行，直到所有行都无法放置，返回<span class=\"hljs-keyword\">false</span><br></code></pre></td></tr></table></figure>\n<p><style>.jweudmfdtnob{zoom: 67%;}</style><img src=\"/2023/09/10/iEDA-test/image-20230825163454933.png\" class=\"jweudmfdtnob\" alt=\"image-20230825163454933\"></p>\n<p>因此对<code>iEDA</code>原始代码<code>Abacus</code>算法调整成<code>Tetris</code>只需要确定两个策略即可：1、如何选择当前<code>instance</code>初始行的策略。2、若初始行无法放置当前<code>instance</code>后，选择其它行的调整策略。</p>\n<ul>\n<li><p>选择初始行策略</p>\n<blockquote>\n<p>合法化是在全局布局过后的步骤，应尽可能的减少相关单元的移动，且尽可能地保证单元移动后和移动前地位置相近，因此最好是在该单元所在行的附近行进行移动</p>\n</blockquote>\n<p>1、加上<code>_row_height</code>后做除法</p>\n</li>\n</ul>\n<figure class=\"highlight gcode\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gcode\">auto row_idx = i<span class=\"hljs-symbol\">nt32</span>_t<span class=\"hljs-comment\">((inst_shape.get_center()</span>.get_y<span class=\"hljs-comment\">()</span>+float_t<span class=\"hljs-comment\">(_row_height/2)</span>)/_row_height);<br><span class=\"hljs-keyword\">if</span><span class=\"hljs-comment\">(inst_shape.get_ll_y()</span> <span class=\"hljs-meta\">%</span> _row_height == <span class=\"hljs-number\">0</span>)&#123;<br>  row_idx -= <span class=\"hljs-number\">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>​        2、直接使用<code>y</code>坐标与<code>_row_height</code>做整数相除</p>\n<figure class=\"highlight abnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs abnf\">auto row_idx <span class=\"hljs-operator\">=</span> inst_shape.get_center().get_y()/_row_height<span class=\"hljs-comment\">;</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>换行策略</li>\n</ul>\n<figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs kotlin\"><span class=\"hljs-keyword\">if</span>(cost == INT32_MAX)&#123;<br>  <span class=\"hljs-comment\">// 更新row_idx的策略</span><br>  auto i = <span class=\"hljs-number\">1</span>;<br>  <span class=\"hljs-keyword\">while</span>(cost == INT32_MAX)&#123;<br>    <span class=\"hljs-comment\">// 使用向上向下的扫描线完成</span><br>    <span class=\"hljs-keyword\">if</span>(row_idx + i &gt;= _database._lg_layout-&gt;get_row_num() &amp;&amp; row_idx - i &lt; <span class=\"hljs-number\">0</span>)&#123;<br>      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(row_idx + i &lt; _database._lg_layout-&gt;get_row_num())&#123;<br>      cost = placeRow(inst, row_idx + i, <span class=\"hljs-literal\">false</span>);<br>      <span class=\"hljs-keyword\">if</span>(cost != INT32_MAX)<span class=\"hljs-keyword\">break</span>;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(row_idx - i &gt;= <span class=\"hljs-number\">0</span>)&#123;<br>      cost = placeRow(inst, row_idx - i, <span class=\"hljs-literal\">false</span>);<br>      <span class=\"hljs-keyword\">if</span>(cost != INT32_MAX)<span class=\"hljs-keyword\">break</span>;<br>    &#125;<br>    i += <span class=\"hljs-number\">1</span>;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"四、结果\"><a href=\"#四、结果\" class=\"headerlink\" title=\"四、结果\"></a>四、结果</h3><ul>\n<li>使用原始的<code>Abacus</code>算法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825163939716.png\" class=\"\" title=\"image-20230825163939716\">\n<ul>\n<li>初始行策略使用：加上<code>_row_height</code>后做除法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825164152609.png\" class=\"\" title=\"image-20230825164152609\">\n<ul>\n<li>初始行策略使用：直接使用<code>y</code>坐标与<code>_row_height</code>做整数相除</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230825164459060.png\" class=\"\" title=\"image-20230825164459060\">\n<ul>\n<li>使用手册上<code>Tetris</code>的方法</li>\n</ul>\n<img src=\"/2023/09/10/iEDA-test/image-20230830164032304.png\" class=\"\" title=\"image-20230830164032304\">\n<img src=\"/2023/09/10/iEDA-test/image-20230830164051317.png\" class=\"\" title=\"image-20230830164051317\">\n<ul>\n<li>对比</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">Abacus</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">Tetris</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">全局布局HPWL</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n<td style=\"text-align:center\">8703921</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">合法化移动总Movement</td>\n<td style=\"text-align:center\">781382</td>\n<td style=\"text-align:center\">1410142</td>\n<td style=\"text-align:center\">865332</td>\n<td style=\"text-align:center\">11052260(14.144)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">合法化运行时间</td>\n<td style=\"text-align:center\">0.010062s</td>\n<td style=\"text-align:center\">0.000919s</td>\n<td style=\"text-align:center\">0.000944s</td>\n<td style=\"text-align:center\">0.086068s</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">布局合法化HPWL</td>\n<td style=\"text-align:center\">10798293</td>\n<td style=\"text-align:center\">10786671</td>\n<td style=\"text-align:center\">10749832</td>\n<td style=\"text-align:center\">21674741（2.007）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">详细布局HPWL</td>\n<td style=\"text-align:center\">10069766</td>\n<td style=\"text-align:center\">10105715</td>\n<td style=\"text-align:center\">10070071</td>\n<td style=\"text-align:center\">13192372</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Average Congestion of Edges</td>\n<td style=\"text-align:center\">0.728164</td>\n<td style=\"text-align:center\">0.718681</td>\n<td style=\"text-align:center\">0.713207</td>\n<td style=\"text-align:center\">0.713207</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total Overflow</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n<td style=\"text-align:center\">10.000000</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Maximal Overflow</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n<td style=\"text-align:center\">2.000000</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Peak BinDensity</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total HPWL</td>\n<td style=\"text-align:center\">10069766</td>\n<td style=\"text-align:center\">10105715</td>\n<td style=\"text-align:center\">10070071</td>\n<td style=\"text-align:center\">13192372</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Total STWL</td>\n<td style=\"text-align:center\">10862347</td>\n<td style=\"text-align:center\">10863122</td>\n<td style=\"text-align:center\">10864139</td>\n<td style=\"text-align:center\">14100332</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Max STWL</td>\n<td style=\"text-align:center\">437405</td>\n<td style=\"text-align:center\">442445</td>\n<td style=\"text-align:center\">460685</td>\n<td style=\"text-align:center\">518305</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>结果分析</strong></p>\n<ul>\n<li><p>将<code>Abacus</code>换成<code>Tetris</code>后，在同样的全局布局的版图中</p>\n<ul>\n<li><p><code>Movement</code>会增加</p>\n<p>因为在<code>Abacus</code>中计算的是每一个单元在所有行中的最小<code>cost</code>，而<code>Tetris</code>中则是计算的是周围行内，会存在差异性，这样的差异性在<strong>较为密集</strong>的全局布局中体现更为明显。</p>\n</li>\n<li><p>合法化运行时间会减少</p>\n<p>很显然，<code>Abacus</code>算法能够降低<code>Movement</code>就是以牺牲时间复杂度作为代价的，每一次<code>instance</code>的放置，平摊下来都会多出<code>_row_nums-1</code>轮次</p>\n</li>\n<li><p>布局合法化<code>HPWL</code>存在不确定性</p>\n<p>在实验中表现出来的是减少的特性，但实际上是表现出的不确定性，因为<code>Abacus</code>算法中的<code>cost</code>仅仅是以当前能够移动的最少的<code>x</code>和<code>y</code>的总和作为基准，并没有将线长给加进去，所以对于线长来说使用<code>Abacus</code>算法仅仅是一个贪心策略，不一定能够达到全局最优的效果</p>\n</li>\n</ul>\n</li>\n<li><p>个人感觉<code>Abacus</code>算法还是有点暴力</p>\n</li>\n</ul>\n<h3 id=\"PS：在重新复盘Tetris算法过后\"><a href=\"#PS：在重新复盘Tetris算法过后\" class=\"headerlink\" title=\"PS：在重新复盘Tetris算法过后\"></a>PS：在重新复盘Tetris算法过后</h3><p>最开始并没有完全理解要求完成的任务所描述的<code>Tetris</code>算法，仅仅是在<code>Abacus</code>的基础上置换了一个选择初始行和换行的策略，所以在最开始的代码当中调用的依然是原始的<code>placeRow</code>函数，在这个函数中的操作依然选择的是距离当前<code>instance</code>当中最近的<code>internel</code>，所以能够达到在时间减小的情况之下能够使得<code>HPWL</code>也减小的情况，这样的结果显然是存在偶然性的，因为找到的解都不一定都是最优解，与全局布局的结果有关。</p>\n<p>当使用手册上描述的<code>Tetris</code>算法后，最终运行期间的<code>Movement</code>变为原来的14倍多，而<code>HPWL</code>也是原来的2倍左右。</p>\n"},{"title":"PyTorch安装使用","date":"2023-02-02T09:05:09.000Z","cover":"/img/default_cover.jpg","top_img":null,"_content":"## PyTorch\n\n### 1、Pytorch的安装以及环境管理\n\n```\n# 安装环境\nconda create -n pytorch python=3.9\n\n# 激活环境，进入pytorch环境下\nconda activate pytorch\n```\n\n* 查看对应显卡类型，显卡算力以及需要下载的CUDA版本\n\n> 显卡型号：GeForce RTX3060\n>\n> 显卡算力：8.6\n>\n> CUDA SDK 11.1 – 11.4 support for compute capability 3.5 – 8.6 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere (in part)).\n>\n> CUDA SDK 11.5 – 11.7.1 support for compute capability 3.5 – 8.7 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere)\n>\n> CUDA版本：11.5-11.7\n>\n> 显卡驱动：11.6\n\n* 进入pytorch官网，pytorch.org\n\n![image-20221022163847897](pytorch-install/image-20221022163847897.png)\n\n* 选择对应型号\n\n> 复制选中的内容，粘贴至pytorch环境下的命令中\n>\n> conda install + 包\n\n```\n# conda的安装包命令 -c pytorch，表示默认从官网下载，会很慢\nconda install pytorch torchvision torchaudio cudatoolkit=11.6 -c 下载地址\n```\n\n* 安装过后检查安装包的情况\n\n```\n# 使用以上命令安装过后，会自动安装一个cpuonly的包，有这个包就不能使用gpu\nconda list\n\n# 卸载cpionly的包\nconda uninstall cpuonly\n\n# 输入yes后会更改pytorch torchvision torchaudio cudatoolkit=11.6\nconda list\n# 再次查看，就会发现\n```\n\n![image-20221022164808915](pytorch-install/image-20221022164808915.png)\n\n* 验证是否可以使用gpu\n\n```\n# 进入pytorch环境下\n# pip list 查看环境下的包\n# 输入python，进入解释器\nimport torch \ntorch.cuda.is_available()\n# 返回为True\n```\n\n![image-20221022165103111](pytorch-install/image-20221022165103111.png)\n\n### 2、Pytorch\n\n* 两大法宝内置函数\n\n> dir()，打开操作，看到有什么函数\n>\n> help()，说明书，如何使用\n\n* 加载数据\n\n> `Dataset`类：提供一种方式取获取数据及其`label`值\n>\n> `Dataloader`类：为网络提供不同的数据形式，打包Dataset类\n\n​\t\t使用dataset类的实战\n\n```\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\n# 继承Dataset类\nclass MyData(Dataset):\n\n    # 构造函数，为后面的方法提供变量\n    def __init__(self, root_dir, label_dir):\n        self.root_dir = root_dir\n        self.label_dir = label_dir\n        self.path = os.path.join(root_dir, label_dir)\n        # 图片所有地址\n        self.img_path = os.listdir(self.path)\n\n    # 读取第idx张图片\n    def __getitem__(self, idx):\n        img_name = self.img_path[idx]\n        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n        img = Image.open(img_item_path)\n        label = self.label_dir\n        return img, label\n\n    def __len__(self):\n        return len(self.img_path)\n\nroot_dir = \"data\\\\train\"\nlabel_dir = \"ants\"\nants_dataset = MyData(root_dir, label_dir)\n\n# 读取第0张图片\nimg, label = ants_dataset[0]\n\n```\n\n![image-20221022174307472](pytorch-install/image-20221022174307472.png)\n\n\n\n* PIL简单用法\n\n```\nfrom PIL import Image\n# 读取图片文件\nimg = Image.open(\"文件路径\")\n# 显示图片\nimg.show()\n```\n\n* os用法\n\n```\n# 将文件夹下的文件名作为列表返回\nos.listdir(文件夹名)\n\n# 将两个文件路径拼接起来\nos.path.join(路径1, 路径2)\n```\n\n### 3、Tensorboard的使用\n\n> 使用Tensorboard的时候，可以将训练的数据图像在网页端监控\n\n* 需要：pip install tensorboard\n* 在Terminal中输入：tensorboard --logdir=logs  --port=***\n  * 主义输入的文件名不用加引号\n\n* 点击链接，可以指定端口号\n* 在使用过程中，不同的图片要用不同的tag\n\n```\n# 写入变化函数\nfrom torch.utils.tensorboard import SummaryWriter\n\nwrite = SummaryWriter(\"logs\")\n#write.add_image()\n# 可以传入标题等\n\nfor i in range(100):\n    write.add_scalar(\"y=2x\", 2*i, i)\n\nwrite.close()\n\n```\n\n​\t\t对图片的显示\n\n```\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nfrom PIL import Image\n\nwrite = SummaryWriter(\"logs\")\nimage_path = \"dataset\\\\train\\\\ants_image\\\\0013035.jpg\"\nimg_PIL = Image.open(image_path)\nimg_array = np.array(img_PIL)\n\nprint(img_array.shape)\n\nwrite.add_image(\"test\", img_array, 1, dataformats='HWC')\n\nwrite.close()\n```\n\n### 4、Torchvision中的transforms\n\n* transforms工具箱：将特定格式的图片通过转化输出图片变化结果\n  * `transforms.ToTensor`：将图片或`numpy.ndarray`数据转化为`Tensor`数据\n  * `ToPILImage`：将Tensor数据类型转化为ndarray数据类型或PIL数据类型\n  * `transforms.Normalize`：图片的归一化，输入均值列表、标准差列表，列表长度为通道数\n  * `Resize`：设计图片的尺寸，若给定两个参数，则进行裁剪，若输入一个参数，则等比缩放，参数以元组的形式\n  * `Compose`：流水线的集合，数据是transforms类型，提供一个操作的列表\n* Tensor数据类型\n  * Tensor数据类型中包装了神经网络的一些数据参数，因此需要将图片的文件转化为Tensor数据\n\n* 输入：PIL、Image.open()\n* 输出：tensor、ToTensor()\n* 作用：ndarray()、cv.imread()\n\n### 5、Torchvision中的数据集的使用\n\n* dataset\n* dataloader：数据加载器，从数据集中取数据\n","source":"_posts/pytorch-install.md","raw":"---\ntitle: PyTorch安装使用\ncategories: 技术研究\ndate: 2023-02-02 17:05:09\ntags: [PyTorch, 人工智能, AI]\ncover:\ntop_img:\n---\n## PyTorch\n\n### 1、Pytorch的安装以及环境管理\n\n```\n# 安装环境\nconda create -n pytorch python=3.9\n\n# 激活环境，进入pytorch环境下\nconda activate pytorch\n```\n\n* 查看对应显卡类型，显卡算力以及需要下载的CUDA版本\n\n> 显卡型号：GeForce RTX3060\n>\n> 显卡算力：8.6\n>\n> CUDA SDK 11.1 – 11.4 support for compute capability 3.5 – 8.6 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere (in part)).\n>\n> CUDA SDK 11.5 – 11.7.1 support for compute capability 3.5 – 8.7 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere)\n>\n> CUDA版本：11.5-11.7\n>\n> 显卡驱动：11.6\n\n* 进入pytorch官网，pytorch.org\n\n![image-20221022163847897](pytorch-install/image-20221022163847897.png)\n\n* 选择对应型号\n\n> 复制选中的内容，粘贴至pytorch环境下的命令中\n>\n> conda install + 包\n\n```\n# conda的安装包命令 -c pytorch，表示默认从官网下载，会很慢\nconda install pytorch torchvision torchaudio cudatoolkit=11.6 -c 下载地址\n```\n\n* 安装过后检查安装包的情况\n\n```\n# 使用以上命令安装过后，会自动安装一个cpuonly的包，有这个包就不能使用gpu\nconda list\n\n# 卸载cpionly的包\nconda uninstall cpuonly\n\n# 输入yes后会更改pytorch torchvision torchaudio cudatoolkit=11.6\nconda list\n# 再次查看，就会发现\n```\n\n![image-20221022164808915](pytorch-install/image-20221022164808915.png)\n\n* 验证是否可以使用gpu\n\n```\n# 进入pytorch环境下\n# pip list 查看环境下的包\n# 输入python，进入解释器\nimport torch \ntorch.cuda.is_available()\n# 返回为True\n```\n\n![image-20221022165103111](pytorch-install/image-20221022165103111.png)\n\n### 2、Pytorch\n\n* 两大法宝内置函数\n\n> dir()，打开操作，看到有什么函数\n>\n> help()，说明书，如何使用\n\n* 加载数据\n\n> `Dataset`类：提供一种方式取获取数据及其`label`值\n>\n> `Dataloader`类：为网络提供不同的数据形式，打包Dataset类\n\n​\t\t使用dataset类的实战\n\n```\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\n# 继承Dataset类\nclass MyData(Dataset):\n\n    # 构造函数，为后面的方法提供变量\n    def __init__(self, root_dir, label_dir):\n        self.root_dir = root_dir\n        self.label_dir = label_dir\n        self.path = os.path.join(root_dir, label_dir)\n        # 图片所有地址\n        self.img_path = os.listdir(self.path)\n\n    # 读取第idx张图片\n    def __getitem__(self, idx):\n        img_name = self.img_path[idx]\n        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n        img = Image.open(img_item_path)\n        label = self.label_dir\n        return img, label\n\n    def __len__(self):\n        return len(self.img_path)\n\nroot_dir = \"data\\\\train\"\nlabel_dir = \"ants\"\nants_dataset = MyData(root_dir, label_dir)\n\n# 读取第0张图片\nimg, label = ants_dataset[0]\n\n```\n\n![image-20221022174307472](pytorch-install/image-20221022174307472.png)\n\n\n\n* PIL简单用法\n\n```\nfrom PIL import Image\n# 读取图片文件\nimg = Image.open(\"文件路径\")\n# 显示图片\nimg.show()\n```\n\n* os用法\n\n```\n# 将文件夹下的文件名作为列表返回\nos.listdir(文件夹名)\n\n# 将两个文件路径拼接起来\nos.path.join(路径1, 路径2)\n```\n\n### 3、Tensorboard的使用\n\n> 使用Tensorboard的时候，可以将训练的数据图像在网页端监控\n\n* 需要：pip install tensorboard\n* 在Terminal中输入：tensorboard --logdir=logs  --port=***\n  * 主义输入的文件名不用加引号\n\n* 点击链接，可以指定端口号\n* 在使用过程中，不同的图片要用不同的tag\n\n```\n# 写入变化函数\nfrom torch.utils.tensorboard import SummaryWriter\n\nwrite = SummaryWriter(\"logs\")\n#write.add_image()\n# 可以传入标题等\n\nfor i in range(100):\n    write.add_scalar(\"y=2x\", 2*i, i)\n\nwrite.close()\n\n```\n\n​\t\t对图片的显示\n\n```\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nfrom PIL import Image\n\nwrite = SummaryWriter(\"logs\")\nimage_path = \"dataset\\\\train\\\\ants_image\\\\0013035.jpg\"\nimg_PIL = Image.open(image_path)\nimg_array = np.array(img_PIL)\n\nprint(img_array.shape)\n\nwrite.add_image(\"test\", img_array, 1, dataformats='HWC')\n\nwrite.close()\n```\n\n### 4、Torchvision中的transforms\n\n* transforms工具箱：将特定格式的图片通过转化输出图片变化结果\n  * `transforms.ToTensor`：将图片或`numpy.ndarray`数据转化为`Tensor`数据\n  * `ToPILImage`：将Tensor数据类型转化为ndarray数据类型或PIL数据类型\n  * `transforms.Normalize`：图片的归一化，输入均值列表、标准差列表，列表长度为通道数\n  * `Resize`：设计图片的尺寸，若给定两个参数，则进行裁剪，若输入一个参数，则等比缩放，参数以元组的形式\n  * `Compose`：流水线的集合，数据是transforms类型，提供一个操作的列表\n* Tensor数据类型\n  * Tensor数据类型中包装了神经网络的一些数据参数，因此需要将图片的文件转化为Tensor数据\n\n* 输入：PIL、Image.open()\n* 输出：tensor、ToTensor()\n* 作用：ndarray()、cv.imread()\n\n### 5、Torchvision中的数据集的使用\n\n* dataset\n* dataloader：数据加载器，从数据集中取数据\n","slug":"pytorch-install","published":1,"updated":"2024-06-05T09:03:03.804Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttx002v08jv74bu6p1p","content":"<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><h3 id=\"1、Pytorch的安装以及环境管理\"><a href=\"#1、Pytorch的安装以及环境管理\" class=\"headerlink\" title=\"1、Pytorch的安装以及环境管理\"></a>1、Pytorch的安装以及环境管理</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># 安装环境</span><br><span class=\"hljs-attribute\">conda</span> create -n pytorch python=<span class=\"hljs-number\">3</span>.<span class=\"hljs-number\">9</span><br><br><span class=\"hljs-comment\"># 激活环境，进入pytorch环境下</span><br><span class=\"hljs-attribute\">conda</span> activate pytorch<br></code></pre></td></tr></table></figure>\n<ul>\n<li>查看对应显卡类型，显卡算力以及需要下载的CUDA版本</li>\n</ul>\n<blockquote>\n<p>显卡型号：GeForce RTX3060</p>\n<p>显卡算力：8.6</p>\n<p>CUDA SDK 11.1 – 11.4 support for compute capability 3.5 – 8.6 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere (in part)).</p>\n<p>CUDA SDK 11.5 – 11.7.1 support for compute capability 3.5 – 8.7 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere)</p>\n<p>CUDA版本：11.5-11.7</p>\n<p>显卡驱动：11.6</p>\n</blockquote>\n<ul>\n<li>进入pytorch官网，pytorch.org</li>\n</ul>\n<img src=\"/2023/02/02/pytorch-install/image-20221022163847897.png\" class=\"\" title=\"image-20221022163847897\">\n<ul>\n<li>选择对应型号</li>\n</ul>\n<blockquote>\n<p>复制选中的内容，粘贴至pytorch环境下的命令中</p>\n<p>conda install + 包</p>\n</blockquote>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># conda的安装包命令 -c pytorch，表示默认从官网下载，会很慢</span><br><span class=\"hljs-attribute\">conda</span> install pytorch torchvision torchaudio cudatoolkit=<span class=\"hljs-number\">11</span>.<span class=\"hljs-number\">6</span> -c 下载地址<br></code></pre></td></tr></table></figure>\n<ul>\n<li>安装过后检查安装包的情况</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># 使用以上命令安装过后，会自动安装一个cpuonly的包，有这个包就不能使用gpu</span><br><span class=\"hljs-attribute\">conda</span> list<br><br><span class=\"hljs-comment\"># 卸载cpionly的包</span><br>conda uninstall cpuonly<br><br><span class=\"hljs-comment\"># 输入yes后会更改pytorch torchvision torchaudio cudatoolkit=11.6</span><br>conda list<br><span class=\"hljs-comment\"># 再次查看，就会发现</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022164808915.png\" class=\"\" title=\"image-20221022164808915\">\n<ul>\n<li>验证是否可以使用gpu</li>\n</ul>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\"># 进入pytorch环境下<br># pip list 查看环境下的包<br># 输入python，进入解释器<br><span class=\"hljs-keyword\">import</span> torch <br>torch.cuda.is_available()<br># 返回为<span class=\"hljs-literal\">True</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022165103111.png\" class=\"\" title=\"image-20221022165103111\">\n<h3 id=\"2、Pytorch\"><a href=\"#2、Pytorch\" class=\"headerlink\" title=\"2、Pytorch\"></a>2、Pytorch</h3><ul>\n<li>两大法宝内置函数</li>\n</ul>\n<blockquote>\n<p>dir()，打开操作，看到有什么函数</p>\n<p>help()，说明书，如何使用</p>\n</blockquote>\n<ul>\n<li>加载数据</li>\n</ul>\n<blockquote>\n<p><code>Dataset</code>类：提供一种方式取获取数据及其<code>label</code>值</p>\n<p><code>Dataloader</code>类：为网络提供不同的数据形式，打包Dataset类</p>\n</blockquote>\n<p>​        使用dataset类的实战</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><span class=\"hljs-keyword\">import</span> os<br><br><span class=\"hljs-comment\"># 继承Dataset类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyData</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):<br><br>    <span class=\"hljs-comment\"># 构造函数，为后面的方法提供变量</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, root_dir, label_dir</span>):<br>        self.root_dir = root_dir<br>        self.label_dir = label_dir<br>        self.path = os.path.join(root_dir, label_dir)<br>        <span class=\"hljs-comment\"># 图片所有地址</span><br>        self.img_path = os.listdir(self.path)<br><br>    <span class=\"hljs-comment\"># 读取第idx张图片</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):<br>        img_name = self.img_path[idx]<br>        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)<br>        img = Image.<span class=\"hljs-built_in\">open</span>(img_item_path)<br>        label = self.label_dir<br>        <span class=\"hljs-keyword\">return</span> img, label<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">len</span>(self.img_path)<br><br>root_dir = <span class=\"hljs-string\">&quot;data\\\\train&quot;</span><br>label_dir = <span class=\"hljs-string\">&quot;ants&quot;</span><br>ants_dataset = MyData(root_dir, label_dir)<br><br><span class=\"hljs-comment\"># 读取第0张图片</span><br>img, label = ants_dataset[<span class=\"hljs-number\">0</span>]<br><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022174307472.png\" class=\"\" title=\"image-20221022174307472\">\n<ul>\n<li>PIL简单用法</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><span class=\"hljs-comment\"># 读取图片文件</span><br>img = Image.<span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&quot;文件路径&quot;</span>)<br><span class=\"hljs-comment\"># 显示图片</span><br>img.show()<br></code></pre></td></tr></table></figure>\n<ul>\n<li>os用法</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># 将文件夹下的文件名作为列表返回</span><br><span class=\"hljs-attribute\">os</span>.listdir(文件夹名)<br><br><span class=\"hljs-comment\"># 将两个文件路径拼接起来</span><br><span class=\"hljs-attribute\">os</span>.path.join(路径<span class=\"hljs-number\">1</span>, 路径<span class=\"hljs-number\">2</span>)<br></code></pre></td></tr></table></figure>\n<h3 id=\"3、Tensorboard的使用\"><a href=\"#3、Tensorboard的使用\" class=\"headerlink\" title=\"3、Tensorboard的使用\"></a>3、Tensorboard的使用</h3><blockquote>\n<p>使用Tensorboard的时候，可以将训练的数据图像在网页端监控</p>\n</blockquote>\n<ul>\n<li>需要：pip install tensorboard</li>\n<li><p>在Terminal中输入：tensorboard —logdir=logs  —port=<em>*</em></p>\n<ul>\n<li>主义输入的文件名不用加引号</li>\n</ul>\n</li>\n<li><p>点击链接，可以指定端口号</p>\n</li>\n<li>在使用过程中，不同的图片要用不同的tag</li>\n</ul>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\"><span class=\"hljs-comment\"># 写入变化函数</span><br><span class=\"hljs-built_in\">from</span> torch.utils.tensorboard import SummaryWriter<br><br><span class=\"hljs-built_in\">write</span> = SummaryWriter(<span class=\"hljs-string\">&quot;logs&quot;</span>)<br><span class=\"hljs-comment\">#write.add_image()</span><br><span class=\"hljs-comment\"># 可以传入标题等</span><br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(<span class=\"hljs-number\">100</span>):<br>    <span class=\"hljs-built_in\">write</span>.add_scalar(<span class=\"hljs-string\">&quot;y=2x&quot;</span>, <span class=\"hljs-number\">2</span>*i, i)<br><br><span class=\"hljs-built_in\">write</span>.<span class=\"hljs-built_in\">close</span>()<br><br></code></pre></td></tr></table></figure>\n<p>​        对图片的显示</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">from</span> torch.utils.tensorboard <span class=\"hljs-keyword\">import</span> SummaryWriter<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><br><span class=\"hljs-keyword\">write</span> = SummaryWriter(&quot;logs&quot;)<br>image_path = &quot;dataset\\\\train\\\\ants_image\\\\0013035.jpg&quot;<br>img_PIL = Image.<span class=\"hljs-keyword\">open</span>(image_path)<br>img_array = np.<span class=\"hljs-keyword\">array</span>(img_PIL)<br><br>print(img_array.shape)<br><br><span class=\"hljs-keyword\">write</span>.add_image(&quot;test&quot;, img_array, <span class=\"hljs-number\">1</span>, dataformats=<span class=\"hljs-string\">&#x27;HWC&#x27;</span>)<br><br><span class=\"hljs-keyword\">write</span>.<span class=\"hljs-keyword\">close</span>()<br></code></pre></td></tr></table></figure>\n<h3 id=\"4、Torchvision中的transforms\"><a href=\"#4、Torchvision中的transforms\" class=\"headerlink\" title=\"4、Torchvision中的transforms\"></a>4、Torchvision中的transforms</h3><ul>\n<li>transforms工具箱：将特定格式的图片通过转化输出图片变化结果<ul>\n<li><code>transforms.ToTensor</code>：将图片或<code>numpy.ndarray</code>数据转化为<code>Tensor</code>数据</li>\n<li><code>ToPILImage</code>：将Tensor数据类型转化为ndarray数据类型或PIL数据类型</li>\n<li><code>transforms.Normalize</code>：图片的归一化，输入均值列表、标准差列表，列表长度为通道数</li>\n<li><code>Resize</code>：设计图片的尺寸，若给定两个参数，则进行裁剪，若输入一个参数，则等比缩放，参数以元组的形式</li>\n<li><code>Compose</code>：流水线的集合，数据是transforms类型，提供一个操作的列表</li>\n</ul>\n</li>\n<li><p>Tensor数据类型</p>\n<ul>\n<li>Tensor数据类型中包装了神经网络的一些数据参数，因此需要将图片的文件转化为Tensor数据</li>\n</ul>\n</li>\n<li><p>输入：PIL、Image.open()</p>\n</li>\n<li>输出：tensor、ToTensor()</li>\n<li>作用：ndarray()、cv.imread()</li>\n</ul>\n<h3 id=\"5、Torchvision中的数据集的使用\"><a href=\"#5、Torchvision中的数据集的使用\" class=\"headerlink\" title=\"5、Torchvision中的数据集的使用\"></a>5、Torchvision中的数据集的使用</h3><ul>\n<li>dataset</li>\n<li>dataloader：数据加载器，从数据集中取数据</li>\n</ul>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><h3 id=\"1、Pytorch的安装以及环境管理\"><a href=\"#1、Pytorch的安装以及环境管理\" class=\"headerlink\" title=\"1、Pytorch的安装以及环境管理\"></a>1、Pytorch的安装以及环境管理</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># 安装环境</span><br><span class=\"hljs-attribute\">conda</span> create -n pytorch python=<span class=\"hljs-number\">3</span>.<span class=\"hljs-number\">9</span><br><br><span class=\"hljs-comment\"># 激活环境，进入pytorch环境下</span><br><span class=\"hljs-attribute\">conda</span> activate pytorch<br></code></pre></td></tr></table></figure>\n<ul>\n<li>查看对应显卡类型，显卡算力以及需要下载的CUDA版本</li>\n</ul>\n<blockquote>\n<p>显卡型号：GeForce RTX3060</p>\n<p>显卡算力：8.6</p>\n<p>CUDA SDK 11.1 – 11.4 support for compute capability 3.5 – 8.6 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere (in part)).</p>\n<p>CUDA SDK 11.5 – 11.7.1 support for compute capability 3.5 – 8.7 (Kepler (in part), Maxwell, Pascal, Volta, Turing, Ampere)</p>\n<p>CUDA版本：11.5-11.7</p>\n<p>显卡驱动：11.6</p>\n</blockquote>\n<ul>\n<li>进入pytorch官网，pytorch.org</li>\n</ul>\n<img src=\"/2023/02/02/pytorch-install/image-20221022163847897.png\" class=\"\" title=\"image-20221022163847897\">\n<ul>\n<li>选择对应型号</li>\n</ul>\n<blockquote>\n<p>复制选中的内容，粘贴至pytorch环境下的命令中</p>\n<p>conda install + 包</p>\n</blockquote>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># conda的安装包命令 -c pytorch，表示默认从官网下载，会很慢</span><br><span class=\"hljs-attribute\">conda</span> install pytorch torchvision torchaudio cudatoolkit=<span class=\"hljs-number\">11</span>.<span class=\"hljs-number\">6</span> -c 下载地址<br></code></pre></td></tr></table></figure>\n<ul>\n<li>安装过后检查安装包的情况</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># 使用以上命令安装过后，会自动安装一个cpuonly的包，有这个包就不能使用gpu</span><br><span class=\"hljs-attribute\">conda</span> list<br><br><span class=\"hljs-comment\"># 卸载cpionly的包</span><br>conda uninstall cpuonly<br><br><span class=\"hljs-comment\"># 输入yes后会更改pytorch torchvision torchaudio cudatoolkit=11.6</span><br>conda list<br><span class=\"hljs-comment\"># 再次查看，就会发现</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022164808915.png\" class=\"\" title=\"image-20221022164808915\">\n<ul>\n<li>验证是否可以使用gpu</li>\n</ul>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs clean\"># 进入pytorch环境下<br># pip list 查看环境下的包<br># 输入python，进入解释器<br><span class=\"hljs-keyword\">import</span> torch <br>torch.cuda.is_available()<br># 返回为<span class=\"hljs-literal\">True</span><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022165103111.png\" class=\"\" title=\"image-20221022165103111\">\n<h3 id=\"2、Pytorch\"><a href=\"#2、Pytorch\" class=\"headerlink\" title=\"2、Pytorch\"></a>2、Pytorch</h3><ul>\n<li>两大法宝内置函数</li>\n</ul>\n<blockquote>\n<p>dir()，打开操作，看到有什么函数</p>\n<p>help()，说明书，如何使用</p>\n</blockquote>\n<ul>\n<li>加载数据</li>\n</ul>\n<blockquote>\n<p><code>Dataset</code>类：提供一种方式取获取数据及其<code>label</code>值</p>\n<p><code>Dataloader</code>类：为网络提供不同的数据形式，打包Dataset类</p>\n</blockquote>\n<p>​        使用dataset类的实战</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><span class=\"hljs-keyword\">import</span> os<br><br><span class=\"hljs-comment\"># 继承Dataset类</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyData</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):<br><br>    <span class=\"hljs-comment\"># 构造函数，为后面的方法提供变量</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, root_dir, label_dir</span>):<br>        self.root_dir = root_dir<br>        self.label_dir = label_dir<br>        self.path = os.path.join(root_dir, label_dir)<br>        <span class=\"hljs-comment\"># 图片所有地址</span><br>        self.img_path = os.listdir(self.path)<br><br>    <span class=\"hljs-comment\"># 读取第idx张图片</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):<br>        img_name = self.img_path[idx]<br>        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)<br>        img = Image.<span class=\"hljs-built_in\">open</span>(img_item_path)<br>        label = self.label_dir<br>        <span class=\"hljs-keyword\">return</span> img, label<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">len</span>(self.img_path)<br><br>root_dir = <span class=\"hljs-string\">&quot;data\\\\train&quot;</span><br>label_dir = <span class=\"hljs-string\">&quot;ants&quot;</span><br>ants_dataset = MyData(root_dir, label_dir)<br><br><span class=\"hljs-comment\"># 读取第0张图片</span><br>img, label = ants_dataset[<span class=\"hljs-number\">0</span>]<br><br></code></pre></td></tr></table></figure>\n<img src=\"/2023/02/02/pytorch-install/image-20221022174307472.png\" class=\"\" title=\"image-20221022174307472\">\n<ul>\n<li>PIL简单用法</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><span class=\"hljs-comment\"># 读取图片文件</span><br>img = Image.<span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&quot;文件路径&quot;</span>)<br><span class=\"hljs-comment\"># 显示图片</span><br>img.show()<br></code></pre></td></tr></table></figure>\n<ul>\n<li>os用法</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-comment\"># 将文件夹下的文件名作为列表返回</span><br><span class=\"hljs-attribute\">os</span>.listdir(文件夹名)<br><br><span class=\"hljs-comment\"># 将两个文件路径拼接起来</span><br><span class=\"hljs-attribute\">os</span>.path.join(路径<span class=\"hljs-number\">1</span>, 路径<span class=\"hljs-number\">2</span>)<br></code></pre></td></tr></table></figure>\n<h3 id=\"3、Tensorboard的使用\"><a href=\"#3、Tensorboard的使用\" class=\"headerlink\" title=\"3、Tensorboard的使用\"></a>3、Tensorboard的使用</h3><blockquote>\n<p>使用Tensorboard的时候，可以将训练的数据图像在网页端监控</p>\n</blockquote>\n<ul>\n<li>需要：pip install tensorboard</li>\n<li><p>在Terminal中输入：tensorboard —logdir=logs  —port=<em>*</em></p>\n<ul>\n<li>主义输入的文件名不用加引号</li>\n</ul>\n</li>\n<li><p>点击链接，可以指定端口号</p>\n</li>\n<li>在使用过程中，不同的图片要用不同的tag</li>\n</ul>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\"><span class=\"hljs-comment\"># 写入变化函数</span><br><span class=\"hljs-built_in\">from</span> torch.utils.tensorboard import SummaryWriter<br><br><span class=\"hljs-built_in\">write</span> = SummaryWriter(<span class=\"hljs-string\">&quot;logs&quot;</span>)<br><span class=\"hljs-comment\">#write.add_image()</span><br><span class=\"hljs-comment\"># 可以传入标题等</span><br><br><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> range(<span class=\"hljs-number\">100</span>):<br>    <span class=\"hljs-built_in\">write</span>.add_scalar(<span class=\"hljs-string\">&quot;y=2x&quot;</span>, <span class=\"hljs-number\">2</span>*i, i)<br><br><span class=\"hljs-built_in\">write</span>.<span class=\"hljs-built_in\">close</span>()<br><br></code></pre></td></tr></table></figure>\n<p>​        对图片的显示</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">from</span> torch.utils.tensorboard <span class=\"hljs-keyword\">import</span> SummaryWriter<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image<br><br><span class=\"hljs-keyword\">write</span> = SummaryWriter(&quot;logs&quot;)<br>image_path = &quot;dataset\\\\train\\\\ants_image\\\\0013035.jpg&quot;<br>img_PIL = Image.<span class=\"hljs-keyword\">open</span>(image_path)<br>img_array = np.<span class=\"hljs-keyword\">array</span>(img_PIL)<br><br>print(img_array.shape)<br><br><span class=\"hljs-keyword\">write</span>.add_image(&quot;test&quot;, img_array, <span class=\"hljs-number\">1</span>, dataformats=<span class=\"hljs-string\">&#x27;HWC&#x27;</span>)<br><br><span class=\"hljs-keyword\">write</span>.<span class=\"hljs-keyword\">close</span>()<br></code></pre></td></tr></table></figure>\n<h3 id=\"4、Torchvision中的transforms\"><a href=\"#4、Torchvision中的transforms\" class=\"headerlink\" title=\"4、Torchvision中的transforms\"></a>4、Torchvision中的transforms</h3><ul>\n<li>transforms工具箱：将特定格式的图片通过转化输出图片变化结果<ul>\n<li><code>transforms.ToTensor</code>：将图片或<code>numpy.ndarray</code>数据转化为<code>Tensor</code>数据</li>\n<li><code>ToPILImage</code>：将Tensor数据类型转化为ndarray数据类型或PIL数据类型</li>\n<li><code>transforms.Normalize</code>：图片的归一化，输入均值列表、标准差列表，列表长度为通道数</li>\n<li><code>Resize</code>：设计图片的尺寸，若给定两个参数，则进行裁剪，若输入一个参数，则等比缩放，参数以元组的形式</li>\n<li><code>Compose</code>：流水线的集合，数据是transforms类型，提供一个操作的列表</li>\n</ul>\n</li>\n<li><p>Tensor数据类型</p>\n<ul>\n<li>Tensor数据类型中包装了神经网络的一些数据参数，因此需要将图片的文件转化为Tensor数据</li>\n</ul>\n</li>\n<li><p>输入：PIL、Image.open()</p>\n</li>\n<li>输出：tensor、ToTensor()</li>\n<li>作用：ndarray()、cv.imread()</li>\n</ul>\n<h3 id=\"5、Torchvision中的数据集的使用\"><a href=\"#5、Torchvision中的数据集的使用\" class=\"headerlink\" title=\"5、Torchvision中的数据集的使用\"></a>5、Torchvision中的数据集的使用</h3><ul>\n<li>dataset</li>\n<li>dataloader：数据加载器，从数据集中取数据</li>\n</ul>\n"},{"title":"PyTorch使用方法","date":"2023-03-02T09:11:36.000Z","cover":"/img/default_cover06.jpg","top_img":null,"_content":"## PyTorch基础语法\n\nPytorch是Facebook主导开发的，基于Python的科学计算包，主要有一下两个特点：\n\n比NumPy更灵活，可以使用GPU的强大计算能力\n\n开源高效的深度学习研究平台\n\n* ### 张量\n\n  > PyTorch中的Tensors可以使用GPU计算\n\n```python\nimport torch\n\n# 可以返回填充了未初始化数据的张量\ntorch.empty(5, 3)\n\n# 创建一个随机初始化矩阵\ntorch.rand(5, 3)\n\n# 创建一个0填充的矩阵，指定数据类型为long：\ntorch.zeros(5, 3, dtype=torch.long)\n\n# 创建 Tensor 并使用现有数据初始化：\nx = torch.tensor([5.5, 3])\nx\n\n#根据现有张量创建新张量。这些方法将重用输入张量的属性，除非设置新的值进行覆盖\nx = x.new_ones(5, 3, dtype=torch.double)  # new_* 方法来创建对象\nx\n\n# 覆盖 dtype，对象的 size 是相同的，只是值和类型发生了变化\nx = torch.randn_like(x, dtype=torch.float)\nx\n\n# 获得张量的size，返回值为tuple\nx.size()\n```\n\n* ### 操作\n\n```python\n#加法操作\ny = torch.rand(5, 3)\nx + y\n\ntorch.add(x, y)\n\n# 提供输出Tensor作为参数\nresult = torch.empty(5, 3)\ntorch.add(x, y, out=result)\nresult\n\n# 替换，将x加到y\ny.add_(x)\ny\n```\n\n任何以下划线结尾的操作都会用结果替换原变量\n\n可以使用与Numpy索引方式相同的操作来对张量进行操作\n\n```python\n# torch.view可以改变张量的维度和大小\nx = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8)  # size -1 从其他维度推断\n\nx.size(), y.size(), z.size()\n\n# 如果张量只有一个元素，使用 .item() 来得到 Python 数据类型的数值\nx = torch.randn(1)\n\nx, x.item()\n```\n\n> 官方文档：[torch — PyTorch 1.12 documentation](https://pytorch.org/docs/stable/torch.html)\n\n* ### NumPy转换\n\n```python\n# PyTorch张量转换为NumPy数组\na = torch.ones(5)\na\nb = a.numpy()\nb\n\n# 了解 NumPy 数组的值如何变化，a和b的数值都会加1\na.add_(1)\na, b\n\n# NumPy 数组转换成 PyTorch 张量时，可以使用 from_numpy 完成\nimport numpy as np\n\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\na, b\n```\n\n所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 NumPy 的转换\n\n* ### CUDA张量\n\nCUDA张量是能够再GPU设备在运算的张量。使用.to方法可以将Tensor移动到GPU设备中去\n\n```python\n# is_available 函数判断是否有 GPU 可以使用\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # torch.device 将张量移动到指定的设备中\n    y = torch.ones_like(x, device=device)  # 直接从 GPU 创建张量\n    x = x.to(device)                       # 或者直接使用 .to(\"cuda\") 将张量移动到 cuda 中\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))       # .to 也会对变量的类型做更改\n```\n\n## Autograd自动求导\n\n> PyTorch中所有神经网络的核心是autograd\n\n`autograd`为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行。\n\n`torch.Tensor` 是这个包的核心类。如果设置`.requires_grad`为`True`，那么将会追踪所有对于该张量的操作。当完成计算后通过调用`.backward()`会自动计算所有的梯度，这个张量的所有梯度将自动积累到`.grad`属性。这也就完成了自动求导的过程。\n\n要组织张量追踪历史记录，可以调用`.detach()`方法将其与计算历史记录分离。为了防止跟踪历史记录（和使用内存），可以将代码块包装在`with tirch.no_grad():`语句中。这一点在评估模型时特别有用，因为模型可能具有`requires_grad=True`的可训练参数，但是并不需要计算梯度。\n\n自动求导还有另一个重要的类`Function`。`Tensor`和`Function`互相连接并生成一个非循环图，存储了完整的计算历史。\n\n如果需要计算导数，可以在`Tensor`上调用`.backward()`。如果`Tensor`是一个标量（即它只包含一个元素数据）则不需要为`backward()`指定任何参数。但是如果他又多个元素，则需要指定一个`gradient`参数来匹配张量的形状。\n\n```python\n# 创建一个张量并设置 requires_grad=True 用来追踪他的计算历史\nx = torch.ones(2, 2, requires_grad=True)\nx\n\n# 对张量进行操作，也就是计算过程\ny = x + 2\ny\n\n# 结果 y 已经被计算出来了，所以，grad_fn 已经被自动生成了\ny.grad_fn\n\n# 然后，再对 y 进行操作\nz = y * y * 3\nout = z.mean()\n\nz, out\n\n# .requires_grad_( ... ) 可以改变现有张量的 requires_grad 属性。 如果没有指定的话，默认输入的 flag 是 False\na = torch.randn(2, 2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)\n```\n\n* ### 梯度\n\n通过反向传播打印对应结点的梯度，因为`out`是一个纯量Scalar，`out.backward()`等于`out.backward(torch.tensor(1))`\n\n```python\nout.backward()\n\n# 打印其梯度\nx.grad\n```\n\n关于Autograd的更多操作\n\n```python\nx = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\ny\n\ngradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\ny.backward(gradients)\n\nx.grad\n\n# 如果 .requires_grad=True 但是你又不希望进行 Autograd 的计算，那么可以将变量包裹在 with torch.no_grad() 中\nprint(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n    print((x ** 2).requires_grad)\n```\n\n> `autograd`和`Function`的官方文档：[Automatic differentiation package - torch.autograd — PyTorch 1.12 documentation](https://pytorch.org/docs/stable/autograd.html)\n\n## 神经网络\n\nPyTorch中，我们可以使用`torch.nn`来构建神经网络\n\n`torch.nn`依赖`autograd`来定义模型并求导。`nn.Module`中包含了构建神经网络所需的各个层和`forward(input)`方法，该方法返回神经网络的输出。\n\n​\t神经网络的典型训练过程如下\n\n1、定义包含可学习参数（权重）的神经网络模型\n\n2、在数据集上迭代\n\n3、通过神经网络处理输入\n\n4、计算损失\n\n5、将梯度反向传播回网络结点\n\n6、更新网络的参数，一般可以使用梯度下降等最优化方法\n\n​\tPyTorch的`nn.Conv2d()`详解，该类作为二维卷积的实现\n\n```python\nin_channels\t\t# 输入张量的channels数\nout_channels\t# 期望的四维输出张量的channels数\nkernel_size\t\t# 卷积核的大小，一般用5×5、3×3\nstride=1\t\t# 卷积核在图像窗口上每次平移的间隔，步长\npadding=0\t\t\n```\n\n","source":"_posts/pytorch-use.md","raw":"---\ntitle: PyTorch使用方法\ncategories: 技术研究\ndate: 2023-03-02 17:11:36\ntags: [PyTorch, DeepLearning, 神经网络, AI]\ncover:\ntop_img:\n---\n## PyTorch基础语法\n\nPytorch是Facebook主导开发的，基于Python的科学计算包，主要有一下两个特点：\n\n比NumPy更灵活，可以使用GPU的强大计算能力\n\n开源高效的深度学习研究平台\n\n* ### 张量\n\n  > PyTorch中的Tensors可以使用GPU计算\n\n```python\nimport torch\n\n# 可以返回填充了未初始化数据的张量\ntorch.empty(5, 3)\n\n# 创建一个随机初始化矩阵\ntorch.rand(5, 3)\n\n# 创建一个0填充的矩阵，指定数据类型为long：\ntorch.zeros(5, 3, dtype=torch.long)\n\n# 创建 Tensor 并使用现有数据初始化：\nx = torch.tensor([5.5, 3])\nx\n\n#根据现有张量创建新张量。这些方法将重用输入张量的属性，除非设置新的值进行覆盖\nx = x.new_ones(5, 3, dtype=torch.double)  # new_* 方法来创建对象\nx\n\n# 覆盖 dtype，对象的 size 是相同的，只是值和类型发生了变化\nx = torch.randn_like(x, dtype=torch.float)\nx\n\n# 获得张量的size，返回值为tuple\nx.size()\n```\n\n* ### 操作\n\n```python\n#加法操作\ny = torch.rand(5, 3)\nx + y\n\ntorch.add(x, y)\n\n# 提供输出Tensor作为参数\nresult = torch.empty(5, 3)\ntorch.add(x, y, out=result)\nresult\n\n# 替换，将x加到y\ny.add_(x)\ny\n```\n\n任何以下划线结尾的操作都会用结果替换原变量\n\n可以使用与Numpy索引方式相同的操作来对张量进行操作\n\n```python\n# torch.view可以改变张量的维度和大小\nx = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8)  # size -1 从其他维度推断\n\nx.size(), y.size(), z.size()\n\n# 如果张量只有一个元素，使用 .item() 来得到 Python 数据类型的数值\nx = torch.randn(1)\n\nx, x.item()\n```\n\n> 官方文档：[torch — PyTorch 1.12 documentation](https://pytorch.org/docs/stable/torch.html)\n\n* ### NumPy转换\n\n```python\n# PyTorch张量转换为NumPy数组\na = torch.ones(5)\na\nb = a.numpy()\nb\n\n# 了解 NumPy 数组的值如何变化，a和b的数值都会加1\na.add_(1)\na, b\n\n# NumPy 数组转换成 PyTorch 张量时，可以使用 from_numpy 完成\nimport numpy as np\n\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\na, b\n```\n\n所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 NumPy 的转换\n\n* ### CUDA张量\n\nCUDA张量是能够再GPU设备在运算的张量。使用.to方法可以将Tensor移动到GPU设备中去\n\n```python\n# is_available 函数判断是否有 GPU 可以使用\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # torch.device 将张量移动到指定的设备中\n    y = torch.ones_like(x, device=device)  # 直接从 GPU 创建张量\n    x = x.to(device)                       # 或者直接使用 .to(\"cuda\") 将张量移动到 cuda 中\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))       # .to 也会对变量的类型做更改\n```\n\n## Autograd自动求导\n\n> PyTorch中所有神经网络的核心是autograd\n\n`autograd`为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行。\n\n`torch.Tensor` 是这个包的核心类。如果设置`.requires_grad`为`True`，那么将会追踪所有对于该张量的操作。当完成计算后通过调用`.backward()`会自动计算所有的梯度，这个张量的所有梯度将自动积累到`.grad`属性。这也就完成了自动求导的过程。\n\n要组织张量追踪历史记录，可以调用`.detach()`方法将其与计算历史记录分离。为了防止跟踪历史记录（和使用内存），可以将代码块包装在`with tirch.no_grad():`语句中。这一点在评估模型时特别有用，因为模型可能具有`requires_grad=True`的可训练参数，但是并不需要计算梯度。\n\n自动求导还有另一个重要的类`Function`。`Tensor`和`Function`互相连接并生成一个非循环图，存储了完整的计算历史。\n\n如果需要计算导数，可以在`Tensor`上调用`.backward()`。如果`Tensor`是一个标量（即它只包含一个元素数据）则不需要为`backward()`指定任何参数。但是如果他又多个元素，则需要指定一个`gradient`参数来匹配张量的形状。\n\n```python\n# 创建一个张量并设置 requires_grad=True 用来追踪他的计算历史\nx = torch.ones(2, 2, requires_grad=True)\nx\n\n# 对张量进行操作，也就是计算过程\ny = x + 2\ny\n\n# 结果 y 已经被计算出来了，所以，grad_fn 已经被自动生成了\ny.grad_fn\n\n# 然后，再对 y 进行操作\nz = y * y * 3\nout = z.mean()\n\nz, out\n\n# .requires_grad_( ... ) 可以改变现有张量的 requires_grad 属性。 如果没有指定的话，默认输入的 flag 是 False\na = torch.randn(2, 2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)\n```\n\n* ### 梯度\n\n通过反向传播打印对应结点的梯度，因为`out`是一个纯量Scalar，`out.backward()`等于`out.backward(torch.tensor(1))`\n\n```python\nout.backward()\n\n# 打印其梯度\nx.grad\n```\n\n关于Autograd的更多操作\n\n```python\nx = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\ny\n\ngradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\ny.backward(gradients)\n\nx.grad\n\n# 如果 .requires_grad=True 但是你又不希望进行 Autograd 的计算，那么可以将变量包裹在 with torch.no_grad() 中\nprint(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n    print((x ** 2).requires_grad)\n```\n\n> `autograd`和`Function`的官方文档：[Automatic differentiation package - torch.autograd — PyTorch 1.12 documentation](https://pytorch.org/docs/stable/autograd.html)\n\n## 神经网络\n\nPyTorch中，我们可以使用`torch.nn`来构建神经网络\n\n`torch.nn`依赖`autograd`来定义模型并求导。`nn.Module`中包含了构建神经网络所需的各个层和`forward(input)`方法，该方法返回神经网络的输出。\n\n​\t神经网络的典型训练过程如下\n\n1、定义包含可学习参数（权重）的神经网络模型\n\n2、在数据集上迭代\n\n3、通过神经网络处理输入\n\n4、计算损失\n\n5、将梯度反向传播回网络结点\n\n6、更新网络的参数，一般可以使用梯度下降等最优化方法\n\n​\tPyTorch的`nn.Conv2d()`详解，该类作为二维卷积的实现\n\n```python\nin_channels\t\t# 输入张量的channels数\nout_channels\t# 期望的四维输出张量的channels数\nkernel_size\t\t# 卷积核的大小，一般用5×5、3×3\nstride=1\t\t# 卷积核在图像窗口上每次平移的间隔，步长\npadding=0\t\t\n```\n\n","slug":"pytorch-use","published":1,"updated":"2024-06-05T09:03:03.809Z","comments":1,"layout":"post","photos":[],"_id":"clyfintty002z08jv5cdn2b0m","content":"<h2 id=\"PyTorch基础语法\"><a href=\"#PyTorch基础语法\" class=\"headerlink\" title=\"PyTorch基础语法\"></a>PyTorch基础语法</h2><p>Pytorch是Facebook主导开发的，基于Python的科学计算包，主要有一下两个特点：</p>\n<p>比NumPy更灵活，可以使用GPU的强大计算能力</p>\n<p>开源高效的深度学习研究平台</p>\n<ul>\n<li><h3 id=\"张量\"><a href=\"#张量\" class=\"headerlink\" title=\"张量\"></a>张量</h3><blockquote>\n<p>PyTorch中的Tensors可以使用GPU计算</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><br><span class=\"hljs-comment\"># 可以返回填充了未初始化数据的张量</span><br>torch.empty(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br><br><span class=\"hljs-comment\"># 创建一个随机初始化矩阵</span><br>torch.rand(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br><br><span class=\"hljs-comment\"># 创建一个0填充的矩阵，指定数据类型为long：</span><br>torch.zeros(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, dtype=torch.long)<br><br><span class=\"hljs-comment\"># 创建 Tensor 并使用现有数据初始化：</span><br>x = torch.tensor([<span class=\"hljs-number\">5.5</span>, <span class=\"hljs-number\">3</span>])<br>x<br><br><span class=\"hljs-comment\">#根据现有张量创建新张量。这些方法将重用输入张量的属性，除非设置新的值进行覆盖</span><br>x = x.new_ones(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, dtype=torch.double)  <span class=\"hljs-comment\"># new_* 方法来创建对象</span><br>x<br><br><span class=\"hljs-comment\"># 覆盖 dtype，对象的 size 是相同的，只是值和类型发生了变化</span><br>x = torch.randn_like(x, dtype=torch.<span class=\"hljs-built_in\">float</span>)<br>x<br><br><span class=\"hljs-comment\"># 获得张量的size，返回值为tuple</span><br>x.size()<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h3 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h3></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#加法操作</span><br>y = torch.rand(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>x + y<br><br>torch.add(x, y)<br><br><span class=\"hljs-comment\"># 提供输出Tensor作为参数</span><br>result = torch.empty(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>torch.add(x, y, out=result)<br>result<br><br><span class=\"hljs-comment\"># 替换，将x加到y</span><br>y.add_(x)<br>y<br></code></pre></td></tr></table></figure>\n<p>任何以下划线结尾的操作都会用结果替换原变量</p>\n<p>可以使用与Numpy索引方式相同的操作来对张量进行操作</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># torch.view可以改变张量的维度和大小</span><br>x = torch.randn(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">4</span>)<br>y = x.view(<span class=\"hljs-number\">16</span>)<br>z = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">8</span>)  <span class=\"hljs-comment\"># size -1 从其他维度推断</span><br><br>x.size(), y.size(), z.size()<br><br><span class=\"hljs-comment\"># 如果张量只有一个元素，使用 .item() 来得到 Python 数据类型的数值</span><br>x = torch.randn(<span class=\"hljs-number\">1</span>)<br><br>x, x.item()<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>官方文档：<a href=\"https://pytorch.org/docs/stable/torch.html\">torch — PyTorch 1.12 documentation</a></p>\n</blockquote>\n<ul>\n<li><h3 id=\"NumPy转换\"><a href=\"#NumPy转换\" class=\"headerlink\" title=\"NumPy转换\"></a>NumPy转换</h3></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># PyTorch张量转换为NumPy数组</span><br>a = torch.ones(<span class=\"hljs-number\">5</span>)<br>a<br>b = a.numpy()<br>b<br><br><span class=\"hljs-comment\"># 了解 NumPy 数组的值如何变化，a和b的数值都会加1</span><br>a.add_(<span class=\"hljs-number\">1</span>)<br>a, b<br><br><span class=\"hljs-comment\"># NumPy 数组转换成 PyTorch 张量时，可以使用 from_numpy 完成</span><br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><br>a = np.ones(<span class=\"hljs-number\">5</span>)<br>b = torch.from_numpy(a)<br>np.add(a, <span class=\"hljs-number\">1</span>, out=a)<br>a, b<br></code></pre></td></tr></table></figure>\n<p>所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 NumPy 的转换</p>\n<ul>\n<li><h3 id=\"CUDA张量\"><a href=\"#CUDA张量\" class=\"headerlink\" title=\"CUDA张量\"></a>CUDA张量</h3></li>\n</ul>\n<p>CUDA张量是能够再GPU设备在运算的张量。使用.to方法可以将Tensor移动到GPU设备中去</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># is_available 函数判断是否有 GPU 可以使用</span><br><span class=\"hljs-keyword\">if</span> torch.cuda.is_available():<br>    device = torch.device(<span class=\"hljs-string\">&quot;cuda&quot;</span>)          <span class=\"hljs-comment\"># torch.device 将张量移动到指定的设备中</span><br>    y = torch.ones_like(x, device=device)  <span class=\"hljs-comment\"># 直接从 GPU 创建张量</span><br>    x = x.to(device)                       <span class=\"hljs-comment\"># 或者直接使用 .to(&quot;cuda&quot;) 将张量移动到 cuda 中</span><br>    z = x + y<br>    <span class=\"hljs-built_in\">print</span>(z)<br>    <span class=\"hljs-built_in\">print</span>(z.to(<span class=\"hljs-string\">&quot;cpu&quot;</span>, torch.double))       <span class=\"hljs-comment\"># .to 也会对变量的类型做更改</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"Autograd自动求导\"><a href=\"#Autograd自动求导\" class=\"headerlink\" title=\"Autograd自动求导\"></a>Autograd自动求导</h2><blockquote>\n<p>PyTorch中所有神经网络的核心是autograd</p>\n</blockquote>\n<p><code>autograd</code>为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行。</p>\n<p><code>torch.Tensor</code> 是这个包的核心类。如果设置<code>.requires_grad</code>为<code>True</code>，那么将会追踪所有对于该张量的操作。当完成计算后通过调用<code>.backward()</code>会自动计算所有的梯度，这个张量的所有梯度将自动积累到<code>.grad</code>属性。这也就完成了自动求导的过程。</p>\n<p>要组织张量追踪历史记录，可以调用<code>.detach()</code>方法将其与计算历史记录分离。为了防止跟踪历史记录（和使用内存），可以将代码块包装在<code>with tirch.no_grad():</code>语句中。这一点在评估模型时特别有用，因为模型可能具有<code>requires_grad=True</code>的可训练参数，但是并不需要计算梯度。</p>\n<p>自动求导还有另一个重要的类<code>Function</code>。<code>Tensor</code>和<code>Function</code>互相连接并生成一个非循环图，存储了完整的计算历史。</p>\n<p>如果需要计算导数，可以在<code>Tensor</code>上调用<code>.backward()</code>。如果<code>Tensor</code>是一个标量（即它只包含一个元素数据）则不需要为<code>backward()</code>指定任何参数。但是如果他又多个元素，则需要指定一个<code>gradient</code>参数来匹配张量的形状。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个张量并设置 requires_grad=True 用来追踪他的计算历史</span><br>x = torch.ones(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>x<br><br><span class=\"hljs-comment\"># 对张量进行操作，也就是计算过程</span><br>y = x + <span class=\"hljs-number\">2</span><br>y<br><br><span class=\"hljs-comment\"># 结果 y 已经被计算出来了，所以，grad_fn 已经被自动生成了</span><br>y.grad_fn<br><br><span class=\"hljs-comment\"># 然后，再对 y 进行操作</span><br>z = y * y * <span class=\"hljs-number\">3</span><br>out = z.mean()<br><br>z, out<br><br><span class=\"hljs-comment\"># .requires_grad_( ... ) 可以改变现有张量的 requires_grad 属性。 如果没有指定的话，默认输入的 flag 是 False</span><br>a = torch.randn(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>a = ((a * <span class=\"hljs-number\">3</span>) / (a - <span class=\"hljs-number\">1</span>))<br><span class=\"hljs-built_in\">print</span>(a.requires_grad)<br>a.requires_grad_(<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-built_in\">print</span>(a.requires_grad)<br>b = (a * a).<span class=\"hljs-built_in\">sum</span>()<br><span class=\"hljs-built_in\">print</span>(b.grad_fn)<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h3 id=\"梯度\"><a href=\"#梯度\" class=\"headerlink\" title=\"梯度\"></a>梯度</h3></li>\n</ul>\n<p>通过反向传播打印对应结点的梯度，因为<code>out</code>是一个纯量Scalar，<code>out.backward()</code>等于<code>out.backward(torch.tensor(1))</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">out.backward()<br><br><span class=\"hljs-comment\"># 打印其梯度</span><br>x.grad<br></code></pre></td></tr></table></figure>\n<p>关于Autograd的更多操作</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = torch.randn(<span class=\"hljs-number\">3</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br><br>y = x * <span class=\"hljs-number\">2</span><br><span class=\"hljs-keyword\">while</span> y.data.norm() &lt; <span class=\"hljs-number\">1000</span>:<br>    y = y * <span class=\"hljs-number\">2</span><br><br>y<br><br>gradients = torch.tensor([<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">0.0001</span>], dtype=torch.<span class=\"hljs-built_in\">float</span>)<br>y.backward(gradients)<br><br>x.grad<br><br><span class=\"hljs-comment\"># 如果 .requires_grad=True 但是你又不希望进行 Autograd 的计算，那么可以将变量包裹在 with torch.no_grad() 中</span><br><span class=\"hljs-built_in\">print</span>(x.requires_grad)<br><span class=\"hljs-built_in\">print</span>((x ** <span class=\"hljs-number\">2</span>).requires_grad)<br><br><span class=\"hljs-keyword\">with</span> torch.no_grad():<br>    <span class=\"hljs-built_in\">print</span>((x ** <span class=\"hljs-number\">2</span>).requires_grad)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p><code>autograd</code>和<code>Function</code>的官方文档：<a href=\"https://pytorch.org/docs/stable/autograd.html\">Automatic differentiation package - torch.autograd — PyTorch 1.12 documentation</a></p>\n</blockquote>\n<h2 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h2><p>PyTorch中，我们可以使用<code>torch.nn</code>来构建神经网络</p>\n<p><code>torch.nn</code>依赖<code>autograd</code>来定义模型并求导。<code>nn.Module</code>中包含了构建神经网络所需的各个层和<code>forward(input)</code>方法，该方法返回神经网络的输出。</p>\n<p>​    神经网络的典型训练过程如下</p>\n<p>1、定义包含可学习参数（权重）的神经网络模型</p>\n<p>2、在数据集上迭代</p>\n<p>3、通过神经网络处理输入</p>\n<p>4、计算损失</p>\n<p>5、将梯度反向传播回网络结点</p>\n<p>6、更新网络的参数，一般可以使用梯度下降等最优化方法</p>\n<p>​    PyTorch的<code>nn.Conv2d()</code>详解，该类作为二维卷积的实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">in_channels\t\t<span class=\"hljs-comment\"># 输入张量的channels数</span><br>out_channels\t<span class=\"hljs-comment\"># 期望的四维输出张量的channels数</span><br>kernel_size\t\t<span class=\"hljs-comment\"># 卷积核的大小，一般用5×5、3×3</span><br>stride=<span class=\"hljs-number\">1</span>\t\t<span class=\"hljs-comment\"># 卷积核在图像窗口上每次平移的间隔，步长</span><br>padding=<span class=\"hljs-number\">0</span>\t\t<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"PyTorch基础语法\"><a href=\"#PyTorch基础语法\" class=\"headerlink\" title=\"PyTorch基础语法\"></a>PyTorch基础语法</h2><p>Pytorch是Facebook主导开发的，基于Python的科学计算包，主要有一下两个特点：</p>\n<p>比NumPy更灵活，可以使用GPU的强大计算能力</p>\n<p>开源高效的深度学习研究平台</p>\n<ul>\n<li><h3 id=\"张量\"><a href=\"#张量\" class=\"headerlink\" title=\"张量\"></a>张量</h3><blockquote>\n<p>PyTorch中的Tensors可以使用GPU计算</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><br><span class=\"hljs-comment\"># 可以返回填充了未初始化数据的张量</span><br>torch.empty(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br><br><span class=\"hljs-comment\"># 创建一个随机初始化矩阵</span><br>torch.rand(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br><br><span class=\"hljs-comment\"># 创建一个0填充的矩阵，指定数据类型为long：</span><br>torch.zeros(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, dtype=torch.long)<br><br><span class=\"hljs-comment\"># 创建 Tensor 并使用现有数据初始化：</span><br>x = torch.tensor([<span class=\"hljs-number\">5.5</span>, <span class=\"hljs-number\">3</span>])<br>x<br><br><span class=\"hljs-comment\">#根据现有张量创建新张量。这些方法将重用输入张量的属性，除非设置新的值进行覆盖</span><br>x = x.new_ones(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, dtype=torch.double)  <span class=\"hljs-comment\"># new_* 方法来创建对象</span><br>x<br><br><span class=\"hljs-comment\"># 覆盖 dtype，对象的 size 是相同的，只是值和类型发生了变化</span><br>x = torch.randn_like(x, dtype=torch.<span class=\"hljs-built_in\">float</span>)<br>x<br><br><span class=\"hljs-comment\"># 获得张量的size，返回值为tuple</span><br>x.size()<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h3 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h3></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#加法操作</span><br>y = torch.rand(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>x + y<br><br>torch.add(x, y)<br><br><span class=\"hljs-comment\"># 提供输出Tensor作为参数</span><br>result = torch.empty(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>)<br>torch.add(x, y, out=result)<br>result<br><br><span class=\"hljs-comment\"># 替换，将x加到y</span><br>y.add_(x)<br>y<br></code></pre></td></tr></table></figure>\n<p>任何以下划线结尾的操作都会用结果替换原变量</p>\n<p>可以使用与Numpy索引方式相同的操作来对张量进行操作</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># torch.view可以改变张量的维度和大小</span><br>x = torch.randn(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">4</span>)<br>y = x.view(<span class=\"hljs-number\">16</span>)<br>z = x.view(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">8</span>)  <span class=\"hljs-comment\"># size -1 从其他维度推断</span><br><br>x.size(), y.size(), z.size()<br><br><span class=\"hljs-comment\"># 如果张量只有一个元素，使用 .item() 来得到 Python 数据类型的数值</span><br>x = torch.randn(<span class=\"hljs-number\">1</span>)<br><br>x, x.item()<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p>官方文档：<a href=\"https://pytorch.org/docs/stable/torch.html\">torch — PyTorch 1.12 documentation</a></p>\n</blockquote>\n<ul>\n<li><h3 id=\"NumPy转换\"><a href=\"#NumPy转换\" class=\"headerlink\" title=\"NumPy转换\"></a>NumPy转换</h3></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># PyTorch张量转换为NumPy数组</span><br>a = torch.ones(<span class=\"hljs-number\">5</span>)<br>a<br>b = a.numpy()<br>b<br><br><span class=\"hljs-comment\"># 了解 NumPy 数组的值如何变化，a和b的数值都会加1</span><br>a.add_(<span class=\"hljs-number\">1</span>)<br>a, b<br><br><span class=\"hljs-comment\"># NumPy 数组转换成 PyTorch 张量时，可以使用 from_numpy 完成</span><br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><br>a = np.ones(<span class=\"hljs-number\">5</span>)<br>b = torch.from_numpy(a)<br>np.add(a, <span class=\"hljs-number\">1</span>, out=a)<br>a, b<br></code></pre></td></tr></table></figure>\n<p>所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 NumPy 的转换</p>\n<ul>\n<li><h3 id=\"CUDA张量\"><a href=\"#CUDA张量\" class=\"headerlink\" title=\"CUDA张量\"></a>CUDA张量</h3></li>\n</ul>\n<p>CUDA张量是能够再GPU设备在运算的张量。使用.to方法可以将Tensor移动到GPU设备中去</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># is_available 函数判断是否有 GPU 可以使用</span><br><span class=\"hljs-keyword\">if</span> torch.cuda.is_available():<br>    device = torch.device(<span class=\"hljs-string\">&quot;cuda&quot;</span>)          <span class=\"hljs-comment\"># torch.device 将张量移动到指定的设备中</span><br>    y = torch.ones_like(x, device=device)  <span class=\"hljs-comment\"># 直接从 GPU 创建张量</span><br>    x = x.to(device)                       <span class=\"hljs-comment\"># 或者直接使用 .to(&quot;cuda&quot;) 将张量移动到 cuda 中</span><br>    z = x + y<br>    <span class=\"hljs-built_in\">print</span>(z)<br>    <span class=\"hljs-built_in\">print</span>(z.to(<span class=\"hljs-string\">&quot;cpu&quot;</span>, torch.double))       <span class=\"hljs-comment\"># .to 也会对变量的类型做更改</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"Autograd自动求导\"><a href=\"#Autograd自动求导\" class=\"headerlink\" title=\"Autograd自动求导\"></a>Autograd自动求导</h2><blockquote>\n<p>PyTorch中所有神经网络的核心是autograd</p>\n</blockquote>\n<p><code>autograd</code>为张量上的所有操作提供了自动求导。它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行。</p>\n<p><code>torch.Tensor</code> 是这个包的核心类。如果设置<code>.requires_grad</code>为<code>True</code>，那么将会追踪所有对于该张量的操作。当完成计算后通过调用<code>.backward()</code>会自动计算所有的梯度，这个张量的所有梯度将自动积累到<code>.grad</code>属性。这也就完成了自动求导的过程。</p>\n<p>要组织张量追踪历史记录，可以调用<code>.detach()</code>方法将其与计算历史记录分离。为了防止跟踪历史记录（和使用内存），可以将代码块包装在<code>with tirch.no_grad():</code>语句中。这一点在评估模型时特别有用，因为模型可能具有<code>requires_grad=True</code>的可训练参数，但是并不需要计算梯度。</p>\n<p>自动求导还有另一个重要的类<code>Function</code>。<code>Tensor</code>和<code>Function</code>互相连接并生成一个非循环图，存储了完整的计算历史。</p>\n<p>如果需要计算导数，可以在<code>Tensor</code>上调用<code>.backward()</code>。如果<code>Tensor</code>是一个标量（即它只包含一个元素数据）则不需要为<code>backward()</code>指定任何参数。但是如果他又多个元素，则需要指定一个<code>gradient</code>参数来匹配张量的形状。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个张量并设置 requires_grad=True 用来追踪他的计算历史</span><br>x = torch.ones(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br>x<br><br><span class=\"hljs-comment\"># 对张量进行操作，也就是计算过程</span><br>y = x + <span class=\"hljs-number\">2</span><br>y<br><br><span class=\"hljs-comment\"># 结果 y 已经被计算出来了，所以，grad_fn 已经被自动生成了</span><br>y.grad_fn<br><br><span class=\"hljs-comment\"># 然后，再对 y 进行操作</span><br>z = y * y * <span class=\"hljs-number\">3</span><br>out = z.mean()<br><br>z, out<br><br><span class=\"hljs-comment\"># .requires_grad_( ... ) 可以改变现有张量的 requires_grad 属性。 如果没有指定的话，默认输入的 flag 是 False</span><br>a = torch.randn(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>a = ((a * <span class=\"hljs-number\">3</span>) / (a - <span class=\"hljs-number\">1</span>))<br><span class=\"hljs-built_in\">print</span>(a.requires_grad)<br>a.requires_grad_(<span class=\"hljs-literal\">True</span>)<br><span class=\"hljs-built_in\">print</span>(a.requires_grad)<br>b = (a * a).<span class=\"hljs-built_in\">sum</span>()<br><span class=\"hljs-built_in\">print</span>(b.grad_fn)<br></code></pre></td></tr></table></figure>\n<ul>\n<li><h3 id=\"梯度\"><a href=\"#梯度\" class=\"headerlink\" title=\"梯度\"></a>梯度</h3></li>\n</ul>\n<p>通过反向传播打印对应结点的梯度，因为<code>out</code>是一个纯量Scalar，<code>out.backward()</code>等于<code>out.backward(torch.tensor(1))</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">out.backward()<br><br><span class=\"hljs-comment\"># 打印其梯度</span><br>x.grad<br></code></pre></td></tr></table></figure>\n<p>关于Autograd的更多操作</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">x = torch.randn(<span class=\"hljs-number\">3</span>, requires_grad=<span class=\"hljs-literal\">True</span>)<br><br>y = x * <span class=\"hljs-number\">2</span><br><span class=\"hljs-keyword\">while</span> y.data.norm() &lt; <span class=\"hljs-number\">1000</span>:<br>    y = y * <span class=\"hljs-number\">2</span><br><br>y<br><br>gradients = torch.tensor([<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">0.0001</span>], dtype=torch.<span class=\"hljs-built_in\">float</span>)<br>y.backward(gradients)<br><br>x.grad<br><br><span class=\"hljs-comment\"># 如果 .requires_grad=True 但是你又不希望进行 Autograd 的计算，那么可以将变量包裹在 with torch.no_grad() 中</span><br><span class=\"hljs-built_in\">print</span>(x.requires_grad)<br><span class=\"hljs-built_in\">print</span>((x ** <span class=\"hljs-number\">2</span>).requires_grad)<br><br><span class=\"hljs-keyword\">with</span> torch.no_grad():<br>    <span class=\"hljs-built_in\">print</span>((x ** <span class=\"hljs-number\">2</span>).requires_grad)<br></code></pre></td></tr></table></figure>\n<blockquote>\n<p><code>autograd</code>和<code>Function</code>的官方文档：<a href=\"https://pytorch.org/docs/stable/autograd.html\">Automatic differentiation package - torch.autograd — PyTorch 1.12 documentation</a></p>\n</blockquote>\n<h2 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h2><p>PyTorch中，我们可以使用<code>torch.nn</code>来构建神经网络</p>\n<p><code>torch.nn</code>依赖<code>autograd</code>来定义模型并求导。<code>nn.Module</code>中包含了构建神经网络所需的各个层和<code>forward(input)</code>方法，该方法返回神经网络的输出。</p>\n<p>​    神经网络的典型训练过程如下</p>\n<p>1、定义包含可学习参数（权重）的神经网络模型</p>\n<p>2、在数据集上迭代</p>\n<p>3、通过神经网络处理输入</p>\n<p>4、计算损失</p>\n<p>5、将梯度反向传播回网络结点</p>\n<p>6、更新网络的参数，一般可以使用梯度下降等最优化方法</p>\n<p>​    PyTorch的<code>nn.Conv2d()</code>详解，该类作为二维卷积的实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">in_channels\t\t<span class=\"hljs-comment\"># 输入张量的channels数</span><br>out_channels\t<span class=\"hljs-comment\"># 期望的四维输出张量的channels数</span><br>kernel_size\t\t<span class=\"hljs-comment\"># 卷积核的大小，一般用5×5、3×3</span><br>stride=<span class=\"hljs-number\">1</span>\t\t<span class=\"hljs-comment\"># 卷积核在图像窗口上每次平移的间隔，步长</span><br>padding=<span class=\"hljs-number\">0</span>\t\t<br></code></pre></td></tr></table></figure>\n"},{"title":"常见的排序算法","date":"2024-02-21T08:53:53.000Z","cover":"/img/default_cover11.jpg","top_img":null,"_content":"## 排序算法\n\n> 输入：整数数组nums\n>\n> 输出： 按照升序排序\n\n```C++\n// 函数接口\nvector<int> sortArray(vector<int>& nums) {\n    \n    return nums;\n}\n```\n\n### 选择排序\n\n思想：每次选择数组当前数组中最小的元素，放置到数组当前未选定的最前的位置\n\n时间复杂度：n^2\n\n```C++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    \n    for(int i = 0; i < n-1; ++i){\n        for(int j = i+1; j < n; ++j){\n            if(nums[i] > nums[j]){\n                std::swap(nums[i], nums[j]);\n            }\n        }\n    }\n    return nums;\n}\n```\n\n\n\n### 冒泡排序\n\n思想：\n\n每次比较相邻的元素，如果前面的元素大于后面的元素，则进行交换\n\n当某一轮没有进行交换时，说明数组已经有序\n\n时间复杂度：n^2\n\n```c++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    // 冒泡排序\n    for(int i = 0; i < n; ++i){\n        bool flag = 0;\n        // 每一次最大的元素都能够沉到最下面\n        for(int j = 0; j < n-i-1; ++j){\n            if(nums[j] > nums[j+1]){\n                std::swap(nums[j], nums[j+1]);\n                flag = 1;\n            }\n        }\n        if(flag == 0)return nums;\n    }\n    return nums;\n}\n```\n\n\n\n### 插入排序\n\n思想：\n\n从前往后选择元素，插入到前面已经排序好的数组元素当中\n\n始终保证当前元素前半部分都是有序的，直到所有元素遍历完\n\n时间复杂度：n^2\n\n```c++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    // 插入排序\n    for(int i = 1; i < n; ++i){\n        for(int j = i-1; j >= 0; --j){\n            // 注意比较的是相邻的元素，而不是num[i]\n            if(nums[j+1] >= nums[j]){\n                break;\n            }\n            else{\n                std::swap(nums[j+1], nums[j]);\n            }\n        }\n    }\n    return nums;\n}\n```\n\n\n\n### 归并排序\n\n思想：分治法\n\n将长度为n的数组分为两个长度为n/2的数组\n\n继续分为长度为n/4的数组，最后分为长度为1的数组\n\n分别对长度为1的两两数组进行合并\n\n对长度为2的两两数组进行合并\n\n长度为4的两两数组进行合并\n\n最后对长度为n/2的数组进行合并得到的就是长度为n的有序数组\n\n**因为合并过程中依赖的小序列都是有序的，通过选择最小元素很容易合并**\n\n时间复杂度：nlog(n)\n\n```c++\nvoid merge(vector<int>& nums, int left, int mid, int right) {\n    int n1 = mid - left + 1;\n    int n2 = right - mid;\n\n    vector<int> L(n1), R(n2);\n    \n    for (int i = 0; i < n1; i++)\n        L[i] = nums[left + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = nums[mid + 1 + j];\n    \n    int i = 0, j = 0, k = left;\n    \n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            nums[k] = L[i];\n            i++;\n        } else {\n            nums[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n    \n    while (i < n1) {\n        nums[k] = L[i];\n        i++;\n        k++;\n    }\n    \n    while (j < n2) {\n        nums[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(vector<int>& nums, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid + 1, right);\n        merge(nums, left, mid, right);\n    }\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    mergeSort(nums, 0, nums.size() - 1);\n    return nums;\n}\n```\n\n\n\n### 快速排序\n\n思想：分治法，快排要注意要从right开始\n\n选择一个主元\n\n将小于主元的元素放在左边\n\n将大于主元的元素放在右边\n\n主元的位置则可以确定\n\n分别对主元左边的数组和右边的数组再次进行快速排序\n\n时间复杂度：nlog(n)\n\n```c++\nint partion(vector<int>& nums, int left, int right){\n    int value = nums[left];\n    int idx = left;\n    // left += 1; left不用+1，相等的情况已经考虑了\n    \n    while(left < right){\n        while(left < right && nums[right] >= value)right--;\n        nums[idx] = nums[right];\n        idx = right;\n        while(left < right && nums[left] <= value)left++;\n        nums[idx] = nums[left];\n        idx = left;\n    }\n    nums[idx] = value;\n    return left;\n}\n    \nvoid quicksort(vector<int>& nums, int left, int right){\n    if(left >= right)return;\n    \n    int mid = partion(nums, left, right);\n    quicksort(nums, left, mid - 1);\n    quicksort(nums, mid+1, right);\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    quicksort(nums, 0, nums.size() - 1);\n    return nums;\n}\n```\n\n\n\n### 堆排序\n\n思想：\n\n将数组看成一棵完全二叉树，按照数组中的元素建立大顶堆\n\n交换堆顶元素和当前最末端元素，此时最大的元素到了数组尾部，锁定位置\n\n对当前堆进行更新\n\n时间复杂度：nlg(n)\n\n> 建堆时间为lg(n)\n>\n> 取出元素为1，更新堆为lg(n)\n\n```c++\nvoid heapify(vector<int>& nums, int n, int i) {\n    int largest = i;  // 初始化最大值为当前节点\n    int left = 2 * i + 1;  // 左孩子节点的索引为 2*i + 1\n    int right = 2 * i + 2;  // 右孩子节点的索引为 2*i + 2\n\n    // 如果左孩子节点比当前节点大\n    if (left < n && nums[left] > nums[largest])\n        largest = left;\n\n    // 如果右孩子节点比当前最大值大\n    if (right < n && nums[right] > nums[largest])\n        largest = right;\n\n    // 如果最大值不是当前节点\n    if (largest != i) {\n        // 交换当前节点和最大值节点的值\n        swap(nums[i], nums[largest]);\n\n        // 递归地对受影响的子树进行堆化\n        heapify(nums, n, largest);\n    }\n}\n\nvoid make_heap(vector<int>& nums) {\n    int n = nums.size();\n\n    // 构建堆（重新排列数组）\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(nums, n, i);\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    make_heap(nums);\n\n    // 逐个从堆中提取元素\n    for (int i = nums.size() - 1; i > 0; i--) {\n        // 将当前根节点移动到末尾\n        swap(nums[0], nums[i]);\n\n        // 对减小后的堆进行堆化\n        heapify(nums, i, 0);\n    }\n    return nums;\n}\n\n```\n\n\n\n### 希尔排序\n\n思想：\n\n使用一定的间隔（数组长度的一半）对数组进行分组，然后对每个分组进行插入排序\n\n随着排序的进行，间隔逐步减小，直到间隔为1，最终完成排序\n\n时间复杂度：n^1.3\n\n设置\n\n```c++\nvoid shellSort(vector<int>& arr) {\n    int n = arr.size();\n\n    // 初始化间隔gap为数组长度的一半，然后逐步缩小间隔直至为1\n    for (int gap = n / 2; gap > 0; gap /= 2) {\n        // 对每个间隔进行插入排序\n        for (int i = gap; i < n; i++) {\n            int temp = arr[i];\n            int j;\n\n            // 将arr[i]插入到正确的位置\n            for (j = i; j >= gap && arr[j - gap] > temp; j -= gap) {\n                arr[j] = arr[j - gap];\n            }\n            arr[j] = temp;\n        }\n    }\n}\nvector<int> sortArray(vector<int>& nums) {\n    shellSort(nums);\n    return nums;\n}\n```\n\n\n\n### 计数排序\n\n时间复杂度：n+k，k为当前数组中的最大值\n\n> 如果有负数还需要进行另外处理\n\n```c++\nstd::vector<int> countingSort(std::vector<int>& nums) {\n    // 找到数组中的最大值\n    int max_num = *std::max_element(nums.begin(), nums.end());\n\n    // 创建计数数组，并初始化为0\n    std::vector<int> count(max_num + 1, 0);\n\n    // 统计每个元素出现的次数\n    for (int num : nums) {\n        count[num]++;\n    }\n\n    // 根据计数数组重建排序后的数组\n    std::vector<int> sortedArray(nums.size());\n    int index = 0;\n    for (int i = 0; i <= max_num; ++i) {\n        while (count[i] > 0) {\n            sortedArray[index++] = i;\n            count[i]--;\n        }\n    }\n\n    return sortedArray;\n}\nvector<int> sortArray(vector<int>& nums) {\n    return countingSort(nums);\n}\n```\n\n","source":"_posts/sort-algrithon.md","raw":"---\ntitle: 常见的排序算法\ntags: [排序, 算法, 选择排序, 冒泡排序, 插入排序, 归并排序, 快速排序, 堆排序, 计数排序]\ncategories: 算法实践\ndate: 2024-02-21 16:53:53\ncover:\ntop_img:\n---\n## 排序算法\n\n> 输入：整数数组nums\n>\n> 输出： 按照升序排序\n\n```C++\n// 函数接口\nvector<int> sortArray(vector<int>& nums) {\n    \n    return nums;\n}\n```\n\n### 选择排序\n\n思想：每次选择数组当前数组中最小的元素，放置到数组当前未选定的最前的位置\n\n时间复杂度：n^2\n\n```C++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    \n    for(int i = 0; i < n-1; ++i){\n        for(int j = i+1; j < n; ++j){\n            if(nums[i] > nums[j]){\n                std::swap(nums[i], nums[j]);\n            }\n        }\n    }\n    return nums;\n}\n```\n\n\n\n### 冒泡排序\n\n思想：\n\n每次比较相邻的元素，如果前面的元素大于后面的元素，则进行交换\n\n当某一轮没有进行交换时，说明数组已经有序\n\n时间复杂度：n^2\n\n```c++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    // 冒泡排序\n    for(int i = 0; i < n; ++i){\n        bool flag = 0;\n        // 每一次最大的元素都能够沉到最下面\n        for(int j = 0; j < n-i-1; ++j){\n            if(nums[j] > nums[j+1]){\n                std::swap(nums[j], nums[j+1]);\n                flag = 1;\n            }\n        }\n        if(flag == 0)return nums;\n    }\n    return nums;\n}\n```\n\n\n\n### 插入排序\n\n思想：\n\n从前往后选择元素，插入到前面已经排序好的数组元素当中\n\n始终保证当前元素前半部分都是有序的，直到所有元素遍历完\n\n时间复杂度：n^2\n\n```c++\nvector<int> sortArray(vector<int>& nums) {\n    int n = nums.size();\n    // 插入排序\n    for(int i = 1; i < n; ++i){\n        for(int j = i-1; j >= 0; --j){\n            // 注意比较的是相邻的元素，而不是num[i]\n            if(nums[j+1] >= nums[j]){\n                break;\n            }\n            else{\n                std::swap(nums[j+1], nums[j]);\n            }\n        }\n    }\n    return nums;\n}\n```\n\n\n\n### 归并排序\n\n思想：分治法\n\n将长度为n的数组分为两个长度为n/2的数组\n\n继续分为长度为n/4的数组，最后分为长度为1的数组\n\n分别对长度为1的两两数组进行合并\n\n对长度为2的两两数组进行合并\n\n长度为4的两两数组进行合并\n\n最后对长度为n/2的数组进行合并得到的就是长度为n的有序数组\n\n**因为合并过程中依赖的小序列都是有序的，通过选择最小元素很容易合并**\n\n时间复杂度：nlog(n)\n\n```c++\nvoid merge(vector<int>& nums, int left, int mid, int right) {\n    int n1 = mid - left + 1;\n    int n2 = right - mid;\n\n    vector<int> L(n1), R(n2);\n    \n    for (int i = 0; i < n1; i++)\n        L[i] = nums[left + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = nums[mid + 1 + j];\n    \n    int i = 0, j = 0, k = left;\n    \n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            nums[k] = L[i];\n            i++;\n        } else {\n            nums[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n    \n    while (i < n1) {\n        nums[k] = L[i];\n        i++;\n        k++;\n    }\n    \n    while (j < n2) {\n        nums[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(vector<int>& nums, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n        mergeSort(nums, left, mid);\n        mergeSort(nums, mid + 1, right);\n        merge(nums, left, mid, right);\n    }\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    mergeSort(nums, 0, nums.size() - 1);\n    return nums;\n}\n```\n\n\n\n### 快速排序\n\n思想：分治法，快排要注意要从right开始\n\n选择一个主元\n\n将小于主元的元素放在左边\n\n将大于主元的元素放在右边\n\n主元的位置则可以确定\n\n分别对主元左边的数组和右边的数组再次进行快速排序\n\n时间复杂度：nlog(n)\n\n```c++\nint partion(vector<int>& nums, int left, int right){\n    int value = nums[left];\n    int idx = left;\n    // left += 1; left不用+1，相等的情况已经考虑了\n    \n    while(left < right){\n        while(left < right && nums[right] >= value)right--;\n        nums[idx] = nums[right];\n        idx = right;\n        while(left < right && nums[left] <= value)left++;\n        nums[idx] = nums[left];\n        idx = left;\n    }\n    nums[idx] = value;\n    return left;\n}\n    \nvoid quicksort(vector<int>& nums, int left, int right){\n    if(left >= right)return;\n    \n    int mid = partion(nums, left, right);\n    quicksort(nums, left, mid - 1);\n    quicksort(nums, mid+1, right);\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    quicksort(nums, 0, nums.size() - 1);\n    return nums;\n}\n```\n\n\n\n### 堆排序\n\n思想：\n\n将数组看成一棵完全二叉树，按照数组中的元素建立大顶堆\n\n交换堆顶元素和当前最末端元素，此时最大的元素到了数组尾部，锁定位置\n\n对当前堆进行更新\n\n时间复杂度：nlg(n)\n\n> 建堆时间为lg(n)\n>\n> 取出元素为1，更新堆为lg(n)\n\n```c++\nvoid heapify(vector<int>& nums, int n, int i) {\n    int largest = i;  // 初始化最大值为当前节点\n    int left = 2 * i + 1;  // 左孩子节点的索引为 2*i + 1\n    int right = 2 * i + 2;  // 右孩子节点的索引为 2*i + 2\n\n    // 如果左孩子节点比当前节点大\n    if (left < n && nums[left] > nums[largest])\n        largest = left;\n\n    // 如果右孩子节点比当前最大值大\n    if (right < n && nums[right] > nums[largest])\n        largest = right;\n\n    // 如果最大值不是当前节点\n    if (largest != i) {\n        // 交换当前节点和最大值节点的值\n        swap(nums[i], nums[largest]);\n\n        // 递归地对受影响的子树进行堆化\n        heapify(nums, n, largest);\n    }\n}\n\nvoid make_heap(vector<int>& nums) {\n    int n = nums.size();\n\n    // 构建堆（重新排列数组）\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(nums, n, i);\n}\n\nvector<int> sortArray(vector<int>& nums) {\n    make_heap(nums);\n\n    // 逐个从堆中提取元素\n    for (int i = nums.size() - 1; i > 0; i--) {\n        // 将当前根节点移动到末尾\n        swap(nums[0], nums[i]);\n\n        // 对减小后的堆进行堆化\n        heapify(nums, i, 0);\n    }\n    return nums;\n}\n\n```\n\n\n\n### 希尔排序\n\n思想：\n\n使用一定的间隔（数组长度的一半）对数组进行分组，然后对每个分组进行插入排序\n\n随着排序的进行，间隔逐步减小，直到间隔为1，最终完成排序\n\n时间复杂度：n^1.3\n\n设置\n\n```c++\nvoid shellSort(vector<int>& arr) {\n    int n = arr.size();\n\n    // 初始化间隔gap为数组长度的一半，然后逐步缩小间隔直至为1\n    for (int gap = n / 2; gap > 0; gap /= 2) {\n        // 对每个间隔进行插入排序\n        for (int i = gap; i < n; i++) {\n            int temp = arr[i];\n            int j;\n\n            // 将arr[i]插入到正确的位置\n            for (j = i; j >= gap && arr[j - gap] > temp; j -= gap) {\n                arr[j] = arr[j - gap];\n            }\n            arr[j] = temp;\n        }\n    }\n}\nvector<int> sortArray(vector<int>& nums) {\n    shellSort(nums);\n    return nums;\n}\n```\n\n\n\n### 计数排序\n\n时间复杂度：n+k，k为当前数组中的最大值\n\n> 如果有负数还需要进行另外处理\n\n```c++\nstd::vector<int> countingSort(std::vector<int>& nums) {\n    // 找到数组中的最大值\n    int max_num = *std::max_element(nums.begin(), nums.end());\n\n    // 创建计数数组，并初始化为0\n    std::vector<int> count(max_num + 1, 0);\n\n    // 统计每个元素出现的次数\n    for (int num : nums) {\n        count[num]++;\n    }\n\n    // 根据计数数组重建排序后的数组\n    std::vector<int> sortedArray(nums.size());\n    int index = 0;\n    for (int i = 0; i <= max_num; ++i) {\n        while (count[i] > 0) {\n            sortedArray[index++] = i;\n            count[i]--;\n        }\n    }\n\n    return sortedArray;\n}\nvector<int> sortArray(vector<int>& nums) {\n    return countingSort(nums);\n}\n```\n\n","slug":"sort-algrithon","published":1,"updated":"2024-06-05T09:03:03.809Z","comments":1,"layout":"post","photos":[],"_id":"clyfintty003208jv557e29th","content":"<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><blockquote>\n<p>输入：整数数组nums</p>\n<p>输出： 按照升序排序</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 函数接口</span><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h3><p>思想：每次选择数组当前数组中最小的元素，放置到数组当前未选定的最前的位置</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n<span class=\"hljs-number\">-1</span>; ++i)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = i+<span class=\"hljs-number\">1</span>; j &lt; n; ++j)&#123;<br>            <span class=\"hljs-keyword\">if</span>(nums[i] &gt; nums[j])&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[i], nums[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h3><p>思想：</p>\n<p>每次比较相邻的元素，如果前面的元素大于后面的元素，则进行交换</p>\n<p>当某一轮没有进行交换时，说明数组已经有序</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <span class=\"hljs-comment\">// 冒泡排序</span><br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n; ++i)&#123;<br>        <span class=\"hljs-type\">bool</span> flag = <span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-comment\">// 每一次最大的元素都能够沉到最下面</span><br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; n-i<span class=\"hljs-number\">-1</span>; ++j)&#123;<br>            <span class=\"hljs-keyword\">if</span>(nums[j] &gt; nums[j+<span class=\"hljs-number\">1</span>])&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[j], nums[j+<span class=\"hljs-number\">1</span>]);<br>                flag = <span class=\"hljs-number\">1</span>;<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">if</span>(flag == <span class=\"hljs-number\">0</span>)<span class=\"hljs-keyword\">return</span> nums;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h3><p>思想：</p>\n<p>从前往后选择元素，插入到前面已经排序好的数组元素当中</p>\n<p>始终保证当前元素前半部分都是有序的，直到所有元素遍历完</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <span class=\"hljs-comment\">// 插入排序</span><br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt; n; ++i)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = i<span class=\"hljs-number\">-1</span>; j &gt;= <span class=\"hljs-number\">0</span>; --j)&#123;<br>            <span class=\"hljs-comment\">// 注意比较的是相邻的元素，而不是num[i]</span><br>            <span class=\"hljs-keyword\">if</span>(nums[j+<span class=\"hljs-number\">1</span>] &gt;= nums[j])&#123;<br>                <span class=\"hljs-keyword\">break</span>;<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span>&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[j+<span class=\"hljs-number\">1</span>], nums[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h3><p>思想：分治法</p>\n<p>将长度为n的数组分为两个长度为n/2的数组</p>\n<p>继续分为长度为n/4的数组，最后分为长度为1的数组</p>\n<p>分别对长度为1的两两数组进行合并</p>\n<p>对长度为2的两两数组进行合并</p>\n<p>长度为4的两两数组进行合并</p>\n<p>最后对长度为n/2的数组进行合并得到的就是长度为n的有序数组</p>\n<p><strong>因为合并过程中依赖的小序列都是有序的，通过选择最小元素很容易合并</strong></p>\n<p>时间复杂度：nlog(n)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">merge</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> mid, <span class=\"hljs-type\">int</span> right)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n1 = mid - left + <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-type\">int</span> n2 = right - mid;<br><br>    <span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">L</span><span class=\"hljs-params\">(n1)</span>, <span class=\"hljs-title\">R</span><span class=\"hljs-params\">(n2)</span></span>;<br>    <br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n1; i++)<br>        L[i] = nums[left + i];<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; n2; j++)<br>        R[j] = nums[mid + <span class=\"hljs-number\">1</span> + j];<br>    <br>    <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>, j = <span class=\"hljs-number\">0</span>, k = left;<br>    <br>    <span class=\"hljs-keyword\">while</span> (i &lt; n1 &amp;&amp; j &lt; n2) &#123;<br>        <span class=\"hljs-keyword\">if</span> (L[i] &lt;= R[j]) &#123;<br>            nums[k] = L[i];<br>            i++;<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>            nums[k] = R[j];<br>            j++;<br>        &#125;<br>        k++;<br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">while</span> (i &lt; n1) &#123;<br>        nums[k] = L[i];<br>        i++;<br>        k++;<br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">while</span> (j &lt; n2) &#123;<br>        nums[k] = R[j];<br>        j++;<br>        k++;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">mergeSort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (left &lt; right) &#123;<br>        <span class=\"hljs-type\">int</span> mid = left + (right - left) / <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-built_in\">mergeSort</span>(nums, left, mid);<br>        <span class=\"hljs-built_in\">mergeSort</span>(nums, mid + <span class=\"hljs-number\">1</span>, right);<br>        <span class=\"hljs-built_in\">merge</span>(nums, left, mid, right);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">mergeSort</span>(nums, <span class=\"hljs-number\">0</span>, nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h3><p>思想：分治法，快排要注意要从right开始</p>\n<p>选择一个主元</p>\n<p>将小于主元的元素放在左边</p>\n<p>将大于主元的元素放在右边</p>\n<p>主元的位置则可以确定</p>\n<p>分别对主元左边的数组和右边的数组再次进行快速排序</p>\n<p>时间复杂度：nlog(n)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">partion</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> value = nums[left];<br>    <span class=\"hljs-type\">int</span> idx = left;<br>    <span class=\"hljs-comment\">// left += 1; left不用+1，相等的情况已经考虑了</span><br>    <br>    <span class=\"hljs-keyword\">while</span>(left &lt; right)&#123;<br>        <span class=\"hljs-keyword\">while</span>(left &lt; right &amp;&amp; nums[right] &gt;= value)right--;<br>        nums[idx] = nums[right];<br>        idx = right;<br>        <span class=\"hljs-keyword\">while</span>(left &lt; right &amp;&amp; nums[left] &lt;= value)left++;<br>        nums[idx] = nums[left];<br>        idx = left;<br>    &#125;<br>    nums[idx] = value;<br>    <span class=\"hljs-keyword\">return</span> left;<br>&#125;<br>    <br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">quicksort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span></span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(left &gt;= right)<span class=\"hljs-keyword\">return</span>;<br>    <br>    <span class=\"hljs-type\">int</span> mid = <span class=\"hljs-built_in\">partion</span>(nums, left, right);<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, left, mid - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, mid+<span class=\"hljs-number\">1</span>, right);<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, <span class=\"hljs-number\">0</span>, nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h3><p>思想：</p>\n<p>将数组看成一棵完全二叉树，按照数组中的元素建立大顶堆</p>\n<p>交换堆顶元素和当前最末端元素，此时最大的元素到了数组尾部，锁定位置</p>\n<p>对当前堆进行更新</p>\n<p>时间复杂度：nlg(n)</p>\n<blockquote>\n<p>建堆时间为lg(n)</p>\n<p>取出元素为1，更新堆为lg(n)</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">heapify</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> n, <span class=\"hljs-type\">int</span> i)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> largest = i;  <span class=\"hljs-comment\">// 初始化最大值为当前节点</span><br>    <span class=\"hljs-type\">int</span> left = <span class=\"hljs-number\">2</span> * i + <span class=\"hljs-number\">1</span>;  <span class=\"hljs-comment\">// 左孩子节点的索引为 2*i + 1</span><br>    <span class=\"hljs-type\">int</span> right = <span class=\"hljs-number\">2</span> * i + <span class=\"hljs-number\">2</span>;  <span class=\"hljs-comment\">// 右孩子节点的索引为 2*i + 2</span><br><br>    <span class=\"hljs-comment\">// 如果左孩子节点比当前节点大</span><br>    <span class=\"hljs-keyword\">if</span> (left &lt; n &amp;&amp; nums[left] &gt; nums[largest])<br>        largest = left;<br><br>    <span class=\"hljs-comment\">// 如果右孩子节点比当前最大值大</span><br>    <span class=\"hljs-keyword\">if</span> (right &lt; n &amp;&amp; nums[right] &gt; nums[largest])<br>        largest = right;<br><br>    <span class=\"hljs-comment\">// 如果最大值不是当前节点</span><br>    <span class=\"hljs-keyword\">if</span> (largest != i) &#123;<br>        <span class=\"hljs-comment\">// 交换当前节点和最大值节点的值</span><br>        <span class=\"hljs-built_in\">swap</span>(nums[i], nums[largest]);<br><br>        <span class=\"hljs-comment\">// 递归地对受影响的子树进行堆化</span><br>        <span class=\"hljs-built_in\">heapify</span>(nums, n, largest);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">make_heap</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br><br>    <span class=\"hljs-comment\">// 构建堆（重新排列数组）</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = n / <span class=\"hljs-number\">2</span> - <span class=\"hljs-number\">1</span>; i &gt;= <span class=\"hljs-number\">0</span>; i--)<br>        <span class=\"hljs-built_in\">heapify</span>(nums, n, i);<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">make_heap</span>(nums);<br><br>    <span class=\"hljs-comment\">// 逐个从堆中提取元素</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; i &gt; <span class=\"hljs-number\">0</span>; i--) &#123;<br>        <span class=\"hljs-comment\">// 将当前根节点移动到末尾</span><br>        <span class=\"hljs-built_in\">swap</span>(nums[<span class=\"hljs-number\">0</span>], nums[i]);<br><br>        <span class=\"hljs-comment\">// 对减小后的堆进行堆化</span><br>        <span class=\"hljs-built_in\">heapify</span>(nums, i, <span class=\"hljs-number\">0</span>);<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h3><p>思想：</p>\n<p>使用一定的间隔（数组长度的一半）对数组进行分组，然后对每个分组进行插入排序</p>\n<p>随着排序的进行，间隔逐步减小，直到间隔为1，最终完成排序</p>\n<p>时间复杂度：n^1.3</p>\n<p>设置</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">shellSort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; arr)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = arr.<span class=\"hljs-built_in\">size</span>();<br><br>    <span class=\"hljs-comment\">// 初始化间隔gap为数组长度的一半，然后逐步缩小间隔直至为1</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> gap = n / <span class=\"hljs-number\">2</span>; gap &gt; <span class=\"hljs-number\">0</span>; gap /= <span class=\"hljs-number\">2</span>) &#123;<br>        <span class=\"hljs-comment\">// 对每个间隔进行插入排序</span><br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = gap; i &lt; n; i++) &#123;<br>            <span class=\"hljs-type\">int</span> temp = arr[i];<br>            <span class=\"hljs-type\">int</span> j;<br><br>            <span class=\"hljs-comment\">// 将arr[i]插入到正确的位置</span><br>            <span class=\"hljs-keyword\">for</span> (j = i; j &gt;= gap &amp;&amp; arr[j - gap] &gt; temp; j -= gap) &#123;<br>                arr[j] = arr[j - gap];<br>            &#125;<br>            arr[j] = temp;<br>        &#125;<br>    &#125;<br>&#125;<br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">shellSort</span>(nums);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"计数排序\"><a href=\"#计数排序\" class=\"headerlink\" title=\"计数排序\"></a>计数排序</h3><p>时间复杂度：n+k，k为当前数组中的最大值</p>\n<blockquote>\n<p>如果有负数还需要进行另外处理</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">countingSort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 找到数组中的最大值</span><br>    <span class=\"hljs-type\">int</span> max_num = *std::<span class=\"hljs-built_in\">max_element</span>(nums.<span class=\"hljs-built_in\">begin</span>(), nums.<span class=\"hljs-built_in\">end</span>());<br><br>    <span class=\"hljs-comment\">// 创建计数数组，并初始化为0</span><br>    <span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">count</span><span class=\"hljs-params\">(max_num + <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>)</span></span>;<br><br>    <span class=\"hljs-comment\">// 统计每个元素出现的次数</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> num : nums) &#123;<br>        count[num]++;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 根据计数数组重建排序后的数组</span><br>    <span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortedArray</span><span class=\"hljs-params\">(nums.size())</span></span>;<br>    <span class=\"hljs-type\">int</span> index = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= max_num; ++i) &#123;<br>        <span class=\"hljs-keyword\">while</span> (count[i] &gt; <span class=\"hljs-number\">0</span>) &#123;<br>            sortedArray[index++] = i;<br>            count[i]--;<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">return</span> sortedArray;<br>&#125;<br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">countingSort</span>(nums);<br>&#125;<br></code></pre></td></tr></table></figure>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><blockquote>\n<p>输入：整数数组nums</p>\n<p>输出： 按照升序排序</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-comment\">// 函数接口</span><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h3><p>思想：每次选择数组当前数组中最小的元素，放置到数组当前未选定的最前的位置</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n<span class=\"hljs-number\">-1</span>; ++i)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = i+<span class=\"hljs-number\">1</span>; j &lt; n; ++j)&#123;<br>            <span class=\"hljs-keyword\">if</span>(nums[i] &gt; nums[j])&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[i], nums[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h3><p>思想：</p>\n<p>每次比较相邻的元素，如果前面的元素大于后面的元素，则进行交换</p>\n<p>当某一轮没有进行交换时，说明数组已经有序</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <span class=\"hljs-comment\">// 冒泡排序</span><br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n; ++i)&#123;<br>        <span class=\"hljs-type\">bool</span> flag = <span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-comment\">// 每一次最大的元素都能够沉到最下面</span><br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; n-i<span class=\"hljs-number\">-1</span>; ++j)&#123;<br>            <span class=\"hljs-keyword\">if</span>(nums[j] &gt; nums[j+<span class=\"hljs-number\">1</span>])&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[j], nums[j+<span class=\"hljs-number\">1</span>]);<br>                flag = <span class=\"hljs-number\">1</span>;<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">if</span>(flag == <span class=\"hljs-number\">0</span>)<span class=\"hljs-keyword\">return</span> nums;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h3><p>思想：</p>\n<p>从前往后选择元素，插入到前面已经排序好的数组元素当中</p>\n<p>始终保证当前元素前半部分都是有序的，直到所有元素遍历完</p>\n<p>时间复杂度：n^2</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br>    <span class=\"hljs-comment\">// 插入排序</span><br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt; n; ++i)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = i<span class=\"hljs-number\">-1</span>; j &gt;= <span class=\"hljs-number\">0</span>; --j)&#123;<br>            <span class=\"hljs-comment\">// 注意比较的是相邻的元素，而不是num[i]</span><br>            <span class=\"hljs-keyword\">if</span>(nums[j+<span class=\"hljs-number\">1</span>] &gt;= nums[j])&#123;<br>                <span class=\"hljs-keyword\">break</span>;<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span>&#123;<br>                std::<span class=\"hljs-built_in\">swap</span>(nums[j+<span class=\"hljs-number\">1</span>], nums[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h3><p>思想：分治法</p>\n<p>将长度为n的数组分为两个长度为n/2的数组</p>\n<p>继续分为长度为n/4的数组，最后分为长度为1的数组</p>\n<p>分别对长度为1的两两数组进行合并</p>\n<p>对长度为2的两两数组进行合并</p>\n<p>长度为4的两两数组进行合并</p>\n<p>最后对长度为n/2的数组进行合并得到的就是长度为n的有序数组</p>\n<p><strong>因为合并过程中依赖的小序列都是有序的，通过选择最小元素很容易合并</strong></p>\n<p>时间复杂度：nlog(n)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">merge</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> mid, <span class=\"hljs-type\">int</span> right)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n1 = mid - left + <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-type\">int</span> n2 = right - mid;<br><br>    <span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">L</span><span class=\"hljs-params\">(n1)</span>, <span class=\"hljs-title\">R</span><span class=\"hljs-params\">(n2)</span></span>;<br>    <br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n1; i++)<br>        L[i] = nums[left + i];<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; n2; j++)<br>        R[j] = nums[mid + <span class=\"hljs-number\">1</span> + j];<br>    <br>    <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>, j = <span class=\"hljs-number\">0</span>, k = left;<br>    <br>    <span class=\"hljs-keyword\">while</span> (i &lt; n1 &amp;&amp; j &lt; n2) &#123;<br>        <span class=\"hljs-keyword\">if</span> (L[i] &lt;= R[j]) &#123;<br>            nums[k] = L[i];<br>            i++;<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>            nums[k] = R[j];<br>            j++;<br>        &#125;<br>        k++;<br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">while</span> (i &lt; n1) &#123;<br>        nums[k] = L[i];<br>        i++;<br>        k++;<br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">while</span> (j &lt; n2) &#123;<br>        nums[k] = R[j];<br>        j++;<br>        k++;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">mergeSort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (left &lt; right) &#123;<br>        <span class=\"hljs-type\">int</span> mid = left + (right - left) / <span class=\"hljs-number\">2</span>;<br>        <span class=\"hljs-built_in\">mergeSort</span>(nums, left, mid);<br>        <span class=\"hljs-built_in\">mergeSort</span>(nums, mid + <span class=\"hljs-number\">1</span>, right);<br>        <span class=\"hljs-built_in\">merge</span>(nums, left, mid, right);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">mergeSort</span>(nums, <span class=\"hljs-number\">0</span>, nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h3><p>思想：分治法，快排要注意要从right开始</p>\n<p>选择一个主元</p>\n<p>将小于主元的元素放在左边</p>\n<p>将大于主元的元素放在右边</p>\n<p>主元的位置则可以确定</p>\n<p>分别对主元左边的数组和右边的数组再次进行快速排序</p>\n<p>时间复杂度：nlog(n)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">partion</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> value = nums[left];<br>    <span class=\"hljs-type\">int</span> idx = left;<br>    <span class=\"hljs-comment\">// left += 1; left不用+1，相等的情况已经考虑了</span><br>    <br>    <span class=\"hljs-keyword\">while</span>(left &lt; right)&#123;<br>        <span class=\"hljs-keyword\">while</span>(left &lt; right &amp;&amp; nums[right] &gt;= value)right--;<br>        nums[idx] = nums[right];<br>        idx = right;<br>        <span class=\"hljs-keyword\">while</span>(left &lt; right &amp;&amp; nums[left] &lt;= value)left++;<br>        nums[idx] = nums[left];<br>        idx = left;<br>    &#125;<br>    nums[idx] = value;<br>    <span class=\"hljs-keyword\">return</span> left;<br>&#125;<br>    <br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">quicksort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> left, <span class=\"hljs-type\">int</span> right)</span></span>&#123;<br>    <span class=\"hljs-keyword\">if</span>(left &gt;= right)<span class=\"hljs-keyword\">return</span>;<br>    <br>    <span class=\"hljs-type\">int</span> mid = <span class=\"hljs-built_in\">partion</span>(nums, left, right);<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, left, mid - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, mid+<span class=\"hljs-number\">1</span>, right);<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">quicksort</span>(nums, <span class=\"hljs-number\">0</span>, nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h3><p>思想：</p>\n<p>将数组看成一棵完全二叉树，按照数组中的元素建立大顶堆</p>\n<p>交换堆顶元素和当前最末端元素，此时最大的元素到了数组尾部，锁定位置</p>\n<p>对当前堆进行更新</p>\n<p>时间复杂度：nlg(n)</p>\n<blockquote>\n<p>建堆时间为lg(n)</p>\n<p>取出元素为1，更新堆为lg(n)</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">heapify</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums, <span class=\"hljs-type\">int</span> n, <span class=\"hljs-type\">int</span> i)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> largest = i;  <span class=\"hljs-comment\">// 初始化最大值为当前节点</span><br>    <span class=\"hljs-type\">int</span> left = <span class=\"hljs-number\">2</span> * i + <span class=\"hljs-number\">1</span>;  <span class=\"hljs-comment\">// 左孩子节点的索引为 2*i + 1</span><br>    <span class=\"hljs-type\">int</span> right = <span class=\"hljs-number\">2</span> * i + <span class=\"hljs-number\">2</span>;  <span class=\"hljs-comment\">// 右孩子节点的索引为 2*i + 2</span><br><br>    <span class=\"hljs-comment\">// 如果左孩子节点比当前节点大</span><br>    <span class=\"hljs-keyword\">if</span> (left &lt; n &amp;&amp; nums[left] &gt; nums[largest])<br>        largest = left;<br><br>    <span class=\"hljs-comment\">// 如果右孩子节点比当前最大值大</span><br>    <span class=\"hljs-keyword\">if</span> (right &lt; n &amp;&amp; nums[right] &gt; nums[largest])<br>        largest = right;<br><br>    <span class=\"hljs-comment\">// 如果最大值不是当前节点</span><br>    <span class=\"hljs-keyword\">if</span> (largest != i) &#123;<br>        <span class=\"hljs-comment\">// 交换当前节点和最大值节点的值</span><br>        <span class=\"hljs-built_in\">swap</span>(nums[i], nums[largest]);<br><br>        <span class=\"hljs-comment\">// 递归地对受影响的子树进行堆化</span><br>        <span class=\"hljs-built_in\">heapify</span>(nums, n, largest);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">make_heap</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = nums.<span class=\"hljs-built_in\">size</span>();<br><br>    <span class=\"hljs-comment\">// 构建堆（重新排列数组）</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = n / <span class=\"hljs-number\">2</span> - <span class=\"hljs-number\">1</span>; i &gt;= <span class=\"hljs-number\">0</span>; i--)<br>        <span class=\"hljs-built_in\">heapify</span>(nums, n, i);<br>&#125;<br><br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">make_heap</span>(nums);<br><br>    <span class=\"hljs-comment\">// 逐个从堆中提取元素</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = nums.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; i &gt; <span class=\"hljs-number\">0</span>; i--) &#123;<br>        <span class=\"hljs-comment\">// 将当前根节点移动到末尾</span><br>        <span class=\"hljs-built_in\">swap</span>(nums[<span class=\"hljs-number\">0</span>], nums[i]);<br><br>        <span class=\"hljs-comment\">// 对减小后的堆进行堆化</span><br>        <span class=\"hljs-built_in\">heapify</span>(nums, i, <span class=\"hljs-number\">0</span>);<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br><br></code></pre></td></tr></table></figure>\n<h3 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h3><p>思想：</p>\n<p>使用一定的间隔（数组长度的一半）对数组进行分组，然后对每个分组进行插入排序</p>\n<p>随着排序的进行，间隔逐步减小，直到间隔为1，最终完成排序</p>\n<p>时间复杂度：n^1.3</p>\n<p>设置</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">shellSort</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; arr)</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> n = arr.<span class=\"hljs-built_in\">size</span>();<br><br>    <span class=\"hljs-comment\">// 初始化间隔gap为数组长度的一半，然后逐步缩小间隔直至为1</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> gap = n / <span class=\"hljs-number\">2</span>; gap &gt; <span class=\"hljs-number\">0</span>; gap /= <span class=\"hljs-number\">2</span>) &#123;<br>        <span class=\"hljs-comment\">// 对每个间隔进行插入排序</span><br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = gap; i &lt; n; i++) &#123;<br>            <span class=\"hljs-type\">int</span> temp = arr[i];<br>            <span class=\"hljs-type\">int</span> j;<br><br>            <span class=\"hljs-comment\">// 将arr[i]插入到正确的位置</span><br>            <span class=\"hljs-keyword\">for</span> (j = i; j &gt;= gap &amp;&amp; arr[j - gap] &gt; temp; j -= gap) &#123;<br>                arr[j] = arr[j - gap];<br>            &#125;<br>            arr[j] = temp;<br>        &#125;<br>    &#125;<br>&#125;<br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">shellSort</span>(nums);<br>    <span class=\"hljs-keyword\">return</span> nums;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"计数排序\"><a href=\"#计数排序\" class=\"headerlink\" title=\"计数排序\"></a>计数排序</h3><p>时间复杂度：n+k，k为当前数组中的最大值</p>\n<blockquote>\n<p>如果有负数还需要进行另外处理</p>\n</blockquote>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">countingSort</span><span class=\"hljs-params\">(std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 找到数组中的最大值</span><br>    <span class=\"hljs-type\">int</span> max_num = *std::<span class=\"hljs-built_in\">max_element</span>(nums.<span class=\"hljs-built_in\">begin</span>(), nums.<span class=\"hljs-built_in\">end</span>());<br><br>    <span class=\"hljs-comment\">// 创建计数数组，并初始化为0</span><br>    <span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">count</span><span class=\"hljs-params\">(max_num + <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>)</span></span>;<br><br>    <span class=\"hljs-comment\">// 统计每个元素出现的次数</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> num : nums) &#123;<br>        count[num]++;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 根据计数数组重建排序后的数组</span><br>    <span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortedArray</span><span class=\"hljs-params\">(nums.size())</span></span>;<br>    <span class=\"hljs-type\">int</span> index = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= max_num; ++i) &#123;<br>        <span class=\"hljs-keyword\">while</span> (count[i] &gt; <span class=\"hljs-number\">0</span>) &#123;<br>            sortedArray[index++] = i;<br>            count[i]--;<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">return</span> sortedArray;<br>&#125;<br><span class=\"hljs-function\">vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">sortArray</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">countingSort</span>(nums);<br>&#125;<br></code></pre></td></tr></table></figure>\n"},{"title":"集成电路静态时序分析学习笔记","date":"2023-08-26T03:39:04.000Z","cover":"/img/default_cover04.jpg","top_img":null,"_content":"## 第一章 引论\n\n> 集成电路：在一块很小的硅单晶片上，利用半导体工艺制作出许多二极管、晶体管以及电阻、电容等，并连接成能完成特定电子技术功能的电子电路。\n\n### 静态时序分析技术\n\n静态时序分析既要检验门级电路的最大延迟、以保证电路在指定的频率下能够满足建立时间的要求，同时要检验门级电路的最小延迟、以满足保持时间的需求。\n\n**静态时序分析优缺点**\n\n* 优点\n  * 分析执行速度快\n  * 不需要测试向量\n  * 对于有时序路径的时序，测试覆盖率可以近乎达到100%\n  * 能够完成动态仿真所不能实现的复杂分析\n* 缺点\n  * 不能验证设计的功能\n  * 智能验证同步时序电路的时序特性\n  * 不能自动识别设计中的特殊路基\n\n## 第二章 静态时序分析的基础知识\n\n### 逻辑门单元\n\n![image-20230810165634110](static-timing-analysis/image-20230810165634110.png)\n\n反相器：根据输入数据的逻辑电平进行逻辑取反的求值运算，并通过输出导出求值结果。\n\n逻辑门延时：逻辑单元自身逻辑求值的时间。信号线延时：逻辑信号从逻辑门单元的输出端口开始在互连线上传播到下一级逻辑输入端口的延时。\n\n### 门单元的时序计算参数\n\n组合逻辑门单元相关的时序参数主要包括信号转换延时和逻辑门延时\n\n**1、信号转换延时**\n\n> 输入端口或输出端口的信号电平由高到低或由低到高所需要的时间即为信号转换延时。\n\n可以调整上升沿和下降沿的阈值，来设置不同的上拉跨度和下降跨度\n\n**2、逻辑门延时**\n\n> 通过由晶体管组成的逻辑门可以使高、低电平输入信号进行逻辑求值并产生对应的高电平或者低电平信号输出。\n\n### 时序单元相关约束\n\n时序单元相关约束信息包括：建立时间、保持时间、恢复时间、移除时间以及最小脉冲宽度\n\n**1、建立时间**\n\n在时钟信号到来之前需要保持的时间，一般是以50%为间隔\n\n![image-20230811144505780](static-timing-analysis/image-20230811144505780.png)\n\n**2、保持时间**\n\n时序单元要实现正确的逻辑功能，信号在时钟沿有效后必须保持的最小时间长度。\n\n**3、恢复时间**\n\n保证单元正常的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之前保持的最小时间长度。\n\n**4、移除时间**\n\n保证单元正确的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之后继续保持有效的最小时间长度。\n\n**5、最小脉冲宽度**\n\n脉冲波形的开始到结束之间的最小时间间隔。\n\n### 时钟特性\n\n> 时钟的时序特性\n>\n> 时钟周期：时钟频率的倒数\n>\n> 时钟占空比：时钟信号高电平在一个周期之内所占的时间比率\n>\n> 时钟转换时间：时钟信号的电压从标准供电电源电压的10-90的时间间隔\n>\n> 时钟延迟：时钟延迟是指时钟信号从时钟源输出端口到达时序单元时钟输入端口所需要的传播时间\n>\n> 时钟偏斜\n>\n> 时钟抖动\n\n### 时序弧\n\n用于表达时序的一种数据\n\n> 静态时序分析是基于时序弧数据的时序分析。\n>\n> 时序弧的信息一般分为连线延时和单元延时，单元延时中的时序弧分为基本时序弧和约束时序弧\n\n### PVT环境\n\n工艺、工作电压、工作温度等参数设置的组合简称为PVT\n\n1、TYP（Typical）工艺\n包括典型的工艺，典型的工艺温度、典型的有效电源电压\n\n2、BCF（Best-Case Fast）\n\n包括最快的工艺、最低的工艺温度、最高的有效电源电压\n\n3、WCS（Worst-Case Show）\n\n包括最慢的工艺、最高的工艺温度、最低的有效电源电压\n\n### 时序计算单位\n\n基于温度、电压、电流、电阻、电容负载和时间等不同类型的变量银子进行计算\n\n## 第三章 单元库时序模型\n\n### 基本时序模型简介\n\n**快速时序模型**\n\n> 通过时序信息库对应单元的时序弧信息，把需要建模的时序路径的时序弧近似为某些单元的时序弧组合\n\n**接口逻辑模型**\n\n使用一种结构化的方法，将原始电路简化为只包含接口逻辑的一个小电路。\n\n**抽取时序模型**\n\n从一个模块的门级网表中抽取模块的时序信息，可以隐藏单元的内部实现细节，有利于保护知识产权。\n\n### Synopsys工艺库模型\n\n线性延时模型：通过线性方程来计算单元的门延时和输出端转换延时\n\n非线性延时模型：由驱动模型和接受模型组成\n\n复合电流源延时模型：指定输入信号转换时间和逻辑门的输出负载值，通过电路仿真模拟出逻辑门的延时和输出转换时间\n\n### 延时计算模型\n\n1、CMOS通用延时计算模型\n\n逻辑门固有的本征延时、输入信号转换延时、信号连线延时、输出信号转换延时\n\n2、CMOS非线性延时计算模型\n\n逻辑门延时、信号互连线连线延时\n\n由输入信号转换时间与输出负载作为索引，时序分析时以一个二维查找表的形式来计算延时。\n\n计算过程：查找表中索引参数的某个采样点延时可直接查表得出，再通过插值算法来计算延时。\n\n#### 互连线计算模型\n\n芯片内的互连线大致可以分为以下3种\n\n1、短线，局部互连线\n\n2、中长线，模块间互连线\n\n3、长线，全局互连线\n\n* 集总C模型\n\n  当导线的电阻部分很小且驱动单元的转换频率在较低范围内，就可以很合理地只考虑导线地电容部分，并把分布的电容集总为单个电容。\n\n* 集总RC模型\n\n  当导线长度超过几微米后会有明显地电阻，因此采用电阻电容模型。\n\n* 分布RC模型\n\n* 传输线模型\n\n#### 线负载时序模型\n\n### 引脚电容值计算\n\n每一个单元的时序模型除了延迟信息外，还包含输入引脚的电容信息\n\n* 方法一、对流入输入引脚的电流进行积分\n* 方法二、基于输出转换时间结果，通过查找表的方法来确定对应的输出电容负载\n\n### 功耗模型计算\n\n> 包括开关功耗，短路电流功耗，哑阈漏流功耗，开关功耗和短路电流功耗组成动态功耗\n\n动态功耗是单元在转换过程中电源电流的积分\n\n静态功耗（哑阈漏流）计算方法，设置单元的输入信号为固定电平，然后对单元的哑阈漏流进行瞬态分析，得到哑阈漏流功耗值。\n\n### 时序信息建模基本方法\n\n> 考虑两方面的延迟信息\n>\n> 1、输入端口到输出端口的延迟信息，即时序弧\n>\n> 2、输入端口之间存在的时序约束信息，建立或保持时间约束\n\n## 第四章、时序信息库文件\n\n> 时序信息库文件中记录着逻辑门延时、输出信号转换延时和功耗等信息，这些信息在用于时序分析时被调用，来计算延时值和功耗值。时序文件的内容主要由组、属性、和因子组成。\n\n这一章是对一些库文件的介绍\n\n## 第五章、静态时序分析的基本方法\n\n### 时序图\n\n从逻辑电路图转化为时序图，需要标记中间的逻辑节点，生成中间结果后，再绘制时序图。\n\n### 时序分析策略\n\n> 基于路径的时序分析策略和基于模块的时序分析策略\n\n1、基于路径的时序分析策略：基于时序图寻找从起点到终点的所有路径并进行时序分析\n\n2、基于模块的时序分析策略：基于图的时序分析策略，基于时序图找到从起点到终点的所有路径，在进行时序分析时只基于该路径下延迟最严重的结点进行计算。\n\n### 时序路径延时计算方法\n\n1、组合逻辑之间路径延时计算方法\n\n把逻辑门延时和信号线延时逐一相加来实现\n\n2、时序逻辑之间路径延时计算方法\n\n通过逻辑路径的逻辑门延时和信号线延时逐一相加来实现\n\n### 时序路径的分析方法\n\n对建立时间和保持时间进行分析\n\n1、建立时间分析：在时钟捕获信号有效沿到来前，数据信号必须提前达到稳定状态的时间\n\n![image-20230817160931612](static-timing-analysis/image-20230817160931612.png)\n\n2、保持时间分析：为保证时序单元对数据读取正确，数据在时钟有效沿到来之后仍需要保持稳定的时间\n\n![image-20230817160942849](static-timing-analysis/image-20230817160942849.png)\n\n\n\n## 第六章、时序约束\n\n### 时钟约束\n\n* 创建时钟\n\n  时钟源点：根据情况定义为设计中的一个端口\n\n  时钟周期：时钟振荡周期，频率的倒数\n\n  时钟占空比：默认百分之50，高低电平在一个周期中的占比\n\n  时钟转换延时：高低电平之间进行切换所需要的延时\n\n  时钟不确定性：抖动、偏斜等\n\n  时钟延迟：从时钟源输出端到达时序单元时钟输入端传播延时。\n\n* 生成时钟\n\n  > 基于主时钟并通过相关逻辑转换后，在相位、频率、占空比等方面和主时钟有一定变化的分支时钟。\n\n* 虚拟时钟\n\n* 最小时钟脉宽\n\n### I/O延时约束\n\n* 设置输入延时：在一个有效时钟周期内，外部逻辑的输出数据到达设计输入端口所占用的延时\n* 设置输出延时：在一个有效时钟周期内，输出端口数据到外部逻辑所占用的延时\n\n### I/O环境建模约束\n\n> 主要包括：\n>\n> 输入驱动建模\n>\n> 输出负载建模\n\n### 时序例外\n\n1、多周期路径设置\n\n2、伪路径设置：某些时序路径在某特定的工作状态下不工作，要求非常宽松，不会有真正的工作信号通过\n\n3、最大演示和最小延时设置\n\n### 恒定状态约束\n\n### 屏蔽时序约束\n\n> 针对单元具体端口内部的时序弧并且进行屏蔽，等价于移除该单元内部的时序弧，时序分析时，与该时序弧相关的所有时序路径都被移除\n\n### 时序设计规则约束\n\n1、最大转换时间\n\n2、最大电容负载\n\n3、最大扇出\n\n> 扇出指逻辑单元输出端直接连接的下级逻辑单元输入端的个数。","source":"_posts/static-timing-analysis.md","raw":"---\ntitle: 集成电路静态时序分析学习笔记\ncategories: 学习笔记\ndate: 2023-08-26 11:39:04\ntags: [EDA, 集成电路, 静态时序分析]\ncover:\ntop_img:\n---\n## 第一章 引论\n\n> 集成电路：在一块很小的硅单晶片上，利用半导体工艺制作出许多二极管、晶体管以及电阻、电容等，并连接成能完成特定电子技术功能的电子电路。\n\n### 静态时序分析技术\n\n静态时序分析既要检验门级电路的最大延迟、以保证电路在指定的频率下能够满足建立时间的要求，同时要检验门级电路的最小延迟、以满足保持时间的需求。\n\n**静态时序分析优缺点**\n\n* 优点\n  * 分析执行速度快\n  * 不需要测试向量\n  * 对于有时序路径的时序，测试覆盖率可以近乎达到100%\n  * 能够完成动态仿真所不能实现的复杂分析\n* 缺点\n  * 不能验证设计的功能\n  * 智能验证同步时序电路的时序特性\n  * 不能自动识别设计中的特殊路基\n\n## 第二章 静态时序分析的基础知识\n\n### 逻辑门单元\n\n![image-20230810165634110](static-timing-analysis/image-20230810165634110.png)\n\n反相器：根据输入数据的逻辑电平进行逻辑取反的求值运算，并通过输出导出求值结果。\n\n逻辑门延时：逻辑单元自身逻辑求值的时间。信号线延时：逻辑信号从逻辑门单元的输出端口开始在互连线上传播到下一级逻辑输入端口的延时。\n\n### 门单元的时序计算参数\n\n组合逻辑门单元相关的时序参数主要包括信号转换延时和逻辑门延时\n\n**1、信号转换延时**\n\n> 输入端口或输出端口的信号电平由高到低或由低到高所需要的时间即为信号转换延时。\n\n可以调整上升沿和下降沿的阈值，来设置不同的上拉跨度和下降跨度\n\n**2、逻辑门延时**\n\n> 通过由晶体管组成的逻辑门可以使高、低电平输入信号进行逻辑求值并产生对应的高电平或者低电平信号输出。\n\n### 时序单元相关约束\n\n时序单元相关约束信息包括：建立时间、保持时间、恢复时间、移除时间以及最小脉冲宽度\n\n**1、建立时间**\n\n在时钟信号到来之前需要保持的时间，一般是以50%为间隔\n\n![image-20230811144505780](static-timing-analysis/image-20230811144505780.png)\n\n**2、保持时间**\n\n时序单元要实现正确的逻辑功能，信号在时钟沿有效后必须保持的最小时间长度。\n\n**3、恢复时间**\n\n保证单元正常的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之前保持的最小时间长度。\n\n**4、移除时间**\n\n保证单元正确的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之后继续保持有效的最小时间长度。\n\n**5、最小脉冲宽度**\n\n脉冲波形的开始到结束之间的最小时间间隔。\n\n### 时钟特性\n\n> 时钟的时序特性\n>\n> 时钟周期：时钟频率的倒数\n>\n> 时钟占空比：时钟信号高电平在一个周期之内所占的时间比率\n>\n> 时钟转换时间：时钟信号的电压从标准供电电源电压的10-90的时间间隔\n>\n> 时钟延迟：时钟延迟是指时钟信号从时钟源输出端口到达时序单元时钟输入端口所需要的传播时间\n>\n> 时钟偏斜\n>\n> 时钟抖动\n\n### 时序弧\n\n用于表达时序的一种数据\n\n> 静态时序分析是基于时序弧数据的时序分析。\n>\n> 时序弧的信息一般分为连线延时和单元延时，单元延时中的时序弧分为基本时序弧和约束时序弧\n\n### PVT环境\n\n工艺、工作电压、工作温度等参数设置的组合简称为PVT\n\n1、TYP（Typical）工艺\n包括典型的工艺，典型的工艺温度、典型的有效电源电压\n\n2、BCF（Best-Case Fast）\n\n包括最快的工艺、最低的工艺温度、最高的有效电源电压\n\n3、WCS（Worst-Case Show）\n\n包括最慢的工艺、最高的工艺温度、最低的有效电源电压\n\n### 时序计算单位\n\n基于温度、电压、电流、电阻、电容负载和时间等不同类型的变量银子进行计算\n\n## 第三章 单元库时序模型\n\n### 基本时序模型简介\n\n**快速时序模型**\n\n> 通过时序信息库对应单元的时序弧信息，把需要建模的时序路径的时序弧近似为某些单元的时序弧组合\n\n**接口逻辑模型**\n\n使用一种结构化的方法，将原始电路简化为只包含接口逻辑的一个小电路。\n\n**抽取时序模型**\n\n从一个模块的门级网表中抽取模块的时序信息，可以隐藏单元的内部实现细节，有利于保护知识产权。\n\n### Synopsys工艺库模型\n\n线性延时模型：通过线性方程来计算单元的门延时和输出端转换延时\n\n非线性延时模型：由驱动模型和接受模型组成\n\n复合电流源延时模型：指定输入信号转换时间和逻辑门的输出负载值，通过电路仿真模拟出逻辑门的延时和输出转换时间\n\n### 延时计算模型\n\n1、CMOS通用延时计算模型\n\n逻辑门固有的本征延时、输入信号转换延时、信号连线延时、输出信号转换延时\n\n2、CMOS非线性延时计算模型\n\n逻辑门延时、信号互连线连线延时\n\n由输入信号转换时间与输出负载作为索引，时序分析时以一个二维查找表的形式来计算延时。\n\n计算过程：查找表中索引参数的某个采样点延时可直接查表得出，再通过插值算法来计算延时。\n\n#### 互连线计算模型\n\n芯片内的互连线大致可以分为以下3种\n\n1、短线，局部互连线\n\n2、中长线，模块间互连线\n\n3、长线，全局互连线\n\n* 集总C模型\n\n  当导线的电阻部分很小且驱动单元的转换频率在较低范围内，就可以很合理地只考虑导线地电容部分，并把分布的电容集总为单个电容。\n\n* 集总RC模型\n\n  当导线长度超过几微米后会有明显地电阻，因此采用电阻电容模型。\n\n* 分布RC模型\n\n* 传输线模型\n\n#### 线负载时序模型\n\n### 引脚电容值计算\n\n每一个单元的时序模型除了延迟信息外，还包含输入引脚的电容信息\n\n* 方法一、对流入输入引脚的电流进行积分\n* 方法二、基于输出转换时间结果，通过查找表的方法来确定对应的输出电容负载\n\n### 功耗模型计算\n\n> 包括开关功耗，短路电流功耗，哑阈漏流功耗，开关功耗和短路电流功耗组成动态功耗\n\n动态功耗是单元在转换过程中电源电流的积分\n\n静态功耗（哑阈漏流）计算方法，设置单元的输入信号为固定电平，然后对单元的哑阈漏流进行瞬态分析，得到哑阈漏流功耗值。\n\n### 时序信息建模基本方法\n\n> 考虑两方面的延迟信息\n>\n> 1、输入端口到输出端口的延迟信息，即时序弧\n>\n> 2、输入端口之间存在的时序约束信息，建立或保持时间约束\n\n## 第四章、时序信息库文件\n\n> 时序信息库文件中记录着逻辑门延时、输出信号转换延时和功耗等信息，这些信息在用于时序分析时被调用，来计算延时值和功耗值。时序文件的内容主要由组、属性、和因子组成。\n\n这一章是对一些库文件的介绍\n\n## 第五章、静态时序分析的基本方法\n\n### 时序图\n\n从逻辑电路图转化为时序图，需要标记中间的逻辑节点，生成中间结果后，再绘制时序图。\n\n### 时序分析策略\n\n> 基于路径的时序分析策略和基于模块的时序分析策略\n\n1、基于路径的时序分析策略：基于时序图寻找从起点到终点的所有路径并进行时序分析\n\n2、基于模块的时序分析策略：基于图的时序分析策略，基于时序图找到从起点到终点的所有路径，在进行时序分析时只基于该路径下延迟最严重的结点进行计算。\n\n### 时序路径延时计算方法\n\n1、组合逻辑之间路径延时计算方法\n\n把逻辑门延时和信号线延时逐一相加来实现\n\n2、时序逻辑之间路径延时计算方法\n\n通过逻辑路径的逻辑门延时和信号线延时逐一相加来实现\n\n### 时序路径的分析方法\n\n对建立时间和保持时间进行分析\n\n1、建立时间分析：在时钟捕获信号有效沿到来前，数据信号必须提前达到稳定状态的时间\n\n![image-20230817160931612](static-timing-analysis/image-20230817160931612.png)\n\n2、保持时间分析：为保证时序单元对数据读取正确，数据在时钟有效沿到来之后仍需要保持稳定的时间\n\n![image-20230817160942849](static-timing-analysis/image-20230817160942849.png)\n\n\n\n## 第六章、时序约束\n\n### 时钟约束\n\n* 创建时钟\n\n  时钟源点：根据情况定义为设计中的一个端口\n\n  时钟周期：时钟振荡周期，频率的倒数\n\n  时钟占空比：默认百分之50，高低电平在一个周期中的占比\n\n  时钟转换延时：高低电平之间进行切换所需要的延时\n\n  时钟不确定性：抖动、偏斜等\n\n  时钟延迟：从时钟源输出端到达时序单元时钟输入端传播延时。\n\n* 生成时钟\n\n  > 基于主时钟并通过相关逻辑转换后，在相位、频率、占空比等方面和主时钟有一定变化的分支时钟。\n\n* 虚拟时钟\n\n* 最小时钟脉宽\n\n### I/O延时约束\n\n* 设置输入延时：在一个有效时钟周期内，外部逻辑的输出数据到达设计输入端口所占用的延时\n* 设置输出延时：在一个有效时钟周期内，输出端口数据到外部逻辑所占用的延时\n\n### I/O环境建模约束\n\n> 主要包括：\n>\n> 输入驱动建模\n>\n> 输出负载建模\n\n### 时序例外\n\n1、多周期路径设置\n\n2、伪路径设置：某些时序路径在某特定的工作状态下不工作，要求非常宽松，不会有真正的工作信号通过\n\n3、最大演示和最小延时设置\n\n### 恒定状态约束\n\n### 屏蔽时序约束\n\n> 针对单元具体端口内部的时序弧并且进行屏蔽，等价于移除该单元内部的时序弧，时序分析时，与该时序弧相关的所有时序路径都被移除\n\n### 时序设计规则约束\n\n1、最大转换时间\n\n2、最大电容负载\n\n3、最大扇出\n\n> 扇出指逻辑单元输出端直接连接的下级逻辑单元输入端的个数。","slug":"static-timing-analysis","published":1,"updated":"2024-06-05T09:03:03.809Z","comments":1,"layout":"post","photos":[],"_id":"clyfinttz003508jvf5n4ekx0","content":"<h2 id=\"第一章-引论\"><a href=\"#第一章-引论\" class=\"headerlink\" title=\"第一章 引论\"></a>第一章 引论</h2><blockquote>\n<p>集成电路：在一块很小的硅单晶片上，利用半导体工艺制作出许多二极管、晶体管以及电阻、电容等，并连接成能完成特定电子技术功能的电子电路。</p>\n</blockquote>\n<h3 id=\"静态时序分析技术\"><a href=\"#静态时序分析技术\" class=\"headerlink\" title=\"静态时序分析技术\"></a>静态时序分析技术</h3><p>静态时序分析既要检验门级电路的最大延迟、以保证电路在指定的频率下能够满足建立时间的要求，同时要检验门级电路的最小延迟、以满足保持时间的需求。</p>\n<p><strong>静态时序分析优缺点</strong></p>\n<ul>\n<li>优点<ul>\n<li>分析执行速度快</li>\n<li>不需要测试向量</li>\n<li>对于有时序路径的时序，测试覆盖率可以近乎达到100%</li>\n<li>能够完成动态仿真所不能实现的复杂分析</li>\n</ul>\n</li>\n<li>缺点<ul>\n<li>不能验证设计的功能</li>\n<li>智能验证同步时序电路的时序特性</li>\n<li>不能自动识别设计中的特殊路基</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第二章-静态时序分析的基础知识\"><a href=\"#第二章-静态时序分析的基础知识\" class=\"headerlink\" title=\"第二章 静态时序分析的基础知识\"></a>第二章 静态时序分析的基础知识</h2><h3 id=\"逻辑门单元\"><a href=\"#逻辑门单元\" class=\"headerlink\" title=\"逻辑门单元\"></a>逻辑门单元</h3><img src=\"/2023/08/26/static-timing-analysis/image-20230810165634110.png\" class=\"\" title=\"image-20230810165634110\">\n<p>反相器：根据输入数据的逻辑电平进行逻辑取反的求值运算，并通过输出导出求值结果。</p>\n<p>逻辑门延时：逻辑单元自身逻辑求值的时间。信号线延时：逻辑信号从逻辑门单元的输出端口开始在互连线上传播到下一级逻辑输入端口的延时。</p>\n<h3 id=\"门单元的时序计算参数\"><a href=\"#门单元的时序计算参数\" class=\"headerlink\" title=\"门单元的时序计算参数\"></a>门单元的时序计算参数</h3><p>组合逻辑门单元相关的时序参数主要包括信号转换延时和逻辑门延时</p>\n<p><strong>1、信号转换延时</strong></p>\n<blockquote>\n<p>输入端口或输出端口的信号电平由高到低或由低到高所需要的时间即为信号转换延时。</p>\n</blockquote>\n<p>可以调整上升沿和下降沿的阈值，来设置不同的上拉跨度和下降跨度</p>\n<p><strong>2、逻辑门延时</strong></p>\n<blockquote>\n<p>通过由晶体管组成的逻辑门可以使高、低电平输入信号进行逻辑求值并产生对应的高电平或者低电平信号输出。</p>\n</blockquote>\n<h3 id=\"时序单元相关约束\"><a href=\"#时序单元相关约束\" class=\"headerlink\" title=\"时序单元相关约束\"></a>时序单元相关约束</h3><p>时序单元相关约束信息包括：建立时间、保持时间、恢复时间、移除时间以及最小脉冲宽度</p>\n<p><strong>1、建立时间</strong></p>\n<p>在时钟信号到来之前需要保持的时间，一般是以50%为间隔</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230811144505780.png\" class=\"\" title=\"image-20230811144505780\">\n<p><strong>2、保持时间</strong></p>\n<p>时序单元要实现正确的逻辑功能，信号在时钟沿有效后必须保持的最小时间长度。</p>\n<p><strong>3、恢复时间</strong></p>\n<p>保证单元正常的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之前保持的最小时间长度。</p>\n<p><strong>4、移除时间</strong></p>\n<p>保证单元正确的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之后继续保持有效的最小时间长度。</p>\n<p><strong>5、最小脉冲宽度</strong></p>\n<p>脉冲波形的开始到结束之间的最小时间间隔。</p>\n<h3 id=\"时钟特性\"><a href=\"#时钟特性\" class=\"headerlink\" title=\"时钟特性\"></a>时钟特性</h3><blockquote>\n<p>时钟的时序特性</p>\n<p>时钟周期：时钟频率的倒数</p>\n<p>时钟占空比：时钟信号高电平在一个周期之内所占的时间比率</p>\n<p>时钟转换时间：时钟信号的电压从标准供电电源电压的10-90的时间间隔</p>\n<p>时钟延迟：时钟延迟是指时钟信号从时钟源输出端口到达时序单元时钟输入端口所需要的传播时间</p>\n<p>时钟偏斜</p>\n<p>时钟抖动</p>\n</blockquote>\n<h3 id=\"时序弧\"><a href=\"#时序弧\" class=\"headerlink\" title=\"时序弧\"></a>时序弧</h3><p>用于表达时序的一种数据</p>\n<blockquote>\n<p>静态时序分析是基于时序弧数据的时序分析。</p>\n<p>时序弧的信息一般分为连线延时和单元延时，单元延时中的时序弧分为基本时序弧和约束时序弧</p>\n</blockquote>\n<h3 id=\"PVT环境\"><a href=\"#PVT环境\" class=\"headerlink\" title=\"PVT环境\"></a>PVT环境</h3><p>工艺、工作电压、工作温度等参数设置的组合简称为PVT</p>\n<p>1、TYP（Typical）工艺<br>包括典型的工艺，典型的工艺温度、典型的有效电源电压</p>\n<p>2、BCF（Best-Case Fast）</p>\n<p>包括最快的工艺、最低的工艺温度、最高的有效电源电压</p>\n<p>3、WCS（Worst-Case Show）</p>\n<p>包括最慢的工艺、最高的工艺温度、最低的有效电源电压</p>\n<h3 id=\"时序计算单位\"><a href=\"#时序计算单位\" class=\"headerlink\" title=\"时序计算单位\"></a>时序计算单位</h3><p>基于温度、电压、电流、电阻、电容负载和时间等不同类型的变量银子进行计算</p>\n<h2 id=\"第三章-单元库时序模型\"><a href=\"#第三章-单元库时序模型\" class=\"headerlink\" title=\"第三章 单元库时序模型\"></a>第三章 单元库时序模型</h2><h3 id=\"基本时序模型简介\"><a href=\"#基本时序模型简介\" class=\"headerlink\" title=\"基本时序模型简介\"></a>基本时序模型简介</h3><p><strong>快速时序模型</strong></p>\n<blockquote>\n<p>通过时序信息库对应单元的时序弧信息，把需要建模的时序路径的时序弧近似为某些单元的时序弧组合</p>\n</blockquote>\n<p><strong>接口逻辑模型</strong></p>\n<p>使用一种结构化的方法，将原始电路简化为只包含接口逻辑的一个小电路。</p>\n<p><strong>抽取时序模型</strong></p>\n<p>从一个模块的门级网表中抽取模块的时序信息，可以隐藏单元的内部实现细节，有利于保护知识产权。</p>\n<h3 id=\"Synopsys工艺库模型\"><a href=\"#Synopsys工艺库模型\" class=\"headerlink\" title=\"Synopsys工艺库模型\"></a>Synopsys工艺库模型</h3><p>线性延时模型：通过线性方程来计算单元的门延时和输出端转换延时</p>\n<p>非线性延时模型：由驱动模型和接受模型组成</p>\n<p>复合电流源延时模型：指定输入信号转换时间和逻辑门的输出负载值，通过电路仿真模拟出逻辑门的延时和输出转换时间</p>\n<h3 id=\"延时计算模型\"><a href=\"#延时计算模型\" class=\"headerlink\" title=\"延时计算模型\"></a>延时计算模型</h3><p>1、CMOS通用延时计算模型</p>\n<p>逻辑门固有的本征延时、输入信号转换延时、信号连线延时、输出信号转换延时</p>\n<p>2、CMOS非线性延时计算模型</p>\n<p>逻辑门延时、信号互连线连线延时</p>\n<p>由输入信号转换时间与输出负载作为索引，时序分析时以一个二维查找表的形式来计算延时。</p>\n<p>计算过程：查找表中索引参数的某个采样点延时可直接查表得出，再通过插值算法来计算延时。</p>\n<h4 id=\"互连线计算模型\"><a href=\"#互连线计算模型\" class=\"headerlink\" title=\"互连线计算模型\"></a>互连线计算模型</h4><p>芯片内的互连线大致可以分为以下3种</p>\n<p>1、短线，局部互连线</p>\n<p>2、中长线，模块间互连线</p>\n<p>3、长线，全局互连线</p>\n<ul>\n<li><p>集总C模型</p>\n<p>当导线的电阻部分很小且驱动单元的转换频率在较低范围内，就可以很合理地只考虑导线地电容部分，并把分布的电容集总为单个电容。</p>\n</li>\n<li><p>集总RC模型</p>\n<p>当导线长度超过几微米后会有明显地电阻，因此采用电阻电容模型。</p>\n</li>\n<li><p>分布RC模型</p>\n</li>\n<li><p>传输线模型</p>\n</li>\n</ul>\n<h4 id=\"线负载时序模型\"><a href=\"#线负载时序模型\" class=\"headerlink\" title=\"线负载时序模型\"></a>线负载时序模型</h4><h3 id=\"引脚电容值计算\"><a href=\"#引脚电容值计算\" class=\"headerlink\" title=\"引脚电容值计算\"></a>引脚电容值计算</h3><p>每一个单元的时序模型除了延迟信息外，还包含输入引脚的电容信息</p>\n<ul>\n<li>方法一、对流入输入引脚的电流进行积分</li>\n<li>方法二、基于输出转换时间结果，通过查找表的方法来确定对应的输出电容负载</li>\n</ul>\n<h3 id=\"功耗模型计算\"><a href=\"#功耗模型计算\" class=\"headerlink\" title=\"功耗模型计算\"></a>功耗模型计算</h3><blockquote>\n<p>包括开关功耗，短路电流功耗，哑阈漏流功耗，开关功耗和短路电流功耗组成动态功耗</p>\n</blockquote>\n<p>动态功耗是单元在转换过程中电源电流的积分</p>\n<p>静态功耗（哑阈漏流）计算方法，设置单元的输入信号为固定电平，然后对单元的哑阈漏流进行瞬态分析，得到哑阈漏流功耗值。</p>\n<h3 id=\"时序信息建模基本方法\"><a href=\"#时序信息建模基本方法\" class=\"headerlink\" title=\"时序信息建模基本方法\"></a>时序信息建模基本方法</h3><blockquote>\n<p>考虑两方面的延迟信息</p>\n<p>1、输入端口到输出端口的延迟信息，即时序弧</p>\n<p>2、输入端口之间存在的时序约束信息，建立或保持时间约束</p>\n</blockquote>\n<h2 id=\"第四章、时序信息库文件\"><a href=\"#第四章、时序信息库文件\" class=\"headerlink\" title=\"第四章、时序信息库文件\"></a>第四章、时序信息库文件</h2><blockquote>\n<p>时序信息库文件中记录着逻辑门延时、输出信号转换延时和功耗等信息，这些信息在用于时序分析时被调用，来计算延时值和功耗值。时序文件的内容主要由组、属性、和因子组成。</p>\n</blockquote>\n<p>这一章是对一些库文件的介绍</p>\n<h2 id=\"第五章、静态时序分析的基本方法\"><a href=\"#第五章、静态时序分析的基本方法\" class=\"headerlink\" title=\"第五章、静态时序分析的基本方法\"></a>第五章、静态时序分析的基本方法</h2><h3 id=\"时序图\"><a href=\"#时序图\" class=\"headerlink\" title=\"时序图\"></a>时序图</h3><p>从逻辑电路图转化为时序图，需要标记中间的逻辑节点，生成中间结果后，再绘制时序图。</p>\n<h3 id=\"时序分析策略\"><a href=\"#时序分析策略\" class=\"headerlink\" title=\"时序分析策略\"></a>时序分析策略</h3><blockquote>\n<p>基于路径的时序分析策略和基于模块的时序分析策略</p>\n</blockquote>\n<p>1、基于路径的时序分析策略：基于时序图寻找从起点到终点的所有路径并进行时序分析</p>\n<p>2、基于模块的时序分析策略：基于图的时序分析策略，基于时序图找到从起点到终点的所有路径，在进行时序分析时只基于该路径下延迟最严重的结点进行计算。</p>\n<h3 id=\"时序路径延时计算方法\"><a href=\"#时序路径延时计算方法\" class=\"headerlink\" title=\"时序路径延时计算方法\"></a>时序路径延时计算方法</h3><p>1、组合逻辑之间路径延时计算方法</p>\n<p>把逻辑门延时和信号线延时逐一相加来实现</p>\n<p>2、时序逻辑之间路径延时计算方法</p>\n<p>通过逻辑路径的逻辑门延时和信号线延时逐一相加来实现</p>\n<h3 id=\"时序路径的分析方法\"><a href=\"#时序路径的分析方法\" class=\"headerlink\" title=\"时序路径的分析方法\"></a>时序路径的分析方法</h3><p>对建立时间和保持时间进行分析</p>\n<p>1、建立时间分析：在时钟捕获信号有效沿到来前，数据信号必须提前达到稳定状态的时间</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230817160931612.png\" class=\"\" title=\"image-20230817160931612\">\n<p>2、保持时间分析：为保证时序单元对数据读取正确，数据在时钟有效沿到来之后仍需要保持稳定的时间</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230817160942849.png\" class=\"\" title=\"image-20230817160942849\">\n<h2 id=\"第六章、时序约束\"><a href=\"#第六章、时序约束\" class=\"headerlink\" title=\"第六章、时序约束\"></a>第六章、时序约束</h2><h3 id=\"时钟约束\"><a href=\"#时钟约束\" class=\"headerlink\" title=\"时钟约束\"></a>时钟约束</h3><ul>\n<li><p>创建时钟</p>\n<p>时钟源点：根据情况定义为设计中的一个端口</p>\n<p>时钟周期：时钟振荡周期，频率的倒数</p>\n<p>时钟占空比：默认百分之50，高低电平在一个周期中的占比</p>\n<p>时钟转换延时：高低电平之间进行切换所需要的延时</p>\n<p>时钟不确定性：抖动、偏斜等</p>\n<p>时钟延迟：从时钟源输出端到达时序单元时钟输入端传播延时。</p>\n</li>\n<li><p>生成时钟</p>\n<blockquote>\n<p>基于主时钟并通过相关逻辑转换后，在相位、频率、占空比等方面和主时钟有一定变化的分支时钟。</p>\n</blockquote>\n</li>\n<li><p>虚拟时钟</p>\n</li>\n<li><p>最小时钟脉宽</p>\n</li>\n</ul>\n<h3 id=\"I-O延时约束\"><a href=\"#I-O延时约束\" class=\"headerlink\" title=\"I/O延时约束\"></a>I/O延时约束</h3><ul>\n<li>设置输入延时：在一个有效时钟周期内，外部逻辑的输出数据到达设计输入端口所占用的延时</li>\n<li>设置输出延时：在一个有效时钟周期内，输出端口数据到外部逻辑所占用的延时</li>\n</ul>\n<h3 id=\"I-O环境建模约束\"><a href=\"#I-O环境建模约束\" class=\"headerlink\" title=\"I/O环境建模约束\"></a>I/O环境建模约束</h3><blockquote>\n<p>主要包括：</p>\n<p>输入驱动建模</p>\n<p>输出负载建模</p>\n</blockquote>\n<h3 id=\"时序例外\"><a href=\"#时序例外\" class=\"headerlink\" title=\"时序例外\"></a>时序例外</h3><p>1、多周期路径设置</p>\n<p>2、伪路径设置：某些时序路径在某特定的工作状态下不工作，要求非常宽松，不会有真正的工作信号通过</p>\n<p>3、最大演示和最小延时设置</p>\n<h3 id=\"恒定状态约束\"><a href=\"#恒定状态约束\" class=\"headerlink\" title=\"恒定状态约束\"></a>恒定状态约束</h3><h3 id=\"屏蔽时序约束\"><a href=\"#屏蔽时序约束\" class=\"headerlink\" title=\"屏蔽时序约束\"></a>屏蔽时序约束</h3><blockquote>\n<p>针对单元具体端口内部的时序弧并且进行屏蔽，等价于移除该单元内部的时序弧，时序分析时，与该时序弧相关的所有时序路径都被移除</p>\n</blockquote>\n<h3 id=\"时序设计规则约束\"><a href=\"#时序设计规则约束\" class=\"headerlink\" title=\"时序设计规则约束\"></a>时序设计规则约束</h3><p>1、最大转换时间</p>\n<p>2、最大电容负载</p>\n<p>3、最大扇出</p>\n<blockquote>\n<p>扇出指逻辑单元输出端直接连接的下级逻辑单元输入端的个数。</p>\n</blockquote>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"第一章-引论\"><a href=\"#第一章-引论\" class=\"headerlink\" title=\"第一章 引论\"></a>第一章 引论</h2><blockquote>\n<p>集成电路：在一块很小的硅单晶片上，利用半导体工艺制作出许多二极管、晶体管以及电阻、电容等，并连接成能完成特定电子技术功能的电子电路。</p>\n</blockquote>\n<h3 id=\"静态时序分析技术\"><a href=\"#静态时序分析技术\" class=\"headerlink\" title=\"静态时序分析技术\"></a>静态时序分析技术</h3><p>静态时序分析既要检验门级电路的最大延迟、以保证电路在指定的频率下能够满足建立时间的要求，同时要检验门级电路的最小延迟、以满足保持时间的需求。</p>\n<p><strong>静态时序分析优缺点</strong></p>\n<ul>\n<li>优点<ul>\n<li>分析执行速度快</li>\n<li>不需要测试向量</li>\n<li>对于有时序路径的时序，测试覆盖率可以近乎达到100%</li>\n<li>能够完成动态仿真所不能实现的复杂分析</li>\n</ul>\n</li>\n<li>缺点<ul>\n<li>不能验证设计的功能</li>\n<li>智能验证同步时序电路的时序特性</li>\n<li>不能自动识别设计中的特殊路基</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"第二章-静态时序分析的基础知识\"><a href=\"#第二章-静态时序分析的基础知识\" class=\"headerlink\" title=\"第二章 静态时序分析的基础知识\"></a>第二章 静态时序分析的基础知识</h2><h3 id=\"逻辑门单元\"><a href=\"#逻辑门单元\" class=\"headerlink\" title=\"逻辑门单元\"></a>逻辑门单元</h3><img src=\"/2023/08/26/static-timing-analysis/image-20230810165634110.png\" class=\"\" title=\"image-20230810165634110\">\n<p>反相器：根据输入数据的逻辑电平进行逻辑取反的求值运算，并通过输出导出求值结果。</p>\n<p>逻辑门延时：逻辑单元自身逻辑求值的时间。信号线延时：逻辑信号从逻辑门单元的输出端口开始在互连线上传播到下一级逻辑输入端口的延时。</p>\n<h3 id=\"门单元的时序计算参数\"><a href=\"#门单元的时序计算参数\" class=\"headerlink\" title=\"门单元的时序计算参数\"></a>门单元的时序计算参数</h3><p>组合逻辑门单元相关的时序参数主要包括信号转换延时和逻辑门延时</p>\n<p><strong>1、信号转换延时</strong></p>\n<blockquote>\n<p>输入端口或输出端口的信号电平由高到低或由低到高所需要的时间即为信号转换延时。</p>\n</blockquote>\n<p>可以调整上升沿和下降沿的阈值，来设置不同的上拉跨度和下降跨度</p>\n<p><strong>2、逻辑门延时</strong></p>\n<blockquote>\n<p>通过由晶体管组成的逻辑门可以使高、低电平输入信号进行逻辑求值并产生对应的高电平或者低电平信号输出。</p>\n</blockquote>\n<h3 id=\"时序单元相关约束\"><a href=\"#时序单元相关约束\" class=\"headerlink\" title=\"时序单元相关约束\"></a>时序单元相关约束</h3><p>时序单元相关约束信息包括：建立时间、保持时间、恢复时间、移除时间以及最小脉冲宽度</p>\n<p><strong>1、建立时间</strong></p>\n<p>在时钟信号到来之前需要保持的时间，一般是以50%为间隔</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230811144505780.png\" class=\"\" title=\"image-20230811144505780\">\n<p><strong>2、保持时间</strong></p>\n<p>时序单元要实现正确的逻辑功能，信号在时钟沿有效后必须保持的最小时间长度。</p>\n<p><strong>3、恢复时间</strong></p>\n<p>保证单元正常的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之前保持的最小时间长度。</p>\n<p><strong>4、移除时间</strong></p>\n<p>保证单元正确的逻辑功能，要求低电平复位信号或者高电平清零信号在时钟有效沿之后继续保持有效的最小时间长度。</p>\n<p><strong>5、最小脉冲宽度</strong></p>\n<p>脉冲波形的开始到结束之间的最小时间间隔。</p>\n<h3 id=\"时钟特性\"><a href=\"#时钟特性\" class=\"headerlink\" title=\"时钟特性\"></a>时钟特性</h3><blockquote>\n<p>时钟的时序特性</p>\n<p>时钟周期：时钟频率的倒数</p>\n<p>时钟占空比：时钟信号高电平在一个周期之内所占的时间比率</p>\n<p>时钟转换时间：时钟信号的电压从标准供电电源电压的10-90的时间间隔</p>\n<p>时钟延迟：时钟延迟是指时钟信号从时钟源输出端口到达时序单元时钟输入端口所需要的传播时间</p>\n<p>时钟偏斜</p>\n<p>时钟抖动</p>\n</blockquote>\n<h3 id=\"时序弧\"><a href=\"#时序弧\" class=\"headerlink\" title=\"时序弧\"></a>时序弧</h3><p>用于表达时序的一种数据</p>\n<blockquote>\n<p>静态时序分析是基于时序弧数据的时序分析。</p>\n<p>时序弧的信息一般分为连线延时和单元延时，单元延时中的时序弧分为基本时序弧和约束时序弧</p>\n</blockquote>\n<h3 id=\"PVT环境\"><a href=\"#PVT环境\" class=\"headerlink\" title=\"PVT环境\"></a>PVT环境</h3><p>工艺、工作电压、工作温度等参数设置的组合简称为PVT</p>\n<p>1、TYP（Typical）工艺<br>包括典型的工艺，典型的工艺温度、典型的有效电源电压</p>\n<p>2、BCF（Best-Case Fast）</p>\n<p>包括最快的工艺、最低的工艺温度、最高的有效电源电压</p>\n<p>3、WCS（Worst-Case Show）</p>\n<p>包括最慢的工艺、最高的工艺温度、最低的有效电源电压</p>\n<h3 id=\"时序计算单位\"><a href=\"#时序计算单位\" class=\"headerlink\" title=\"时序计算单位\"></a>时序计算单位</h3><p>基于温度、电压、电流、电阻、电容负载和时间等不同类型的变量银子进行计算</p>\n<h2 id=\"第三章-单元库时序模型\"><a href=\"#第三章-单元库时序模型\" class=\"headerlink\" title=\"第三章 单元库时序模型\"></a>第三章 单元库时序模型</h2><h3 id=\"基本时序模型简介\"><a href=\"#基本时序模型简介\" class=\"headerlink\" title=\"基本时序模型简介\"></a>基本时序模型简介</h3><p><strong>快速时序模型</strong></p>\n<blockquote>\n<p>通过时序信息库对应单元的时序弧信息，把需要建模的时序路径的时序弧近似为某些单元的时序弧组合</p>\n</blockquote>\n<p><strong>接口逻辑模型</strong></p>\n<p>使用一种结构化的方法，将原始电路简化为只包含接口逻辑的一个小电路。</p>\n<p><strong>抽取时序模型</strong></p>\n<p>从一个模块的门级网表中抽取模块的时序信息，可以隐藏单元的内部实现细节，有利于保护知识产权。</p>\n<h3 id=\"Synopsys工艺库模型\"><a href=\"#Synopsys工艺库模型\" class=\"headerlink\" title=\"Synopsys工艺库模型\"></a>Synopsys工艺库模型</h3><p>线性延时模型：通过线性方程来计算单元的门延时和输出端转换延时</p>\n<p>非线性延时模型：由驱动模型和接受模型组成</p>\n<p>复合电流源延时模型：指定输入信号转换时间和逻辑门的输出负载值，通过电路仿真模拟出逻辑门的延时和输出转换时间</p>\n<h3 id=\"延时计算模型\"><a href=\"#延时计算模型\" class=\"headerlink\" title=\"延时计算模型\"></a>延时计算模型</h3><p>1、CMOS通用延时计算模型</p>\n<p>逻辑门固有的本征延时、输入信号转换延时、信号连线延时、输出信号转换延时</p>\n<p>2、CMOS非线性延时计算模型</p>\n<p>逻辑门延时、信号互连线连线延时</p>\n<p>由输入信号转换时间与输出负载作为索引，时序分析时以一个二维查找表的形式来计算延时。</p>\n<p>计算过程：查找表中索引参数的某个采样点延时可直接查表得出，再通过插值算法来计算延时。</p>\n<h4 id=\"互连线计算模型\"><a href=\"#互连线计算模型\" class=\"headerlink\" title=\"互连线计算模型\"></a>互连线计算模型</h4><p>芯片内的互连线大致可以分为以下3种</p>\n<p>1、短线，局部互连线</p>\n<p>2、中长线，模块间互连线</p>\n<p>3、长线，全局互连线</p>\n<ul>\n<li><p>集总C模型</p>\n<p>当导线的电阻部分很小且驱动单元的转换频率在较低范围内，就可以很合理地只考虑导线地电容部分，并把分布的电容集总为单个电容。</p>\n</li>\n<li><p>集总RC模型</p>\n<p>当导线长度超过几微米后会有明显地电阻，因此采用电阻电容模型。</p>\n</li>\n<li><p>分布RC模型</p>\n</li>\n<li><p>传输线模型</p>\n</li>\n</ul>\n<h4 id=\"线负载时序模型\"><a href=\"#线负载时序模型\" class=\"headerlink\" title=\"线负载时序模型\"></a>线负载时序模型</h4><h3 id=\"引脚电容值计算\"><a href=\"#引脚电容值计算\" class=\"headerlink\" title=\"引脚电容值计算\"></a>引脚电容值计算</h3><p>每一个单元的时序模型除了延迟信息外，还包含输入引脚的电容信息</p>\n<ul>\n<li>方法一、对流入输入引脚的电流进行积分</li>\n<li>方法二、基于输出转换时间结果，通过查找表的方法来确定对应的输出电容负载</li>\n</ul>\n<h3 id=\"功耗模型计算\"><a href=\"#功耗模型计算\" class=\"headerlink\" title=\"功耗模型计算\"></a>功耗模型计算</h3><blockquote>\n<p>包括开关功耗，短路电流功耗，哑阈漏流功耗，开关功耗和短路电流功耗组成动态功耗</p>\n</blockquote>\n<p>动态功耗是单元在转换过程中电源电流的积分</p>\n<p>静态功耗（哑阈漏流）计算方法，设置单元的输入信号为固定电平，然后对单元的哑阈漏流进行瞬态分析，得到哑阈漏流功耗值。</p>\n<h3 id=\"时序信息建模基本方法\"><a href=\"#时序信息建模基本方法\" class=\"headerlink\" title=\"时序信息建模基本方法\"></a>时序信息建模基本方法</h3><blockquote>\n<p>考虑两方面的延迟信息</p>\n<p>1、输入端口到输出端口的延迟信息，即时序弧</p>\n<p>2、输入端口之间存在的时序约束信息，建立或保持时间约束</p>\n</blockquote>\n<h2 id=\"第四章、时序信息库文件\"><a href=\"#第四章、时序信息库文件\" class=\"headerlink\" title=\"第四章、时序信息库文件\"></a>第四章、时序信息库文件</h2><blockquote>\n<p>时序信息库文件中记录着逻辑门延时、输出信号转换延时和功耗等信息，这些信息在用于时序分析时被调用，来计算延时值和功耗值。时序文件的内容主要由组、属性、和因子组成。</p>\n</blockquote>\n<p>这一章是对一些库文件的介绍</p>\n<h2 id=\"第五章、静态时序分析的基本方法\"><a href=\"#第五章、静态时序分析的基本方法\" class=\"headerlink\" title=\"第五章、静态时序分析的基本方法\"></a>第五章、静态时序分析的基本方法</h2><h3 id=\"时序图\"><a href=\"#时序图\" class=\"headerlink\" title=\"时序图\"></a>时序图</h3><p>从逻辑电路图转化为时序图，需要标记中间的逻辑节点，生成中间结果后，再绘制时序图。</p>\n<h3 id=\"时序分析策略\"><a href=\"#时序分析策略\" class=\"headerlink\" title=\"时序分析策略\"></a>时序分析策略</h3><blockquote>\n<p>基于路径的时序分析策略和基于模块的时序分析策略</p>\n</blockquote>\n<p>1、基于路径的时序分析策略：基于时序图寻找从起点到终点的所有路径并进行时序分析</p>\n<p>2、基于模块的时序分析策略：基于图的时序分析策略，基于时序图找到从起点到终点的所有路径，在进行时序分析时只基于该路径下延迟最严重的结点进行计算。</p>\n<h3 id=\"时序路径延时计算方法\"><a href=\"#时序路径延时计算方法\" class=\"headerlink\" title=\"时序路径延时计算方法\"></a>时序路径延时计算方法</h3><p>1、组合逻辑之间路径延时计算方法</p>\n<p>把逻辑门延时和信号线延时逐一相加来实现</p>\n<p>2、时序逻辑之间路径延时计算方法</p>\n<p>通过逻辑路径的逻辑门延时和信号线延时逐一相加来实现</p>\n<h3 id=\"时序路径的分析方法\"><a href=\"#时序路径的分析方法\" class=\"headerlink\" title=\"时序路径的分析方法\"></a>时序路径的分析方法</h3><p>对建立时间和保持时间进行分析</p>\n<p>1、建立时间分析：在时钟捕获信号有效沿到来前，数据信号必须提前达到稳定状态的时间</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230817160931612.png\" class=\"\" title=\"image-20230817160931612\">\n<p>2、保持时间分析：为保证时序单元对数据读取正确，数据在时钟有效沿到来之后仍需要保持稳定的时间</p>\n<img src=\"/2023/08/26/static-timing-analysis/image-20230817160942849.png\" class=\"\" title=\"image-20230817160942849\">\n<h2 id=\"第六章、时序约束\"><a href=\"#第六章、时序约束\" class=\"headerlink\" title=\"第六章、时序约束\"></a>第六章、时序约束</h2><h3 id=\"时钟约束\"><a href=\"#时钟约束\" class=\"headerlink\" title=\"时钟约束\"></a>时钟约束</h3><ul>\n<li><p>创建时钟</p>\n<p>时钟源点：根据情况定义为设计中的一个端口</p>\n<p>时钟周期：时钟振荡周期，频率的倒数</p>\n<p>时钟占空比：默认百分之50，高低电平在一个周期中的占比</p>\n<p>时钟转换延时：高低电平之间进行切换所需要的延时</p>\n<p>时钟不确定性：抖动、偏斜等</p>\n<p>时钟延迟：从时钟源输出端到达时序单元时钟输入端传播延时。</p>\n</li>\n<li><p>生成时钟</p>\n<blockquote>\n<p>基于主时钟并通过相关逻辑转换后，在相位、频率、占空比等方面和主时钟有一定变化的分支时钟。</p>\n</blockquote>\n</li>\n<li><p>虚拟时钟</p>\n</li>\n<li><p>最小时钟脉宽</p>\n</li>\n</ul>\n<h3 id=\"I-O延时约束\"><a href=\"#I-O延时约束\" class=\"headerlink\" title=\"I/O延时约束\"></a>I/O延时约束</h3><ul>\n<li>设置输入延时：在一个有效时钟周期内，外部逻辑的输出数据到达设计输入端口所占用的延时</li>\n<li>设置输出延时：在一个有效时钟周期内，输出端口数据到外部逻辑所占用的延时</li>\n</ul>\n<h3 id=\"I-O环境建模约束\"><a href=\"#I-O环境建模约束\" class=\"headerlink\" title=\"I/O环境建模约束\"></a>I/O环境建模约束</h3><blockquote>\n<p>主要包括：</p>\n<p>输入驱动建模</p>\n<p>输出负载建模</p>\n</blockquote>\n<h3 id=\"时序例外\"><a href=\"#时序例外\" class=\"headerlink\" title=\"时序例外\"></a>时序例外</h3><p>1、多周期路径设置</p>\n<p>2、伪路径设置：某些时序路径在某特定的工作状态下不工作，要求非常宽松，不会有真正的工作信号通过</p>\n<p>3、最大演示和最小延时设置</p>\n<h3 id=\"恒定状态约束\"><a href=\"#恒定状态约束\" class=\"headerlink\" title=\"恒定状态约束\"></a>恒定状态约束</h3><h3 id=\"屏蔽时序约束\"><a href=\"#屏蔽时序约束\" class=\"headerlink\" title=\"屏蔽时序约束\"></a>屏蔽时序约束</h3><blockquote>\n<p>针对单元具体端口内部的时序弧并且进行屏蔽，等价于移除该单元内部的时序弧，时序分析时，与该时序弧相关的所有时序路径都被移除</p>\n</blockquote>\n<h3 id=\"时序设计规则约束\"><a href=\"#时序设计规则约束\" class=\"headerlink\" title=\"时序设计规则约束\"></a>时序设计规则约束</h3><p>1、最大转换时间</p>\n<p>2、最大电容负载</p>\n<p>3、最大扇出</p>\n<blockquote>\n<p>扇出指逻辑单元输出端直接连接的下级逻辑单元输入端的个数。</p>\n</blockquote>\n"},{"title":"C++多线程编程","date":"2024-03-03T05:09:32.000Z","cover":"/img/default_cover04.jpg","top_img":null,"_content":"## C++11多线程编程\n\n### C++11 Thread线程库的基本用法\n\n> 进程：运行中的程序，线程：进程中的进程\n>\n> 一个操作系统可以有多个进程，一个进程中可以有多个线程，线程的最大数量取决于电脑CPU的核数\n\n导入头文件thread\n\n* 创建线程\t`thread th(function, arg)`\n\n创建线程需要绑定一个函数，function表示已经定义的函数名，通过arg可以传入函数的参数，线程在std标准库当中\n\n创建线程对函数加引用`&`和不加引用的区别\n\n当线程需要执行的函数中需要使用引用传递参数时，在主线程中传入变量值，程序将无法通过编译，需要使用`std::ref`来确保引用传递\n\n```C++\nvoid threadFunction(int &x) {\n    // 现在x确实是主线程中x的引用\n}\n\nint main() {\n    int x = 0;\n    // 编译报错\n    // std::thread t(threadFunction, x)\n    std::thread t(threadFunction, std::ref(x)); // 使用std::ref来确保引用传递\n    t.join();\n    // 现在主线程的x可能会被子线程修改\n    return 0;\n}\n```\n\n* `join`和`detach`\n\njoin：调用此接口，当前线程会一直阻塞，直到目标线程完成，如果目标线程十分耗时，主线程会一直阻塞。让主线程等待其他线程结束以后才结束。\n\n`detach`：让目标线程称为守护线程（daemon threads）。一旦detach之后，目标线程将独立执行，即便其对应的thread对象销毁也不影响线程的执行，并且，无法再与其通信\n\n可以通过`joinable()`接口查询是否可以对接口进行join和detach\n\n### 互斥量解决多线程数据共享问题\n\n当一个资源需要被多个线程进行使用并修改的时候，就会存在资源的冲突\n\n下面的函数线程`t`和`t2`都需要对变量`a`进行1000000次的自增操作，因为线程的并行操作，所以两个线程在进行取a的值的时候，有可能获取到同样的值，再次写回时，原本需要+2最终只完成了+1，或者运行较快的线程的写入值会被运行较慢的线程覆盖，这就导致了结果会小于原来预期的值\n\n```c++\n#include <thread>\n#include <iostream>\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        a += 1;\n    }\n    \n}\n\nint main(){\n    int a = 0;\n\n    std::thread t(thread_function, std::ref(a));\n    std::thread t2(thread_function, std::ref(a));\n\n    t.join();\n    t2.join();\n\n    std::cout<<a<<std::endl;\n    \n}\n```\n\n![image-20240303195554869](thread-pool/image-20240303195554869.png)\n\n这个情况就需要两个线程对a进行互斥使用，用到`mutex`\n\n在需要对资源`a`进行访问的前后，分别进行加锁和解锁，确保这一段临界区只由一个线程访问\n\n```c++\n#include <thread>\n#include <iostream>\n#include <mutex>\n\n// 互斥信号量\nstd::mutex m;\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        // 加锁\n        m.lock();\n        a += 1;\n        m.unlock();\n    }\n    \n}\n\nint main(){\n    int a = 0;\n\n    std::thread t(thread_function, std::ref(a));\n    std::thread t2(thread_function, std::ref(a));\n\n    t.join();\n    t2.join();\n\n    std::cout<<a<<std::endl;\n    \n}\n```\n\n![image-20240303200213188](thread-pool/image-20240303200213188.png)\n\n### lock_guard与unique_lock\n\n* lock_guard\n\nlock_guard是一种互斥量封装类，用于保护共享数据，防止多个线程同时访问统一资源而导致数据竞争问题\n\n当构造函数被调用时，该互斥量会被自动锁定\n\n当析构函数被调用时，该互斥量会自动解锁\n\n该对象不能复制或移动，只能在局部作用域中使用\n\n使用到的就是RAII思想\n\n```c++\nstd::mutex m;\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        std::lock_guard<std::mutex> lg(m);\n        // m.lock();\n        a += 1;\n        // 不需要对锁释放，当作用域结束自动释放\n        // m.unlock();\n    }\n}\n```\n\n* unique_lock，构造函数会自动加锁，传入`std::defer_lock`后会延迟加锁\n\nunique_lock是一个互斥量封装类，用于在多线程中对互斥量进行加锁和解锁操作，特点是，可以对互斥量进行更加灵活的管理，包括延迟加锁、条件变量、超时等\n\n`lock()`：尝试对互斥量进行加锁，如果当前互斥量被其他线程持有则会阻塞\n\n`try_lock()`L：尝试对互斥量进行加锁，如果被占有则返回false\n\n`try_lock_for(const std::chrono::duration<Rep, Period>& rel_time)`：尝试加锁，如果被占有，则超时以后会释放\n\n### std::call_once使用场景\n\n单例设计模式是一种常见的设计模式，用于确保某个类只能创建一个实例，由于单例实例是全局唯一的，因此在多线程环境中使用单例模式时，需要考虑线程安全的问题\n\n```c++\n// 单例模式\nclass Log{\nprivate:\n    Log() {};\npublic:\n    Log(const Log& log) = delete;\n    Log& operator=(const Log& log) = delete;\n    \n    static Log& GetInstance(){\n        static Log * log = nullptr;\n        if(!log){\n            log = new Log();\n        }\n        return log;\n    }\n    \n    void PrintLog(std::string msg){\n        std::cout << msg << std::endl;\n    }\n}\n```\n\n在多线程的情况下，如果都需要使用到同一个单例，当多个线程同时获取log时，如果此时log都为空，单例就会被多次初始化，违背了单例模式的设计初衷\n\n`call_once`可以确保某个函数指挥被调用一次\n\ncall_once只能在线程中使用\n\n```c++\n// 原型\ntemplate<class Callable, class... Args>\nvoid call_once(std::once_flag&flag, Callable&& func, Args&&...args);\n```\n\n对单例模式的修改\n\n```c++\n// 单例模式\nclass Log{\nprivate:\n    Log() {};\npublic:\n    // 声明一个变量\n    static std::once_flag once;\n    Log(const Log& log) = delete;\n    Log& operator=(const Log& log) = delete;\n    \n    static Log& GetInstance(){\n        static Log * log = nullptr;\n        \n        // 单次调用\n        std::call_once(once, init);\n        return log;\n    }\n    // 封装一个初始化的函数\n    static void init(){\n        if(!log){\n            log = new Log();\n        }\n    }\n    \n    void PrintLog(std::string msg){\n        std::cout << msg << std::endl;\n    }\n}\n```\n\n### condition_variable使用场景\n\n使用步骤如下\n\n* 创建一个std::condition_variable对象\n\n* 创建一个互斥锁std::mutex，用来保护共享资源的访问\n\n* 在需要等待条件变量的地方\n\n  使用std::unique_lock< std::mutex >对象锁定互斥锁并调用std::condition_variable::wait_for()或std::condition_variable::wait_until()函数等待条件变量\n\n* 在其他线程中需要通知等待的线程时，调用std::condition_variable::notify_one()或者std::condition_variable::notify_all()函数通知等待的线程\n\n生产者消费者模型\n\n```c++\n#include <string>\n#include <mutex>\n#include <queue>\n#include <thread>\n#include <iostream>\n#include <condition_variable>\n\nstd::queue<int> q;\nstd::condition_variable cv;\nstd::mutex m;\n\nvoid Producer(){\n    for (size_t i = 0; i < 100; i++)\n    {\n        std::unique_lock<std::mutex> ul(m);\n        q.push(i);\n        cv.notify_one();\n        std::cout<<\"Produced: \"<<i<<std::endl;\n        std::this_thread::sleep_for(std::chrono::microseconds(10000));\n    }\n}\n\nvoid Consumer(){\n    while(1)\n    {\n        std::unique_lock<std::mutex> ul(m);\n        cv.wait(ul, []{return !q.empty();});\n        std::cout<<\"Consumed: \"<<q.front()<<std::endl;\n        q.pop();\n    }\n}\n\nint main(){\n    std::thread t1(Producer);\n    std::thread t2(Consumer);\n\n    t1.join();\n    t2.join();\n    \n    return 0;\n}\n```\n\n![image-20240303211229196](thread-pool/image-20240303211229196.png)\n\n### 线程池的实现\n\n维护一个线程数组：可以初始化线程的个数\n\n维护一个任务队列：当前正在进行的任务\n\n线程数组负责从队列取任务，生产者负责从任务队列里加任务（需要提供加任务的接口）\n\n![image-20240303214601818](thread-pool/image-20240303214601818.png)\n\n构造函数中指定起始线程的个数，初始化线程，每一个线程都在循环的在任务队列里取任务并完成，给用户提供一个接口，不断的往任务队列中添加任务，并且每次添加任务过后会通知一个维护的线程去完成任务\n\n每一次访问tasks和stop变量的时候，这是临界区，都需要进行加锁\n\n```c++\n#include <mutex>\n#include <queue>\n#include <thread>\n#include <iostream>\n#include <functional>\n#include <condition_variable>\n\nclass ThreadPool\n{\nprivate:\n    std::vector<std::thread> threads;\n    std::queue<std::function<void()>> tasks;\n    std::condition_variable cv;\n    std::mutex m;\n    bool stop;\n\npublic:\n    // 构造函数，构造一共大小为n的线程池\n    // 每一个线程执行的函数是检查tasks是否为空，或者stop是否为true\n    // 从tasks中取出任务执行，取任务的时候，和访问stop的时候都需要加锁\n    ThreadPool(int n) : stop(false){\n        for( int i = 0; i < n; ++i ){\n            threads.emplace_back([this]{\n                while(true){\n                    std::unique_lock<std::mutex> ul(m);\n                    cv.wait(ul, [this]{\n                        return stop || !tasks.empty();\n                        });\n\n                    if( stop && tasks.empty() ){\n                        return;\n                    }\n\n                    // 使用右值引用，避免拷贝\n                    std::function<void()> task(std::move(tasks.front()));\n                    tasks.pop();\n                    ul.unlock();\n                    task();\n                }\n            });\n        }\n    }\n\n    // 析构函数，将stop置为true，然后notify_all\n    // 然后join所有的线程\n    ~ThreadPool(){\n        {\n            std::unique_lock<std::mutex> ul(m);\n            stop = true;\n        }\n        cv.notify_all();\n        for( auto& t : threads ){\n            t.join();\n        }\n    }\n\n    // 添加任务，将任务放入tasks中，然后notify_one\n    // 用到模板以及多个变量的传参，可以使用通用型函数\n    template<class F, class... Args>\n    void enqueue(F&& f, Args&&... args){\n        // 使用std::bind将传入的函数和参数绑定\n        // 因为传入的是万能引用，使用forward可以让参数自动选择是右值还是左值引用\n        std::function<void()> task = std::bind(std::forward<F>(f), std::forward<Args>(args)...);\n        {\n            std::unique_lock<std::mutex> ul(m);\n            tasks.emplace(std::move(task));\n        }\n        // 通知一个线程执行任务\n        cv.notify_one();\n    }\n\n};\n\nint main(){\n    ThreadPool tp(4);\n    for( int i = 0; i < 8; ++i ){\n        tp.enqueue([i]{\n            // 用printf而不是cout，避免输出混乱\n            printf(\"Thread %d is working\\n\", i);\n            std::this_thread::sleep_for(std::chrono::seconds(1));\n            printf(\"Thread %d is done\\n\", i);\n        });\n    }\n    return 0;\n\n}\n```\n\n* 使用cout输出\n\ncout的单个输出是线程安全的，这种线程安全是针对在操作系统层面，即每一次`<<`的调用都是原子的，但是多个`<<`进行串联输出的时候，整个表达式并不是原子的，因此在串联输出的过程中，会被其他输出线程打断\n\n![image-20240303224717307](thread-pool/image-20240303224717307.png)\n\n* 使用printf输出\n\n> printf(\"Thread %d is working\\n\", i);\n\n使用printf输出则是将串联的输出转化为单一的输出，因此单条语句不会产生混乱，但是多个线程输出还是会产生混乱。\n\n![image-20240303224732958](thread-pool/image-20240303224732958.png)\n\n","source":"_posts/thread-pool.md","raw":"---\ntitle: C++多线程编程\ntags:\n  - C++\n  - 多线程\n  - 并行\n  - Thread\ncategories: 技术研究\ndate: 2024-03-03 13:09:32\ncover:\ntop_img:\n---\n## C++11多线程编程\n\n### C++11 Thread线程库的基本用法\n\n> 进程：运行中的程序，线程：进程中的进程\n>\n> 一个操作系统可以有多个进程，一个进程中可以有多个线程，线程的最大数量取决于电脑CPU的核数\n\n导入头文件thread\n\n* 创建线程\t`thread th(function, arg)`\n\n创建线程需要绑定一个函数，function表示已经定义的函数名，通过arg可以传入函数的参数，线程在std标准库当中\n\n创建线程对函数加引用`&`和不加引用的区别\n\n当线程需要执行的函数中需要使用引用传递参数时，在主线程中传入变量值，程序将无法通过编译，需要使用`std::ref`来确保引用传递\n\n```C++\nvoid threadFunction(int &x) {\n    // 现在x确实是主线程中x的引用\n}\n\nint main() {\n    int x = 0;\n    // 编译报错\n    // std::thread t(threadFunction, x)\n    std::thread t(threadFunction, std::ref(x)); // 使用std::ref来确保引用传递\n    t.join();\n    // 现在主线程的x可能会被子线程修改\n    return 0;\n}\n```\n\n* `join`和`detach`\n\njoin：调用此接口，当前线程会一直阻塞，直到目标线程完成，如果目标线程十分耗时，主线程会一直阻塞。让主线程等待其他线程结束以后才结束。\n\n`detach`：让目标线程称为守护线程（daemon threads）。一旦detach之后，目标线程将独立执行，即便其对应的thread对象销毁也不影响线程的执行，并且，无法再与其通信\n\n可以通过`joinable()`接口查询是否可以对接口进行join和detach\n\n### 互斥量解决多线程数据共享问题\n\n当一个资源需要被多个线程进行使用并修改的时候，就会存在资源的冲突\n\n下面的函数线程`t`和`t2`都需要对变量`a`进行1000000次的自增操作，因为线程的并行操作，所以两个线程在进行取a的值的时候，有可能获取到同样的值，再次写回时，原本需要+2最终只完成了+1，或者运行较快的线程的写入值会被运行较慢的线程覆盖，这就导致了结果会小于原来预期的值\n\n```c++\n#include <thread>\n#include <iostream>\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        a += 1;\n    }\n    \n}\n\nint main(){\n    int a = 0;\n\n    std::thread t(thread_function, std::ref(a));\n    std::thread t2(thread_function, std::ref(a));\n\n    t.join();\n    t2.join();\n\n    std::cout<<a<<std::endl;\n    \n}\n```\n\n![image-20240303195554869](thread-pool/image-20240303195554869.png)\n\n这个情况就需要两个线程对a进行互斥使用，用到`mutex`\n\n在需要对资源`a`进行访问的前后，分别进行加锁和解锁，确保这一段临界区只由一个线程访问\n\n```c++\n#include <thread>\n#include <iostream>\n#include <mutex>\n\n// 互斥信号量\nstd::mutex m;\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        // 加锁\n        m.lock();\n        a += 1;\n        m.unlock();\n    }\n    \n}\n\nint main(){\n    int a = 0;\n\n    std::thread t(thread_function, std::ref(a));\n    std::thread t2(thread_function, std::ref(a));\n\n    t.join();\n    t2.join();\n\n    std::cout<<a<<std::endl;\n    \n}\n```\n\n![image-20240303200213188](thread-pool/image-20240303200213188.png)\n\n### lock_guard与unique_lock\n\n* lock_guard\n\nlock_guard是一种互斥量封装类，用于保护共享数据，防止多个线程同时访问统一资源而导致数据竞争问题\n\n当构造函数被调用时，该互斥量会被自动锁定\n\n当析构函数被调用时，该互斥量会自动解锁\n\n该对象不能复制或移动，只能在局部作用域中使用\n\n使用到的就是RAII思想\n\n```c++\nstd::mutex m;\n\nvoid thread_function(int& a){\n    for (size_t i = 0; i < 1000000; i++)\n    {\n        std::lock_guard<std::mutex> lg(m);\n        // m.lock();\n        a += 1;\n        // 不需要对锁释放，当作用域结束自动释放\n        // m.unlock();\n    }\n}\n```\n\n* unique_lock，构造函数会自动加锁，传入`std::defer_lock`后会延迟加锁\n\nunique_lock是一个互斥量封装类，用于在多线程中对互斥量进行加锁和解锁操作，特点是，可以对互斥量进行更加灵活的管理，包括延迟加锁、条件变量、超时等\n\n`lock()`：尝试对互斥量进行加锁，如果当前互斥量被其他线程持有则会阻塞\n\n`try_lock()`L：尝试对互斥量进行加锁，如果被占有则返回false\n\n`try_lock_for(const std::chrono::duration<Rep, Period>& rel_time)`：尝试加锁，如果被占有，则超时以后会释放\n\n### std::call_once使用场景\n\n单例设计模式是一种常见的设计模式，用于确保某个类只能创建一个实例，由于单例实例是全局唯一的，因此在多线程环境中使用单例模式时，需要考虑线程安全的问题\n\n```c++\n// 单例模式\nclass Log{\nprivate:\n    Log() {};\npublic:\n    Log(const Log& log) = delete;\n    Log& operator=(const Log& log) = delete;\n    \n    static Log& GetInstance(){\n        static Log * log = nullptr;\n        if(!log){\n            log = new Log();\n        }\n        return log;\n    }\n    \n    void PrintLog(std::string msg){\n        std::cout << msg << std::endl;\n    }\n}\n```\n\n在多线程的情况下，如果都需要使用到同一个单例，当多个线程同时获取log时，如果此时log都为空，单例就会被多次初始化，违背了单例模式的设计初衷\n\n`call_once`可以确保某个函数指挥被调用一次\n\ncall_once只能在线程中使用\n\n```c++\n// 原型\ntemplate<class Callable, class... Args>\nvoid call_once(std::once_flag&flag, Callable&& func, Args&&...args);\n```\n\n对单例模式的修改\n\n```c++\n// 单例模式\nclass Log{\nprivate:\n    Log() {};\npublic:\n    // 声明一个变量\n    static std::once_flag once;\n    Log(const Log& log) = delete;\n    Log& operator=(const Log& log) = delete;\n    \n    static Log& GetInstance(){\n        static Log * log = nullptr;\n        \n        // 单次调用\n        std::call_once(once, init);\n        return log;\n    }\n    // 封装一个初始化的函数\n    static void init(){\n        if(!log){\n            log = new Log();\n        }\n    }\n    \n    void PrintLog(std::string msg){\n        std::cout << msg << std::endl;\n    }\n}\n```\n\n### condition_variable使用场景\n\n使用步骤如下\n\n* 创建一个std::condition_variable对象\n\n* 创建一个互斥锁std::mutex，用来保护共享资源的访问\n\n* 在需要等待条件变量的地方\n\n  使用std::unique_lock< std::mutex >对象锁定互斥锁并调用std::condition_variable::wait_for()或std::condition_variable::wait_until()函数等待条件变量\n\n* 在其他线程中需要通知等待的线程时，调用std::condition_variable::notify_one()或者std::condition_variable::notify_all()函数通知等待的线程\n\n生产者消费者模型\n\n```c++\n#include <string>\n#include <mutex>\n#include <queue>\n#include <thread>\n#include <iostream>\n#include <condition_variable>\n\nstd::queue<int> q;\nstd::condition_variable cv;\nstd::mutex m;\n\nvoid Producer(){\n    for (size_t i = 0; i < 100; i++)\n    {\n        std::unique_lock<std::mutex> ul(m);\n        q.push(i);\n        cv.notify_one();\n        std::cout<<\"Produced: \"<<i<<std::endl;\n        std::this_thread::sleep_for(std::chrono::microseconds(10000));\n    }\n}\n\nvoid Consumer(){\n    while(1)\n    {\n        std::unique_lock<std::mutex> ul(m);\n        cv.wait(ul, []{return !q.empty();});\n        std::cout<<\"Consumed: \"<<q.front()<<std::endl;\n        q.pop();\n    }\n}\n\nint main(){\n    std::thread t1(Producer);\n    std::thread t2(Consumer);\n\n    t1.join();\n    t2.join();\n    \n    return 0;\n}\n```\n\n![image-20240303211229196](thread-pool/image-20240303211229196.png)\n\n### 线程池的实现\n\n维护一个线程数组：可以初始化线程的个数\n\n维护一个任务队列：当前正在进行的任务\n\n线程数组负责从队列取任务，生产者负责从任务队列里加任务（需要提供加任务的接口）\n\n![image-20240303214601818](thread-pool/image-20240303214601818.png)\n\n构造函数中指定起始线程的个数，初始化线程，每一个线程都在循环的在任务队列里取任务并完成，给用户提供一个接口，不断的往任务队列中添加任务，并且每次添加任务过后会通知一个维护的线程去完成任务\n\n每一次访问tasks和stop变量的时候，这是临界区，都需要进行加锁\n\n```c++\n#include <mutex>\n#include <queue>\n#include <thread>\n#include <iostream>\n#include <functional>\n#include <condition_variable>\n\nclass ThreadPool\n{\nprivate:\n    std::vector<std::thread> threads;\n    std::queue<std::function<void()>> tasks;\n    std::condition_variable cv;\n    std::mutex m;\n    bool stop;\n\npublic:\n    // 构造函数，构造一共大小为n的线程池\n    // 每一个线程执行的函数是检查tasks是否为空，或者stop是否为true\n    // 从tasks中取出任务执行，取任务的时候，和访问stop的时候都需要加锁\n    ThreadPool(int n) : stop(false){\n        for( int i = 0; i < n; ++i ){\n            threads.emplace_back([this]{\n                while(true){\n                    std::unique_lock<std::mutex> ul(m);\n                    cv.wait(ul, [this]{\n                        return stop || !tasks.empty();\n                        });\n\n                    if( stop && tasks.empty() ){\n                        return;\n                    }\n\n                    // 使用右值引用，避免拷贝\n                    std::function<void()> task(std::move(tasks.front()));\n                    tasks.pop();\n                    ul.unlock();\n                    task();\n                }\n            });\n        }\n    }\n\n    // 析构函数，将stop置为true，然后notify_all\n    // 然后join所有的线程\n    ~ThreadPool(){\n        {\n            std::unique_lock<std::mutex> ul(m);\n            stop = true;\n        }\n        cv.notify_all();\n        for( auto& t : threads ){\n            t.join();\n        }\n    }\n\n    // 添加任务，将任务放入tasks中，然后notify_one\n    // 用到模板以及多个变量的传参，可以使用通用型函数\n    template<class F, class... Args>\n    void enqueue(F&& f, Args&&... args){\n        // 使用std::bind将传入的函数和参数绑定\n        // 因为传入的是万能引用，使用forward可以让参数自动选择是右值还是左值引用\n        std::function<void()> task = std::bind(std::forward<F>(f), std::forward<Args>(args)...);\n        {\n            std::unique_lock<std::mutex> ul(m);\n            tasks.emplace(std::move(task));\n        }\n        // 通知一个线程执行任务\n        cv.notify_one();\n    }\n\n};\n\nint main(){\n    ThreadPool tp(4);\n    for( int i = 0; i < 8; ++i ){\n        tp.enqueue([i]{\n            // 用printf而不是cout，避免输出混乱\n            printf(\"Thread %d is working\\n\", i);\n            std::this_thread::sleep_for(std::chrono::seconds(1));\n            printf(\"Thread %d is done\\n\", i);\n        });\n    }\n    return 0;\n\n}\n```\n\n* 使用cout输出\n\ncout的单个输出是线程安全的，这种线程安全是针对在操作系统层面，即每一次`<<`的调用都是原子的，但是多个`<<`进行串联输出的时候，整个表达式并不是原子的，因此在串联输出的过程中，会被其他输出线程打断\n\n![image-20240303224717307](thread-pool/image-20240303224717307.png)\n\n* 使用printf输出\n\n> printf(\"Thread %d is working\\n\", i);\n\n使用printf输出则是将串联的输出转化为单一的输出，因此单条语句不会产生混乱，但是多个线程输出还是会产生混乱。\n\n![image-20240303224732958](thread-pool/image-20240303224732958.png)\n\n","slug":"thread-pool","published":1,"updated":"2024-06-05T09:03:03.813Z","comments":1,"layout":"post","photos":[],"_id":"clyfintub007c08jvhfkqcayy","content":"<h2 id=\"C-11多线程编程\"><a href=\"#C-11多线程编程\" class=\"headerlink\" title=\"C++11多线程编程\"></a>C++11多线程编程</h2><h3 id=\"C-11-Thread线程库的基本用法\"><a href=\"#C-11-Thread线程库的基本用法\" class=\"headerlink\" title=\"C++11 Thread线程库的基本用法\"></a>C++11 Thread线程库的基本用法</h3><blockquote>\n<p>进程：运行中的程序，线程：进程中的进程</p>\n<p>一个操作系统可以有多个进程，一个进程中可以有多个线程，线程的最大数量取决于电脑CPU的核数</p>\n</blockquote>\n<p>导入头文件thread</p>\n<ul>\n<li>创建线程    <code>thread th(function, arg)</code></li>\n</ul>\n<p>创建线程需要绑定一个函数，function表示已经定义的函数名，通过arg可以传入函数的参数，线程在std标准库当中</p>\n<p>创建线程对函数加引用<code>&amp;</code>和不加引用的区别</p>\n<p>当线程需要执行的函数中需要使用引用传递参数时，在主线程中传入变量值，程序将无法通过编译，需要使用<code>std::ref</code>来确保引用传递</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">threadFunction</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> &amp;x)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 现在x确实是主线程中x的引用</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-comment\">// 编译报错</span><br>    <span class=\"hljs-comment\">// std::thread t(threadFunction, x)</span><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(threadFunction, std::ref(x))</span></span>; <span class=\"hljs-comment\">// 使用std::ref来确保引用传递</span><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    <span class=\"hljs-comment\">// 现在主线程的x可能会被子线程修改</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>join</code>和<code>detach</code></li>\n</ul>\n<p>join：调用此接口，当前线程会一直阻塞，直到目标线程完成，如果目标线程十分耗时，主线程会一直阻塞。让主线程等待其他线程结束以后才结束。</p>\n<p><code>detach</code>：让目标线程称为守护线程（daemon threads）。一旦detach之后，目标线程将独立执行，即便其对应的thread对象销毁也不影响线程的执行，并且，无法再与其通信</p>\n<p>可以通过<code>joinable()</code>接口查询是否可以对接口进行join和detach</p>\n<h3 id=\"互斥量解决多线程数据共享问题\"><a href=\"#互斥量解决多线程数据共享问题\" class=\"headerlink\" title=\"互斥量解决多线程数据共享问题\"></a>互斥量解决多线程数据共享问题</h3><p>当一个资源需要被多个线程进行使用并修改的时候，就会存在资源的冲突</p>\n<p>下面的函数线程<code>t</code>和<code>t2</code>都需要对变量<code>a</code>进行1000000次的自增操作，因为线程的并行操作，所以两个线程在进行取a的值的时候，有可能获取到同样的值，再次写回时，原本需要+2最终只完成了+1，或者运行较快的线程的写入值会被运行较慢的线程覆盖，这就导致了结果会小于原来预期的值</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        a += <span class=\"hljs-number\">1</span>;<br>    &#125;<br>    <br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br><br>    std::cout&lt;&lt;a&lt;&lt;std::endl;<br>    <br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303195554869.png\" class=\"\" title=\"image-20240303195554869\">\n<p>这个情况就需要两个线程对a进行互斥使用，用到<code>mutex</code></p>\n<p>在需要对资源<code>a</code>进行访问的前后，分别进行加锁和解锁，确保这一段临界区只由一个线程访问</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><br><span class=\"hljs-comment\">// 互斥信号量</span><br>std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        <span class=\"hljs-comment\">// 加锁</span><br>        m.<span class=\"hljs-built_in\">lock</span>();<br>        a += <span class=\"hljs-number\">1</span>;<br>        m.<span class=\"hljs-built_in\">unlock</span>();<br>    &#125;<br>    <br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br><br>    std::cout&lt;&lt;a&lt;&lt;std::endl;<br>    <br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303200213188.png\" class=\"\" title=\"image-20240303200213188\">\n<h3 id=\"lock-guard与unique-lock\"><a href=\"#lock-guard与unique-lock\" class=\"headerlink\" title=\"lock_guard与unique_lock\"></a>lock_guard与unique_lock</h3><ul>\n<li>lock_guard</li>\n</ul>\n<p>lock_guard是一种互斥量封装类，用于保护共享数据，防止多个线程同时访问统一资源而导致数据竞争问题</p>\n<p>当构造函数被调用时，该互斥量会被自动锁定</p>\n<p>当析构函数被调用时，该互斥量会自动解锁</p>\n<p>该对象不能复制或移动，只能在局部作用域中使用</p>\n<p>使用到的就是RAII思想</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lg</span><span class=\"hljs-params\">(m)</span></span>;<br>        <span class=\"hljs-comment\">// m.lock();</span><br>        a += <span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-comment\">// 不需要对锁释放，当作用域结束自动释放</span><br>        <span class=\"hljs-comment\">// m.unlock();</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>unique_lock，构造函数会自动加锁，传入<code>std::defer_lock</code>后会延迟加锁</li>\n</ul>\n<p>unique_lock是一个互斥量封装类，用于在多线程中对互斥量进行加锁和解锁操作，特点是，可以对互斥量进行更加灵活的管理，包括延迟加锁、条件变量、超时等</p>\n<p><code>lock()</code>：尝试对互斥量进行加锁，如果当前互斥量被其他线程持有则会阻塞</p>\n<p><code>try_lock()</code>L：尝试对互斥量进行加锁，如果被占有则返回false</p>\n<p><code>try_lock_for(const std::chrono::duration&lt;Rep, Period&gt;&amp; rel_time)</code>：尝试加锁，如果被占有，则超时以后会释放</p>\n<h3 id=\"std-call-once使用场景\"><a href=\"#std-call-once使用场景\" class=\"headerlink\" title=\"std::call_once使用场景\"></a>std::call_once使用场景</h3><p>单例设计模式是一种常见的设计模式，用于确保某个类只能创建一个实例，由于单例实例是全局唯一的，因此在多线程环境中使用单例模式时，需要考虑线程安全的问题</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 单例模式</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Log</span>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-built_in\">Log</span>() &#123;&#125;;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Log</span>(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    Log&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Log&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-type\">static</span> Log * log = <span class=\"hljs-literal\">nullptr</span>;<br>        <span class=\"hljs-keyword\">if</span>(!log)&#123;<br>            log = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Log</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> log;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">PrintLog</span><span class=\"hljs-params\">(std::string msg)</span></span>&#123;<br>        std::cout &lt;&lt; msg &lt;&lt; std::endl;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>在多线程的情况下，如果都需要使用到同一个单例，当多个线程同时获取log时，如果此时log都为空，单例就会被多次初始化，违背了单例模式的设计初衷</p>\n<p><code>call_once</code>可以确保某个函数指挥被调用一次</p>\n<p>call_once只能在线程中使用</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 原型</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">class</span> Callable, <span class=\"hljs-keyword\">class</span>... Args&gt;</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">call_once</span><span class=\"hljs-params\">(std::once_flag&amp;flag, Callable&amp;&amp; func, Args&amp;&amp;...args)</span></span>;<br></code></pre></td></tr></table></figure>\n<p>对单例模式的修改</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 单例模式</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Log</span>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-built_in\">Log</span>() &#123;&#125;;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 声明一个变量</span><br>    <span class=\"hljs-type\">static</span> std::once_flag once;<br>    <span class=\"hljs-built_in\">Log</span>(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    Log&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Log&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-type\">static</span> Log * log = <span class=\"hljs-literal\">nullptr</span>;<br>        <br>        <span class=\"hljs-comment\">// 单次调用</span><br>        std::<span class=\"hljs-built_in\">call_once</span>(once, init);<br>        <span class=\"hljs-keyword\">return</span> log;<br>    &#125;<br>    <span class=\"hljs-comment\">// 封装一个初始化的函数</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">init</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-keyword\">if</span>(!log)&#123;<br>            log = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Log</span>();<br>        &#125;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">PrintLog</span><span class=\"hljs-params\">(std::string msg)</span></span>&#123;<br>        std::cout &lt;&lt; msg &lt;&lt; std::endl;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"condition-variable使用场景\"><a href=\"#condition-variable使用场景\" class=\"headerlink\" title=\"condition_variable使用场景\"></a>condition_variable使用场景</h3><p>使用步骤如下</p>\n<ul>\n<li><p>创建一个std::condition_variable对象</p>\n</li>\n<li><p>创建一个互斥锁std::mutex，用来保护共享资源的访问</p>\n</li>\n<li><p>在需要等待条件变量的地方</p>\n<p>使用std::unique_lock&lt; std::mutex &gt;对象锁定互斥锁并调用std::condition_variable::wait_for()或std::condition_variable::wait_until()函数等待条件变量</p>\n</li>\n<li><p>在其他线程中需要通知等待的线程时，调用std::condition_variable::notify_one()或者std::condition_variable::notify_all()函数通知等待的线程</p>\n</li>\n</ul>\n<p>生产者消费者模型</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;queue&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;condition_variable&gt;</span></span><br><br>std::queue&lt;<span class=\"hljs-type\">int</span>&gt; q;<br>std::condition_variable cv;<br>std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Producer</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">100</span>; i++)<br>    &#123;<br>        <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>        q.<span class=\"hljs-built_in\">push</span>(i);<br>        cv.<span class=\"hljs-built_in\">notify_one</span>();<br>        std::cout&lt;&lt;<span class=\"hljs-string\">&quot;Produced: &quot;</span>&lt;&lt;i&lt;&lt;std::endl;<br>        std::this_thread::<span class=\"hljs-built_in\">sleep_for</span>(std::chrono::<span class=\"hljs-built_in\">microseconds</span>(<span class=\"hljs-number\">10000</span>));<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Consumer</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-keyword\">while</span>(<span class=\"hljs-number\">1</span>)<br>    &#123;<br>        <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>        cv.<span class=\"hljs-built_in\">wait</span>(ul, []&#123;<span class=\"hljs-keyword\">return</span> !q.<span class=\"hljs-built_in\">empty</span>();&#125;);<br>        std::cout&lt;&lt;<span class=\"hljs-string\">&quot;Consumed: &quot;</span>&lt;&lt;q.<span class=\"hljs-built_in\">front</span>()&lt;&lt;std::endl;<br>        q.<span class=\"hljs-built_in\">pop</span>();<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t1</span><span class=\"hljs-params\">(Producer)</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(Consumer)</span></span>;<br><br>    t1.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303211229196.png\" class=\"\" title=\"image-20240303211229196\">\n<h3 id=\"线程池的实现\"><a href=\"#线程池的实现\" class=\"headerlink\" title=\"线程池的实现\"></a>线程池的实现</h3><p>维护一个线程数组：可以初始化线程的个数</p>\n<p>维护一个任务队列：当前正在进行的任务</p>\n<p>线程数组负责从队列取任务，生产者负责从任务队列里加任务（需要提供加任务的接口）</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303214601818.png\" class=\"\" title=\"image-20240303214601818\">\n<p>构造函数中指定起始线程的个数，初始化线程，每一个线程都在循环的在任务队列里取任务并完成，给用户提供一个接口，不断的往任务队列中添加任务，并且每次添加任务过后会通知一个维护的线程去完成任务</p>\n<p>每一次访问tasks和stop变量的时候，这是临界区，都需要进行加锁</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;queue&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;functional&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;condition_variable&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ThreadPool</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::vector&lt;std::thread&gt; threads;<br>    std::queue&lt;std::function&lt;<span class=\"hljs-type\">void</span>()&gt;&gt; tasks;<br>    std::condition_variable cv;<br>    std::mutex m;<br>    <span class=\"hljs-type\">bool</span> stop;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 构造函数，构造一共大小为n的线程池</span><br>    <span class=\"hljs-comment\">// 每一个线程执行的函数是检查tasks是否为空，或者stop是否为true</span><br>    <span class=\"hljs-comment\">// 从tasks中取出任务执行，取任务的时候，和访问stop的时候都需要加锁</span><br>    <span class=\"hljs-built_in\">ThreadPool</span>(<span class=\"hljs-type\">int</span> n) : <span class=\"hljs-built_in\">stop</span>(<span class=\"hljs-literal\">false</span>)&#123;<br>        <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n; ++i )&#123;<br>            threads.<span class=\"hljs-built_in\">emplace_back</span>([<span class=\"hljs-keyword\">this</span>]&#123;<br>                <span class=\"hljs-keyword\">while</span>(<span class=\"hljs-literal\">true</span>)&#123;<br>                    std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-built_in\">ul</span>(m);<br>                    cv.<span class=\"hljs-built_in\">wait</span>(ul, [<span class=\"hljs-keyword\">this</span>]&#123;<br>                        <span class=\"hljs-keyword\">return</span> stop || !tasks.<span class=\"hljs-built_in\">empty</span>();<br>                        &#125;);<br><br>                    <span class=\"hljs-keyword\">if</span>( stop &amp;&amp; tasks.<span class=\"hljs-built_in\">empty</span>() )&#123;<br>                        <span class=\"hljs-keyword\">return</span>;<br>                    &#125;<br><br>                    <span class=\"hljs-comment\">// 使用右值引用，避免拷贝</span><br>                    std::function&lt;<span class=\"hljs-built_in\">void</span>()&gt; <span class=\"hljs-built_in\">task</span>(std::<span class=\"hljs-built_in\">move</span>(tasks.<span class=\"hljs-built_in\">front</span>()));<br>                    tasks.<span class=\"hljs-built_in\">pop</span>();<br>                    ul.<span class=\"hljs-built_in\">unlock</span>();<br>                    <span class=\"hljs-built_in\">task</span>();<br>                &#125;<br>            &#125;);<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 析构函数，将stop置为true，然后notify_all</span><br>    <span class=\"hljs-comment\">// 然后join所有的线程</span><br>    ~<span class=\"hljs-built_in\">ThreadPool</span>()&#123;<br>        &#123;<br>            <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>            stop = <span class=\"hljs-literal\">true</span>;<br>        &#125;<br>        cv.<span class=\"hljs-built_in\">notify_all</span>();<br>        <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-keyword\">auto</span>&amp; t : threads )&#123;<br>            t.<span class=\"hljs-built_in\">join</span>();<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 添加任务，将任务放入tasks中，然后notify_one</span><br>    <span class=\"hljs-comment\">// 用到模板以及多个变量的传参，可以使用通用型函数</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">class</span> F, <span class=\"hljs-keyword\">class</span>... Args&gt;</span><br><span class=\"hljs-function\">    <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">enqueue</span><span class=\"hljs-params\">(F&amp;&amp; f, Args&amp;&amp;... args)</span></span>&#123;<br>        <span class=\"hljs-comment\">// 使用std::bind将传入的函数和参数绑定</span><br>        <span class=\"hljs-comment\">// 因为传入的是万能引用，使用forward可以让参数自动选择是右值还是左值引用</span><br>        std::function&lt;<span class=\"hljs-type\">void</span>()&gt; task = std::<span class=\"hljs-built_in\">bind</span>(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);<br>        &#123;<br>            <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>            tasks.<span class=\"hljs-built_in\">emplace</span>(std::<span class=\"hljs-built_in\">move</span>(task));<br>        &#125;<br>        <span class=\"hljs-comment\">// 通知一个线程执行任务</span><br>        cv.<span class=\"hljs-built_in\">notify_one</span>();<br>    &#125;<br><br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-function\">ThreadPool <span class=\"hljs-title\">tp</span><span class=\"hljs-params\">(<span class=\"hljs-number\">4</span>)</span></span>;<br>    <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">8</span>; ++i )&#123;<br>        tp.<span class=\"hljs-built_in\">enqueue</span>([i]&#123;<br>            <span class=\"hljs-comment\">// 用printf而不是cout，避免输出混乱</span><br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d is working\\n&quot;</span>, i);<br>            std::this_thread::<span class=\"hljs-built_in\">sleep_for</span>(std::chrono::<span class=\"hljs-built_in\">seconds</span>(<span class=\"hljs-number\">1</span>));<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d is done\\n&quot;</span>, i);<br>        &#125;);<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>使用cout输出</li>\n</ul>\n<p>cout的单个输出是线程安全的，这种线程安全是针对在操作系统层面，即每一次<code>&lt;&lt;</code>的调用都是原子的，但是多个<code>&lt;&lt;</code>进行串联输出的时候，整个表达式并不是原子的，因此在串联输出的过程中，会被其他输出线程打断</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303224717307.png\" class=\"\" title=\"image-20240303224717307\">\n<ul>\n<li>使用printf输出</li>\n</ul>\n<blockquote>\n<p>printf(“Thread %d is working\\n”, i);</p>\n</blockquote>\n<p>使用printf输出则是将串联的输出转化为单一的输出，因此单条语句不会产生混乱，但是多个线程输出还是会产生混乱。</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303224732958.png\" class=\"\" title=\"image-20240303224732958\">\n","cover_type":"img","excerpt":"","more":"<h2 id=\"C-11多线程编程\"><a href=\"#C-11多线程编程\" class=\"headerlink\" title=\"C++11多线程编程\"></a>C++11多线程编程</h2><h3 id=\"C-11-Thread线程库的基本用法\"><a href=\"#C-11-Thread线程库的基本用法\" class=\"headerlink\" title=\"C++11 Thread线程库的基本用法\"></a>C++11 Thread线程库的基本用法</h3><blockquote>\n<p>进程：运行中的程序，线程：进程中的进程</p>\n<p>一个操作系统可以有多个进程，一个进程中可以有多个线程，线程的最大数量取决于电脑CPU的核数</p>\n</blockquote>\n<p>导入头文件thread</p>\n<ul>\n<li>创建线程    <code>thread th(function, arg)</code></li>\n</ul>\n<p>创建线程需要绑定一个函数，function表示已经定义的函数名，通过arg可以传入函数的参数，线程在std标准库当中</p>\n<p>创建线程对函数加引用<code>&amp;</code>和不加引用的区别</p>\n<p>当线程需要执行的函数中需要使用引用传递参数时，在主线程中传入变量值，程序将无法通过编译，需要使用<code>std::ref</code>来确保引用传递</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">threadFunction</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> &amp;x)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 现在x确实是主线程中x的引用</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-comment\">// 编译报错</span><br>    <span class=\"hljs-comment\">// std::thread t(threadFunction, x)</span><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(threadFunction, std::ref(x))</span></span>; <span class=\"hljs-comment\">// 使用std::ref来确保引用传递</span><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    <span class=\"hljs-comment\">// 现在主线程的x可能会被子线程修改</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><code>join</code>和<code>detach</code></li>\n</ul>\n<p>join：调用此接口，当前线程会一直阻塞，直到目标线程完成，如果目标线程十分耗时，主线程会一直阻塞。让主线程等待其他线程结束以后才结束。</p>\n<p><code>detach</code>：让目标线程称为守护线程（daemon threads）。一旦detach之后，目标线程将独立执行，即便其对应的thread对象销毁也不影响线程的执行，并且，无法再与其通信</p>\n<p>可以通过<code>joinable()</code>接口查询是否可以对接口进行join和detach</p>\n<h3 id=\"互斥量解决多线程数据共享问题\"><a href=\"#互斥量解决多线程数据共享问题\" class=\"headerlink\" title=\"互斥量解决多线程数据共享问题\"></a>互斥量解决多线程数据共享问题</h3><p>当一个资源需要被多个线程进行使用并修改的时候，就会存在资源的冲突</p>\n<p>下面的函数线程<code>t</code>和<code>t2</code>都需要对变量<code>a</code>进行1000000次的自增操作，因为线程的并行操作，所以两个线程在进行取a的值的时候，有可能获取到同样的值，再次写回时，原本需要+2最终只完成了+1，或者运行较快的线程的写入值会被运行较慢的线程覆盖，这就导致了结果会小于原来预期的值</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        a += <span class=\"hljs-number\">1</span>;<br>    &#125;<br>    <br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br><br>    std::cout&lt;&lt;a&lt;&lt;std::endl;<br>    <br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303195554869.png\" class=\"\" title=\"image-20240303195554869\">\n<p>这个情况就需要两个线程对a进行互斥使用，用到<code>mutex</code></p>\n<p>在需要对资源<code>a</code>进行访问的前后，分别进行加锁和解锁，确保这一段临界区只由一个线程访问</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><br><span class=\"hljs-comment\">// 互斥信号量</span><br>std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        <span class=\"hljs-comment\">// 加锁</span><br>        m.<span class=\"hljs-built_in\">lock</span>();<br>        a += <span class=\"hljs-number\">1</span>;<br>        m.<span class=\"hljs-built_in\">unlock</span>();<br>    &#125;<br>    <br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">0</span>;<br><br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(thread_function, std::ref(a))</span></span>;<br><br>    t.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br><br>    std::cout&lt;&lt;a&lt;&lt;std::endl;<br>    <br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303200213188.png\" class=\"\" title=\"image-20240303200213188\">\n<h3 id=\"lock-guard与unique-lock\"><a href=\"#lock-guard与unique-lock\" class=\"headerlink\" title=\"lock_guard与unique_lock\"></a>lock_guard与unique_lock</h3><ul>\n<li>lock_guard</li>\n</ul>\n<p>lock_guard是一种互斥量封装类，用于保护共享数据，防止多个线程同时访问统一资源而导致数据竞争问题</p>\n<p>当构造函数被调用时，该互斥量会被自动锁定</p>\n<p>当析构函数被调用时，该互斥量会自动解锁</p>\n<p>该对象不能复制或移动，只能在局部作用域中使用</p>\n<p>使用到的就是RAII思想</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">thread_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; a)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">1000000</span>; i++)<br>    &#123;<br>        <span class=\"hljs-function\">std::lock_guard&lt;std::mutex&gt; <span class=\"hljs-title\">lg</span><span class=\"hljs-params\">(m)</span></span>;<br>        <span class=\"hljs-comment\">// m.lock();</span><br>        a += <span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-comment\">// 不需要对锁释放，当作用域结束自动释放</span><br>        <span class=\"hljs-comment\">// m.unlock();</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>unique_lock，构造函数会自动加锁，传入<code>std::defer_lock</code>后会延迟加锁</li>\n</ul>\n<p>unique_lock是一个互斥量封装类，用于在多线程中对互斥量进行加锁和解锁操作，特点是，可以对互斥量进行更加灵活的管理，包括延迟加锁、条件变量、超时等</p>\n<p><code>lock()</code>：尝试对互斥量进行加锁，如果当前互斥量被其他线程持有则会阻塞</p>\n<p><code>try_lock()</code>L：尝试对互斥量进行加锁，如果被占有则返回false</p>\n<p><code>try_lock_for(const std::chrono::duration&lt;Rep, Period&gt;&amp; rel_time)</code>：尝试加锁，如果被占有，则超时以后会释放</p>\n<h3 id=\"std-call-once使用场景\"><a href=\"#std-call-once使用场景\" class=\"headerlink\" title=\"std::call_once使用场景\"></a>std::call_once使用场景</h3><p>单例设计模式是一种常见的设计模式，用于确保某个类只能创建一个实例，由于单例实例是全局唯一的，因此在多线程环境中使用单例模式时，需要考虑线程安全的问题</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 单例模式</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Log</span>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-built_in\">Log</span>() &#123;&#125;;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">Log</span>(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    Log&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Log&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-type\">static</span> Log * log = <span class=\"hljs-literal\">nullptr</span>;<br>        <span class=\"hljs-keyword\">if</span>(!log)&#123;<br>            log = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Log</span>();<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> log;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">PrintLog</span><span class=\"hljs-params\">(std::string msg)</span></span>&#123;<br>        std::cout &lt;&lt; msg &lt;&lt; std::endl;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>在多线程的情况下，如果都需要使用到同一个单例，当多个线程同时获取log时，如果此时log都为空，单例就会被多次初始化，违背了单例模式的设计初衷</p>\n<p><code>call_once</code>可以确保某个函数指挥被调用一次</p>\n<p>call_once只能在线程中使用</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 原型</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">class</span> Callable, <span class=\"hljs-keyword\">class</span>... Args&gt;</span><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">call_once</span><span class=\"hljs-params\">(std::once_flag&amp;flag, Callable&amp;&amp; func, Args&amp;&amp;...args)</span></span>;<br></code></pre></td></tr></table></figure>\n<p>对单例模式的修改</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 单例模式</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Log</span>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    <span class=\"hljs-built_in\">Log</span>() &#123;&#125;;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 声明一个变量</span><br>    <span class=\"hljs-type\">static</span> std::once_flag once;<br>    <span class=\"hljs-built_in\">Log</span>(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    Log&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> Log&amp; log) = <span class=\"hljs-keyword\">delete</span>;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> Log&amp; <span class=\"hljs-title\">GetInstance</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-type\">static</span> Log * log = <span class=\"hljs-literal\">nullptr</span>;<br>        <br>        <span class=\"hljs-comment\">// 单次调用</span><br>        std::<span class=\"hljs-built_in\">call_once</span>(once, init);<br>        <span class=\"hljs-keyword\">return</span> log;<br>    &#125;<br>    <span class=\"hljs-comment\">// 封装一个初始化的函数</span><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">init</span><span class=\"hljs-params\">()</span></span>&#123;<br>        <span class=\"hljs-keyword\">if</span>(!log)&#123;<br>            log = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Log</span>();<br>        &#125;<br>    &#125;<br>    <br>    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">PrintLog</span><span class=\"hljs-params\">(std::string msg)</span></span>&#123;<br>        std::cout &lt;&lt; msg &lt;&lt; std::endl;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"condition-variable使用场景\"><a href=\"#condition-variable使用场景\" class=\"headerlink\" title=\"condition_variable使用场景\"></a>condition_variable使用场景</h3><p>使用步骤如下</p>\n<ul>\n<li><p>创建一个std::condition_variable对象</p>\n</li>\n<li><p>创建一个互斥锁std::mutex，用来保护共享资源的访问</p>\n</li>\n<li><p>在需要等待条件变量的地方</p>\n<p>使用std::unique_lock&lt; std::mutex &gt;对象锁定互斥锁并调用std::condition_variable::wait_for()或std::condition_variable::wait_until()函数等待条件变量</p>\n</li>\n<li><p>在其他线程中需要通知等待的线程时，调用std::condition_variable::notify_one()或者std::condition_variable::notify_all()函数通知等待的线程</p>\n</li>\n</ul>\n<p>生产者消费者模型</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;queue&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;condition_variable&gt;</span></span><br><br>std::queue&lt;<span class=\"hljs-type\">int</span>&gt; q;<br>std::condition_variable cv;<br>std::mutex m;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Producer</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">100</span>; i++)<br>    &#123;<br>        <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>        q.<span class=\"hljs-built_in\">push</span>(i);<br>        cv.<span class=\"hljs-built_in\">notify_one</span>();<br>        std::cout&lt;&lt;<span class=\"hljs-string\">&quot;Produced: &quot;</span>&lt;&lt;i&lt;&lt;std::endl;<br>        std::this_thread::<span class=\"hljs-built_in\">sleep_for</span>(std::chrono::<span class=\"hljs-built_in\">microseconds</span>(<span class=\"hljs-number\">10000</span>));<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">Consumer</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-keyword\">while</span>(<span class=\"hljs-number\">1</span>)<br>    &#123;<br>        <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>        cv.<span class=\"hljs-built_in\">wait</span>(ul, []&#123;<span class=\"hljs-keyword\">return</span> !q.<span class=\"hljs-built_in\">empty</span>();&#125;);<br>        std::cout&lt;&lt;<span class=\"hljs-string\">&quot;Consumed: &quot;</span>&lt;&lt;q.<span class=\"hljs-built_in\">front</span>()&lt;&lt;std::endl;<br>        q.<span class=\"hljs-built_in\">pop</span>();<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t1</span><span class=\"hljs-params\">(Producer)</span></span>;<br>    <span class=\"hljs-function\">std::thread <span class=\"hljs-title\">t2</span><span class=\"hljs-params\">(Consumer)</span></span>;<br><br>    t1.<span class=\"hljs-built_in\">join</span>();<br>    t2.<span class=\"hljs-built_in\">join</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<img src=\"/2024/03/03/thread-pool/image-20240303211229196.png\" class=\"\" title=\"image-20240303211229196\">\n<h3 id=\"线程池的实现\"><a href=\"#线程池的实现\" class=\"headerlink\" title=\"线程池的实现\"></a>线程池的实现</h3><p>维护一个线程数组：可以初始化线程的个数</p>\n<p>维护一个任务队列：当前正在进行的任务</p>\n<p>线程数组负责从队列取任务，生产者负责从任务队列里加任务（需要提供加任务的接口）</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303214601818.png\" class=\"\" title=\"image-20240303214601818\">\n<p>构造函数中指定起始线程的个数，初始化线程，每一个线程都在循环的在任务队列里取任务并完成，给用户提供一个接口，不断的往任务队列中添加任务，并且每次添加任务过后会通知一个维护的线程去完成任务</p>\n<p>每一次访问tasks和stop变量的时候，这是临界区，都需要进行加锁</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;mutex&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;queue&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;thread&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;functional&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;condition_variable&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ThreadPool</span><br>&#123;<br><span class=\"hljs-keyword\">private</span>:<br>    std::vector&lt;std::thread&gt; threads;<br>    std::queue&lt;std::function&lt;<span class=\"hljs-type\">void</span>()&gt;&gt; tasks;<br>    std::condition_variable cv;<br>    std::mutex m;<br>    <span class=\"hljs-type\">bool</span> stop;<br><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-comment\">// 构造函数，构造一共大小为n的线程池</span><br>    <span class=\"hljs-comment\">// 每一个线程执行的函数是检查tasks是否为空，或者stop是否为true</span><br>    <span class=\"hljs-comment\">// 从tasks中取出任务执行，取任务的时候，和访问stop的时候都需要加锁</span><br>    <span class=\"hljs-built_in\">ThreadPool</span>(<span class=\"hljs-type\">int</span> n) : <span class=\"hljs-built_in\">stop</span>(<span class=\"hljs-literal\">false</span>)&#123;<br>        <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; n; ++i )&#123;<br>            threads.<span class=\"hljs-built_in\">emplace_back</span>([<span class=\"hljs-keyword\">this</span>]&#123;<br>                <span class=\"hljs-keyword\">while</span>(<span class=\"hljs-literal\">true</span>)&#123;<br>                    std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-built_in\">ul</span>(m);<br>                    cv.<span class=\"hljs-built_in\">wait</span>(ul, [<span class=\"hljs-keyword\">this</span>]&#123;<br>                        <span class=\"hljs-keyword\">return</span> stop || !tasks.<span class=\"hljs-built_in\">empty</span>();<br>                        &#125;);<br><br>                    <span class=\"hljs-keyword\">if</span>( stop &amp;&amp; tasks.<span class=\"hljs-built_in\">empty</span>() )&#123;<br>                        <span class=\"hljs-keyword\">return</span>;<br>                    &#125;<br><br>                    <span class=\"hljs-comment\">// 使用右值引用，避免拷贝</span><br>                    std::function&lt;<span class=\"hljs-built_in\">void</span>()&gt; <span class=\"hljs-built_in\">task</span>(std::<span class=\"hljs-built_in\">move</span>(tasks.<span class=\"hljs-built_in\">front</span>()));<br>                    tasks.<span class=\"hljs-built_in\">pop</span>();<br>                    ul.<span class=\"hljs-built_in\">unlock</span>();<br>                    <span class=\"hljs-built_in\">task</span>();<br>                &#125;<br>            &#125;);<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 析构函数，将stop置为true，然后notify_all</span><br>    <span class=\"hljs-comment\">// 然后join所有的线程</span><br>    ~<span class=\"hljs-built_in\">ThreadPool</span>()&#123;<br>        &#123;<br>            <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>            stop = <span class=\"hljs-literal\">true</span>;<br>        &#125;<br>        cv.<span class=\"hljs-built_in\">notify_all</span>();<br>        <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-keyword\">auto</span>&amp; t : threads )&#123;<br>            t.<span class=\"hljs-built_in\">join</span>();<br>        &#125;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 添加任务，将任务放入tasks中，然后notify_one</span><br>    <span class=\"hljs-comment\">// 用到模板以及多个变量的传参，可以使用通用型函数</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">template</span>&lt;<span class=\"hljs-keyword\">class</span> F, <span class=\"hljs-keyword\">class</span>... Args&gt;</span><br><span class=\"hljs-function\">    <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">enqueue</span><span class=\"hljs-params\">(F&amp;&amp; f, Args&amp;&amp;... args)</span></span>&#123;<br>        <span class=\"hljs-comment\">// 使用std::bind将传入的函数和参数绑定</span><br>        <span class=\"hljs-comment\">// 因为传入的是万能引用，使用forward可以让参数自动选择是右值还是左值引用</span><br>        std::function&lt;<span class=\"hljs-type\">void</span>()&gt; task = std::<span class=\"hljs-built_in\">bind</span>(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);<br>        &#123;<br>            <span class=\"hljs-function\">std::unique_lock&lt;std::mutex&gt; <span class=\"hljs-title\">ul</span><span class=\"hljs-params\">(m)</span></span>;<br>            tasks.<span class=\"hljs-built_in\">emplace</span>(std::<span class=\"hljs-built_in\">move</span>(task));<br>        &#125;<br>        <span class=\"hljs-comment\">// 通知一个线程执行任务</span><br>        cv.<span class=\"hljs-built_in\">notify_one</span>();<br>    &#125;<br><br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-function\">ThreadPool <span class=\"hljs-title\">tp</span><span class=\"hljs-params\">(<span class=\"hljs-number\">4</span>)</span></span>;<br>    <span class=\"hljs-keyword\">for</span>( <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">8</span>; ++i )&#123;<br>        tp.<span class=\"hljs-built_in\">enqueue</span>([i]&#123;<br>            <span class=\"hljs-comment\">// 用printf而不是cout，避免输出混乱</span><br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d is working\\n&quot;</span>, i);<br>            std::this_thread::<span class=\"hljs-built_in\">sleep_for</span>(std::chrono::<span class=\"hljs-built_in\">seconds</span>(<span class=\"hljs-number\">1</span>));<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d is done\\n&quot;</span>, i);<br>        &#125;);<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br><br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>使用cout输出</li>\n</ul>\n<p>cout的单个输出是线程安全的，这种线程安全是针对在操作系统层面，即每一次<code>&lt;&lt;</code>的调用都是原子的，但是多个<code>&lt;&lt;</code>进行串联输出的时候，整个表达式并不是原子的，因此在串联输出的过程中，会被其他输出线程打断</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303224717307.png\" class=\"\" title=\"image-20240303224717307\">\n<ul>\n<li>使用printf输出</li>\n</ul>\n<blockquote>\n<p>printf(“Thread %d is working\\n”, i);</p>\n</blockquote>\n<p>使用printf输出则是将串联的输出转化为单一的输出，因此单条语句不会产生混乱，但是多个线程输出还是会产生混乱。</p>\n<img src=\"/2024/03/03/thread-pool/image-20240303224732958.png\" class=\"\" title=\"image-20240303224732958\">\n"},{"title":"平方根倒数算法","date":"2024-01-24T11:53:09.000Z","cover":"/img/default_cover04.jpg","top_img":"2024/01/24/平方根倒数算法/WTF.png","mathjax":true,"_content":"\n### 平方根倒数算法\n\n$$\n1/\\sqrt{x}\n$$\n\n#### 求一个数的平方根倒数\n\n对于计算机来说求一个数的平方根一般有两种方式，二分法和牛顿迭代法\n\n* 二分法\n\n  EXP表示精度，从0-num不断开始计算mid的平方，直到left>right，此时返回right的值即为所求的平方根，其中注意边界条件：\n\n  当mid * mid = num时，此时left需要加上EXP，往后的循环中mid * mid 都会大于num，所以right还会不停减小，直到right < left，返回right，这时right已经在精度范围内\n\n```c++\ndouble Sqrt(double num) {\n    double left = 0, right = num;\n \n    while (left <= right) {\n        double mid = left + (right - left) / 2;\n \n        if (mid * mid <= num)\n            left = mid + EXP;\n        else\n            right = mid - EXP;\n    }   \n \n    return right;\n}\n```\n\n* 牛顿迭代法\n\n  牛顿迭代法是将原来的求开方问题转化为数学函数问题，即假设`x * x = n`，求n的开方转化为`x * x - n = 0`的解，即`y = x * x - n`与x轴的交点\n\n  代码中last表示上一次的切线与x轴的交点的x坐标，初始值为num，ret表示x = last时的切线与x轴的交点，不断迭代，直到ret - last小于精度，即达到精度返回ret。\n\n```c++\ndouble Sqrt(double num) {\n    if (0 == num)\n        return num;\n \n    double last = num, ret = num;\n \n    for (;;) {\n        last = 0.5 * (ret + num / ret);\n        if (fabs(ret - last) < EXP)\n            break;\n        ret = last;\n    }   \n \n    return ret;\n}\n```\n\n计算完平方根过后，再计算其倒数，也是一个对计算机来说并不是很友好的运算\n\n#### 快速平方根倒数计算推导\n\n快速平方根算法是利用了计算机存储浮点数的特性并和牛顿迭代法来共同完成的，也是一个近似计算。对于牛顿迭代法，其精髓是如果能够找到一个接近于解的初始值，是有可能通过一次迭代或者较少次数的迭代达到比较高的近似解，而快速平方根算法旨在于找到一个较为近似的初始值。具体的运算如下。\n\n**笔记中有一处笔误0xD5F400000应改成0x5F400000**\n\n![运算过程](平方根倒数算法/运算过程.png)\n\n快速平方根算法代码\n\n* 初始值由0x5F400000改为了0x5f3759df，对于X/2代码中使用了位运算加速求解\n\n```C++\nfloat Q_rsqrt(float number)\n{\n    long i;\n    float x2, y;\n    const float threehalfs = 1.5F;\n    x2 = number * 0.5F;\n    y = number;\n    i = * ( long* ) &y;\t\t\t\t\t\t\t// evil floating point bit hack\n    i = 0x5f3759df - (i >> 1);\t\t\t\t\t// what the fuck? \n    y = * ( float * ) &i;\n    y = y * (threehalfs - ( x2 * y * y ) );\t\t// 1st iteration\n//  y = y * (threehalfs - ( x2 * y * y ) );\t\t// 2st iteration, can be removed\n    \n    return y;\n}\n```","source":"_posts/平方根倒数算法.md","raw":"---\ntitle: 平方根倒数算法\ndate: 2024-01-24 19:53:09\ntags: [数学, 算法]\ncategories: 技术研究\ncover: /img/default_cover04.jpg\ntop_img: WTF.png\nmathjax: true\n---\n\n### 平方根倒数算法\n\n$$\n1/\\sqrt{x}\n$$\n\n#### 求一个数的平方根倒数\n\n对于计算机来说求一个数的平方根一般有两种方式，二分法和牛顿迭代法\n\n* 二分法\n\n  EXP表示精度，从0-num不断开始计算mid的平方，直到left>right，此时返回right的值即为所求的平方根，其中注意边界条件：\n\n  当mid * mid = num时，此时left需要加上EXP，往后的循环中mid * mid 都会大于num，所以right还会不停减小，直到right < left，返回right，这时right已经在精度范围内\n\n```c++\ndouble Sqrt(double num) {\n    double left = 0, right = num;\n \n    while (left <= right) {\n        double mid = left + (right - left) / 2;\n \n        if (mid * mid <= num)\n            left = mid + EXP;\n        else\n            right = mid - EXP;\n    }   \n \n    return right;\n}\n```\n\n* 牛顿迭代法\n\n  牛顿迭代法是将原来的求开方问题转化为数学函数问题，即假设`x * x = n`，求n的开方转化为`x * x - n = 0`的解，即`y = x * x - n`与x轴的交点\n\n  代码中last表示上一次的切线与x轴的交点的x坐标，初始值为num，ret表示x = last时的切线与x轴的交点，不断迭代，直到ret - last小于精度，即达到精度返回ret。\n\n```c++\ndouble Sqrt(double num) {\n    if (0 == num)\n        return num;\n \n    double last = num, ret = num;\n \n    for (;;) {\n        last = 0.5 * (ret + num / ret);\n        if (fabs(ret - last) < EXP)\n            break;\n        ret = last;\n    }   \n \n    return ret;\n}\n```\n\n计算完平方根过后，再计算其倒数，也是一个对计算机来说并不是很友好的运算\n\n#### 快速平方根倒数计算推导\n\n快速平方根算法是利用了计算机存储浮点数的特性并和牛顿迭代法来共同完成的，也是一个近似计算。对于牛顿迭代法，其精髓是如果能够找到一个接近于解的初始值，是有可能通过一次迭代或者较少次数的迭代达到比较高的近似解，而快速平方根算法旨在于找到一个较为近似的初始值。具体的运算如下。\n\n**笔记中有一处笔误0xD5F400000应改成0x5F400000**\n\n![运算过程](平方根倒数算法/运算过程.png)\n\n快速平方根算法代码\n\n* 初始值由0x5F400000改为了0x5f3759df，对于X/2代码中使用了位运算加速求解\n\n```C++\nfloat Q_rsqrt(float number)\n{\n    long i;\n    float x2, y;\n    const float threehalfs = 1.5F;\n    x2 = number * 0.5F;\n    y = number;\n    i = * ( long* ) &y;\t\t\t\t\t\t\t// evil floating point bit hack\n    i = 0x5f3759df - (i >> 1);\t\t\t\t\t// what the fuck? \n    y = * ( float * ) &i;\n    y = y * (threehalfs - ( x2 * y * y ) );\t\t// 1st iteration\n//  y = y * (threehalfs - ( x2 * y * y ) );\t\t// 2st iteration, can be removed\n    \n    return y;\n}\n```","slug":"平方根倒数算法","published":1,"updated":"2024-06-05T09:03:03.816Z","comments":1,"layout":"post","photos":[],"_id":"clyfintuc007d08jvbgpsc268","content":"<h3 id=\"平方根倒数算法\"><a href=\"#平方根倒数算法\" class=\"headerlink\" title=\"平方根倒数算法\"></a>平方根倒数算法</h3><script type=\"math/tex; mode=display\">\n1/\\sqrt{x}</script><h4 id=\"求一个数的平方根倒数\"><a href=\"#求一个数的平方根倒数\" class=\"headerlink\" title=\"求一个数的平方根倒数\"></a>求一个数的平方根倒数</h4><p>对于计算机来说求一个数的平方根一般有两种方式，二分法和牛顿迭代法</p>\n<ul>\n<li><p>二分法</p>\n<p>EXP表示精度，从0-num不断开始计算mid的平方，直到left&gt;right，此时返回right的值即为所求的平方根，其中注意边界条件：</p>\n<p>当mid <em> mid = num时，此时left需要加上EXP，往后的循环中mid </em> mid 都会大于num，所以right还会不停减小，直到right &lt; left，返回right，这时right已经在精度范围内</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">Sqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> num)</span> </span>&#123;<br>    <span class=\"hljs-type\">double</span> left = <span class=\"hljs-number\">0</span>, right = num;<br> <br>    <span class=\"hljs-keyword\">while</span> (left &lt;= right) &#123;<br>        <span class=\"hljs-type\">double</span> mid = left + (right - left) / <span class=\"hljs-number\">2</span>;<br> <br>        <span class=\"hljs-keyword\">if</span> (mid * mid &lt;= num)<br>            left = mid + EXP;<br>        <span class=\"hljs-keyword\">else</span><br>            right = mid - EXP;<br>    &#125;   <br> <br>    <span class=\"hljs-keyword\">return</span> right;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>牛顿迭代法</p>\n<p>牛顿迭代法是将原来的求开方问题转化为数学函数问题，即假设<code>x * x = n</code>，求n的开方转化为<code>x * x - n = 0</code>的解，即<code>y = x * x - n</code>与x轴的交点</p>\n<p>代码中last表示上一次的切线与x轴的交点的x坐标，初始值为num，ret表示x = last时的切线与x轴的交点，不断迭代，直到ret - last小于精度，即达到精度返回ret。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">Sqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> num)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-number\">0</span> == num)<br>        <span class=\"hljs-keyword\">return</span> num;<br> <br>    <span class=\"hljs-type\">double</span> last = num, ret = num;<br> <br>    <span class=\"hljs-keyword\">for</span> (;;) &#123;<br>        last = <span class=\"hljs-number\">0.5</span> * (ret + num / ret);<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">fabs</span>(ret - last) &lt; EXP)<br>            <span class=\"hljs-keyword\">break</span>;<br>        ret = last;<br>    &#125;   <br> <br>    <span class=\"hljs-keyword\">return</span> ret;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>计算完平方根过后，再计算其倒数，也是一个对计算机来说并不是很友好的运算</p>\n<h4 id=\"快速平方根倒数计算推导\"><a href=\"#快速平方根倒数计算推导\" class=\"headerlink\" title=\"快速平方根倒数计算推导\"></a>快速平方根倒数计算推导</h4><p>快速平方根算法是利用了计算机存储浮点数的特性并和牛顿迭代法来共同完成的，也是一个近似计算。对于牛顿迭代法，其精髓是如果能够找到一个接近于解的初始值，是有可能通过一次迭代或者较少次数的迭代达到比较高的近似解，而快速平方根算法旨在于找到一个较为近似的初始值。具体的运算如下。</p>\n<p><strong>笔记中有一处笔误0xD5F400000应改成0x5F400000</strong></p>\n<img src=\"/2024/01/24/%E5%B9%B3%E6%96%B9%E6%A0%B9%E5%80%92%E6%95%B0%E7%AE%97%E6%B3%95/%E8%BF%90%E7%AE%97%E8%BF%87%E7%A8%8B.png\" class=\"\" title=\"运算过程\">\n<p>快速平方根算法代码</p>\n<ul>\n<li>初始值由0x5F400000改为了0x5f3759df，对于X/2代码中使用了位运算加速求解</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">float</span> <span class=\"hljs-title\">Q_rsqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">float</span> number)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-type\">long</span> i;<br>    <span class=\"hljs-type\">float</span> x2, y;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> threehalfs = <span class=\"hljs-number\">1.5F</span>;<br>    x2 = number * <span class=\"hljs-number\">0.5F</span>;<br>    y = number;<br>    i = * ( <span class=\"hljs-type\">long</span>* ) &amp;y;\t\t\t\t\t\t\t<span class=\"hljs-comment\">// evil floating point bit hack</span><br>    i = <span class=\"hljs-number\">0x5f3759df</span> - (i &gt;&gt; <span class=\"hljs-number\">1</span>);\t\t\t\t\t<span class=\"hljs-comment\">// what the fuck? </span><br>    y = * ( <span class=\"hljs-type\">float</span> * ) &amp;i;<br>    y = y * (threehalfs - ( x2 * y * y ) );\t\t<span class=\"hljs-comment\">// 1st iteration</span><br><span class=\"hljs-comment\">//  y = y * (threehalfs - ( x2 * y * y ) );\t\t// 2st iteration, can be removed</span><br>    <br>    <span class=\"hljs-keyword\">return</span> y;<br>&#125;<br></code></pre></td></tr></table></figure>","cover_type":"img","excerpt":"","more":"<h3 id=\"平方根倒数算法\"><a href=\"#平方根倒数算法\" class=\"headerlink\" title=\"平方根倒数算法\"></a>平方根倒数算法</h3><script type=\"math/tex; mode=display\">\n1/\\sqrt{x}</script><h4 id=\"求一个数的平方根倒数\"><a href=\"#求一个数的平方根倒数\" class=\"headerlink\" title=\"求一个数的平方根倒数\"></a>求一个数的平方根倒数</h4><p>对于计算机来说求一个数的平方根一般有两种方式，二分法和牛顿迭代法</p>\n<ul>\n<li><p>二分法</p>\n<p>EXP表示精度，从0-num不断开始计算mid的平方，直到left&gt;right，此时返回right的值即为所求的平方根，其中注意边界条件：</p>\n<p>当mid <em> mid = num时，此时left需要加上EXP，往后的循环中mid </em> mid 都会大于num，所以right还会不停减小，直到right &lt; left，返回right，这时right已经在精度范围内</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">Sqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> num)</span> </span>&#123;<br>    <span class=\"hljs-type\">double</span> left = <span class=\"hljs-number\">0</span>, right = num;<br> <br>    <span class=\"hljs-keyword\">while</span> (left &lt;= right) &#123;<br>        <span class=\"hljs-type\">double</span> mid = left + (right - left) / <span class=\"hljs-number\">2</span>;<br> <br>        <span class=\"hljs-keyword\">if</span> (mid * mid &lt;= num)<br>            left = mid + EXP;<br>        <span class=\"hljs-keyword\">else</span><br>            right = mid - EXP;<br>    &#125;   <br> <br>    <span class=\"hljs-keyword\">return</span> right;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li><p>牛顿迭代法</p>\n<p>牛顿迭代法是将原来的求开方问题转化为数学函数问题，即假设<code>x * x = n</code>，求n的开方转化为<code>x * x - n = 0</code>的解，即<code>y = x * x - n</code>与x轴的交点</p>\n<p>代码中last表示上一次的切线与x轴的交点的x坐标，初始值为num，ret表示x = last时的切线与x轴的交点，不断迭代，直到ret - last小于精度，即达到精度返回ret。</p>\n</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">Sqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">double</span> num)</span> </span>&#123;<br>    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-number\">0</span> == num)<br>        <span class=\"hljs-keyword\">return</span> num;<br> <br>    <span class=\"hljs-type\">double</span> last = num, ret = num;<br> <br>    <span class=\"hljs-keyword\">for</span> (;;) &#123;<br>        last = <span class=\"hljs-number\">0.5</span> * (ret + num / ret);<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">fabs</span>(ret - last) &lt; EXP)<br>            <span class=\"hljs-keyword\">break</span>;<br>        ret = last;<br>    &#125;   <br> <br>    <span class=\"hljs-keyword\">return</span> ret;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>计算完平方根过后，再计算其倒数，也是一个对计算机来说并不是很友好的运算</p>\n<h4 id=\"快速平方根倒数计算推导\"><a href=\"#快速平方根倒数计算推导\" class=\"headerlink\" title=\"快速平方根倒数计算推导\"></a>快速平方根倒数计算推导</h4><p>快速平方根算法是利用了计算机存储浮点数的特性并和牛顿迭代法来共同完成的，也是一个近似计算。对于牛顿迭代法，其精髓是如果能够找到一个接近于解的初始值，是有可能通过一次迭代或者较少次数的迭代达到比较高的近似解，而快速平方根算法旨在于找到一个较为近似的初始值。具体的运算如下。</p>\n<p><strong>笔记中有一处笔误0xD5F400000应改成0x5F400000</strong></p>\n<img src=\"/2024/01/24/%E5%B9%B3%E6%96%B9%E6%A0%B9%E5%80%92%E6%95%B0%E7%AE%97%E6%B3%95/%E8%BF%90%E7%AE%97%E8%BF%87%E7%A8%8B.png\" class=\"\" title=\"运算过程\">\n<p>快速平方根算法代码</p>\n<ul>\n<li>初始值由0x5F400000改为了0x5f3759df，对于X/2代码中使用了位运算加速求解</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">float</span> <span class=\"hljs-title\">Q_rsqrt</span><span class=\"hljs-params\">(<span class=\"hljs-type\">float</span> number)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-type\">long</span> i;<br>    <span class=\"hljs-type\">float</span> x2, y;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> threehalfs = <span class=\"hljs-number\">1.5F</span>;<br>    x2 = number * <span class=\"hljs-number\">0.5F</span>;<br>    y = number;<br>    i = * ( <span class=\"hljs-type\">long</span>* ) &amp;y;\t\t\t\t\t\t\t<span class=\"hljs-comment\">// evil floating point bit hack</span><br>    i = <span class=\"hljs-number\">0x5f3759df</span> - (i &gt;&gt; <span class=\"hljs-number\">1</span>);\t\t\t\t\t<span class=\"hljs-comment\">// what the fuck? </span><br>    y = * ( <span class=\"hljs-type\">float</span> * ) &amp;i;<br>    y = y * (threehalfs - ( x2 * y * y ) );\t\t<span class=\"hljs-comment\">// 1st iteration</span><br><span class=\"hljs-comment\">//  y = y * (threehalfs - ( x2 * y * y ) );\t\t// 2st iteration, can be removed</span><br>    <br>    <span class=\"hljs-keyword\">return</span> y;<br>&#125;<br></code></pre></td></tr></table></figure>"},{"title":"进程间的通信方式","date":"2024-01-30T03:27:05.000Z","cover":"/img/default_cover.jpg","top_img":null,"_content":"\n## 进程间的通信方式\n\n每个进程的用户地址空间是独立的，一般情况之下，不同的进程是**无法**通过进程间各自的地址空间来进行互相访问，但是不同的进程所拥有的内核空间是共享的，因此如果不同进程之间需要进行通信必须要通过内核。\n\n### 管道通信\n\n管道通信分为匿名管道和命名管道，通过名字可以区分，匿名管道是无法获取和控制的管道，命名管道是通过用户可以自己建立的管道。\n\n管道智能进行半双工的通信，即数据传输是单向的，如果想要实现互相通信，就需要创建两个管道。\n\n#### 匿名管道\n\n* 在linux中的`|`竖线就是一个管道，将管道符前的操作的输出作为管道符后的操作的输入\n\n一个匿名管道的创建会使用到下面的系统调用\n\n```C++\nint pipe(int fd[2]);\n```\n\n表示创建了一个匿名管道并返回了两个文件描述符，一个是管道读取端的描述符`fd[0]`，另一个是管道写入端的描述符`fd[1]`，**匿名管道是特殊的文件，只存在于内存当中，不存在于文件系统中**\n\n管道实际上就是内核中的一串缓存，进程通过文件描述符来对这一串缓存进行读写操作\n\n![image-20240130223824673](进程间的通信方式/image-20240130223824673.png)\n\n**如果说需要实现多个进程之间的通信**，可以使用`fork`操作来创建子进程，创建子进程时，子进程会同时复制父进程的文件描述符，两个进程便可以通过各自的文件描述符来进行跨进程之间的通信。\n\n![image-20240130224638178](进程间的通信方式/image-20240130224638178.png)\n\n通过对文件描述符的开放和关闭，可以控制父进程和子进程之间的读写操作。\n\n* 如：父进程关闭读取的 fd[0]，只保留写入的 fd[1]；子进程关闭写入的 fd[1]，只保留读取的 fd[0]；\n* 便可以实现从父进程向子进程的数据写入\n\n实现多个进程之间匿名管道的通信另一种方式就是fork两个子进程，关闭父进程的文件描述符，开启子进程的`fd`，实现子进程之间的通信。\n\n可以看出来，匿名管道的通信范围仅限于父子关系的进程。因为管道没有实体，没有管道文件，只能通过复制父进程的fd来使用文件描述符。\n\n#### 命名管道\n\n* 在linux中可以通过`mkfifo`命令来创建并指定管道名字\n\n```\nmkfifo myPipe\n```\n\n因为命名管道，提前创建了一个类型为管道的设备文件，在进程中只要使用到这个设备，便可以互相通信。\n\n**管道的通信方式，效率较低，不适合进程间的频繁交换数据**\n\n### 消息队列\n\n> 在管道通信的缺点下，消息队列可以解决进程间频繁交换数据的问题。\n\n消息队列是保护在内核中的消息列表，如果进程之间需要进行通信，只需要将消息放在对应的消息队列中便可以正常返回，无需阻塞等待，等到另一个进程需要的时候去消息队列中去读取便可以。\n\n如果消息队列没有释放或者没有关闭操作系统，消息队列会一直存在，而匿名管道则是随着进程的生命周期的结束而销毁。\n\n* 优点\n\n  * 解决频繁交换数据的问题\n\n    两个进程之间就像发邮件一样可以你来我往进行沟通\n\n  * 进程发送消息后无需阻塞等待消息的接收\n\n* 缺点\n\n  * 不适合比较大的数据传输\n\n    消息队列中的消息体是由结构化的数据结构来组织的，有最大长度的限制。\n\n  * 消息队列的通信过程中，存在用户态与内核态之间的数据拷贝开销\n\n### 共享内存\n\n共享内存用到的是现代操作系统中的内存管理的**虚拟内存技术**，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。\n\n**共享内存的机制：拿出一块虚拟地址空间，映射到相同的物理内存中。**不同的进程可以使用各自的虚拟地址访问到这一片相同的物理内存。\n\n![image-20240130232827259](进程间的通信方式/image-20240130232827259.png)\n\n* 优点\n  * 解决了消息队列中不适合大的数据的通信\n  * 不同进程之间无需进行频繁的用户态和内核态的转换，因为进程都是在自己的用户地址空间中来进行操作\n\n* 缺点\n\n  * 对共享内存的读写问题\n\n    因为共享内存存储的信息一旦发生改变对于不同的进程都是可见的，所以会涉及到读写一致性的问题\n\n  * 共享内存也变为了临界资源，存在进程进程之间的竞争\n\n    需要保护机制，使得共享资源在任意时刻只能被一个进程访问。\n\n### 信号量\n\n> 信号量可以提供对临界资源的保护\n\n信号量是一个整型的计数器，可以用于实现进程间的互斥以及同步，不是用于缓存进程间通信的数据。\n\n信号量的大小表示为资源的数量，对信号量的操作方式有两种原子操作\n\n* 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。\n* 一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；\n\n通过PV操作可以控制进程对资源的互斥访问以及控制进程的同步顺序，**涉及到操作系统的知识**\n\n### 信号\n\n> 在进程工作异常情况下，需要通过信号来通知进程\n\n信号是进程间通信机制中的唯一的异步通信方式，因为可以在任何时候发送信号到某一进程，一旦有信号产生，用户就可以进行对信号处理。\n\n* 信号的处理方式\n  * 执行默认操作： 例如linux中的SIGTERM 信号，就是终止进程的意思\n  * 捕捉信号：可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数\n  * 忽略信号：当不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。\n\n* `SIGKILL` 和 `SEGSTOP`无法被捕捉和忽略。\n\n### Socket\n\nSocket通信实现的是在不同主机之间的通信，分为两种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式\n\n> 基于 TCP 协议的通信方式需要客户和服务器之间建立TCP连接，进行三次握手。\n\n![image-20240130234627976](进程间的通信方式/image-20240130234627976.png)\n\n- 服务端和客户端初始化 `socket`，得到文件描述符；\n- 服务端调用 `bind`，将绑定在 IP 地址和端口;\n- 服务端调用 `listen`，进行监听；\n- 服务端调用 `accept`，等待客户端连接；\n- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；\n- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；\n- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；\n- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。\n\n这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。\n\n所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。\n\n成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。\n\n> 基于UDP的Socket通信\n\n![image-20240130234754230](进程间的通信方式/image-20240130234754230.png)\n\nUDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。\n\n对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。\n\n另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。\n","source":"_posts/进程间的通信方式.md","raw":"---\ntitle: 进程间的通信方式\ndate: 2024-01-30 11:27:05\ntags: [操作系统, 进程通信]\ncategories: 技术研究\ncover: /img/default_cover.jpg\ntop_img:\n---\n\n## 进程间的通信方式\n\n每个进程的用户地址空间是独立的，一般情况之下，不同的进程是**无法**通过进程间各自的地址空间来进行互相访问，但是不同的进程所拥有的内核空间是共享的，因此如果不同进程之间需要进行通信必须要通过内核。\n\n### 管道通信\n\n管道通信分为匿名管道和命名管道，通过名字可以区分，匿名管道是无法获取和控制的管道，命名管道是通过用户可以自己建立的管道。\n\n管道智能进行半双工的通信，即数据传输是单向的，如果想要实现互相通信，就需要创建两个管道。\n\n#### 匿名管道\n\n* 在linux中的`|`竖线就是一个管道，将管道符前的操作的输出作为管道符后的操作的输入\n\n一个匿名管道的创建会使用到下面的系统调用\n\n```C++\nint pipe(int fd[2]);\n```\n\n表示创建了一个匿名管道并返回了两个文件描述符，一个是管道读取端的描述符`fd[0]`，另一个是管道写入端的描述符`fd[1]`，**匿名管道是特殊的文件，只存在于内存当中，不存在于文件系统中**\n\n管道实际上就是内核中的一串缓存，进程通过文件描述符来对这一串缓存进行读写操作\n\n![image-20240130223824673](进程间的通信方式/image-20240130223824673.png)\n\n**如果说需要实现多个进程之间的通信**，可以使用`fork`操作来创建子进程，创建子进程时，子进程会同时复制父进程的文件描述符，两个进程便可以通过各自的文件描述符来进行跨进程之间的通信。\n\n![image-20240130224638178](进程间的通信方式/image-20240130224638178.png)\n\n通过对文件描述符的开放和关闭，可以控制父进程和子进程之间的读写操作。\n\n* 如：父进程关闭读取的 fd[0]，只保留写入的 fd[1]；子进程关闭写入的 fd[1]，只保留读取的 fd[0]；\n* 便可以实现从父进程向子进程的数据写入\n\n实现多个进程之间匿名管道的通信另一种方式就是fork两个子进程，关闭父进程的文件描述符，开启子进程的`fd`，实现子进程之间的通信。\n\n可以看出来，匿名管道的通信范围仅限于父子关系的进程。因为管道没有实体，没有管道文件，只能通过复制父进程的fd来使用文件描述符。\n\n#### 命名管道\n\n* 在linux中可以通过`mkfifo`命令来创建并指定管道名字\n\n```\nmkfifo myPipe\n```\n\n因为命名管道，提前创建了一个类型为管道的设备文件，在进程中只要使用到这个设备，便可以互相通信。\n\n**管道的通信方式，效率较低，不适合进程间的频繁交换数据**\n\n### 消息队列\n\n> 在管道通信的缺点下，消息队列可以解决进程间频繁交换数据的问题。\n\n消息队列是保护在内核中的消息列表，如果进程之间需要进行通信，只需要将消息放在对应的消息队列中便可以正常返回，无需阻塞等待，等到另一个进程需要的时候去消息队列中去读取便可以。\n\n如果消息队列没有释放或者没有关闭操作系统，消息队列会一直存在，而匿名管道则是随着进程的生命周期的结束而销毁。\n\n* 优点\n\n  * 解决频繁交换数据的问题\n\n    两个进程之间就像发邮件一样可以你来我往进行沟通\n\n  * 进程发送消息后无需阻塞等待消息的接收\n\n* 缺点\n\n  * 不适合比较大的数据传输\n\n    消息队列中的消息体是由结构化的数据结构来组织的，有最大长度的限制。\n\n  * 消息队列的通信过程中，存在用户态与内核态之间的数据拷贝开销\n\n### 共享内存\n\n共享内存用到的是现代操作系统中的内存管理的**虚拟内存技术**，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。\n\n**共享内存的机制：拿出一块虚拟地址空间，映射到相同的物理内存中。**不同的进程可以使用各自的虚拟地址访问到这一片相同的物理内存。\n\n![image-20240130232827259](进程间的通信方式/image-20240130232827259.png)\n\n* 优点\n  * 解决了消息队列中不适合大的数据的通信\n  * 不同进程之间无需进行频繁的用户态和内核态的转换，因为进程都是在自己的用户地址空间中来进行操作\n\n* 缺点\n\n  * 对共享内存的读写问题\n\n    因为共享内存存储的信息一旦发生改变对于不同的进程都是可见的，所以会涉及到读写一致性的问题\n\n  * 共享内存也变为了临界资源，存在进程进程之间的竞争\n\n    需要保护机制，使得共享资源在任意时刻只能被一个进程访问。\n\n### 信号量\n\n> 信号量可以提供对临界资源的保护\n\n信号量是一个整型的计数器，可以用于实现进程间的互斥以及同步，不是用于缓存进程间通信的数据。\n\n信号量的大小表示为资源的数量，对信号量的操作方式有两种原子操作\n\n* 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。\n* 一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；\n\n通过PV操作可以控制进程对资源的互斥访问以及控制进程的同步顺序，**涉及到操作系统的知识**\n\n### 信号\n\n> 在进程工作异常情况下，需要通过信号来通知进程\n\n信号是进程间通信机制中的唯一的异步通信方式，因为可以在任何时候发送信号到某一进程，一旦有信号产生，用户就可以进行对信号处理。\n\n* 信号的处理方式\n  * 执行默认操作： 例如linux中的SIGTERM 信号，就是终止进程的意思\n  * 捕捉信号：可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数\n  * 忽略信号：当不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。\n\n* `SIGKILL` 和 `SEGSTOP`无法被捕捉和忽略。\n\n### Socket\n\nSocket通信实现的是在不同主机之间的通信，分为两种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式\n\n> 基于 TCP 协议的通信方式需要客户和服务器之间建立TCP连接，进行三次握手。\n\n![image-20240130234627976](进程间的通信方式/image-20240130234627976.png)\n\n- 服务端和客户端初始化 `socket`，得到文件描述符；\n- 服务端调用 `bind`，将绑定在 IP 地址和端口;\n- 服务端调用 `listen`，进行监听；\n- 服务端调用 `accept`，等待客户端连接；\n- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；\n- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；\n- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；\n- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。\n\n这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。\n\n所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。\n\n成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。\n\n> 基于UDP的Socket通信\n\n![image-20240130234754230](进程间的通信方式/image-20240130234754230.png)\n\nUDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。\n\n对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。\n\n另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。\n","slug":"进程间的通信方式","published":1,"updated":"2024-06-05T09:03:03.818Z","comments":1,"layout":"post","photos":[],"_id":"clyfintuc007f08jv8lrnd5qx","content":"<h2 id=\"进程间的通信方式\"><a href=\"#进程间的通信方式\" class=\"headerlink\" title=\"进程间的通信方式\"></a>进程间的通信方式</h2><p>每个进程的用户地址空间是独立的，一般情况之下，不同的进程是<strong>无法</strong>通过进程间各自的地址空间来进行互相访问，但是不同的进程所拥有的内核空间是共享的，因此如果不同进程之间需要进行通信必须要通过内核。</p>\n<h3 id=\"管道通信\"><a href=\"#管道通信\" class=\"headerlink\" title=\"管道通信\"></a>管道通信</h3><p>管道通信分为匿名管道和命名管道，通过名字可以区分，匿名管道是无法获取和控制的管道，命名管道是通过用户可以自己建立的管道。</p>\n<p>管道智能进行半双工的通信，即数据传输是单向的，如果想要实现互相通信，就需要创建两个管道。</p>\n<h4 id=\"匿名管道\"><a href=\"#匿名管道\" class=\"headerlink\" title=\"匿名管道\"></a>匿名管道</h4><ul>\n<li>在linux中的<code>|</code>竖线就是一个管道，将管道符前的操作的输出作为管道符后的操作的输入</li>\n</ul>\n<p>一个匿名管道的创建会使用到下面的系统调用</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">pipe</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> fd[<span class=\"hljs-number\">2</span>])</span></span>;<br></code></pre></td></tr></table></figure>\n<p>表示创建了一个匿名管道并返回了两个文件描述符，一个是管道读取端的描述符<code>fd[0]</code>，另一个是管道写入端的描述符<code>fd[1]</code>，<strong>匿名管道是特殊的文件，只存在于内存当中，不存在于文件系统中</strong></p>\n<p>管道实际上就是内核中的一串缓存，进程通过文件描述符来对这一串缓存进行读写操作</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130223824673.png\" class=\"\" title=\"image-20240130223824673\">\n<p><strong>如果说需要实现多个进程之间的通信</strong>，可以使用<code>fork</code>操作来创建子进程，创建子进程时，子进程会同时复制父进程的文件描述符，两个进程便可以通过各自的文件描述符来进行跨进程之间的通信。</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130224638178.png\" class=\"\" title=\"image-20240130224638178\">\n<p>通过对文件描述符的开放和关闭，可以控制父进程和子进程之间的读写操作。</p>\n<ul>\n<li>如：父进程关闭读取的 fd[0]，只保留写入的 fd[1]；子进程关闭写入的 fd[1]，只保留读取的 fd[0]；</li>\n<li>便可以实现从父进程向子进程的数据写入</li>\n</ul>\n<p>实现多个进程之间匿名管道的通信另一种方式就是fork两个子进程，关闭父进程的文件描述符，开启子进程的<code>fd</code>，实现子进程之间的通信。</p>\n<p>可以看出来，匿名管道的通信范围仅限于父子关系的进程。因为管道没有实体，没有管道文件，只能通过复制父进程的fd来使用文件描述符。</p>\n<h4 id=\"命名管道\"><a href=\"#命名管道\" class=\"headerlink\" title=\"命名管道\"></a>命名管道</h4><ul>\n<li>在linux中可以通过<code>mkfifo</code>命令来创建并指定管道名字</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">mkfifo</span> myPipe<br></code></pre></td></tr></table></figure>\n<p>因为命名管道，提前创建了一个类型为管道的设备文件，在进程中只要使用到这个设备，便可以互相通信。</p>\n<p><strong>管道的通信方式，效率较低，不适合进程间的频繁交换数据</strong></p>\n<h3 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h3><blockquote>\n<p>在管道通信的缺点下，消息队列可以解决进程间频繁交换数据的问题。</p>\n</blockquote>\n<p>消息队列是保护在内核中的消息列表，如果进程之间需要进行通信，只需要将消息放在对应的消息队列中便可以正常返回，无需阻塞等待，等到另一个进程需要的时候去消息队列中去读取便可以。</p>\n<p>如果消息队列没有释放或者没有关闭操作系统，消息队列会一直存在，而匿名管道则是随着进程的生命周期的结束而销毁。</p>\n<ul>\n<li><p>优点</p>\n<ul>\n<li><p>解决频繁交换数据的问题</p>\n<p>两个进程之间就像发邮件一样可以你来我往进行沟通</p>\n</li>\n<li><p>进程发送消息后无需阻塞等待消息的接收</p>\n</li>\n</ul>\n</li>\n<li><p>缺点</p>\n<ul>\n<li><p>不适合比较大的数据传输</p>\n<p>消息队列中的消息体是由结构化的数据结构来组织的，有最大长度的限制。</p>\n</li>\n<li><p>消息队列的通信过程中，存在用户态与内核态之间的数据拷贝开销</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>共享内存用到的是现代操作系统中的内存管理的<strong>虚拟内存技术</strong>，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。</p>\n<p><strong>共享内存的机制：拿出一块虚拟地址空间，映射到相同的物理内存中。</strong>不同的进程可以使用各自的虚拟地址访问到这一片相同的物理内存。</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130232827259.png\" class=\"\" title=\"image-20240130232827259\">\n<ul>\n<li><p>优点</p>\n<ul>\n<li>解决了消息队列中不适合大的数据的通信</li>\n<li>不同进程之间无需进行频繁的用户态和内核态的转换，因为进程都是在自己的用户地址空间中来进行操作</li>\n</ul>\n</li>\n<li><p>缺点</p>\n<ul>\n<li><p>对共享内存的读写问题</p>\n<p>因为共享内存存储的信息一旦发生改变对于不同的进程都是可见的，所以会涉及到读写一致性的问题</p>\n</li>\n<li><p>共享内存也变为了临界资源，存在进程进程之间的竞争</p>\n<p>需要保护机制，使得共享资源在任意时刻只能被一个进程访问。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><blockquote>\n<p>信号量可以提供对临界资源的保护</p>\n</blockquote>\n<p>信号量是一个整型的计数器，可以用于实现进程间的互斥以及同步，不是用于缓存进程间通信的数据。</p>\n<p>信号量的大小表示为资源的数量，对信号量的操作方式有两种原子操作</p>\n<ul>\n<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。</li>\n<li>一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>\n</ul>\n<p>通过PV操作可以控制进程对资源的互斥访问以及控制进程的同步顺序，<strong>涉及到操作系统的知识</strong></p>\n<h3 id=\"信号\"><a href=\"#信号\" class=\"headerlink\" title=\"信号\"></a>信号</h3><blockquote>\n<p>在进程工作异常情况下，需要通过信号来通知进程</p>\n</blockquote>\n<p>信号是进程间通信机制中的唯一的异步通信方式，因为可以在任何时候发送信号到某一进程，一旦有信号产生，用户就可以进行对信号处理。</p>\n<ul>\n<li><p>信号的处理方式</p>\n<ul>\n<li>执行默认操作： 例如linux中的SIGTERM 信号，就是终止进程的意思</li>\n<li>捕捉信号：可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数</li>\n<li>忽略信号：当不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。</li>\n</ul>\n</li>\n<li><p><code>SIGKILL</code> 和 <code>SEGSTOP</code>无法被捕捉和忽略。</p>\n</li>\n</ul>\n<h3 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h3><p>Socket通信实现的是在不同主机之间的通信，分为两种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式</p>\n<blockquote>\n<p>基于 TCP 协议的通信方式需要客户和服务器之间建立TCP连接，进行三次握手。</p>\n</blockquote>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130234627976.png\" class=\"\" title=\"image-20240130234627976\">\n<ul>\n<li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li>\n<li>服务端调用 <code>bind</code>，将绑定在 IP 地址和端口;</li>\n<li>服务端调用 <code>listen</code>，进行监听；</li>\n<li>服务端调用 <code>accept</code>，等待客户端连接；</li>\n<li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li>\n<li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li>\n<li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li>\n<li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li>\n</ul>\n<p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p>\n<p>所以，监听的 socket 和真正用来传送数据的 socket，是「<strong>两个</strong>」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p>\n<p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p>\n<blockquote>\n<p>基于UDP的Socket通信</p>\n</blockquote>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130234754230.png\" class=\"\" title=\"image-20240130234754230\">\n<p>UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。</p>\n<p>对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。</p>\n<p>另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。</p>\n","cover_type":"img","excerpt":"","more":"<h2 id=\"进程间的通信方式\"><a href=\"#进程间的通信方式\" class=\"headerlink\" title=\"进程间的通信方式\"></a>进程间的通信方式</h2><p>每个进程的用户地址空间是独立的，一般情况之下，不同的进程是<strong>无法</strong>通过进程间各自的地址空间来进行互相访问，但是不同的进程所拥有的内核空间是共享的，因此如果不同进程之间需要进行通信必须要通过内核。</p>\n<h3 id=\"管道通信\"><a href=\"#管道通信\" class=\"headerlink\" title=\"管道通信\"></a>管道通信</h3><p>管道通信分为匿名管道和命名管道，通过名字可以区分，匿名管道是无法获取和控制的管道，命名管道是通过用户可以自己建立的管道。</p>\n<p>管道智能进行半双工的通信，即数据传输是单向的，如果想要实现互相通信，就需要创建两个管道。</p>\n<h4 id=\"匿名管道\"><a href=\"#匿名管道\" class=\"headerlink\" title=\"匿名管道\"></a>匿名管道</h4><ul>\n<li>在linux中的<code>|</code>竖线就是一个管道，将管道符前的操作的输出作为管道符后的操作的输入</li>\n</ul>\n<p>一个匿名管道的创建会使用到下面的系统调用</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C++\"><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">pipe</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> fd[<span class=\"hljs-number\">2</span>])</span></span>;<br></code></pre></td></tr></table></figure>\n<p>表示创建了一个匿名管道并返回了两个文件描述符，一个是管道读取端的描述符<code>fd[0]</code>，另一个是管道写入端的描述符<code>fd[1]</code>，<strong>匿名管道是特殊的文件，只存在于内存当中，不存在于文件系统中</strong></p>\n<p>管道实际上就是内核中的一串缓存，进程通过文件描述符来对这一串缓存进行读写操作</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130223824673.png\" class=\"\" title=\"image-20240130223824673\">\n<p><strong>如果说需要实现多个进程之间的通信</strong>，可以使用<code>fork</code>操作来创建子进程，创建子进程时，子进程会同时复制父进程的文件描述符，两个进程便可以通过各自的文件描述符来进行跨进程之间的通信。</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130224638178.png\" class=\"\" title=\"image-20240130224638178\">\n<p>通过对文件描述符的开放和关闭，可以控制父进程和子进程之间的读写操作。</p>\n<ul>\n<li>如：父进程关闭读取的 fd[0]，只保留写入的 fd[1]；子进程关闭写入的 fd[1]，只保留读取的 fd[0]；</li>\n<li>便可以实现从父进程向子进程的数据写入</li>\n</ul>\n<p>实现多个进程之间匿名管道的通信另一种方式就是fork两个子进程，关闭父进程的文件描述符，开启子进程的<code>fd</code>，实现子进程之间的通信。</p>\n<p>可以看出来，匿名管道的通信范围仅限于父子关系的进程。因为管道没有实体，没有管道文件，只能通过复制父进程的fd来使用文件描述符。</p>\n<h4 id=\"命名管道\"><a href=\"#命名管道\" class=\"headerlink\" title=\"命名管道\"></a>命名管道</h4><ul>\n<li>在linux中可以通过<code>mkfifo</code>命令来创建并指定管道名字</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-built_in\">mkfifo</span> myPipe<br></code></pre></td></tr></table></figure>\n<p>因为命名管道，提前创建了一个类型为管道的设备文件，在进程中只要使用到这个设备，便可以互相通信。</p>\n<p><strong>管道的通信方式，效率较低，不适合进程间的频繁交换数据</strong></p>\n<h3 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h3><blockquote>\n<p>在管道通信的缺点下，消息队列可以解决进程间频繁交换数据的问题。</p>\n</blockquote>\n<p>消息队列是保护在内核中的消息列表，如果进程之间需要进行通信，只需要将消息放在对应的消息队列中便可以正常返回，无需阻塞等待，等到另一个进程需要的时候去消息队列中去读取便可以。</p>\n<p>如果消息队列没有释放或者没有关闭操作系统，消息队列会一直存在，而匿名管道则是随着进程的生命周期的结束而销毁。</p>\n<ul>\n<li><p>优点</p>\n<ul>\n<li><p>解决频繁交换数据的问题</p>\n<p>两个进程之间就像发邮件一样可以你来我往进行沟通</p>\n</li>\n<li><p>进程发送消息后无需阻塞等待消息的接收</p>\n</li>\n</ul>\n</li>\n<li><p>缺点</p>\n<ul>\n<li><p>不适合比较大的数据传输</p>\n<p>消息队列中的消息体是由结构化的数据结构来组织的，有最大长度的限制。</p>\n</li>\n<li><p>消息队列的通信过程中，存在用户态与内核态之间的数据拷贝开销</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>共享内存用到的是现代操作系统中的内存管理的<strong>虚拟内存技术</strong>，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。</p>\n<p><strong>共享内存的机制：拿出一块虚拟地址空间，映射到相同的物理内存中。</strong>不同的进程可以使用各自的虚拟地址访问到这一片相同的物理内存。</p>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130232827259.png\" class=\"\" title=\"image-20240130232827259\">\n<ul>\n<li><p>优点</p>\n<ul>\n<li>解决了消息队列中不适合大的数据的通信</li>\n<li>不同进程之间无需进行频繁的用户态和内核态的转换，因为进程都是在自己的用户地址空间中来进行操作</li>\n</ul>\n</li>\n<li><p>缺点</p>\n<ul>\n<li><p>对共享内存的读写问题</p>\n<p>因为共享内存存储的信息一旦发生改变对于不同的进程都是可见的，所以会涉及到读写一致性的问题</p>\n</li>\n<li><p>共享内存也变为了临界资源，存在进程进程之间的竞争</p>\n<p>需要保护机制，使得共享资源在任意时刻只能被一个进程访问。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><blockquote>\n<p>信号量可以提供对临界资源的保护</p>\n</blockquote>\n<p>信号量是一个整型的计数器，可以用于实现进程间的互斥以及同步，不是用于缓存进程间通信的数据。</p>\n<p>信号量的大小表示为资源的数量，对信号量的操作方式有两种原子操作</p>\n<ul>\n<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。</li>\n<li>一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>\n</ul>\n<p>通过PV操作可以控制进程对资源的互斥访问以及控制进程的同步顺序，<strong>涉及到操作系统的知识</strong></p>\n<h3 id=\"信号\"><a href=\"#信号\" class=\"headerlink\" title=\"信号\"></a>信号</h3><blockquote>\n<p>在进程工作异常情况下，需要通过信号来通知进程</p>\n</blockquote>\n<p>信号是进程间通信机制中的唯一的异步通信方式，因为可以在任何时候发送信号到某一进程，一旦有信号产生，用户就可以进行对信号处理。</p>\n<ul>\n<li><p>信号的处理方式</p>\n<ul>\n<li>执行默认操作： 例如linux中的SIGTERM 信号，就是终止进程的意思</li>\n<li>捕捉信号：可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数</li>\n<li>忽略信号：当不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。</li>\n</ul>\n</li>\n<li><p><code>SIGKILL</code> 和 <code>SEGSTOP</code>无法被捕捉和忽略。</p>\n</li>\n</ul>\n<h3 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h3><p>Socket通信实现的是在不同主机之间的通信，分为两种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式</p>\n<blockquote>\n<p>基于 TCP 协议的通信方式需要客户和服务器之间建立TCP连接，进行三次握手。</p>\n</blockquote>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130234627976.png\" class=\"\" title=\"image-20240130234627976\">\n<ul>\n<li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li>\n<li>服务端调用 <code>bind</code>，将绑定在 IP 地址和端口;</li>\n<li>服务端调用 <code>listen</code>，进行监听；</li>\n<li>服务端调用 <code>accept</code>，等待客户端连接；</li>\n<li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li>\n<li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li>\n<li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li>\n<li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li>\n</ul>\n<p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p>\n<p>所以，监听的 socket 和真正用来传送数据的 socket，是「<strong>两个</strong>」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p>\n<p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p>\n<blockquote>\n<p>基于UDP的Socket通信</p>\n</blockquote>\n<img src=\"/2024/01/30/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/image-20240130234754230.png\" class=\"\" title=\"image-20240130234754230\">\n<p>UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。</p>\n<p>对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。</p>\n<p>另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。</p>\n"}],"PostAsset":[{"_id":"source/_posts/AI-lab01/image-20230109194724331.png","slug":"image-20230109194724331.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109194800246.png","slug":"image-20230109194800246.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109195226820.png","slug":"image-20230109195226820.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109195428838.png","slug":"image-20230109195428838.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109195525256.png","slug":"image-20230109195525256.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109204708818.png","slug":"image-20230109204708818.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109205151944.png","slug":"image-20230109205151944.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109205407961.png","slug":"image-20230109205407961.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109205438300.png","slug":"image-20230109205438300.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109205453040.png","slug":"image-20230109205453040.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109214257445.png","slug":"image-20230109214257445.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab01/image-20230109222224342.png","slug":"image-20230109222224342.png","post":"clyfinttd000808jv7cz4gn9x","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240102163927925.png","slug":"image-20240102163927925.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240102201317281.png","slug":"image-20240102201317281.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240103093506806.png","slug":"image-20240103093506806.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240104092359606.png","slug":"image-20240104092359606.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240104193223551.png","slug":"image-20240104193223551.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240105160547664.png","slug":"image-20240105160547664.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240110074224104.png","slug":"image-20240110074224104.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240110074349028.png","slug":"image-20240110074349028.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240112101151040.png","slug":"image-20240112101151040.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/15445-study-notes-01-04/image-20240112102928169.png","slug":"image-20240112102928169.png","post":"clyfinttd000708jvcqa5cy2c","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108225530690.png","slug":"image-20230108225530690.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108225641834.png","slug":"image-20230108225641834.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108225724739.png","slug":"image-20230108225724739.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108225829669.png","slug":"image-20230108225829669.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108230000075.png","slug":"image-20230108230000075.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108230820413.png","slug":"image-20230108230820413.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108232000280.png","slug":"image-20230108232000280.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108232106204.png","slug":"image-20230108232106204.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab02/image-20230108232154796.png","slug":"image-20230108232154796.png","post":"clyfinttf000b08jv9t4ccfzm","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111212922711.png","slug":"image-20230111212922711.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111213029737.png","slug":"image-20230111213029737.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111213218547.png","slug":"image-20230111213218547.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111213428993.png","slug":"image-20230111213428993.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111213530417.png","slug":"image-20230111213530417.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111215240888.png","slug":"image-20230111215240888.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221331595.png","slug":"image-20230111221331595.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221612234.png","slug":"image-20230111221612234.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221801614.png","slug":"image-20230111221801614.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221851068.png","slug":"image-20230111221851068.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221914620.png","slug":"image-20230111221914620.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/AI-lab03/image-20230111221947792.png","slug":"image-20230111221947792.png","post":"clyfinttg000c08jv4wce27d7","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/games101.png","slug":"games101.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104112951691.png","slug":"image-20231104112951691.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113151777-17084112899531.png","slug":"image-20231104113151777-17084112899531.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113151777.png","slug":"image-20231104113151777.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104113201064.png","slug":"image-20231104113201064.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104150955701-17084112899532.png","slug":"image-20231104150955701-17084112899532.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104150955701.png","slug":"image-20231104150955701.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164540980.png","slug":"image-20231104164540980.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164542395.png","slug":"image-20231104164542395.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164606082.png","slug":"image-20231104164606082.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164704660-17084112899533.png","slug":"image-20231104164704660-17084112899533.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164704660.png","slug":"image-20231104164704660.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164849274-17084112899534.png","slug":"image-20231104164849274-17084112899534.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104164849274.png","slug":"image-20231104164849274.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104165645532-17084112899535.png","slug":"image-20231104165645532-17084112899535.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231104165645532.png","slug":"image-20231104165645532.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116154858801-17084112899536.png","slug":"image-20231116154858801-17084112899536.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116154858801.png","slug":"image-20231116154858801.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116155210293-17084112899537.png","slug":"image-20231116155210293-17084112899537.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-01/image-20231116155210293.png","slug":"image-20231116155210293.png","post":"clyfintti000h08jv79qw46au","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/01.png","slug":"01.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/02.png","slug":"02.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/03.png","slug":"03.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/04.png","slug":"04.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/05.png","slug":"05.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/06.png","slug":"06.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/07.png","slug":"07.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/08.png","slug":"08.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/09.png","slug":"09.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/10.png","slug":"10.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/11.png","slug":"11.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/image-20230809095839094.png","slug":"image-20230809095839094.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/image-20230809102800761.png","slug":"image-20230809102800761.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/Physical-design/image-20230809105341276.png","slug":"image-20230809105341276.png","post":"clyfinttm000n08jvg31sauo9","modified":0,"renderable":0},{"_id":"source/_posts/VLSI-Physical-Design/image-20230817170808037.png","slug":"image-20230817170808037.png","post":"clyfinttn000s08jv2o5d8urh","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/1.jpg","slug":"1.jpg","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803165730214.png","slug":"image-20230803165730214.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803171605818.png","slug":"image-20230803171605818.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803171645811.png","slug":"image-20230803171645811.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803172210807.png","slug":"image-20230803172210807.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173053255.png","slug":"image-20230803173053255.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173141837.png","slug":"image-20230803173141837.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173212434.png","slug":"image-20230803173212434.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173244879.png","slug":"image-20230803173244879.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173329009.png","slug":"image-20230803173329009.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173754572.png","slug":"image-20230803173754572.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803173808529.png","slug":"image-20230803173808529.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803183655944.png","slug":"image-20230803183655944.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/image-20230803183939400.png","slug":"image-20230803183939400.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/a-star-assignment/问题：插入优先队列以后没有更新f值.png","slug":"问题：插入优先队列以后没有更新f值.png","post":"clyfinttn000u08jv56vq9p5c","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/games101.png","slug":"games101.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/games101_top.png","slug":"games101_top.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161524873-17084118809551.png","slug":"image-20231116161524873-17084118809551.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161524873.png","slug":"image-20231116161524873.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161727694-17084118809562.png","slug":"image-20231116161727694-17084118809562.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161727694.png","slug":"image-20231116161727694.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161842894-17084118809563.png","slug":"image-20231116161842894-17084118809563.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116161842894.png","slug":"image-20231116161842894.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116164956551-17084118809564.png","slug":"image-20231116164956551-17084118809564.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116164956551.png","slug":"image-20231116164956551.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116165833300-17084118809565.png","slug":"image-20231116165833300-17084118809565.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116165833300.png","slug":"image-20231116165833300.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170519094.png","slug":"image-20231116170519094.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170520355-17084118809566.png","slug":"image-20231116170520355-17084118809566.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116170520355.png","slug":"image-20231116170520355.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171040632.png","slug":"image-20231116171040632.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171041924-17084118809567.png","slug":"image-20231116171041924-17084118809567.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116171041924.png","slug":"image-20231116171041924.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116200444279-17084118809568.png","slug":"image-20231116200444279-17084118809568.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116200444279.png","slug":"image-20231116200444279.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201110927.png","slug":"image-20231116201110927.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201112834-17084118809569.png","slug":"image-20231116201112834-17084118809569.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201112834.png","slug":"image-20231116201112834.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201139440-170841188095610.png","slug":"image-20231116201139440-170841188095610.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231116201139440.png","slug":"image-20231116201139440.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142130480-170841188095611.png","slug":"image-20231118142130480-170841188095611.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142130480.png","slug":"image-20231118142130480.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142833380-170841188095612.png","slug":"image-20231118142833380-170841188095612.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/image-20231118142833380.png","slug":"image-20231118142833380.png","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/GAMES101现代计算机图形学入门-02/IMG_0318(20231116-164749).PNG","slug":"IMG_0318(20231116-164749).PNG","post":"clyfinttm000l08jv0wy7bbrm","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240210160421874.png","slug":"image-20240210160421874.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240216162803064.png","slug":"image-20240216162803064.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240216162850762.png","slug":"image-20240216162850762.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240216162915509.png","slug":"image-20240216162915509.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240216163439353.png","slug":"image-20240216163439353.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218203730285.png","slug":"image-20240218203730285.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218204502697.png","slug":"image-20240218204502697.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218211138993.png","slug":"image-20240218211138993.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218212115878.png","slug":"image-20240218212115878.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218212542921.png","slug":"image-20240218212542921.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218212814126.png","slug":"image-20240218212814126.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218221534161.png","slug":"image-20240218221534161.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218221539849.png","slug":"image-20240218221539849.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218221642388.png","slug":"image-20240218221642388.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218221919863.png","slug":"image-20240218221919863.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218223950361.png","slug":"image-20240218223950361.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240218224016746.png","slug":"image-20240218224016746.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240222075448991.png","slug":"image-20240222075448991.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240222075706155.png","slug":"image-20240222075706155.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240223203653517.png","slug":"image-20240223203653517.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240223204149464.png","slug":"image-20240223204149464.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240224160500080.png","slug":"image-20240224160500080.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240224161313751.png","slug":"image-20240224161313751.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240224162152111.png","slug":"image-20240224162152111.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240224162359110.png","slug":"image-20240224162359110.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/image-20240224162626695.png","slug":"image-20240224162626695.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/innodb-architecture-8-0.png","slug":"innodb-architecture-8-0.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/database-mysql/Mysql.png","slug":"Mysql.png","post":"clyfinttq001a08jvaa6v01cv","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test03/output_1_0.png","slug":"output_1_0.png","post":"clyfinttr001k08jv7son6iau","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test03/output_9_1.png","slug":"output_9_1.png","post":"clyfinttr001k08jv7son6iau","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_11_0.png","slug":"output_11_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_15_1.png","slug":"output_15_1.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_16_0.png","slug":"output_16_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_20_3.png","slug":"output_20_3.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_21_0.png","slug":"output_21_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_3_0.png","slug":"output_3_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_6_0.png","slug":"output_6_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test01/output_8_0.png","slug":"output_8_0.png","post":"clyfinttq001d08jv8jbz2l07","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test02/output_7_1.png","slug":"output_7_1.png","post":"clyfinttr001h08jv6axkc048","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test02/output_8_0.png","slug":"output_8_0.png","post":"clyfinttr001h08jv6axkc048","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test04/output_4_3.png","slug":"output_4_3.png","post":"clyfintts001o08jv7vf34z3b","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test04/output_5_1.png","slug":"output_5_1.png","post":"clyfintts001o08jv7vf34z3b","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test05/output_3_1.png","slug":"output_3_1.png","post":"clyfintts001r08jv0eq24ir7","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test05/output_4_1.png","slug":"output_4_1.png","post":"clyfintts001r08jv0eq24ir7","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning-test05/output_5_1.png","slug":"output_5_1.png","post":"clyfintts001r08jv0eq24ir7","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183456769.png","slug":"image-20240302183456769.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183504049.png","slug":"image-20240302183504049.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183514481.png","slug":"image-20240302183514481.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183527447.png","slug":"image-20240302183527447.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183532846.png","slug":"image-20240302183532846.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183534696.png","slug":"image-20240302183534696.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183542527.png","slug":"image-20240302183542527.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test01/image-20240302183548286.png","slug":"image-20240302183548286.png","post":"clyfintts001u08jvbi0tdlr5","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/clip_image002.jpg","slug":"clip_image002.jpg","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/clip_image004.jpg","slug":"clip_image004.jpg","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/clip_image006.jpg","slug":"clip_image006.jpg","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/clip_image008.jpg","slug":"clip_image008.jpg","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184201998.png","slug":"image-20240302184201998.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184304968.png","slug":"image-20240302184304968.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184311057.png","slug":"image-20240302184311057.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184323543.png","slug":"image-20240302184323543.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184327658.png","slug":"image-20240302184327658.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184347311.png","slug":"image-20240302184347311.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test02/image-20240302184359230.png","slug":"image-20240302184359230.png","post":"clyfinttt001y08jv7swa13c3","modified":0,"renderable":0},{"_id":"source/_posts/design-model/享元模式_01.png","slug":"享元模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/单例模式_01.png","slug":"单例模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/工厂模式_01.png","slug":"工厂模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/工厂模式_02.png","slug":"工厂模式_02.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/策略模式_01.png","slug":"策略模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/装饰器模式_01.png","slug":"装饰器模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/design-model/适配器模式_01.png","slug":"适配器模式_01.png","post":"clyfinttt002108jvarze669h","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302184920811.png","slug":"image-20240302184920811.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302184935209.png","slug":"image-20240302184935209.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302184940449.png","slug":"image-20240302184940449.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302184950081.png","slug":"image-20240302184950081.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302184959151.png","slug":"image-20240302184959151.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185003442.png","slug":"image-20240302185003442.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185107213.png","slug":"image-20240302185107213.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185113358.png","slug":"image-20240302185113358.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185116864.png","slug":"image-20240302185116864.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185124222.png","slug":"image-20240302185124222.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185128004.png","slug":"image-20240302185128004.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185142206.png","slug":"image-20240302185142206.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185150777.png","slug":"image-20240302185150777.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test03/image-20240302185159151.png","slug":"image-20240302185159151.png","post":"clyfinttu002508jv5ht5edwo","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/clip_image002.jpg","slug":"clip_image002.jpg","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/clip_image004.jpg","slug":"clip_image004.jpg","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185557410.png","slug":"image-20240302185557410.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185602980.png","slug":"image-20240302185602980.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185608155.png","slug":"image-20240302185608155.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185735104.png","slug":"image-20240302185735104.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185739084.png","slug":"image-20240302185739084.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185751435.png","slug":"image-20240302185751435.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185800747.png","slug":"image-20240302185800747.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185819182.png","slug":"image-20240302185819182.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185829105.png","slug":"image-20240302185829105.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185837682.png","slug":"image-20240302185837682.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/digital-image-test04/image-20240302185841933.png","slug":"image-20240302185841933.png","post":"clyfinttu002808jv4g1bgyej","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221126155708747.png","slug":"image-20221126155708747.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221126155754925.png","slug":"image-20221126155754925.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130091729650.png","slug":"image-20221130091729650.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130092344725.png","slug":"image-20221130092344725.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130094553260.png","slug":"image-20221130094553260.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130101048848.png","slug":"image-20221130101048848.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130101949954.png","slug":"image-20221130101949954.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130102217372.png","slug":"image-20221130102217372.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130140722941.png","slug":"image-20221130140722941.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130143607842.png","slug":"image-20221130143607842.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221130151005907.png","slug":"image-20221130151005907.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201100317779.png","slug":"image-20221201100317779.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201101403269.png","slug":"image-20221201101403269.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201101451311.png","slug":"image-20221201101451311.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201110722218.png","slug":"image-20221201110722218.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201111903470.png","slug":"image-20221201111903470.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201151303341.png","slug":"image-20221201151303341.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201152139305.png","slug":"image-20221201152139305.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20221201160233164.png","slug":"image-20221201160233164.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20240302163915592.png","slug":"image-20240302163915592.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20240302165702511.png","slug":"image-20240302165702511.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20240302165713656.png","slug":"image-20240302165713656.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/distributed-system/image-20240302165721466.png","slug":"image-20240302165721466.png","post":"clyfinttv002c08jv98rtc5ym","modified":0,"renderable":0},{"_id":"source/_posts/eda-summary/EDA流程.jpg","slug":"EDA流程.jpg","post":"clyfinttv002f08jv8fih51z5","modified":0,"renderable":0},{"_id":"source/_posts/eda-summary/image-20230818160028154.png","slug":"image-20230818160028154.png","post":"clyfinttv002f08jv8fih51z5","modified":0,"renderable":0},{"_id":"source/_posts/eda-summary/image-20230818170602715.png","slug":"image-20230818170602715.png","post":"clyfinttv002f08jv8fih51z5","modified":0,"renderable":0},{"_id":"source/_posts/eda-summary/image-20230828141138808.png","slug":"image-20230828141138808.png","post":"clyfinttv002f08jv8fih51z5","modified":0,"renderable":0},{"_id":"source/_posts/eda-summary/image-20230828144127572.png","slug":"image-20230828144127572.png","post":"clyfinttv002f08jv8fih51z5","modified":0,"renderable":0},{"_id":"source/_posts/pytorch-install/image-20221022163847897.png","slug":"image-20221022163847897.png","post":"clyfinttx002v08jv74bu6p1p","modified":0,"renderable":0},{"_id":"source/_posts/pytorch-install/image-20221022164808915.png","slug":"image-20221022164808915.png","post":"clyfinttx002v08jv74bu6p1p","modified":0,"renderable":0},{"_id":"source/_posts/pytorch-install/image-20221022165103111.png","slug":"image-20221022165103111.png","post":"clyfinttx002v08jv74bu6p1p","modified":0,"renderable":0},{"_id":"source/_posts/pytorch-install/image-20221022174307472.png","slug":"image-20221022174307472.png","post":"clyfinttx002v08jv74bu6p1p","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230823094215828.png","slug":"image-20230823094215828.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825151306959.png","slug":"image-20230825151306959.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825154317023.png","slug":"image-20230825154317023.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825163454933.png","slug":"image-20230825163454933.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825163939716.png","slug":"image-20230825163939716.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825164152609.png","slug":"image-20230825164152609.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230825164459060.png","slug":"image-20230825164459060.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230830164032304.png","slug":"image-20230830164032304.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/iEDA-test/image-20230830164051317.png","slug":"image-20230830164051317.png","post":"clyfinttx002t08jvhsjzdl7x","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204110955462.png","slug":"image-20231204110955462.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204111125551.png","slug":"image-20231204111125551.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204111350240.png","slug":"image-20231204111350240.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204112945547.png","slug":"image-20231204112945547.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204113100512.png","slug":"image-20231204113100512.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204113208566.png","slug":"image-20231204113208566.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/git/image-20231204113304822.png","slug":"image-20231204113304822.png","post":"clyfinttw002m08jvbn4chfz2","modified":0,"renderable":0},{"_id":"source/_posts/static-timing-analysis/image-20230810165634110.png","slug":"image-20230810165634110.png","post":"clyfinttz003508jvf5n4ekx0","modified":0,"renderable":0},{"_id":"source/_posts/static-timing-analysis/image-20230811144505780.png","slug":"image-20230811144505780.png","post":"clyfinttz003508jvf5n4ekx0","modified":0,"renderable":0},{"_id":"source/_posts/static-timing-analysis/image-20230817160931612.png","slug":"image-20230817160931612.png","post":"clyfinttz003508jvf5n4ekx0","modified":0,"renderable":0},{"_id":"source/_posts/static-timing-analysis/image-20230817160942849.png","slug":"image-20230817160942849.png","post":"clyfinttz003508jvf5n4ekx0","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303195554869.png","slug":"image-20240303195554869.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303200213188.png","slug":"image-20240303200213188.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303211229196.png","slug":"image-20240303211229196.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303214601818.png","slug":"image-20240303214601818.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303224717307.png","slug":"image-20240303224717307.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/thread-pool/image-20240303224732958.png","slug":"image-20240303224732958.png","post":"clyfintub007c08jvhfkqcayy","modified":0,"renderable":0},{"_id":"source/_posts/平方根倒数算法/WTF.png","slug":"WTF.png","post":"clyfintuc007d08jvbgpsc268","modified":0,"renderable":0},{"_id":"source/_posts/平方根倒数算法/运算过程.png","slug":"运算过程.png","post":"clyfintuc007d08jvbgpsc268","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130223824673.png","slug":"image-20240130223824673.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130223920751.png","slug":"image-20240130223920751.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130224638178.png","slug":"image-20240130224638178.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130232827259.png","slug":"image-20240130232827259.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130234556499.png","slug":"image-20240130234556499.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130234627976.png","slug":"image-20240130234627976.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0},{"_id":"source/_posts/进程间的通信方式/image-20240130234754230.png","slug":"image-20240130234754230.png","post":"clyfintuc007f08jv8lrnd5qx","modified":0,"renderable":0}],"PostCategory":[{"post_id":"clyfinttd000708jvcqa5cy2c","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintti000i08jv0p246qli"},{"post_id":"clyfintth000g08jv8e5qdnby","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttm000o08jvft97chyq"},{"post_id":"clyfinttd000808jv7cz4gn9x","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttn000t08jvd1zhcfnv"},{"post_id":"clyfintti000h08jv79qw46au","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttn000v08jv45jyf30i"},{"post_id":"clyfinttm000l08jv0wy7bbrm","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintto000z08jv7j543l3m"},{"post_id":"clyfinttf000b08jv9t4ccfzm","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttp001208jvbj3a27lr"},{"post_id":"clyfinttm000n08jvg31sauo9","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttp001608jv0otwhxcs"},{"post_id":"clyfinttn000s08jv2o5d8urh","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttp001808jvepwlcl1u"},{"post_id":"clyfinttg000c08jv4wce27d7","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttq001b08jv3rgjh8af"},{"post_id":"clyfinttn000u08jv56vq9p5c","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttq001e08jv2e158xy9"},{"post_id":"clyfintto000y08jv1z4c2f09","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttr001i08jvfpmbehkf"},{"post_id":"clyfinttg000d08jva4934yz2","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttr001l08jv35o4fuos"},{"post_id":"clyfintto001108jvcpmfe2lj","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintts001p08jv2pzld5wa"},{"post_id":"clyfinttp001508jvgjr906v2","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfintts001s08jv5xwud63l"},{"post_id":"clyfinttp001708jv7znkdl7g","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttt001v08jv3obx9sux"},{"post_id":"clyfinttq001a08jvaa6v01cv","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfinttt001z08jv9ys853rr"},{"post_id":"clyfinttq001d08jv8jbz2l07","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttu002208jv9p8c1moz"},{"post_id":"clyfinttr001h08jv6axkc048","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttu002608jvbcz04xmi"},{"post_id":"clyfinttr001k08jv7son6iau","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttu002908jv3o4cdzxs"},{"post_id":"clyfintts001o08jv7vf34z3b","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttv002d08jvegorfndd"},{"post_id":"clyfintts001r08jv0eq24ir7","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttv002g08jv2l0ug1lc"},{"post_id":"clyfintts001u08jvbi0tdlr5","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttw002k08jvakar85zs"},{"post_id":"clyfinttt001y08jv7swa13c3","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttw002n08jv7e5u76sm"},{"post_id":"clyfinttt002108jvarze669h","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttx002r08jvbf4kaw6h"},{"post_id":"clyfinttu002508jv5ht5edwo","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttx002u08jv3yw62i1x"},{"post_id":"clyfinttu002808jv4g1bgyej","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttx002w08jv6kvfb1yx"},{"post_id":"clyfinttv002c08jv98rtc5ym","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintty003008jvf0wk6ofh"},{"post_id":"clyfinttv002f08jv8fih51z5","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintty003308jvdtsaeo8q"},{"post_id":"clyfinttv002j08jvaxnfdxdu","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttz003608jvh3ixenx5"},{"post_id":"clyfinttw002m08jvbn4chfz2","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttz003708jvfvg1hb97"},{"post_id":"clyfinttw002q08jva3na0k4k","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttz003a08jvayoe5mwq"},{"post_id":"clyfinttx002t08jvhsjzdl7x","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfinttz003c08jv4s0n0rlc"},{"post_id":"clyfinttx002v08jv74bu6p1p","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttz003e08jv4mezfjn5"},{"post_id":"clyfintty002z08jv5cdn2b0m","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfinttz003f08jv2eo8b7x5"},{"post_id":"clyfintty003208jv557e29th","category_id":"clyfintth000e08jv8c5eaakv","_id":"clyfintu0003h08jvb6ja752u"},{"post_id":"clyfinttz003508jvf5n4ekx0","category_id":"clyfintte000908jv0ltv0uyy","_id":"clyfintu0003i08jv5jfm7lwk"},{"post_id":"clyfintub007c08jvhfkqcayy","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfintud007g08jvcrjvgj0x"},{"post_id":"clyfintuc007d08jvbgpsc268","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfintud007h08jvcfpf6bm0"},{"post_id":"clyfintuc007f08jv8lrnd5qx","category_id":"clyfinttn000w08jv6x5og5vf","_id":"clyfintud007j08jvbz9q95r4"}],"PostTag":[{"post_id":"clyfinttd000708jvcqa5cy2c","tag_id":"clyfinttf000a08jvcljnhzs6","_id":"clyfinttm000m08jvh84l7f7v"},{"post_id":"clyfinttd000708jvcqa5cy2c","tag_id":"clyfintth000f08jvdq5n50bt","_id":"clyfinttm000p08jve3zd0g9r"},{"post_id":"clyfinttd000808jv7cz4gn9x","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfintto001008jv6582cghr"},{"post_id":"clyfinttd000808jv7cz4gn9x","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttp001308jvat7s5fbd"},{"post_id":"clyfinttf000b08jv9t4ccfzm","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfinttq001c08jv2h3fguki"},{"post_id":"clyfinttf000b08jv9t4ccfzm","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttr001f08jvezbc8owk"},{"post_id":"clyfinttq001d08jv8jbz2l07","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttr001j08jv18zw5dpj"},{"post_id":"clyfinttq001d08jv8jbz2l07","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfinttr001m08jvdtgd1trd"},{"post_id":"clyfinttr001h08jv6axkc048","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfintts001q08jvharac10m"},{"post_id":"clyfinttr001h08jv6axkc048","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfintts001t08jv3f3w2lqj"},{"post_id":"clyfinttg000c08jv4wce27d7","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfinttt001x08jv2l7lcir0"},{"post_id":"clyfinttg000c08jv4wce27d7","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttt002008jvdoexcvbj"},{"post_id":"clyfinttr001k08jv7son6iau","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttu002408jv3ear48fs"},{"post_id":"clyfinttr001k08jv7son6iau","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfinttu002708jv4aqn19su"},{"post_id":"clyfintts001r08jv0eq24ir7","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfinttv002b08jv6ywn7ivm"},{"post_id":"clyfintts001r08jv0eq24ir7","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfinttv002e08jv2zpiaikj"},{"post_id":"clyfinttg000d08jva4934yz2","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfinttv002i08jv3ll6f91m"},{"post_id":"clyfinttg000d08jva4934yz2","tag_id":"clyfinttt001w08jv7r8p1xvt","_id":"clyfinttw002l08jvevgyc71x"},{"post_id":"clyfintth000g08jv8e5qdnby","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfinttw002o08jvbf2nas2o"},{"post_id":"clyfintth000g08jv8e5qdnby","tag_id":"clyfinttu002a08jv934fdd5z","_id":"clyfinttx002s08jv2ibuftxz"},{"post_id":"clyfintti000h08jv79qw46au","tag_id":"clyfinttv002h08jvdqt16cr5","_id":"clyfintty002y08jv6r8b5h2d"},{"post_id":"clyfintti000h08jv79qw46au","tag_id":"clyfinttw002p08jv709b9glx","_id":"clyfintty003108jv17egf9wm"},{"post_id":"clyfinttm000l08jv0wy7bbrm","tag_id":"clyfinttv002h08jvdqt16cr5","_id":"clyfinttz003908jvdlgkbbf4"},{"post_id":"clyfinttm000l08jv0wy7bbrm","tag_id":"clyfinttw002p08jv709b9glx","_id":"clyfinttz003b08jv1eeo1839"},{"post_id":"clyfinttm000n08jvg31sauo9","tag_id":"clyfinttz003808jvbyyfas01","_id":"clyfintu0003l08jv24n5b7zq"},{"post_id":"clyfinttm000n08jvg31sauo9","tag_id":"clyfinttz003d08jvdddm243p","_id":"clyfintu0003m08jvhge27r08"},{"post_id":"clyfinttm000n08jvg31sauo9","tag_id":"clyfintu0003g08jv07t814x3","_id":"clyfintu0003o08jv2v574k09"},{"post_id":"clyfinttm000n08jvg31sauo9","tag_id":"clyfintu0003j08jv5il5bm54","_id":"clyfintu0003p08jv4l1t8cnw"},{"post_id":"clyfinttn000s08jv2o5d8urh","tag_id":"clyfintu0003g08jv07t814x3","_id":"clyfintu1003t08jva9difq60"},{"post_id":"clyfinttn000s08jv2o5d8urh","tag_id":"clyfintu0003n08jveysd81pg","_id":"clyfintu1003u08jv3wefbo7d"},{"post_id":"clyfinttn000s08jv2o5d8urh","tag_id":"clyfinttz003d08jvdddm243p","_id":"clyfintu1003w08jvdwu4h07g"},{"post_id":"clyfinttn000s08jv2o5d8urh","tag_id":"clyfintu0003r08jv18co3t5g","_id":"clyfintu1003x08jv89r62ocq"},{"post_id":"clyfinttn000u08jv56vq9p5c","tag_id":"clyfintu1003s08jvc4hf2k6e","_id":"clyfintu1003z08jv7r0y8pqb"},{"post_id":"clyfinttn000u08jv56vq9p5c","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu1004008jvgyof75wr"},{"post_id":"clyfintto000y08jv1z4c2f09","tag_id":"clyfinttf000a08jvcljnhzs6","_id":"clyfintu1004408jvea1ydn0a"},{"post_id":"clyfintto000y08jv1z4c2f09","tag_id":"clyfintu1003y08jv9c0v4nzk","_id":"clyfintu1004508jvh4g77lpt"},{"post_id":"clyfintto000y08jv1z4c2f09","tag_id":"clyfintu1004108jv9tc86ymt","_id":"clyfintu1004708jvcu307f5c"},{"post_id":"clyfintto000y08jv1z4c2f09","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu2004808jv3rstf06i"},{"post_id":"clyfintto001108jvcpmfe2lj","tag_id":"clyfintu1004308jvbdd8691x","_id":"clyfintu2004a08jvbaa3het5"},{"post_id":"clyfintto001108jvcpmfe2lj","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu2004b08jvdavn5p2i"},{"post_id":"clyfinttp001508jvgjr906v2","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu2004e08jv9gxu0n52"},{"post_id":"clyfinttp001508jvgjr906v2","tag_id":"clyfintu2004c08jv1agdecvf","_id":"clyfintu2004f08jvan347t2n"},{"post_id":"clyfinttp001708jv7znkdl7g","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu2004j08jv3g4v9axl"},{"post_id":"clyfinttp001708jv7znkdl7g","tag_id":"clyfintu2004g08jvfvvi0jul","_id":"clyfintu2004k08jv5cqe7g36"},{"post_id":"clyfinttp001708jv7znkdl7g","tag_id":"clyfintu2004h08jvhr9rb1jr","_id":"clyfintu2004m08jve2ifc1gc"},{"post_id":"clyfinttq001a08jvaa6v01cv","tag_id":"clyfintu2004i08jv15ef9ydw","_id":"clyfintu3004p08jv64m9gzk2"},{"post_id":"clyfinttq001a08jvaa6v01cv","tag_id":"clyfinttf000a08jvcljnhzs6","_id":"clyfintu3004q08jv63d8b9uu"},{"post_id":"clyfinttq001a08jvaa6v01cv","tag_id":"clyfintu2004l08jvd98eab9f","_id":"clyfintu3004s08jvc1u93wju"},{"post_id":"clyfinttq001a08jvaa6v01cv","tag_id":"clyfintu2004n08jv7immcskv","_id":"clyfintu3004t08jv5lau5ern"},{"post_id":"clyfintts001o08jv7vf34z3b","tag_id":"clyfinttn000r08jv7pqt8v41","_id":"clyfintu3004v08jvdstv92xz"},{"post_id":"clyfintts001o08jv7vf34z3b","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfintu3004w08jv0top28c1"},{"post_id":"clyfintts001o08jv7vf34z3b","tag_id":"clyfintu3004o08jv95ho89e5","_id":"clyfintu3004y08jvepvy363j"},{"post_id":"clyfintts001u08jvbi0tdlr5","tag_id":"clyfintu3004r08jv4s5e0smp","_id":"clyfintu3004z08jvdi4d9cbo"},{"post_id":"clyfintts001u08jvbi0tdlr5","tag_id":"clyfintu3004u08jv3wt4f2m6","_id":"clyfintu3005108jv62fob3ss"},{"post_id":"clyfinttt001y08jv7swa13c3","tag_id":"clyfintu3004r08jv4s5e0smp","_id":"clyfintu3005308jv1ftjd8fq"},{"post_id":"clyfinttt001y08jv7swa13c3","tag_id":"clyfintu3004u08jv3wt4f2m6","_id":"clyfintu4005408jve0sh3hza"},{"post_id":"clyfinttt002108jvarze669h","tag_id":"clyfintu3005208jv6xdc5tof","_id":"clyfintu4005808jvepzo226j"},{"post_id":"clyfinttt002108jvarze669h","tag_id":"clyfintu4005508jv9zivcacf","_id":"clyfintu4005908jv1wbudbd1"},{"post_id":"clyfinttt002108jvarze669h","tag_id":"clyfintu4005608jv9y2tgzyj","_id":"clyfintu4005b08jv4m708kj7"},{"post_id":"clyfinttu002508jv5ht5edwo","tag_id":"clyfintu3004r08jv4s5e0smp","_id":"clyfintu4005d08jv8j711iwv"},{"post_id":"clyfinttu002508jv5ht5edwo","tag_id":"clyfintu3004u08jv3wt4f2m6","_id":"clyfintu4005e08jvfzxbajhn"},{"post_id":"clyfinttu002808jv4g1bgyej","tag_id":"clyfintu3004r08jv4s5e0smp","_id":"clyfintu4005h08jv906s4suw"},{"post_id":"clyfinttu002808jv4g1bgyej","tag_id":"clyfintu3004u08jv3wt4f2m6","_id":"clyfintu4005i08jv6e7adnzd"},{"post_id":"clyfinttv002c08jv98rtc5ym","tag_id":"clyfintu4005g08jv81dj28i0","_id":"clyfintu5005k08jve5cgc83r"},{"post_id":"clyfinttv002f08jv8fih51z5","tag_id":"clyfintu0003g08jv07t814x3","_id":"clyfintu5005p08jv1un68tzx"},{"post_id":"clyfinttv002f08jv8fih51z5","tag_id":"clyfintu5005l08jvcdm26l2h","_id":"clyfintu5005q08jv8p1cca1h"},{"post_id":"clyfinttv002f08jv8fih51z5","tag_id":"clyfintu5005m08jv0vrlekav","_id":"clyfintu5005s08jv4nvjcqoi"},{"post_id":"clyfinttv002f08jv8fih51z5","tag_id":"clyfinttz003d08jvdddm243p","_id":"clyfintu5005t08jve3tgdmq7"},{"post_id":"clyfinttv002j08jvaxnfdxdu","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintu6005w08jvh7u79frr"},{"post_id":"clyfinttv002j08jvaxnfdxdu","tag_id":"clyfintu5005o08jvcxyxh1ye","_id":"clyfintu6005x08jv1tmu2hpv"},{"post_id":"clyfinttv002j08jvaxnfdxdu","tag_id":"clyfintu5005r08jv06654f2w","_id":"clyfintu6005z08jv4a2s26wo"},{"post_id":"clyfinttv002j08jvaxnfdxdu","tag_id":"clyfintu2004h08jvhr9rb1jr","_id":"clyfintu6006008jva7z654x9"},{"post_id":"clyfinttw002m08jvbn4chfz2","tag_id":"clyfintu5005v08jv77k73t60","_id":"clyfintu6006208jvf4sq7dvm"},{"post_id":"clyfinttw002q08jva3na0k4k","tag_id":"clyfintu6005y08jvbd83bkhg","_id":"clyfintu6006308jv6zeh7mil"},{"post_id":"clyfinttx002t08jvhsjzdl7x","tag_id":"clyfintu6006108jv2ia23o49","_id":"clyfintu6006808jv5ozu8o3z"},{"post_id":"clyfinttx002t08jvhsjzdl7x","tag_id":"clyfintu0003g08jv07t814x3","_id":"clyfintu6006908jvda9mdih4"},{"post_id":"clyfinttx002t08jvhsjzdl7x","tag_id":"clyfintu5005l08jvcdm26l2h","_id":"clyfintu7006b08jvdfmadw8y"},{"post_id":"clyfinttx002t08jvhsjzdl7x","tag_id":"clyfintu6006608jv4ivw8zz9","_id":"clyfintu7006c08jva5wr2sg5"},{"post_id":"clyfinttx002v08jv74bu6p1p","tag_id":"clyfintu6006708jvdcvgceyr","_id":"clyfintu7006e08jv8mszct7u"},{"post_id":"clyfinttx002v08jv74bu6p1p","tag_id":"clyfinttj000k08jvfm0480ec","_id":"clyfintu7006f08jv9iuygncf"},{"post_id":"clyfinttx002v08jv74bu6p1p","tag_id":"clyfintu6006a08jv1snv8i80","_id":"clyfintu7006h08jvbviydazl"},{"post_id":"clyfintty002z08jv5cdn2b0m","tag_id":"clyfintu6006708jvdcvgceyr","_id":"clyfintu7006l08jveis787ey"},{"post_id":"clyfintty002z08jv5cdn2b0m","tag_id":"clyfintu7006g08jv39lh4woc","_id":"clyfintu7006m08jv3rbncqne"},{"post_id":"clyfintty002z08jv5cdn2b0m","tag_id":"clyfintu3004o08jv95ho89e5","_id":"clyfintu8006o08jv0xh17fh1"},{"post_id":"clyfintty002z08jv5cdn2b0m","tag_id":"clyfintu6006a08jv1snv8i80","_id":"clyfintu8006p08jv9f9c3hah"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu7006k08jv8nadfwc3","_id":"clyfintu9006y08jv0o5lc5d6"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu7006n08jv7t9hbzs4","_id":"clyfintu9006z08jv5vhyhiur"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006q08jvgfln3l1u","_id":"clyfintu9007108jv0fdjh3c7"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006r08jv0inhc1qc","_id":"clyfintu9007208jv3o7a6s9z"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006s08jv9ncifd95","_id":"clyfintu9007408jv5a177s24"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006t08jvg6gi89ez","_id":"clyfintu9007508jvgnh1a3ca"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006u08jve8h94o5a","_id":"clyfintu9007608jv5m2i5g1g"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006v08jv9dfg5tr1","_id":"clyfintu9007708jvbse60eyt"},{"post_id":"clyfintty003208jv557e29th","tag_id":"clyfintu8006w08jv6tlh8irn","_id":"clyfintu9007808jvfyem6xzl"},{"post_id":"clyfinttz003508jvf5n4ekx0","tag_id":"clyfintu0003g08jv07t814x3","_id":"clyfintu9007908jv5pfr1t92"},{"post_id":"clyfinttz003508jvf5n4ekx0","tag_id":"clyfinttz003808jvbyyfas01","_id":"clyfintu9007a08jv65gzduob"},{"post_id":"clyfinttz003508jvf5n4ekx0","tag_id":"clyfintu9007308jvdpjpfpxn","_id":"clyfintu9007b08jv0ubh4kxx"},{"post_id":"clyfintub007c08jvhfkqcayy","tag_id":"clyfinttr001n08jvcsnjc9e8","_id":"clyfintud007m08jv910wa6kh"},{"post_id":"clyfintub007c08jvhfkqcayy","tag_id":"clyfintuc007e08jv81bn2fpl","_id":"clyfintud007n08jvabfweczb"},{"post_id":"clyfintub007c08jvhfkqcayy","tag_id":"clyfintud007i08jv6dt140vs","_id":"clyfintue007p08jv0ijofj35"},{"post_id":"clyfintub007c08jvhfkqcayy","tag_id":"clyfintud007k08jvb1x64tl8","_id":"clyfintue007q08jvg2hgb7xr"},{"post_id":"clyfintuc007d08jvbgpsc268","tag_id":"clyfintud007l08jv1ym28voj","_id":"clyfintue007s08jv9lta5pie"},{"post_id":"clyfintuc007d08jvbgpsc268","tag_id":"clyfintu7006n08jv7t9hbzs4","_id":"clyfintue007t08jvhw2s3hfj"},{"post_id":"clyfintuc007f08jv8lrnd5qx","tag_id":"clyfintue007o08jv8wp0g68n","_id":"clyfintue007u08jvg9gebfab"},{"post_id":"clyfintuc007f08jv8lrnd5qx","tag_id":"clyfintue007r08jvgvr6dtct","_id":"clyfintue007v08jv798u7ye7"}],"Tag":[{"name":"数据库","_id":"clyfinttf000a08jvcljnhzs6"},{"name":"CMU15445","_id":"clyfintth000f08jvdq5n50bt"},{"name":"人工智能","_id":"clyfinttj000k08jvfm0480ec"},{"name":"深度学习","_id":"clyfinttn000r08jv7pqt8v41"},{"name":"C++","_id":"clyfinttr001n08jvcsnjc9e8"},{"name":"zlib","_id":"clyfinttt001w08jv7r8p1xvt"},{"name":"C++新特性","_id":"clyfinttu002a08jv934fdd5z"},{"name":"计算机图形学","_id":"clyfinttv002h08jvdqt16cr5"},{"name":"GAMES101","_id":"clyfinttw002p08jv709b9glx"},{"name":"集成电路","_id":"clyfinttz003808jvbyyfas01"},{"name":"物理设计","_id":"clyfinttz003d08jvdddm243p"},{"name":"EDA","_id":"clyfintu0003g08jv07t814x3"},{"name":"Pyhsical Design","_id":"clyfintu0003j08jv5il5bm54"},{"name":"电子设计自动化","_id":"clyfintu0003n08jveysd81pg"},{"name":"VLSI","_id":"clyfintu0003r08jv18co3t5g"},{"name":"A*算法","_id":"clyfintu1003s08jvc4hf2k6e"},{"name":"Redis","_id":"clyfintu1003y08jv9c0v4nzk"},{"name":"数据库缓存","_id":"clyfintu1004108jv9tc86ymt"},{"name":"C++进阶","_id":"clyfintu1004308jvbdd8691x"},{"name":"优先队列","_id":"clyfintu2004c08jv1agdecvf"},{"name":"Cmake","_id":"clyfintu2004g08jvfvvi0jul"},{"name":"编译","_id":"clyfintu2004h08jvhr9rb1jr"},{"name":"Database","_id":"clyfintu2004i08jv15ef9ydw"},{"name":"Mysql","_id":"clyfintu2004l08jvd98eab9f"},{"name":"SQL","_id":"clyfintu2004n08jv7immcskv"},{"name":"神经网络","_id":"clyfintu3004o08jv95ho89e5"},{"name":"数字图像","_id":"clyfintu3004r08jv4s5e0smp"},{"name":"OpenCV","_id":"clyfintu3004u08jv3wt4f2m6"},{"name":"设计模式","_id":"clyfintu3005208jv6xdc5tof"},{"name":"UML","_id":"clyfintu4005508jv9zivcacf"},{"name":"软件工程","_id":"clyfintu4005608jv9y2tgzyj"},{"name":"分布式系统","_id":"clyfintu4005g08jv81dj28i0"},{"name":"布局","_id":"clyfintu5005l08jvcdm26l2h"},{"name":"布线","_id":"clyfintu5005m08jv0vrlekav"},{"name":"GCC","_id":"clyfintu5005o08jvcxyxh1ye"},{"name":"G++","_id":"clyfintu5005r08jv06654f2w"},{"name":"git","_id":"clyfintu5005v08jv77k73t60"},{"name":"Golang","_id":"clyfintu6005y08jvbd83bkhg"},{"name":"iEDA","_id":"clyfintu6006108jv2ia23o49"},{"name":"开源项目","_id":"clyfintu6006608jv4ivw8zz9"},{"name":"PyTorch","_id":"clyfintu6006708jvdcvgceyr"},{"name":"AI","_id":"clyfintu6006a08jv1snv8i80"},{"name":"DeepLearning","_id":"clyfintu7006g08jv39lh4woc"},{"name":"排序","_id":"clyfintu7006k08jv8nadfwc3"},{"name":"算法","_id":"clyfintu7006n08jv7t9hbzs4"},{"name":"选择排序","_id":"clyfintu8006q08jvgfln3l1u"},{"name":"冒泡排序","_id":"clyfintu8006r08jv0inhc1qc"},{"name":"插入排序","_id":"clyfintu8006s08jv9ncifd95"},{"name":"归并排序","_id":"clyfintu8006t08jvg6gi89ez"},{"name":"快速排序","_id":"clyfintu8006u08jve8h94o5a"},{"name":"堆排序","_id":"clyfintu8006v08jv9dfg5tr1"},{"name":"计数排序","_id":"clyfintu8006w08jv6tlh8irn"},{"name":"静态时序分析","_id":"clyfintu9007308jvdpjpfpxn"},{"name":"多线程","_id":"clyfintuc007e08jv81bn2fpl"},{"name":"并行","_id":"clyfintud007i08jv6dt140vs"},{"name":"Thread","_id":"clyfintud007k08jvb1x64tl8"},{"name":"数学","_id":"clyfintud007l08jv1ym28voj"},{"name":"操作系统","_id":"clyfintue007o08jv8wp0g68n"},{"name":"进程通信","_id":"clyfintue007r08jvgvr6dtct"}]}}